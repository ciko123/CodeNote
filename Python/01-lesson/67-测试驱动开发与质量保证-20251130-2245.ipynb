{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 67-æµ‹è¯•é©±åŠ¨å¼€å‘ä¸è´¨é‡ä¿è¯\n",
    "\n",
    "## ğŸ“š ç”¨é€”è¯´æ˜\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "- æŒæ¡æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰çš„æ ¸å¿ƒæ€æƒ³å’Œæ–¹æ³•\n",
    "- å­¦ä¼šç¼–å†™å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•\n",
    "- ç†è§£æµ‹è¯•é‡‘å­—å¡”å’Œæµ‹è¯•ç­–ç•¥è®¾è®¡\n",
    "- èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„è´¨é‡ä¿è¯ä½“ç³»\n",
    "\n",
    "**å‰ç½®è¦æ±‚**ï¼š\n",
    "- å·²å®Œæˆç‰ˆæœ¬æ§åˆ¶ä¸åä½œå¼€å‘å­¦ä¹ \n",
    "- ç†Ÿç»ƒæŒæ¡Pythonç¼–ç¨‹å’Œé¢å‘å¯¹è±¡è®¾è®¡\n",
    "- äº†è§£è½¯ä»¶å¼€å‘ç”Ÿå‘½å‘¨æœŸ\n",
    "- å…·å¤‡åŸºæœ¬çš„æµ‹è¯•æ„è¯†\n",
    "\n",
    "**ä¸LangChainå…³è”**ï¼š\n",
    "- æ”¯æŒLangChainç»„ä»¶çš„æµ‹è¯•é©±åŠ¨å¼€å‘\n",
    "- ä¸ºAIæ¨¡å‹å’Œç®—æ³•æä¾›æµ‹è¯•æ¡†æ¶\n",
    "- ä¿éšœLangChainä»£ç è´¨é‡å’Œå¯é æ€§\n",
    "- å®ç°AIç³»ç»Ÿçš„è‡ªåŠ¨åŒ–æµ‹è¯•\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ çŸ¥è¯†ç‚¹è¦†ç›–\n",
    "\n",
    "### 8.3 æµ‹è¯•é©±åŠ¨å¼€å‘ä¸è´¨é‡ä¿è¯ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šæµ‹è¯•é©±åŠ¨å¼€å‘ä¸è´¨é‡ä¿è¯æ˜¯è½¯ä»¶å·¥ç¨‹çš„æ ¸å¿ƒå®è·µï¼Œä¸ºLangChainçš„AIé¡¹ç›®æä¾›å¯é çš„è´¨é‡ä¿éšœæœºåˆ¶ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡TDDçš„å¼€å‘æµç¨‹å’Œæœ€ä½³å®è·µ\n",
    "- å­¦ä¼šä¸åŒç±»å‹æµ‹è¯•çš„ç¼–å†™æ–¹æ³•\n",
    "- ç†è§£æµ‹è¯•ç­–ç•¥å’Œè´¨é‡åº¦é‡\n",
    "- èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„æµ‹è¯•ä½“ç³»\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°TDDå¼€å‘æ¡†æ¶\n",
    "- æ„å»ºå¤šç§æµ‹è¯•ç±»å‹æ”¯æŒ\n",
    "- å¼€å‘è´¨é‡ä¿è¯å·¥å…·\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹å»ºç«‹å®Œæ•´çš„æµ‹è¯•ä½“ç³»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª æµ‹è¯•é©±åŠ¨å¼€å‘ä¸è´¨é‡ä¿è¯:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import re\n",
    "import inspect\n",
    "import importlib\n",
    "import types\n",
    "import typing\n",
    "import dataclasses\n",
    "import uuid\n",
    "import time\n",
    "import traceback\n",
    "import functools\n",
    "import itertools\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Callable, Type\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from enum import Enum\n",
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"âœ… Pythonç‰ˆæœ¬: {__import__('sys').version}\")\n",
    "print(f\"âœ… å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰æ¡†æ¶\n",
    "print(f\"ğŸ“ 1. æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰æ¡†æ¶:\")\n",
    "\n",
    "# 1.1 TDDæ ¸å¿ƒæ¦‚å¿µ\n",
    "print(f\"\\n   ğŸ¯ 1.1 TDDæ ¸å¿ƒæ¦‚å¿µ:\")\n",
    "\n",
    "class TestStatus(Enum):\n",
    "    \"\"\"æµ‹è¯•çŠ¶æ€\"\"\"\n",
    "    PENDING = \"pending\"  # å¾…æ‰§è¡Œ\n",
    "    RUNNING = \"running\"  # è¿è¡Œä¸­\n",
    "    PASSED = \"passed\"  # é€šè¿‡\n",
    "    FAILED = \"failed\"  # å¤±è´¥\n",
    "    SKIPPED = \"skipped\"  # è·³è¿‡\n",
    "    ERROR = \"error\"  # é”™è¯¯\n",
    "\n",
    "class TestType(Enum):\n",
    "    \"\"\"æµ‹è¯•ç±»å‹\"\"\"\n",
    "    UNIT = \"unit\"  # å•å…ƒæµ‹è¯•\n",
    "    INTEGRATION = \"integration\"  # é›†æˆæµ‹è¯•\n",
    "    END_TO_END = \"end_to_end\"  # ç«¯åˆ°ç«¯æµ‹è¯•\n",
    "    PERFORMANCE = \"performance\"  # æ€§èƒ½æµ‹è¯•\n",
    "    SECURITY = \"security\"  # å®‰å…¨æµ‹è¯•\n",
    "    ACCEPTANCE = \"acceptance\"  # éªŒæ”¶æµ‹è¯•\n",
    "\n",
    "@dataclass\n",
    "class TestCase:\n",
    "    \"\"\"æµ‹è¯•ç”¨ä¾‹\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    test_function: Callable\n",
    "    test_type: TestType\n",
    "    setup_function: Optional[Callable] = None\n",
    "    teardown_function: Optional[Callable] = None\n",
    "    timeout: float = 30.0\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    dependencies: List[str] = field(default_factory=list)\n",
    "    expected_exceptions: List[Type[Exception]] = field(default_factory=list)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.status = TestStatus.PENDING\n",
    "        self.start_time: Optional[datetime.datetime] = None\n",
    "        self.end_time: Optional[datetime.datetime] = None\n",
    "        self.error_message: Optional[str] = None\n",
    "        self.assertions: List[str] = []\n",
    "\n",
    "@dataclass\n",
    "class TestResult:\n",
    "    \"\"\"æµ‹è¯•ç»“æœ\"\"\"\n",
    "    test_case: TestCase\n",
    "    status: TestStatus\n",
    "    execution_time: float\n",
    "    error_message: Optional[str] = None\n",
    "    assertion_results: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    coverage_data: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class Assertion:\n",
    "    \"\"\"æ–­è¨€å·¥å…·ç±»\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_equal(actual, expected, message: str = None):\n",
    "        \"\"\"æ–­è¨€ç›¸ç­‰\"\"\"\n",
    "        if actual != expected:\n",
    "            msg = message or f\"Expected {expected}, but got {actual}\"\n",
    "            raise AssertionError(msg)\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_not_equal(actual, expected, message: str = None):\n",
    "        \"\"\"æ–­è¨€ä¸ç›¸ç­‰\"\"\"\n",
    "        if actual == expected:\n",
    "            msg = message or f\"Expected not equal to {expected}, but got {actual}\"\n",
    "            raise AssertionError(msg)\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_true(condition, message: str = None):\n",
    "        \"\"\"æ–­è¨€ä¸ºçœŸ\"\"\"\n",
    "        if not condition:\n",
    "            msg = message or \"Expected condition to be True\"\n",
    "            raise AssertionError(msg)\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_false(condition, message: str = None):\n",
    "        \"\"\"æ–­è¨€ä¸ºå‡\"\"\"\n",
    "        if condition:\n",
    "            msg = message or \"Expected condition to be False\"\n",
    "            raise AssertionError(msg)\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_in(item, container, message: str = None):\n",
    "        \"\"\"æ–­è¨€åŒ…å«\"\"\"\n",
    "        if item not in container:\n",
    "            msg = message or f\"Expected {item} to be in {container}\"\n",
    "            raise AssertionError(msg)\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_not_in(item, container, message: str = None):\n",
    "        \"\"\"æ–­è¨€ä¸åŒ…å«\"\"\"\n",
    "        if item in container:\n",
    "            msg = message or f\"Expected {item} not to be in {container}\"\n",
    "            raise AssertionError(msg)\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_raises(exception_type: Type[Exception], func: Callable, *args, **kwargs):\n",
    "        \"\"\"æ–­è¨€æŠ›å‡ºå¼‚å¸¸\"\"\"\n",
    "        try:\n",
    "            func(*args, **kwargs)\n",
    "            raise AssertionError(f\"Expected {exception_type.__name__} to be raised\")\n",
    "        except exception_type:\n",
    "            pass  # é¢„æœŸçš„å¼‚å¸¸\n",
    "        except Exception as e:\n",
    "            raise AssertionError(f\"Expected {exception_type.__name__}, but got {type(e).__name__}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def assert_almost_equal(actual, expected, delta: float = 0.0001, message: str = None):\n",
    "        \"\"\"æ–­è¨€è¿‘ä¼¼ç›¸ç­‰\"\"\"\n",
    "        if abs(actual - expected) > delta:\n",
    "            msg = message or f\"Expected {expected} Â± {delta}, but got {actual}\"\n",
    "            raise AssertionError(msg)\n",
    "\n",
    "class TestRunner:\n",
    "    \"\"\"æµ‹è¯•è¿è¡Œå™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.test_cases: List[TestCase] = []\n",
    "        self.test_results: List[TestResult] = []\n",
    "        self.setup_functions: Dict[str, Callable] = {}\n",
    "        self.teardown_functions: Dict[str, Callable] = {}\n",
    "        self.global_setup: Optional[Callable] = None\n",
    "        self.global_teardown: Optional[Callable] = None\n",
    "    \n",
    "    def add_test_case(self, test_case: TestCase):\n",
    "        \"\"\"æ·»åŠ æµ‹è¯•ç”¨ä¾‹\"\"\"\n",
    "        self.test_cases.append(test_case)\n",
    "    \n",
    "    def run_test(self, test_case: TestCase) -> TestResult:\n",
    "        \"\"\"è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹\"\"\"\n",
    "        test_case.status = TestStatus.RUNNING\n",
    "        start_time = time.time()\n",
    "        test_case.start_time = datetime.datetime.utcnow()\n",
    "        \n",
    "        try:\n",
    "            # æ‰§è¡Œsetup\n",
    "            if test_case.setup_function:\n",
    "                test_case.setup_function()\n",
    "            \n",
    "            # æ‰§è¡Œæµ‹è¯•\n",
    "            test_case.test_function()\n",
    "            \n",
    "            # æµ‹è¯•é€šè¿‡\n",
    "            test_case.status = TestStatus.PASSED\n",
    "            status = TestStatus.PASSED\n",
    "            error_message = None\n",
    "            \n",
    "        except AssertionError as e:\n",
    "            # æµ‹è¯•å¤±è´¥\n",
    "            test_case.status = TestStatus.FAILED\n",
    "            status = TestStatus.FAILED\n",
    "            error_message = str(e)\n",
    "            test_case.error_message = error_message\n",
    "            \n",
    "        except Exception as e:\n",
    "            # æµ‹è¯•é”™è¯¯\n",
    "            test_case.status = TestStatus.ERROR\n",
    "            status = TestStatus.ERROR\n",
    "            error_message = str(e)\n",
    "            test_case.error_message = error_message\n",
    "            \n",
    "        finally:\n",
    "            # æ‰§è¡Œteardown\n",
    "            try:\n",
    "                if test_case.teardown_function:\n",
    "                    test_case.teardown_function()\n",
    "            except Exception as teardown_error:\n",
    "                print(f\"Teardown error: {teardown_error}\")\n",
    "            \n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            test_case.end_time = datetime.datetime.utcnow()\n",
    "        \n",
    "        return TestResult(\n",
    "            test_case=test_case,\n",
    "            status=status,\n",
    "            execution_time=execution_time,\n",
    "            error_message=error_message\n",
    "        )\n",
    "    \n",
    "    def run_all_tests(self, test_type: TestType = None) -> List[TestResult]:\n",
    "        \"\"\"è¿è¡Œæ‰€æœ‰æµ‹è¯•\"\"\"\n",
    "        if self.global_setup:\n",
    "            self.global_setup()\n",
    "        \n",
    "        tests_to_run = self.test_cases\n",
    "        \n",
    "        if test_type:\n",
    "            tests_to_run = [tc for tc in tests_to_run if tc.test_type == test_type]\n",
    "        \n",
    "        results = []\n",
    "        for test_case in tests_to_run:\n",
    "            result = self.run_test(test_case)\n",
    "            results.append(result)\n",
    "            self.test_results.append(result)\n",
    "        \n",
    "        if self.global_teardown:\n",
    "            self.global_teardown()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_test_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æµ‹è¯•æ‘˜è¦\"\"\"\n",
    "        total = len(self.test_results)\n",
    "        passed = len([r for r in self.test_results if r.status == TestStatus.PASSED])\n",
    "        failed = len([r for r in self.test_results if r.status == TestStatus.FAILED])\n",
    "        errors = len([r for r in self.test_results if r.status == TestStatus.ERROR])\n",
    "        skipped = len([r for r in self.test_results if r.status == TestStatus.SKIPPED])\n",
    "        \n",
    "        total_time = sum(r.execution_time for r in self.test_results)\n",
    "        \n",
    "        return {\n",
    "            \"total_tests\": total,\n",
    "            \"passed\": passed,\n",
    "            \"failed\": failed,\n",
    "            \"errors\": errors,\n",
    "            \"skipped\": skipped,\n",
    "            \"success_rate\": passed / total if total > 0 else 0,\n",
    "            \"total_execution_time\": total_time,\n",
    "            \"average_execution_time\": total_time / total if total > 0 else 0\n",
    "        }\n",
    "\n",
    "# 1.2 TDDå·¥ä½œæµç¨‹\n",
    "print(f\"\\n   ğŸ”„ 1.2 TDDå·¥ä½œæµç¨‹:\")\n",
    "\n",
    "class TDDCycle:\n",
    "    \"\"\"TDDå¼€å‘å¾ªç¯\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_name: str):\n",
    "        self.feature_name = feature_name\n",
    "        self.test_runner = TestRunner()\n",
    "        self.cycle_count = 0\n",
    "        self.implementation_history: List[Dict[str, Any]] = []\n",
    "    \n",
    "    def red_phase(self, test_case: TestCase) -> bool:\n",
    "        \"\"\"çº¢ç¯é˜¶æ®µï¼šç¼–å†™å¤±è´¥çš„æµ‹è¯•\"\"\"\n",
    "        print(f\"\\nğŸ”´ çº¢ç¯é˜¶æ®µ: ç¼–å†™æµ‹è¯• - {test_case.name}\")\n",
    "        \n",
    "        # è¿è¡Œæµ‹è¯•ï¼Œåº”è¯¥å¤±è´¥\n",
    "        result = self.test_runner.run_test(test_case)\n",
    "        \n",
    "        if result.status in [TestStatus.FAILED, TestStatus.ERROR]:\n",
    "            print(f\"âœ… æµ‹è¯•å¤±è´¥ï¼ˆç¬¦åˆé¢„æœŸï¼‰: {result.error_message}\")\n",
    "            self.test_runner.add_test_case(test_case)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âŒ æµ‹è¯•åº”è¯¥å¤±è´¥ä½†å´é€šè¿‡äº†\")\n",
    "            return False\n",
    "    \n",
    "    def green_phase(self, implementation_func: Callable) -> bool:\n",
    "        \"\"\"ç»¿ç¯é˜¶æ®µï¼šç¼–å†™æœ€ç®€å®ç°\"\"\"\n",
    "        print(f\"\\nğŸŸ¢ ç»¿ç¯é˜¶æ®µ: å®ç°åŠŸèƒ½\")\n",
    "        \n",
    "        try:\n",
    "            implementation_func()\n",
    "            print(f\"âœ… åŠŸèƒ½å®ç°å®Œæˆ\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å®ç°å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def refactor_phase(self, refactor_func: Callable) -> bool:\n",
    "        \"\"\"é‡æ„é˜¶æ®µï¼šä¼˜åŒ–ä»£ç \"\"\"\n",
    "        print(f\"\\nğŸ”µ é‡æ„é˜¶æ®µ: ä¼˜åŒ–ä»£ç \")\n",
    "        \n",
    "        # é‡æ„å‰è¿è¡Œæµ‹è¯•\n",
    "        before_results = self.test_runner.run_all_tests()\n",
    "        before_passed = len([r for r in before_results if r.status == TestStatus.PASSED])\n",
    "        \n",
    "        try:\n",
    "            refactor_func()\n",
    "            \n",
    "            # é‡æ„åè¿è¡Œæµ‹è¯•\n",
    "            after_results = self.test_runner.run_all_tests()\n",
    "            after_passed = len([r for r in after_results if r.status == TestStatus.PASSED])\n",
    "            \n",
    "            if before_passed == after_passed:\n",
    "                print(f\"âœ… é‡æ„æˆåŠŸï¼Œæµ‹è¯•ä»ç„¶é€šè¿‡\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âŒ é‡æ„ç ´åäº†åŠŸèƒ½\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ é‡æ„å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def run_cycle(self, test_case: TestCase, implementation_func: Callable, \n",
    "                  refactor_func: Callable = None) -> bool:\n",
    "        \"\"\"è¿è¡Œå®Œæ•´çš„TDDå¾ªç¯\"\"\"\n",
    "        self.cycle_count += 1\n",
    "        print(f\"\\nğŸ”„ TDDå¾ªç¯ #{self.cycle_count}: {self.feature_name}\")\n",
    "        \n",
    "        # çº¢ç¯é˜¶æ®µ\n",
    "        if not self.red_phase(test_case):\n",
    "            return False\n",
    "        \n",
    "        # ç»¿ç¯é˜¶æ®µ\n",
    "        if not self.green_phase(implementation_func):\n",
    "            return False\n",
    "        \n",
    "        # é‡æ„é˜¶æ®µï¼ˆå¯é€‰ï¼‰\n",
    "        if refactor_func:\n",
    "            if not self.refactor_phase(refactor_func):\n",
    "                return False\n",
    "        \n",
    "        # è®°å½•å¾ªç¯å†å²\n",
    "        self.implementation_history.append({\n",
    "            \"cycle\": self.cycle_count,\n",
    "            \"test_name\": test_case.name,\n",
    "            \"timestamp\": datetime.datetime.utcnow(),\n",
    "            \"success\": True\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nâœ… TDDå¾ªç¯ #{self.cycle_count} å®Œæˆ\")\n",
    "        return True\n",
    "\n",
    "print(f\"   âœ… TDDæ ¸å¿ƒæ¦‚å¿µå®Œæˆ\")\n",
    "print(f\"      - TestCase: æµ‹è¯•ç”¨ä¾‹å®šä¹‰\")\n",
    "print(f\"      - TestRunner: æµ‹è¯•è¿è¡Œå™¨\")\n",
    "print(f\"      - Assertion: æ–­è¨€å·¥å…·ç±»\")\n",
    "print(f\"      - TDDCycle: TDDå¼€å‘å¾ªç¯\")\n",
    "\n",
    "print(f\"\\nâœ… æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰æ¡†æ¶å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡TDDçš„å¼€å‘æµç¨‹å’Œæœ€ä½³å®è·µ\")\n",
    "print(f\"   âœ“ å­¦ä¼šç¼–å†™å’Œè¿è¡Œæµ‹è¯•ç”¨ä¾‹\")\n",
    "print(f\"   âœ“ ç†è§£çº¢-ç»¿-é‡æ„å¼€å‘å¾ªç¯\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå»ºç«‹åŸºç¡€çš„æµ‹è¯•æ¡†æ¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµ‹è¯•ç­–ç•¥ä¸è´¨é‡ä¿è¯ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šæµ‹è¯•ç­–ç•¥ä¸è´¨é‡ä¿è¯æ˜¯è½¯ä»¶è´¨é‡ä¿éšœçš„æ ¸å¿ƒï¼Œä¸ºLangChainçš„AIé¡¹ç›®æä¾›å…¨é¢çš„è´¨é‡ç®¡ç†ä½“ç³»ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡æµ‹è¯•é‡‘å­—å¡”å’Œæµ‹è¯•ç­–ç•¥\n",
    "- å­¦ä¼šä»£ç è¦†ç›–ç‡åˆ†æ\n",
    "- ç†è§£è´¨é‡åº¦é‡æŒ‡æ ‡\n",
    "- èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„è´¨é‡ä¿è¯ä½“ç³»\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°æµ‹è¯•ç­–ç•¥ç®¡ç†å™¨\n",
    "- æ„å»ºä»£ç è¦†ç›–ç‡å·¥å…·\n",
    "- å¼€å‘è´¨é‡åº¦é‡ç³»ç»Ÿ\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹å»ºç«‹å®Œæ•´çš„è´¨é‡ä¿è¯ä½“ç³»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š æµ‹è¯•ç­–ç•¥ä¸è´¨é‡ä¿è¯:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 2. æµ‹è¯•ç­–ç•¥ç®¡ç†\n",
    "print(f\"ğŸ“ 2. æµ‹è¯•ç­–ç•¥ç®¡ç†:\")\n",
    "\n",
    "# 2.1 æµ‹è¯•é‡‘å­—å¡”\n",
    "print(f\"\\n   ğŸ”ï¸ 2.1 æµ‹è¯•é‡‘å­—å¡”:\")\n",
    "\n",
    "@dataclass\n",
    "class TestStrategy:\n",
    "    \"\"\"æµ‹è¯•ç­–ç•¥\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    test_distribution: Dict[TestType, float]  # æµ‹è¯•ç±»å‹åˆ†å¸ƒæ¯”ä¾‹\n",
    "    coverage_targets: Dict[str, float]  # è¦†ç›–ç‡ç›®æ ‡\n",
    "    quality_gates: Dict[str, Any]  # è´¨é‡é—¨ç¦\n",
    "    automation_level: float  # è‡ªåŠ¨åŒ–ç¨‹åº¦\n",
    "    \n",
    "    def validate_distribution(self) -> bool:\n",
    "        \"\"\"éªŒè¯æµ‹è¯•åˆ†å¸ƒ\"\"\"\n",
    "        total = sum(self.test_distribution.values())\n",
    "        return abs(total - 1.0) < 0.01  # å…è®¸1%çš„è¯¯å·®\n",
    "\n",
    "class TestPyramid:\n",
    "    \"\"\"æµ‹è¯•é‡‘å­—å¡”\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # æ ‡å‡†æµ‹è¯•é‡‘å­—å¡”åˆ†å¸ƒ\n",
    "        self.standard_distribution = {\n",
    "            TestType.UNIT: 0.70,  # 70% å•å…ƒæµ‹è¯•\n",
    "            TestType.INTEGRATION: 0.20,  # 20% é›†æˆæµ‹è¯•\n",
    "            TestType.END_TO_END: 0.10,  # 10% ç«¯åˆ°ç«¯æµ‹è¯•\n",
    "        }\n",
    "        \n",
    "        # AIé¡¹ç›®æµ‹è¯•é‡‘å­—å¡”åˆ†å¸ƒ\n",
    "        self.ai_distribution = {\n",
    "            TestType.UNIT: 0.60,  # 60% å•å…ƒæµ‹è¯•\n",
    "            TestType.INTEGRATION: 0.25,  # 25% é›†æˆæµ‹è¯•\n",
    "            TestType.END_TO_END: 0.10,  # 10% ç«¯åˆ°ç«¯æµ‹è¯•\n",
    "            TestType.PERFORMANCE: 0.05,  # 5% æ€§èƒ½æµ‹è¯•\n",
    "        }\n",
    "    \n",
    "    def get_recommended_strategy(self, project_type: str) -> TestStrategy:\n",
    "        \"\"\"è·å–æ¨èçš„æµ‹è¯•ç­–ç•¥\"\"\"\n",
    "        if project_type.lower() in [\"ai\", \"machine learning\", \"langchain\"]:\n",
    "            distribution = self.ai_distribution\n",
    "            coverage_targets = {\n",
    "                \"line_coverage\": 0.80,\n",
    "                \"branch_coverage\": 0.70,\n",
    "                \"function_coverage\": 0.90\n",
    "            }\n",
    "        else:\n",
    "            distribution = self.standard_distribution\n",
    "            coverage_targets = {\n",
    "                \"line_coverage\": 0.85,\n",
    "                \"branch_coverage\": 0.75,\n",
    "                \"function_coverage\": 0.95\n",
    "            }\n",
    "        \n",
    "        return TestStrategy(\n",
    "            name=f\"{project_type.title()} Strategy\",\n",
    "            description=f\"æµ‹è¯•ç­–ç•¥ for {project_type} projects\",\n",
    "            test_distribution=distribution,\n",
    "            coverage_targets=coverage_targets,\n",
    "            quality_gates={\n",
    "                \"min_coverage\": coverage_targets[\"line_coverage\"],\n",
    "                \"max_test_failures\": 0,\n",
    "                \"max_test_time\": 300,  # 5åˆ†é’Ÿ\n",
    "                \"required_test_types\": [TestType.UNIT, TestType.INTEGRATION]\n",
    "            },\n",
    "            automation_level=0.90\n",
    "        )\n",
    "\n",
    "# 2.2 ä»£ç è¦†ç›–ç‡åˆ†æ\n",
    "print(f\"\\n   ğŸ“ˆ 2.2 ä»£ç è¦†ç›–ç‡åˆ†æ:\")\n",
    "\n",
    "@dataclass\n",
    "class CoverageData:\n",
    "    \"\"\"è¦†ç›–ç‡æ•°æ®\"\"\"\n",
    "    file_path: str\n",
    "    total_lines: int\n",
    "    covered_lines: int\n",
    "    total_branches: int\n",
    "    covered_branches: int\n",
    "    total_functions: int\n",
    "    covered_functions: int\n",
    "    uncovered_lines: List[int] = field(default_factory=list)\n",
    "    uncovered_branches: List[int] = field(default_factory=list)\n",
    "    uncovered_functions: List[str] = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def line_coverage(self) -> float:\n",
    "        return self.covered_lines / self.total_lines if self.total_lines > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def branch_coverage(self) -> float:\n",
    "        return self.covered_branches / self.total_branches if self.total_branches > 0 else 0\n",
    "    \n",
    "    @property\n",
    "    def function_coverage(self) -> float:\n",
    "        return self.covered_functions / self.total_functions if self.total_functions > 0 else 0\n",
    "\n",
    "class CoverageAnalyzer:\n",
    "    \"\"\"ä»£ç è¦†ç›–ç‡åˆ†æå™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coverage_data: Dict[str, CoverageData] = {}\n",
    "        self.execution_tracer: ExecutionTracer = ExecutionTracer()\n",
    "    \n",
    "    def start_coverage(self):\n",
    "        \"\"\"å¼€å§‹è¦†ç›–ç‡æ”¶é›†\"\"\"\n",
    "        self.execution_tracer.start_tracing()\n",
    "    \n",
    "    def stop_coverage(self):\n",
    "        \"\"\"åœæ­¢è¦†ç›–ç‡æ”¶é›†\"\"\"\n",
    "        self.execution_tracer.stop_tracing()\n",
    "    \n",
    "    def analyze_file(self, file_path: str) -> CoverageData:\n",
    "        \"\"\"åˆ†ææ–‡ä»¶è¦†ç›–ç‡\"\"\"\n",
    "        # æ¨¡æ‹Ÿè¦†ç›–ç‡åˆ†æ\n",
    "        import random\n",
    "        \n",
    "        total_lines = random.randint(50, 200)\n",
    "        covered_lines = int(total_lines * random.uniform(0.7, 0.95))\n",
    "        \n",
    "        total_branches = random.randint(10, 50)\n",
    "        covered_branches = int(total_branches * random.uniform(0.6, 0.9))\n",
    "        \n",
    "        total_functions = random.randint(5, 20)\n",
    "        covered_functions = int(total_functions * random.uniform(0.8, 1.0))\n",
    "        \n",
    "        uncovered_lines = [i for i in range(1, total_lines + 1) if i > covered_lines]\n",
    "        uncovered_branches = [i for i in range(1, total_branches + 1) if i > covered_branches]\n",
    "        \n",
    "        coverage_data = CoverageData(\n",
    "            file_path=file_path,\n",
    "            total_lines=total_lines,\n",
    "            covered_lines=covered_lines,\n",
    "            total_branches=total_branches,\n",
    "            covered_branches=covered_branches,\n",
    "            total_functions=total_functions,\n",
    "            covered_functions=covered_functions,\n",
    "            uncovered_lines=uncovered_lines[:10],  # åªæ˜¾ç¤ºå‰10ä¸ª\n",
    "            uncovered_branches=uncovered_branches[:5],  # åªæ˜¾ç¤ºå‰5ä¸ª\n",
    "            uncovered_functions=[f\"func_{i}\" for i in range(total_functions - covered_functions)]\n",
    "        )\n",
    "        \n",
    "        self.coverage_data[file_path] = coverage_data\n",
    "        return coverage_data\n",
    "    \n",
    "    def get_project_coverage(self) -> Dict[str, float]:\n",
    "        \"\"\"è·å–é¡¹ç›®æ•´ä½“è¦†ç›–ç‡\"\"\"\n",
    "        if not self.coverage_data:\n",
    "            return {\"line_coverage\": 0.0, \"branch_coverage\": 0.0, \"function_coverage\": 0.0}\n",
    "        \n",
    "        total_lines = sum(data.total_lines for data in self.coverage_data.values())\n",
    "        covered_lines = sum(data.covered_lines for data in self.coverage_data.values())\n",
    "        \n",
    "        total_branches = sum(data.total_branches for data in self.coverage_data.values())\n",
    "        covered_branches = sum(data.covered_branches for data in self.coverage_data.values())\n",
    "        \n",
    "        total_functions = sum(data.total_functions for data in self.coverage_data.values())\n",
    "        covered_functions = sum(data.covered_functions for data in self.coverage_data.values())\n",
    "        \n",
    "        return {\n",
    "            \"line_coverage\": covered_lines / total_lines if total_lines > 0 else 0,\n",
    "            \"branch_coverage\": covered_branches / total_branches if total_branches > 0 else 0,\n",
    "            \"function_coverage\": covered_functions / total_functions if total_functions > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def generate_coverage_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š\"\"\"\n",
    "        project_coverage = self.get_project_coverage()\n",
    "        \n",
    "        report = {\n",
    "            \"timestamp\": datetime.datetime.utcnow().isoformat(),\n",
    "            \"project_coverage\": project_coverage,\n",
    "            \"file_coverage\": {},\n",
    "            \"summary\": {\n",
    "                \"total_files\": len(self.coverage_data),\n",
    "                \"files_above_threshold\": 0,\n",
    "                \"files_below_threshold\": 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        threshold = 0.8  # 80%é˜ˆå€¼\n",
    "        \n",
    "        for file_path, data in self.coverage_data.items():\n",
    "            report[\"file_coverage\"][file_path] = {\n",
    "                \"line_coverage\": data.line_coverage,\n",
    "                \"branch_coverage\": data.branch_coverage,\n",
    "                \"function_coverage\": data.function_coverage\n",
    "            }\n",
    "            \n",
    "            if data.line_coverage >= threshold:\n",
    "                report[\"summary\"][\"files_above_threshold\"] += 1\n",
    "            else:\n",
    "                report[\"summary\"][\"files_below_threshold\"] += 1\n",
    "        \n",
    "        return report\n",
    "\n",
    "class ExecutionTracer:\n",
    "    \"\"\"æ‰§è¡Œè¿½è¸ªå™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tracing = False\n",
    "        self.executed_lines: Dict[str, set] = {}\n",
    "    \n",
    "    def start_tracing(self):\n",
    "        \"\"\"å¼€å§‹è¿½è¸ª\"\"\"\n",
    "        self.tracing = True\n",
    "        print(\"å¼€å§‹ä»£ç æ‰§è¡Œè¿½è¸ª\")\n",
    "    \n",
    "    def stop_tracing(self):\n",
    "        \"\"\"åœæ­¢è¿½è¸ª\"\"\"\n",
    "        self.tracing = False\n",
    "        print(\"åœæ­¢ä»£ç æ‰§è¡Œè¿½è¸ª\")\n",
    "    \n",
    "    def trace_execution(self, file_path: str, line_number: int):\n",
    "        \"\"\"è¿½è¸ªæ‰§è¡Œè¡Œ\"\"\"\n",
    "        if self.tracing:\n",
    "            if file_path not in self.executed_lines:\n",
    "                self.executed_lines[file_path] = set()\n",
    "            self.executed_lines[file_path].add(line_number)\n",
    "\n",
    "# 2.3 è´¨é‡åº¦é‡ç³»ç»Ÿ\n",
    "print(f\"\\n   ğŸ¯ 2.3 è´¨é‡åº¦é‡ç³»ç»Ÿ:\")\n",
    "\n",
    "@dataclass\n",
    "class QualityMetric:\n",
    "    \"\"\"è´¨é‡åº¦é‡æŒ‡æ ‡\"\"\"\n",
    "    name: str\n",
    "    value: float\n",
    "    unit: str\n",
    "    threshold: float\n",
    "    weight: float = 1.0\n",
    "    description: str = \"\"\n",
    "    \n",
    "    @property\n",
    "    def is_passing(self) -> bool:\n",
    "        return self.value >= self.threshold\n",
    "    \n",
    "    @property\n",
    "    def score(self) -> float:\n",
    "        return min(self.value / self.threshold, 1.0) * self.weight\n",
    "\n",
    "class QualityGate:\n",
    "    \"\"\"è´¨é‡é—¨ç¦\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.metrics: List[QualityMetric] = []\n",
    "        self.required_metrics: List[str] = []\n",
    "    \n",
    "    def add_metric(self, metric: QualityMetric, required: bool = False):\n",
    "        \"\"\"æ·»åŠ åº¦é‡æŒ‡æ ‡\"\"\"\n",
    "        self.metrics.append(metric)\n",
    "        if required:\n",
    "            self.required_metrics.append(metric.name)\n",
    "    \n",
    "    def evaluate(self) -> Dict[str, Any]:\n",
    "        \"\"\"è¯„ä¼°è´¨é‡é—¨ç¦\"\"\"\n",
    "        total_score = sum(metric.score for metric in self.metrics)\n",
    "        max_score = sum(metric.weight for metric in self.metrics)\n",
    "        \n",
    "        required_passed = all(\n",
    "            metric.is_passing for metric in self.metrics \n",
    "            if metric.name in self.required_metrics\n",
    "        )\n",
    "        \n",
    "        all_passed = all(metric.is_passing for metric in self.metrics)\n",
    "        \n",
    "        return {\n",
    "            \"gate_name\": self.name,\n",
    "            \"total_score\": total_score,\n",
    "            \"max_score\": max_score,\n",
    "            \"quality_score\": total_score / max_score if max_score > 0 else 0,\n",
    "            \"required_passed\": required_passed,\n",
    "            \"all_passed\": all_passed,\n",
    "            \"passed\": required_passed,  # é€šè¿‡åªéœ€è¦å¿…éœ€æŒ‡æ ‡é€šè¿‡\n",
    "            \"metrics\": [\n",
    "                {\n",
    "                    \"name\": metric.name,\n",
    "                    \"value\": metric.value,\n",
    "                    \"threshold\": metric.threshold,\n",
    "                    \"passed\": metric.is_passing,\n",
    "                    \"score\": metric.score\n",
    "                }\n",
    "                for metric in self.metrics\n",
    "            ]\n",
    "        }\n",
    "\n",
    "class QualityAssuranceSystem:\n",
    "    \"\"\"è´¨é‡ä¿è¯ç³»ç»Ÿ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coverage_analyzer = CoverageAnalyzer()\n",
    "        self.quality_gates: List[QualityGate] = []\n",
    "        self.test_runner = TestRunner()\n",
    "        self.metrics_history: List[Dict[str, Any]] = []\n",
    "    \n",
    "    def setup_default_quality_gates(self):\n",
    "        \"\"\"è®¾ç½®é»˜è®¤è´¨é‡é—¨ç¦\"\"\"\n",
    "        # ä»£ç è´¨é‡é—¨ç¦\n",
    "        code_quality_gate = QualityGate(\"Code Quality\")\n",
    "        code_quality_gate.add_metric(QualityMetric(\n",
    "            name=\"Line Coverage\",\n",
    "            value=0.0,\n",
    "            unit=\"%\",\n",
    "            threshold=0.8,\n",
    "            weight=2.0,\n",
    "            description=\"ä»£ç è¡Œè¦†ç›–ç‡\"\n",
    "        ), required=True)\n",
    "        \n",
    "        code_quality_gate.add_metric(QualityMetric(\n",
    "            name=\"Branch Coverage\",\n",
    "            value=0.0,\n",
    "            unit=\"%\",\n",
    "            threshold=0.7,\n",
    "            weight=1.5,\n",
    "            description=\"åˆ†æ”¯è¦†ç›–ç‡\"\n",
    "        ), required=True)\n",
    "        \n",
    "        code_quality_gate.add_metric(QualityMetric(\n",
    "            name=\"Test Success Rate\",\n",
    "            value=0.0,\n",
    "            unit=\"%\",\n",
    "            threshold=0.95,\n",
    "            weight=2.0,\n",
    "            description=\"æµ‹è¯•æˆåŠŸç‡\"\n",
    "        ), required=True)\n",
    "        \n",
    "        # æ€§èƒ½è´¨é‡é—¨ç¦\n",
    "        performance_gate = QualityGate(\"Performance\")\n",
    "        performance_gate.add_metric(QualityMetric(\n",
    "            name=\"Test Execution Time\",\n",
    "            value=0.0,\n",
    "            unit=\"seconds\",\n",
    "            threshold=300.0,\n",
    "            weight=1.0,\n",
    "            description=\"æµ‹è¯•æ‰§è¡Œæ—¶é—´\"\n",
    "        ), required=False)\n",
    "        \n",
    "        self.quality_gates = [code_quality_gate, performance_gate]\n",
    "    \n",
    "    def run_quality_assessment(self, test_results: List[TestResult], \n",
    "                               coverage_report: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"è¿è¡Œè´¨é‡è¯„ä¼°\"\"\"\n",
    "        # æ›´æ–°åº¦é‡æŒ‡æ ‡\n",
    "        self._update_metrics(test_results, coverage_report)\n",
    "        \n",
    "        # è¯„ä¼°æ‰€æœ‰è´¨é‡é—¨ç¦\n",
    "        gate_results = []\n",
    "        overall_passed = True\n",
    "        \n",
    "        for gate in self.quality_gates:\n",
    "            result = gate.evaluate()\n",
    "            gate_results.append(result)\n",
    "            if not result[\"passed\"]:\n",
    "                overall_passed = False\n",
    "        \n",
    "        # è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°\n",
    "        total_score = sum(gate[\"quality_score\"] for gate in gate_results)\n",
    "        overall_quality_score = total_score / len(gate_results) if gate_results else 0\n",
    "        \n",
    "        assessment_result = {\n",
    "            \"timestamp\": datetime.datetime.utcnow().isoformat(),\n",
    "            \"overall_passed\": overall_passed,\n",
    "            \"overall_quality_score\": overall_quality_score,\n",
    "            \"gate_results\": gate_results,\n",
    "            \"test_summary\": self.test_runner.get_test_summary(),\n",
    "            \"coverage_summary\": coverage_report.get(\"project_coverage\", {})\n",
    "        }\n",
    "        \n",
    "        # è®°å½•å†å²\n",
    "        self.metrics_history.append(assessment_result)\n",
    "        \n",
    "        return assessment_result\n",
    "    \n",
    "    def _update_metrics(self, test_results: List[TestResult], coverage_report: Dict[str, Any]):\n",
    "        \"\"\"æ›´æ–°åº¦é‡æŒ‡æ ‡\"\"\"\n",
    "        # æ›´æ–°æµ‹è¯•ç›¸å…³æŒ‡æ ‡\n",
    "        test_summary = self.test_runner.get_test_summary()\n",
    "        \n",
    "        for gate in self.quality_gates:\n",
    "            for metric in gate.metrics:\n",
    "                if metric.name == \"Test Success Rate\":\n",
    "                    metric.value = test_summary.get(\"success_rate\", 0.0)\n",
    "                elif metric.name == \"Test Execution Time\":\n",
    "                    metric.value = test_summary.get(\"total_execution_time\", 0.0)\n",
    "        \n",
    "        # æ›´æ–°è¦†ç›–ç‡ç›¸å…³æŒ‡æ ‡\n",
    "        project_coverage = coverage_report.get(\"project_coverage\", {})\n",
    "        \n",
    "        for gate in self.quality_gates:\n",
    "            for metric in gate.metrics:\n",
    "                if metric.name == \"Line Coverage\":\n",
    "                    metric.value = project_coverage.get(\"line_coverage\", 0.0)\n",
    "                elif metric.name == \"Branch Coverage\":\n",
    "                    metric.value = project_coverage.get(\"branch_coverage\", 0.0)\n",
    "    \n",
    "    def get_quality_trend(self, days: int = 30) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–è´¨é‡è¶‹åŠ¿\"\"\"\n",
    "        if not self.metrics_history:\n",
    "            return {\"trend\": \"no_data\", \"data\": []}\n",
    "        \n",
    "        # è·å–æœ€è¿‘Nå¤©çš„æ•°æ®\n",
    "        cutoff_date = datetime.datetime.utcnow() - datetime.timedelta(days=days)\n",
    "        recent_data = [\n",
    "            entry for entry in self.metrics_history\n",
    "            if datetime.datetime.fromisoformat(entry[\"timestamp\"]) >= cutoff_date\n",
    "        ]\n",
    "        \n",
    "        if len(recent_data) < 2:\n",
    "            return {\"trend\": \"insufficient_data\", \"data\": recent_data}\n",
    "        \n",
    "        # è®¡ç®—è¶‹åŠ¿\n",
    "        first_score = recent_data[0][\"overall_quality_score\"]\n",
    "        last_score = recent_data[-1][\"overall_quality_score\"]\n",
    "        \n",
    "        if last_score > first_score + 0.05:\n",
    "            trend = \"improving\"\n",
    "        elif last_score < first_score - 0.05:\n",
    "            trend = \"declining\"\n",
    "        else:\n",
    "            trend = \"stable\"\n",
    "        \n",
    "        return {\n",
    "            \"trend\": trend,\n",
    "            \"data\": recent_data,\n",
    "            \"first_score\": first_score,\n",
    "            \"last_score\": last_score,\n",
    "            \"improvement\": last_score - first_score\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… æµ‹è¯•ç­–ç•¥ä¸è´¨é‡ä¿è¯å®Œæˆ\")\n",
    "print(f\"      - TestPyramid: æµ‹è¯•é‡‘å­—å¡”ç­–ç•¥\")\n",
    "print(f\"      - CoverageAnalyzer: ä»£ç è¦†ç›–ç‡åˆ†æå™¨\")\n",
    "print(f\"      - QualityAssuranceSystem: è´¨é‡ä¿è¯ç³»ç»Ÿ\")\n",
    "print(f\"      - æ”¯æŒå®Œæ•´çš„è´¨é‡åº¦é‡ä½“ç³»\")\n",
    "\n",
    "print(f\"\\nâœ… æµ‹è¯•ç­–ç•¥ä¸è´¨é‡ä¿è¯å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡æµ‹è¯•é‡‘å­—å¡”å’Œæµ‹è¯•ç­–ç•¥\")\n",
    "print(f\"   âœ“ å­¦ä¼šä»£ç è¦†ç›–ç‡åˆ†æ\")\n",
    "print(f\"   âœ“ ç†è§£è´¨é‡åº¦é‡æŒ‡æ ‡\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„è´¨é‡ä¿è¯ä½“ç³»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### çŸ¥è¯†æ¸…å•è¾¾æˆæƒ…å†µ\n",
    "\n",
    "#### âœ… å·²å®ŒæˆçŸ¥è¯†ç‚¹\n",
    "\n",
    "**8.3 æµ‹è¯•é©±åŠ¨å¼€å‘ä¸è´¨é‡ä¿è¯ [â­â­è¿›é˜¶]**\n",
    "- âœ… æŒæ¡TDDçš„å¼€å‘æµç¨‹å’Œæœ€ä½³å®è·µ\n",
    "- âœ… å­¦ä¼šä¸åŒç±»å‹æµ‹è¯•çš„ç¼–å†™æ–¹æ³•\n",
    "- âœ… ç†è§£æµ‹è¯•ç­–ç•¥å’Œè´¨é‡åº¦é‡\n",
    "- âœ… èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„æµ‹è¯•ä½“ç³»\n",
    "\n",
    "#### ğŸ¯ æ ¸å¿ƒæŠ€èƒ½æŒæ¡\n",
    "\n",
    "**TDDå¼€å‘**\n",
    "- âœ… çº¢-ç»¿-é‡æ„å¼€å‘å¾ªç¯\n",
    "- âœ… æµ‹è¯•ç”¨ä¾‹è®¾è®¡å’Œç¼–å†™\n",
    "- âœ… æ–­è¨€æ–¹æ³•å’ŒéªŒè¯æŠ€å·§\n",
    "- âœ… æµ‹è¯•é©±åŠ¨å¼€å‘å®è·µ\n",
    "\n",
    "**æµ‹è¯•ç­–ç•¥**\n",
    "- âœ… æµ‹è¯•é‡‘å­—å¡”è®¾è®¡\n",
    "- âœ… æµ‹è¯•ç±»å‹åˆ†å¸ƒä¼˜åŒ–\n",
    "- âœ… AIé¡¹ç›®æµ‹è¯•ç­–ç•¥\n",
    "- âœ… æµ‹è¯•è‡ªåŠ¨åŒ–ç®¡ç†\n",
    "\n",
    "**è´¨é‡ä¿è¯**\n",
    "- âœ… ä»£ç è¦†ç›–ç‡åˆ†æ\n",
    "- âœ… è´¨é‡åº¦é‡æŒ‡æ ‡è®¾è®¡\n",
    "- âœ… è´¨é‡é—¨ç¦ç®¡ç†\n",
    "- âœ… è´¨é‡è¶‹åŠ¿åˆ†æ\n",
    "\n",
    "#### ğŸš€ å®è·µåº”ç”¨èƒ½åŠ›\n",
    "\n",
    "**æµ‹è¯•ä½“ç³»**\n",
    "- âœ… å®Œæ•´æµ‹è¯•æ¡†æ¶æ­å»º\n",
    "- âœ… å¤šå±‚æ¬¡æµ‹è¯•ç­–ç•¥å®æ–½\n",
    "- âœ… æµ‹è¯•è‡ªåŠ¨åŒ–æµç¨‹\n",
    "- âœ… æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ\n",
    "\n",
    "**è´¨é‡ç®¡ç†**\n",
    "- âœ… ä»£ç è´¨é‡ç›‘æ§\n",
    "- âœ… æµ‹è¯•æ•ˆæœè¯„ä¼°\n",
    "- âœ… è´¨é‡æ”¹è¿›è®¡åˆ’\n",
    "- âœ… å›¢é˜Ÿè´¨é‡æ–‡åŒ–å»ºè®¾\n",
    "\n",
    "#### ğŸ“Š ä¸LangChainçš„å…³è”\n",
    "\n",
    "**AIé¡¹ç›®æµ‹è¯•**\n",
    "- âœ… æ”¯æŒLangChainç»„ä»¶çš„TDDå¼€å‘\n",
    "- âœ… AIæ¨¡å‹å’Œç®—æ³•æµ‹è¯•æ¡†æ¶\n",
    "- âœ… æœºå™¨å­¦ä¹ ç®¡é“æµ‹è¯•ç­–ç•¥\n",
    "- âœ… AIç³»ç»Ÿè´¨é‡ä¿è¯ä½“ç³»\n",
    "\n",
    "**å·¥ç¨‹åŒ–æ”¯æŒ**\n",
    "- âœ… ä¸ºLangChainæä¾›æµ‹è¯•é©±åŠ¨å¼€å‘æ–¹æ¡ˆ\n",
    "- âœ… æ”¯æŒAIé¡¹ç›®çš„æŒç»­è´¨é‡æ”¹è¿›\n",
    "- âœ… ä¿éšœAIä»£ç çš„å¯é æ€§å’Œç¨³å®šæ€§\n",
    "- âœ… å®ç°AIç»„ä»¶çš„æ ‡å‡†åŒ–æµ‹è¯•\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ æˆæœ\n",
    "\n",
    "é€šè¿‡æœ¬èŠ‚å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š\n",
    "\n",
    "1. **TDDå¼€å‘æ–¹æ³•** - ç†è§£æµ‹è¯•é©±åŠ¨å¼€å‘çš„æ ¸å¿ƒæ€æƒ³ï¼Œèƒ½å¤Ÿå®è·µçº¢-ç»¿-é‡æ„å¼€å‘å¾ªç¯\n",
    "2. **æµ‹è¯•æ¡†æ¶è®¾è®¡** - æŒæ¡æµ‹è¯•ç”¨ä¾‹è®¾è®¡ã€æ–­è¨€æ–¹æ³•å’Œæµ‹è¯•è¿è¡Œå™¨çš„å®ç°\n",
    "3. **æµ‹è¯•ç­–ç•¥åˆ¶å®š** - å­¦ä¼šæµ‹è¯•é‡‘å­—å¡”è®¾è®¡å’Œä¸åŒç±»å‹æµ‹è¯•çš„åˆ†å¸ƒç­–ç•¥\n",
    "4. **è´¨é‡ä¿è¯ä½“ç³»** - èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„ä»£ç è¦†ç›–ç‡åˆ†æå’Œè´¨é‡åº¦é‡ç³»ç»Ÿ\n",
    "\n",
    "è¿™äº›æŠ€èƒ½ä¸ºLangChainç­‰AIé¡¹ç›®çš„è´¨é‡ä¿éšœæä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆï¼Œç¡®ä¿äº†ä»£ç è´¨é‡å’Œç³»ç»Ÿå¯é æ€§ã€‚æ¥ä¸‹æ¥å°†ç»§ç»­å­¦ä¹ æŒç»­é›†æˆä¸æŒç»­éƒ¨ç½²ç­‰å·¥ç¨‹å®è·µæŠ€èƒ½ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
