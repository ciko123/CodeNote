{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 51-å¹¶å‘ç¼–ç¨‹æ¨¡å¼\n",
    "\n",
    "## ğŸ“š ç”¨é€”è¯´æ˜\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "- æŒæ¡ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼çš„å¼‚æ­¥å®ç°\n",
    "- å­¦ä¼šå·¥ä½œæ± å’Œçº¿ç¨‹æ± çš„å¹¶å‘ç®¡ç†\n",
    "- ç†è§£æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼çš„æ•°æ®å¤„ç†æµç¨‹\n",
    "- èƒ½å¤Ÿåº”ç”¨å¹¶å‘æ¨¡å¼è§£å†³å®é™…é—®é¢˜\n",
    "\n",
    "**å‰ç½®è¦æ±‚**ï¼š\n",
    "- å·²å®Œæˆå¼‚æ­¥Webæ¡†æ¶å­¦ä¹ \n",
    "- ç†Ÿç»ƒæŒæ¡åç¨‹å’Œäº‹ä»¶å¾ªç¯æœºåˆ¶\n",
    "- äº†è§£åŸºæœ¬çš„å¹¶å‘ç¼–ç¨‹æ¦‚å¿µ\n",
    "- ç†è§£é˜Ÿåˆ—å’ŒåŒæ­¥åŸè¯­çš„ä½¿ç”¨\n",
    "\n",
    "**ä¸LangChainå…³è”**ï¼š\n",
    "- ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼ä¼˜åŒ–LangChainçš„æ•°æ®å¤„ç†æµç¨‹\n",
    "- å·¥ä½œæ± æ¨¡å¼æå‡LangChainçš„å¹¶å‘æ¨ç†èƒ½åŠ›\n",
    "- æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼å¢å¼ºLangChainçš„å¹¶è¡Œå¤„ç†æ•ˆç‡\n",
    "- å¹¶å‘æ¨¡å¼ä¸ºLangChainçš„åˆ†å¸ƒå¼éƒ¨ç½²æä¾›åŸºç¡€\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ çŸ¥è¯†ç‚¹è¦†ç›–\n",
    "\n",
    "### 6.6 å¹¶å‘ç¼–ç¨‹æ¨¡å¼ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šå¹¶å‘ç¼–ç¨‹æ¨¡å¼æ˜¯æ„å»ºé«˜æ€§èƒ½å¼‚æ­¥ç³»ç»Ÿçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œå¯¹äºLangChainçš„å¤§è§„æ¨¡æ•°æ®å¤„ç†å’Œå¹¶è¡Œæ¨ç†è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼çš„å¼‚æ­¥å®ç°\n",
    "- å­¦ä¼šå·¥ä½œæ± å’Œçº¿ç¨‹æ± çš„å¹¶å‘ç®¡ç†\n",
    "- ç†è§£æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼çš„æ•°æ®å¤„ç†æµç¨‹\n",
    "- èƒ½å¤Ÿåº”ç”¨å¹¶å‘æ¨¡å¼è§£å†³å®é™…é—®é¢˜\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„å¹¶å‘æ¨¡å¼ç³»ç»Ÿ\n",
    "- è¿›è¡Œå¹¶å‘æ€§èƒ½å¯¹æ¯”å’Œåˆ†æ\n",
    "- åº”ç”¨å¹¶å‘æ¨¡å¼è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è®¾è®¡å’Œå®ç°å¹¶å‘è§£å†³æ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ å¹¶å‘ç¼–ç¨‹æ¨¡å¼:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import asyncio\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import threading\n",
    "from typing import List, Dict, Any, Optional, AsyncGenerator, Callable\n",
    "from dataclasses import dataclass, asdict\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from collections import deque\n",
    "import weakref\n",
    "\n",
    "print(f\"âœ… Pythonç‰ˆæœ¬: {__import__('sys').version}\")\n",
    "print(f\"âœ… å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼\n",
    "print(f\"ğŸ“ 1. ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼:\")\n",
    "\n",
    "# 1.1 å¼‚æ­¥ç”Ÿäº§è€…æ¶ˆè´¹è€…åŸºç¡€å®ç°\n",
    "print(f\"\\n   ğŸ” 1.1 å¼‚æ­¥ç”Ÿäº§è€…æ¶ˆè´¹è€…åŸºç¡€å®ç°:\")\n",
    "\n",
    "@dataclass\n",
    "class TaskItem:\n",
    "    \"\"\"ä»»åŠ¡é¡¹\"\"\"\n",
    "    id: str\n",
    "    data: Any\n",
    "    priority: int = 0\n",
    "    created_at: float = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.created_at is None:\n",
    "            self.created_at = time.time()\n",
    "\n",
    "@dataclass\n",
    "class ResultItem:\n",
    "    \"\"\"ç»“æœé¡¹\"\"\"\n",
    "    task_id: str\n",
    "    result: Any\n",
    "    processing_time: float\n",
    "    worker_id: str\n",
    "    completed_at: float = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.completed_at is None:\n",
    "            self.completed_at = time.time()\n",
    "\n",
    "class AsyncProducerConsumer:\n",
    "    \"\"\"å¼‚æ­¥ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼å®ç°\"\"\"\n",
    "    \n",
    "    def __init__(self, max_queue_size: int = 100, max_workers: int = 3):\n",
    "        self.task_queue = asyncio.Queue(maxsize=max_queue_size)\n",
    "        self.result_queue = asyncio.Queue(maxsize=max_queue_size)\n",
    "        self.max_workers = max_workers\n",
    "        self.workers = []\n",
    "        self.running = False\n",
    "        self.stats = {\n",
    "            \"produced_tasks\": 0,\n",
    "            \"consumed_tasks\": 0,\n",
    "            \"failed_tasks\": 0,\n",
    "            \"total_processing_time\": 0\n",
    "        }\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨ç”Ÿäº§è€…æ¶ˆè´¹è€…ç³»ç»Ÿ\"\"\"\n",
    "        self.running = True\n",
    "        \n",
    "        # å¯åŠ¨æ¶ˆè´¹è€…å·¥ä½œè¿›ç¨‹\n",
    "        self.workers = [\n",
    "            asyncio.create_task(self._worker(f\"worker-{i}\"))\n",
    "            for i in range(self.max_workers)\n",
    "        ]\n",
    "        \n",
    "        print(f\"      ğŸš€ ç”Ÿäº§è€…æ¶ˆè´¹è€…ç³»ç»Ÿå¯åŠ¨ ({self.max_workers} ä¸ªå·¥ä½œè¿›ç¨‹)\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢ç”Ÿäº§è€…æ¶ˆè´¹è€…ç³»ç»Ÿ\"\"\"\n",
    "        self.running = False\n",
    "        \n",
    "        # ç­‰å¾…æ‰€æœ‰å·¥ä½œè¿›ç¨‹å®Œæˆ\n",
    "        await asyncio.gather(*self.workers, return_exceptions=True)\n",
    "        \n",
    "        print(f\"      ğŸ›‘ ç”Ÿäº§è€…æ¶ˆè´¹è€…ç³»ç»Ÿåœæ­¢\")\n",
    "    \n",
    "    async def produce(self, task: TaskItem):\n",
    "        \"\"\"ç”Ÿäº§ä»»åŠ¡\"\"\"\n",
    "        try:\n",
    "            await self.task_queue.put(task)\n",
    "            self.stats[\"produced_tasks\"] += 1\n",
    "            return True\n",
    "        except asyncio.QueueFull:\n",
    "            print(f\"      âš ï¸ ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä»»åŠ¡: {task.id}\")\n",
    "            return False\n",
    "    \n",
    "    async def consume(self) -> Optional[ResultItem]:\n",
    "        \"\"\"æ¶ˆè´¹ç»“æœ\"\"\"\n",
    "        try:\n",
    "            result = await asyncio.wait_for(\n",
    "                self.result_queue.get(), \n",
    "                timeout=1.0\n",
    "            )\n",
    "            return result\n",
    "        except asyncio.TimeoutError:\n",
    "            return None\n",
    "    \n",
    "    async def _worker(self, worker_id: str):\n",
    "        \"\"\"å·¥ä½œè¿›ç¨‹\"\"\"\n",
    "        print(f\"      ğŸ‘· {worker_id} å¼€å§‹å·¥ä½œ\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # è·å–ä»»åŠ¡ï¼ˆè¶…æ—¶1ç§’ï¼‰\n",
    "                task = await asyncio.wait_for(\n",
    "                    self.task_queue.get(), \n",
    "                    timeout=1.0\n",
    "                )\n",
    "                \n",
    "                # å¤„ç†ä»»åŠ¡\n",
    "                start_time = time.time()\n",
    "                result = await self._process_task(task, worker_id)\n",
    "                processing_time = time.time() - start_time\n",
    "                \n",
    "                # åˆ›å»ºç»“æœé¡¹\n",
    "                result_item = ResultItem(\n",
    "                    task_id=task.id,\n",
    "                    result=result,\n",
    "                    processing_time=processing_time,\n",
    "                    worker_id=worker_id\n",
    "                )\n",
    "                \n",
    "                # å‘é€ç»“æœ\n",
    "                await self.result_queue.put(result_item)\n",
    "                \n",
    "                # æ›´æ–°ç»Ÿè®¡\n",
    "                self.stats[\"consumed_tasks\"] += 1\n",
    "                self.stats[\"total_processing_time\"] += processing_time\n",
    "                \n",
    "                print(f\"      âœ… {worker_id} å®Œæˆä»»åŠ¡: {task.id} ({processing_time:.3f}s)\")\n",
    "                \n",
    "            except asyncio.TimeoutError:\n",
    "                continue  # æ²¡æœ‰ä»»åŠ¡ï¼Œç»§ç»­ç­‰å¾…\n",
    "            except Exception as e:\n",
    "                self.stats[\"failed_tasks\"] += 1\n",
    "                print(f\"      âŒ {worker_id} ä»»åŠ¡å¤±è´¥: {e}\")\n",
    "        \n",
    "        print(f\"      ğŸ‘· {worker_id} åœæ­¢å·¥ä½œ\")\n",
    "    \n",
    "    async def _process_task(self, task: TaskItem, worker_id: str) -> Any:\n",
    "        \"\"\"å¤„ç†ä»»åŠ¡ï¼ˆå¯é‡å†™ï¼‰\"\"\"\n",
    "        # æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†\n",
    "        processing_time = random.uniform(0.1, 1.0)\n",
    "        await asyncio.sleep(processing_time)\n",
    "        \n",
    "        # æ¨¡æ‹Ÿå¤„ç†ç»“æœ\n",
    "        if isinstance(task.data, dict):\n",
    "            return {\n",
    "                **task.data,\n",
    "                \"processed_by\": worker_id,\n",
    "                \"processing_time\": processing_time,\n",
    "                \"timestamp\": time.time()\n",
    "            }\n",
    "        else:\n",
    "            return f\"Processed: {task.data} by {worker_id}\"\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        stats = self.stats.copy()\n",
    "        \n",
    "        if stats[\"consumed_tasks\"] > 0:\n",
    "            stats[\"average_processing_time\"] = (\n",
    "                stats[\"total_processing_time\"] / stats[\"consumed_tasks\"]\n",
    "            )\n",
    "        else:\n",
    "            stats[\"average_processing_time\"] = 0\n",
    "        \n",
    "        stats[\"queue_size\"] = self.task_queue.qsize()\n",
    "        stats[\"result_queue_size\"] = self.result_queue.qsize()\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# 1.2 ä¼˜å…ˆçº§ç”Ÿäº§è€…æ¶ˆè´¹è€…\n",
    "print(f\"\\n   ğŸ¯ 1.2 ä¼˜å…ˆçº§ç”Ÿäº§è€…æ¶ˆè´¹è€…:\")\n",
    "\n",
    "class PriorityProducerConsumer:\n",
    "    \"\"\"ä¼˜å…ˆçº§ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼\"\"\"\n",
    "    \n",
    "    def __init__(self, max_queue_size: int = 100, max_workers: int = 3):\n",
    "        self.task_queue = asyncio.PriorityQueue(maxsize=max_queue_size)\n",
    "        self.result_queue = asyncio.Queue(maxsize=max_queue_size)\n",
    "        self.max_workers = max_workers\n",
    "        self.workers = []\n",
    "        self.running = False\n",
    "        self.stats = {\n",
    "            \"high_priority_tasks\": 0,\n",
    "            \"normal_priority_tasks\": 0,\n",
    "            \"low_priority_tasks\": 0,\n",
    "            \"total_processed\": 0\n",
    "        }\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨ç³»ç»Ÿ\"\"\"\n",
    "        self.running = True\n",
    "        \n",
    "        self.workers = [\n",
    "            asyncio.create_task(self._worker(f\"priority-worker-{i}\"))\n",
    "            for i in range(self.max_workers)\n",
    "        ]\n",
    "        \n",
    "        print(f\"      ğŸš€ ä¼˜å…ˆçº§ç”Ÿäº§è€…æ¶ˆè´¹è€…ç³»ç»Ÿå¯åŠ¨\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢ç³»ç»Ÿ\"\"\"\n",
    "        self.running = False\n",
    "        await asyncio.gather(*self.workers, return_exceptions=True)\n",
    "        print(f\"      ğŸ›‘ ä¼˜å…ˆçº§ç”Ÿäº§è€…æ¶ˆè´¹è€…ç³»ç»Ÿåœæ­¢\")\n",
    "    \n",
    "    async def produce(self, task: TaskItem):\n",
    "        \"\"\"ç”Ÿäº§ä»»åŠ¡ï¼ˆå¸¦ä¼˜å…ˆçº§ï¼‰\"\"\"\n",
    "        # ä¼˜å…ˆçº§æ˜ å°„ï¼šé«˜(0) < æ­£å¸¸(1) < ä½(2)\n",
    "        priority_value = max(0, min(2, task.priority))\n",
    "        \n",
    "        try:\n",
    "            await self.task_queue.put((priority_value, task))\n",
    "            \n",
    "            # æ›´æ–°ç»Ÿè®¡\n",
    "            if priority_value == 0:\n",
    "                self.stats[\"high_priority_tasks\"] += 1\n",
    "            elif priority_value == 1:\n",
    "                self.stats[\"normal_priority_tasks\"] += 1\n",
    "            else:\n",
    "                self.stats[\"low_priority_tasks\"] += 1\n",
    "            \n",
    "            return True\n",
    "        except asyncio.QueueFull:\n",
    "            return False\n",
    "    \n",
    "    async def consume(self) -> Optional[ResultItem]:\n",
    "        \"\"\"æ¶ˆè´¹ç»“æœ\"\"\"\n",
    "        try:\n",
    "            return await asyncio.wait_for(\n",
    "                self.result_queue.get(), \n",
    "                timeout=1.0\n",
    "            )\n",
    "        except asyncio.TimeoutError:\n",
    "            return None\n",
    "    \n",
    "    async def _worker(self, worker_id: str):\n",
    "        \"\"\"å·¥ä½œè¿›ç¨‹\"\"\"\n",
    "        while self.running:\n",
    "            try:\n",
    "                # è·å–ä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰\n",
    "                priority, task = await asyncio.wait_for(\n",
    "                    self.task_queue.get(), \n",
    "                    timeout=1.0\n",
    "                )\n",
    "                \n",
    "                # å¤„ç†ä»»åŠ¡\n",
    "                start_time = time.time()\n",
    "                result = await self._process_task(task, worker_id)\n",
    "                processing_time = time.time() - start_time\n",
    "                \n",
    "                # åˆ›å»ºç»“æœé¡¹\n",
    "                result_item = ResultItem(\n",
    "                    task_id=task.id,\n",
    "                    result=result,\n",
    "                    processing_time=processing_time,\n",
    "                    worker_id=worker_id\n",
    "                )\n",
    "                \n",
    "                await self.result_queue.put(result_item)\n",
    "                self.stats[\"total_processed\"] += 1\n",
    "                \n",
    "                priority_name = [\"é«˜\", \"æ­£å¸¸\", \"ä½\"][priority]\n",
    "                print(f\"      âœ… {worker_id} å®Œæˆ{priority_name}ä¼˜å…ˆçº§ä»»åŠ¡: {task.id}\")\n",
    "                \n",
    "            except asyncio.TimeoutError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ {worker_id} ä»»åŠ¡å¤±è´¥: {e}\")\n",
    "    \n",
    "    async def _process_task(self, task: TaskItem, worker_id: str) -> Any:\n",
    "        \"\"\"å¤„ç†ä»»åŠ¡\"\"\"\n",
    "        # é«˜ä¼˜å…ˆçº§ä»»åŠ¡å¤„ç†æ›´å¿«\n",
    "        if task.priority == 0:\n",
    "            processing_time = random.uniform(0.05, 0.3)\n",
    "        elif task.priority == 1:\n",
    "            processing_time = random.uniform(0.1, 0.5)\n",
    "        else:\n",
    "            processing_time = random.uniform(0.2, 0.8)\n",
    "        \n",
    "        await asyncio.sleep(processing_time)\n",
    "        \n",
    "        return {\n",
    "            \"task_data\": task.data,\n",
    "            \"priority\": task.priority,\n",
    "            \"processed_by\": worker_id,\n",
    "            \"processing_time\": processing_time\n",
    "        }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        return {\n",
    "            **self.stats,\n",
    "            \"queue_size\": self.task_queue.qsize(),\n",
    "            \"result_queue_size\": self.result_queue.qsize()\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼å®Œæˆ\")\n",
    "print(f\"      - AsyncProducerConsumer: åŸºç¡€å¼‚æ­¥ç”Ÿäº§è€…æ¶ˆè´¹è€…\")\n",
    "print(f\"      - PriorityProducerConsumer: ä¼˜å…ˆçº§ç”Ÿäº§è€…æ¶ˆè´¹è€…\")\n",
    "\n",
    "# 2. å·¥ä½œæ± æ¨¡å¼\n",
    "print(f\"\\n   ğŸŠ 2. å·¥ä½œæ± æ¨¡å¼:\")\n",
    "\n",
    "# 2.1 å¼‚æ­¥å·¥ä½œæ± \n",
    "print(f\"\\n      2.1 å¼‚æ­¥å·¥ä½œæ± :\")\n",
    "\n",
    "class AsyncWorkerPool:\n",
    "    \"\"\"å¼‚æ­¥å·¥ä½œæ± \"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = 5, max_queue_size: int = 100):\n",
    "        self.max_workers = max_workers\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.task_queue = asyncio.Queue(maxsize=max_queue_size)\n",
    "        self.result_futures = {}\n",
    "        self.workers = []\n",
    "        self.running = False\n",
    "        self.worker_stats = {}\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨å·¥ä½œæ± \"\"\"\n",
    "        self.running = True\n",
    "        \n",
    "        # å¯åŠ¨å·¥ä½œè¿›ç¨‹\n",
    "        self.workers = [\n",
    "            asyncio.create_task(self._worker(f\"pool-worker-{i}\"))\n",
    "            for i in range(self.max_workers)\n",
    "        ]\n",
    "        \n",
    "        print(f\"      ğŸš€ å¼‚æ­¥å·¥ä½œæ± å¯åŠ¨ ({self.max_workers} ä¸ªå·¥ä½œè¿›ç¨‹)\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢å·¥ä½œæ± \"\"\"\n",
    "        self.running = False\n",
    "        \n",
    "        # å–æ¶ˆæ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡\n",
    "        for future in self.result_futures.values():\n",
    "            if not future.done():\n",
    "                future.cancel()\n",
    "        \n",
    "        # ç­‰å¾…å·¥ä½œè¿›ç¨‹å®Œæˆ\n",
    "        await asyncio.gather(*self.workers, return_exceptions=True)\n",
    "        \n",
    "        print(f\"      ğŸ›‘ å¼‚æ­¥å·¥ä½œæ± åœæ­¢\")\n",
    "    \n",
    "    async def submit(self, task_func: Callable, *args, **kwargs) -> asyncio.Future:\n",
    "        \"\"\"æäº¤ä»»åŠ¡åˆ°å·¥ä½œæ± \"\"\"\n",
    "        if not self.running:\n",
    "            raise RuntimeError(\"å·¥ä½œæ± æœªå¯åŠ¨\")\n",
    "        \n",
    "        # åˆ›å»ºç»“æœFuture\n",
    "        result_future = asyncio.Future()\n",
    "        task_id = str(uuid.uuid4())[:8]\n",
    "        \n",
    "        # å­˜å‚¨Future\n",
    "        self.result_futures[task_id] = result_future\n",
    "        \n",
    "        # æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—\n",
    "        task_data = {\n",
    "            \"id\": task_id,\n",
    "            \"func\": task_func,\n",
    "            \"args\": args,\n",
    "            \"kwargs\": kwargs\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            await self.task_queue.put(task_data)\n",
    "            return result_future\n",
    "        except asyncio.QueueFull:\n",
    "            # é˜Ÿåˆ—æ»¡ï¼Œè®¾ç½®å¼‚å¸¸å¹¶è¿”å›\n",
    "            result_future.set_exception(Exception(\"ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡\"))\n",
    "            del self.result_futures[task_id]\n",
    "            return result_future\n",
    "    \n",
    "    async def _worker(self, worker_id: str):\n",
    "        \"\"\"å·¥ä½œè¿›ç¨‹\"\"\"\n",
    "        print(f\"      ğŸ‘· {worker_id} å¼€å§‹å·¥ä½œ\")\n",
    "        \n",
    "        # åˆå§‹åŒ–å·¥ä½œç»Ÿè®¡\n",
    "        self.worker_stats[worker_id] = {\n",
    "            \"tasks_completed\": 0,\n",
    "            \"tasks_failed\": 0,\n",
    "            \"total_time\": 0\n",
    "        }\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # è·å–ä»»åŠ¡\n",
    "                task_data = await asyncio.wait_for(\n",
    "                    self.task_queue.get(), \n",
    "                    timeout=1.0\n",
    "                )\n",
    "                \n",
    "                task_id = task_data[\"id\"]\n",
    "                start_time = time.time()\n",
    "                \n",
    "                try:\n",
    "                    # æ‰§è¡Œä»»åŠ¡\n",
    "                    if asyncio.iscoroutinefunction(task_data[\"func\"]):\n",
    "                        result = await task_data[\"func\"](*task_data[\"args\"], **task_data[\"kwargs\"])\n",
    "                    else:\n",
    "                        # åŒæ­¥å‡½æ•°åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ\n",
    "                        loop = asyncio.get_event_loop()\n",
    "                        result = await loop.run_in_executor(\n",
    "                            None, \n",
    "                            task_data[\"func\"], \n",
    "                            *task_data[\"args\"], \n",
    "                            **task_data[\"kwargs\"]\n",
    "                        )\n",
    "                    \n",
    "                    # è®¾ç½®ç»“æœ\n",
    "                    if task_id in self.result_futures:\n",
    "                        self.result_futures[task_id].set_result(result)\n",
    "                        del self.result_futures[task_id]\n",
    "                    \n",
    "                    # æ›´æ–°ç»Ÿè®¡\n",
    "                    processing_time = time.time() - start_time\n",
    "                    self.worker_stats[worker_id][\"tasks_completed\"] += 1\n",
    "                    self.worker_stats[worker_id][\"total_time\"] += processing_time\n",
    "                    \n",
    "                    print(f\"      âœ… {worker_id} å®Œæˆä»»åŠ¡: {task_id} ({processing_time:.3f}s)\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # è®¾ç½®å¼‚å¸¸\n",
    "                    if task_id in self.result_futures:\n",
    "                        self.result_futures[task_id].set_exception(e)\n",
    "                        del self.result_futures[task_id]\n",
    "                    \n",
    "                    # æ›´æ–°ç»Ÿè®¡\n",
    "                    self.worker_stats[worker_id][\"tasks_failed\"] += 1\n",
    "                    \n",
    "                    print(f\"      âŒ {worker_id} ä»»åŠ¡å¤±è´¥: {task_id} - {e}\")\n",
    "                \n",
    "            except asyncio.TimeoutError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ {worker_id} å·¥ä½œè¿›ç¨‹é”™è¯¯: {e}\")\n",
    "        \n",
    "        print(f\"      ğŸ‘· {worker_id} åœæ­¢å·¥ä½œ\")\n",
    "    \n",
    "    def get_pool_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–å·¥ä½œæ± ç»Ÿè®¡\"\"\"\n",
    "        total_completed = sum(stats[\"tasks_completed\"] for stats in self.worker_stats.values())\n",
    "        total_failed = sum(stats[\"tasks_failed\"] for stats in self.worker_stats.values())\n",
    "        total_time = sum(stats[\"total_time\"] for stats in self.worker_stats.values())\n",
    "        \n",
    "        return {\n",
    "            \"max_workers\": self.max_workers,\n",
    "            \"active_workers\": len(self.workers),\n",
    "            \"queue_size\": self.task_queue.qsize(),\n",
    "            \"pending_futures\": len(self.result_futures),\n",
    "            \"total_completed\": total_completed,\n",
    "            \"total_failed\": total_failed,\n",
    "            \"success_rate\": f\"{total_completed/(total_completed+total_failed)*100:.1f}%\" if (total_completed+total_failed) > 0 else \"0%\",\n",
    "            \"average_time\": f\"{total_time/total_completed:.3f}s\" if total_completed > 0 else \"0s\",\n",
    "            \"worker_stats\": self.worker_stats\n",
    "        }\n",
    "\n",
    "# 2.2 çº¿ç¨‹æ± å·¥ä½œæ± \n",
    "print(f\"\\n      2.2 çº¿ç¨‹æ± å·¥ä½œæ± :\")\n",
    "\n",
    "class ThreadPoolWorkerPool:\n",
    "    \"\"\"çº¿ç¨‹æ± å·¥ä½œæ± ï¼ˆç”¨äºCPUå¯†é›†å‹ä»»åŠ¡ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = 4):\n",
    "        self.max_workers = max_workers\n",
    "        self.executor = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        self.loop = None\n",
    "        self.running = False\n",
    "        self.task_counter = 0\n",
    "        self.stats = {\n",
    "            \"submitted_tasks\": 0,\n",
    "            \"completed_tasks\": 0,\n",
    "            \"failed_tasks\": 0\n",
    "        }\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨çº¿ç¨‹æ± å·¥ä½œæ± \"\"\"\n",
    "        self.running = True\n",
    "        self.loop = asyncio.get_event_loop()\n",
    "        print(f\"      ğŸš€ çº¿ç¨‹æ± å·¥ä½œæ± å¯åŠ¨ ({self.max_workers} ä¸ªçº¿ç¨‹)\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢çº¿ç¨‹æ± å·¥ä½œæ± \"\"\"\n",
    "        self.running = False\n",
    "        self.executor.shutdown(wait=True)\n",
    "        print(f\"      ğŸ›‘ çº¿ç¨‹æ± å·¥ä½œæ± åœæ­¢\")\n",
    "    \n",
    "    async def submit(self, func: Callable, *args, **kwargs) -> asyncio.Future:\n",
    "        \"\"\"æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± \"\"\"\n",
    "        if not self.running:\n",
    "            raise RuntimeError(\"çº¿ç¨‹æ± å·¥ä½œæ± æœªå¯åŠ¨\")\n",
    "        \n",
    "        self.task_counter += 1\n",
    "        self.stats[\"submitted_tasks\"] += 1\n",
    "        \n",
    "        try:\n",
    "            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œä»»åŠ¡\n",
    "            future = await self.loop.run_in_executor(\n",
    "                self.executor, \n",
    "                self._execute_task, \n",
    "                func, \n",
    "                args, \n",
    "                kwargs\n",
    "            )\n",
    "            return future\n",
    "        except Exception as e:\n",
    "            self.stats[\"failed_tasks\"] += 1\n",
    "            raise e\n",
    "    \n",
    "    def _execute_task(self, func: Callable, args: tuple, kwargs: dict) -> Any:\n",
    "        \"\"\"åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œä»»åŠ¡\"\"\"\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self.stats[\"completed_tasks\"] += 1\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.stats[\"failed_tasks\"] += 1\n",
    "            raise e\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        total = self.stats[\"submitted_tasks\"]\n",
    "        completed = self.stats[\"completed_tasks\"]\n",
    "        failed = self.stats[\"failed_tasks\"]\n",
    "        \n",
    "        return {\n",
    "            **self.stats,\n",
    "            \"success_rate\": f\"{completed/total*100:.1f}%\" if total > 0 else \"0%\",\n",
    "            \"pending_tasks\": total - completed - failed\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… å·¥ä½œæ± æ¨¡å¼å®Œæˆ\")\n",
    "print(f\"      - AsyncWorkerPool: å¼‚æ­¥å·¥ä½œæ± \")\n",
    "print(f\"      - ThreadPoolWorkerPool: çº¿ç¨‹æ± å·¥ä½œæ± \")\n",
    "\n",
    "# 3. æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼\n",
    "print(f\"\\n   ğŸŒŠ 3. æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼:\")\n",
    "\n",
    "# 3.1 æ‰‡å‡ºæ‰‡å…¥åŸºç¡€å®ç°\n",
    "print(f\"\\n      3.1 æ‰‡å‡ºæ‰‡å…¥åŸºç¡€å®ç°:\")\n",
    "\n",
    "class FanOutFanIn:\n",
    "    \"\"\"æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼å®ç°\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent: int = 10):\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        self.stats = {\n",
    "            \"fan_out_tasks\": 0,\n",
    "            \"fan_in_results\": 0,\n",
    "            \"failed_tasks\": 0,\n",
    "            \"total_time\": 0\n",
    "        }\n",
    "    \n",
    "    async def fan_out(self, tasks: List[Callable]) -> List[asyncio.Task]:\n",
    "        \"\"\"æ‰‡å‡ºï¼šåˆ›å»ºå¤šä¸ªå¹¶å‘ä»»åŠ¡\"\"\"\n",
    "        print(f\"      ğŸŒŠ æ‰‡å‡º {len(tasks)} ä¸ªä»»åŠ¡\")\n",
    "        \n",
    "        # åˆ›å»ºå¹¶å‘ä»»åŠ¡\n",
    "        concurrent_tasks = []\n",
    "        \n",
    "        for i, task_func in enumerate(tasks):\n",
    "            task = asyncio.create_task(\n",
    "                self._execute_with_semaphore(task_func, f\"task-{i}\")\n",
    "            )\n",
    "            concurrent_tasks.append(task)\n",
    "            self.stats[\"fan_out_tasks\"] += 1\n",
    "        \n",
    "        return concurrent_tasks\n",
    "    \n",
    "    async def fan_in(self, tasks: List[asyncio.Task]) -> List[Any]:\n",
    "        \"\"\"æ‰‡å…¥ï¼šæ”¶é›†å¹¶å‘ä»»åŠ¡ç»“æœ\"\"\"\n",
    "        print(f\"      ğŸ”„ æ‰‡å…¥ {len(tasks)} ä¸ªä»»åŠ¡ç»“æœ\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        # å¤„ç†ç»“æœ\n",
    "        successful_results = []\n",
    "        for i, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"      âŒ ä»»åŠ¡ {i} å¤±è´¥: {result}\")\n",
    "                self.stats[\"failed_tasks\"] += 1\n",
    "            else:\n",
    "                successful_results.append(result)\n",
    "                self.stats[\"fan_in_results\"] += 1\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        self.stats[\"total_time\"] += total_time\n",
    "        \n",
    "        print(f\"      âœ… æ‰‡å…¥å®Œæˆ: {len(successful_results)}/{len(tasks)} æˆåŠŸ ({total_time:.3f}s)\")\n",
    "        \n",
    "        return successful_results\n",
    "    \n",
    "    async def _execute_with_semaphore(self, task_func: Callable, task_id: str) -> Any:\n",
    "        \"\"\"ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘çš„ä»»åŠ¡æ‰§è¡Œ\"\"\"\n",
    "        async with self.semaphore:\n",
    "            try:\n",
    "                if asyncio.iscoroutinefunction(task_func):\n",
    "                    return await task_func()\n",
    "                else:\n",
    "                    # åŒæ­¥å‡½æ•°åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ\n",
    "                    loop = asyncio.get_event_loop()\n",
    "                    return await loop.run_in_executor(None, task_func)\n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ {task_id} æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "                raise e\n",
    "    \n",
    "    async def process_batch(self, data_items: List[Any], processor: Callable) -> List[Any]:\n",
    "        \"\"\"æ‰¹é‡å¤„ç†æ•°æ®ï¼ˆæ‰‡å‡ºæ‰‡å…¥æ¨¡å¼ï¼‰\"\"\"\n",
    "        print(f\"      ğŸ“¦ æ‰¹é‡å¤„ç† {len(data_items)} ä¸ªæ•°æ®é¡¹\")\n",
    "        \n",
    "        # åˆ›å»ºå¤„ç†ä»»åŠ¡\n",
    "        tasks = [\n",
    "            lambda item=item: processor(item) \n",
    "            for item in data_items\n",
    "        ]\n",
    "        \n",
    "        # æ‰‡å‡º\n",
    "        concurrent_tasks = await self.fan_out(tasks)\n",
    "        \n",
    "        # æ‰‡å…¥\n",
    "        results = await self.fan_in(concurrent_tasks)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        stats = self.stats.copy()\n",
    "        \n",
    "        if stats[\"fan_in_results\"] > 0:\n",
    "            stats[\"average_time\"] = stats[\"total_time\"] / stats[\"fan_in_results\"]\n",
    "        else:\n",
    "            stats[\"average_time\"] = 0\n",
    "        \n",
    "        total_tasks = stats[\"fan_out_tasks\"]\n",
    "        successful_tasks = stats[\"fan_in_results\"]\n",
    "        \n",
    "        if total_tasks > 0:\n",
    "            stats[\"success_rate\"] = f\"{successful_tasks/total_tasks*100:.1f}%\"\n",
    "        else:\n",
    "            stats[\"success_rate\"] = \"0%\"\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# 3.2 åˆ†é˜¶æ®µæ‰‡å‡ºæ‰‡å…¥\n",
    "print(f\"\\n      3.2 åˆ†é˜¶æ®µæ‰‡å‡ºæ‰‡å…¥:\")\n",
    "\n",
    "class StagedFanOutFanIn:\n",
    "    \"\"\"åˆ†é˜¶æ®µæ‰‡å‡ºæ‰‡å…¥æ¨¡å¼\"\"\"\n",
    "    \n",
    "    def __init__(self, stage_workers: List[int] = None):\n",
    "        if stage_workers is None:\n",
    "            stage_workers = [5, 3, 2]  # é»˜è®¤3ä¸ªé˜¶æ®µ\n",
    "        \n",
    "        self.stage_workers = stage_workers\n",
    "        self.stages = []\n",
    "        self.stats = {\n",
    "            \"stage_stats\": [{\n",
    "                \"input_items\": 0,\n",
    "                \"output_items\": 0,\n",
    "                \"failed_items\": 0,\n",
    "                \"processing_time\": 0\n",
    "            } for _ in stage_workers]\n",
    "        }\n",
    "    \n",
    "    async def process_pipeline(self, data_items: List[Any], \n",
    "                               processors: List[Callable]) -> List[Any]:\n",
    "        \"\"\"å¤šé˜¶æ®µæµæ°´çº¿å¤„ç†\"\"\"\n",
    "        if len(processors) != len(self.stage_workers):\n",
    "            raise ValueError(\"å¤„ç†å™¨æ•°é‡å¿…é¡»ä¸é˜¶æ®µæ•°é‡åŒ¹é…\")\n",
    "        \n",
    "        print(f\"      ğŸ­ å¯åŠ¨ {len(processors)} é˜¶æ®µæµæ°´çº¿å¤„ç†\")\n",
    "        \n",
    "        current_data = data_items\n",
    "        \n",
    "        for stage_idx, (processor, max_workers) in enumerate(zip(processors, self.stage_workers)):\n",
    "            print(f\"      ğŸ”„ é˜¶æ®µ {stage_idx + 1}: {len(current_data)} -> ? (æœ€å¤§ {max_workers} å¹¶å‘)\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # å½“å‰é˜¶æ®µçš„æ‰‡å‡ºæ‰‡å…¥å¤„ç†\n",
    "            stage_fan_out_fan_in = FanOutFanIn(max_concurrent=max_workers)\n",
    "            \n",
    "            # å¤„ç†å½“å‰é˜¶æ®µ\n",
    "            current_data = await stage_fan_out_fan_in.process_batch(\n",
    "                current_data, \n",
    "                processor\n",
    "            )\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # æ›´æ–°é˜¶æ®µç»Ÿè®¡\n",
    "            stage_stats = stage_fan_out_fan_in.get_stats()\n",
    "            self.stats[\"stage_stats\"][stage_idx] = {\n",
    "                \"input_items\": stage_stats[\"fan_out_tasks\"],\n",
    "                \"output_items\": stage_stats[\"fan_in_results\"],\n",
    "                \"failed_items\": stage_stats[\"failed_tasks\"],\n",
    "                \"processing_time\": processing_time\n",
    "            }\n",
    "            \n",
    "            print(f\"      âœ… é˜¶æ®µ {stage_idx + 1} å®Œæˆ: {len(current_data)} ä¸ªç»“æœ ({processing_time:.3f}s)\")\n",
    "        \n",
    "        return current_data\n",
    "    \n",
    "    def get_pipeline_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æµæ°´çº¿ç»Ÿè®¡\"\"\"\n",
    "        total_input = sum(stage[\"input_items\"] for stage in self.stats[\"stage_stats\"])\n",
    "        total_output = self.stats[\"stage_stats\"][-1][\"output_items\"]\n",
    "        total_time = sum(stage[\"processing_time\"] for stage in self.stats[\"stage_stats\"])\n",
    "        \n",
    "        return {\n",
    "            \"total_stages\": len(self.stage_workers),\n",
    "            \"stage_workers\": self.stage_workers,\n",
    "            \"total_input_items\": total_input,\n",
    "            \"total_output_items\": total_output,\n",
    "            \"total_processing_time\": total_time,\n",
    "            \"overall_throughput\": total_output / total_time if total_time > 0 else 0,\n",
    "            \"stage_stats\": self.stats[\"stage_stats\"]\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼å®Œæˆ\")\n",
    "print(f\"      - FanOutFanIn: åŸºç¡€æ‰‡å‡ºæ‰‡å…¥\")\n",
    "print(f\"      - StagedFanOutFanIn: åˆ†é˜¶æ®µæ‰‡å‡ºæ‰‡å…¥\")\n",
    "\n",
    "print(f\"\\nâœ… å¹¶å‘ç¼–ç¨‹æ¨¡å¼å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼çš„å¼‚æ­¥å®ç°\")\n",
    "print(f\"   âœ“ å­¦ä¼šå·¥ä½œæ± å’Œçº¿ç¨‹æ± çš„å¹¶å‘ç®¡ç†\")\n",
    "print(f\"   âœ“ ç†è§£æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼çš„æ•°æ®å¤„ç†æµç¨‹\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿåº”ç”¨å¹¶å‘æ¨¡å¼è§£å†³å®é™…é—®é¢˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¹¶å‘æ¨¡å¼å®æˆ˜åº”ç”¨ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šå¹¶å‘æ¨¡å¼çš„å®æˆ˜åº”ç”¨æ˜¯æŒæ¡é«˜æ€§èƒ½å¼‚æ­¥ç¼–ç¨‹çš„å…³é”®ï¼Œå¯¹äºLangChainçš„åˆ†å¸ƒå¼å¤„ç†å’Œå¤§è§„æ¨¡éƒ¨ç½²å…·æœ‰é‡è¦æ„ä¹‰ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡å¹¶å‘æ¨¡å¼çš„å®é™…åº”ç”¨åœºæ™¯\n",
    "- å­¦ä¼šå¹¶å‘æ€§èƒ½è°ƒä¼˜å’Œç›‘æ§\n",
    "- ç†è§£å¹¶å‘æ¨¡å¼çš„å±€é™æ€§å’Œé€‚ç”¨æ¡ä»¶\n",
    "- èƒ½å¤Ÿè®¾è®¡é«˜æ•ˆçš„å¹¶å‘è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„å¹¶å‘æ¨¡å¼åº”ç”¨ç³»ç»Ÿ\n",
    "- è¿›è¡Œå¹¶å‘æ€§èƒ½å¯¹æ¯”å’Œä¼˜åŒ–\n",
    "- åº”ç”¨å¹¶å‘æ¨¡å¼è§£å†³LangChainç›¸å…³é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è®¾è®¡å¹¶å®ç°é«˜æ€§èƒ½å¹¶å‘ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸš€ å¹¶å‘æ¨¡å¼å®æˆ˜åº”ç”¨:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. LangChainæ•°æ®å¤„ç†å¹¶å‘æ¨¡å¼\n",
    "print(f\"ğŸ“ 1. LangChainæ•°æ®å¤„ç†å¹¶å‘æ¨¡å¼:\")\n",
    "\n",
    "# 1.1 å¹¶å‘æ–‡æœ¬å¤„ç†\n",
    "print(f\"\\n   ğŸ” 1.1 å¹¶å‘æ–‡æœ¬å¤„ç†:\")\n",
    "\n",
    "@dataclass\n",
    "class TextProcessingTask:\n",
    "    \"\"\"æ–‡æœ¬å¤„ç†ä»»åŠ¡\"\"\"\n",
    "    id: str\n",
    "    text: str\n",
    "    operation: str  # 'summarize', 'translate', 'analyze', 'extract'\n",
    "    priority: int = 1\n",
    "    metadata: Dict[str, Any] = None\n",
    "\n",
    "@dataclass\n",
    "class TextProcessingResult:\n",
    "    \"\"\"æ–‡æœ¬å¤„ç†ç»“æœ\"\"\"\n",
    "    task_id: str\n",
    "    result: str\n",
    "    operation: str\n",
    "    processing_time: float\n",
    "    confidence: float\n",
    "    worker_id: str\n",
    "\n",
    "class LangChainTextProcessor:\n",
    "    \"\"\"LangChainæ–‡æœ¬å¤„ç†å™¨ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = 5):\n",
    "        self.producer_consumer = AsyncProducerConsumer(\n",
    "            max_queue_size=200, \n",
    "            max_workers=max_workers\n",
    "        )\n",
    "        self.processing_stats = {\n",
    "            \"summarize\": {\"count\": 0, \"total_time\": 0},\n",
    "            \"translate\": {\"count\": 0, \"total_time\": 0},\n",
    "            \"analyze\": {\"count\": 0, \"total_time\": 0},\n",
    "            \"extract\": {\"count\": 0, \"total_time\": 0}\n",
    "        }\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨æ–‡æœ¬å¤„ç†å™¨\"\"\"\n",
    "        await self.producer_consumer.start()\n",
    "        print(f\"      ğŸš€ LangChainæ–‡æœ¬å¤„ç†å™¨å¯åŠ¨\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢æ–‡æœ¬å¤„ç†å™¨\"\"\"\n",
    "        await self.producer_consumer.stop()\n",
    "        print(f\"      ğŸ›‘ LangChainæ–‡æœ¬å¤„ç†å™¨åœæ­¢\")\n",
    "    \n",
    "    async def submit_text_task(self, task: TextProcessingTask) -> str:\n",
    "        \"\"\"æäº¤æ–‡æœ¬å¤„ç†ä»»åŠ¡\"\"\"\n",
    "        task_item = TaskItem(\n",
    "            id=task.id,\n",
    "            data=task,\n",
    "            priority=task.priority\n",
    "        )\n",
    "        \n",
    "        success = await self.producer_consumer.produce(task_item)\n",
    "        if success:\n",
    "            return task.id\n",
    "        else:\n",
    "            raise Exception(\"ä»»åŠ¡æäº¤å¤±è´¥\")\n",
    "    \n",
    "    async def get_result(self) -> Optional[TextProcessingResult]:\n",
    "        \"\"\"è·å–å¤„ç†ç»“æœ\"\"\"\n",
    "        result_item = await self.producer_consumer.consume()\n",
    "        if result_item:\n",
    "            return result_item.result\n",
    "        return None\n",
    "    \n",
    "    async def _process_task(self, task: TextProcessingTask, worker_id: str) -> TextProcessingResult:\n",
    "        \"\"\"å¤„ç†æ–‡æœ¬ä»»åŠ¡\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ–‡æœ¬å¤„ç†\n",
    "        if task.operation == \"summarize\":\n",
    "            processing_time = random.uniform(0.5, 2.0)\n",
    "            await asyncio.sleep(processing_time)\n",
    "            \n",
    "            result = f\"Summary of '{task.text[:50]}...': Key points extracted and condensed.\"\n",
    "            confidence = random.uniform(0.7, 0.95)\n",
    "            \n",
    "        elif task.operation == \"translate\":\n",
    "            processing_time = random.uniform(0.3, 1.0)\n",
    "            await asyncio.sleep(processing_time)\n",
    "            \n",
    "            result = f\"Translated '{task.text[:30]}...' to target language with high accuracy.\"\n",
    "            confidence = random.uniform(0.8, 0.98)\n",
    "            \n",
    "        elif task.operation == \"analyze\":\n",
    "            processing_time = random.uniform(0.8, 2.5)\n",
    "            await asyncio.sleep(processing_time)\n",
    "            \n",
    "            result = f\"Analysis of '{task.text[:40]}...': Sentiment positive, key entities identified.\"\n",
    "            confidence = random.uniform(0.6, 0.9)\n",
    "            \n",
    "        elif task.operation == \"extract\":\n",
    "            processing_time = random.uniform(0.4, 1.5)\n",
    "            await asyncio.sleep(processing_time)\n",
    "            \n",
    "            result = f\"Extracted information from '{task.text[:35]}...': Names, dates, locations found.\"\n",
    "            confidence = random.uniform(0.75, 0.95)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"ä¸æ”¯æŒçš„æ“ä½œ: {task.operation}\")\n",
    "        \n",
    "        # æ›´æ–°ç»Ÿè®¡\n",
    "        actual_time = time.time() - start_time\n",
    "        self.processing_stats[task.operation][\"count\"] += 1\n",
    "        self.processing_stats[task.operation][\"total_time\"] += actual_time\n",
    "        \n",
    "        return TextProcessingResult(\n",
    "            task_id=task.id,\n",
    "            result=result,\n",
    "            operation=task.operation,\n",
    "            processing_time=actual_time,\n",
    "            confidence=confidence,\n",
    "            worker_id=worker_id\n",
    "        )\n",
    "    \n",
    "    # é‡å†™çˆ¶ç±»æ–¹æ³•\n",
    "    async def _process_task_override(self, task: TaskItem, worker_id: str) -> Any:\n",
    "        \"\"\"é‡å†™ä»»åŠ¡å¤„ç†æ–¹æ³•\"\"\"\n",
    "        text_task = task.data\n",
    "        return await self._process_task(text_task, worker_id)\n",
    "    \n",
    "    def get_processing_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–å¤„ç†ç»Ÿè®¡\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        for operation, data in self.processing_stats.items():\n",
    "            if data[\"count\"] > 0:\n",
    "                avg_time = data[\"total_time\"] / data[\"count\"]\n",
    "            else:\n",
    "                avg_time = 0\n",
    "            \n",
    "            stats[operation] = {\n",
    "                \"count\": data[\"count\"],\n",
    "                \"total_time\": data[\"total_time\"],\n",
    "                \"average_time\": avg_time\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"operation_stats\": stats,\n",
    "            \"system_stats\": self.producer_consumer.get_stats()\n",
    "        }\n",
    "\n",
    "# 1.2 å¹¶å‘æ¨¡å‹æ¨ç†\n",
    "print(f\"\\n   ğŸ¤– 1.2 å¹¶å‘æ¨¡å‹æ¨ç†:\")\n",
    "\n",
    "@dataclass\n",
    "class InferenceTask:\n",
    "    \"\"\"æ¨ç†ä»»åŠ¡\"\"\"\n",
    "    id: str\n",
    "    prompt: str\n",
    "    model: str\n",
    "    parameters: Dict[str, Any]\n",
    "    priority: int = 1\n",
    "\n",
    "@dataclass\n",
    "class InferenceResult:\n",
    "    \"\"\"æ¨ç†ç»“æœ\"\"\"\n",
    "    task_id: str\n",
    "    response: str\n",
    "    model: str\n",
    "    tokens_used: int\n",
    "    processing_time: float\n",
    "    worker_id: str\n",
    "\n",
    "class LangChainInferencePool:\n",
    "    \"\"\"LangChainæ¨ç†æ± ï¼ˆå·¥ä½œæ± æ¨¡å¼ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = 3):\n",
    "        self.worker_pool = AsyncWorkerPool(\n",
    "            max_workers=max_workers,\n",
    "            max_queue_size=100\n",
    "        )\n",
    "        self.model_stats = {}\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨æ¨ç†æ± \"\"\"\n",
    "        await self.worker_pool.start()\n",
    "        print(f\"      ğŸš€ LangChainæ¨ç†æ± å¯åŠ¨\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢æ¨ç†æ± \"\"\"\n",
    "        await self.worker_pool.stop()\n",
    "        print(f\"      ğŸ›‘ LangChainæ¨ç†æ± åœæ­¢\")\n",
    "    \n",
    "    async def submit_inference(self, task: InferenceTask) -> asyncio.Future:\n",
    "        \"\"\"æäº¤æ¨ç†ä»»åŠ¡\"\"\"\n",
    "        return await self.worker_pool.submit(\n",
    "            self._perform_inference,\n",
    "            task\n",
    "        )\n",
    "    \n",
    "    async def _perform_inference(self, task: InferenceTask) -> InferenceResult:\n",
    "        \"\"\"æ‰§è¡Œæ¨ç†ä»»åŠ¡\"\"\"\n",
    "        start_time = time.time()\n",
    "        worker_id = f\"inference-worker-{random.randint(1, 100)}\"\n",
    "        \n",
    "        # æ¨¡æ‹Ÿä¸åŒæ¨¡å‹çš„æ¨ç†æ—¶é—´\n",
    "        if task.model == \"gpt-4\":\n",
    "            processing_time = random.uniform(1.0, 3.0)\n",
    "        elif task.model == \"gpt-3.5-turbo\":\n",
    "            processing_time = random.uniform(0.5, 1.5)\n",
    "        elif task.model == \"claude-3\":\n",
    "            processing_time = random.uniform(0.8, 2.0)\n",
    "        else:\n",
    "            processing_time = random.uniform(0.3, 1.0)\n",
    "        \n",
    "        await asyncio.sleep(processing_time)\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ¨ç†ç»“æœ\n",
    "        response = f\"Model {task.model} response to '{task.prompt[:50]}...': Generated comprehensive answer.\"\n",
    "        tokens_used = len(response.split()) + len(task.prompt.split())\n",
    "        \n",
    "        actual_time = time.time() - start_time\n",
    "        \n",
    "        # æ›´æ–°æ¨¡å‹ç»Ÿè®¡\n",
    "        if task.model not in self.model_stats:\n",
    "            self.model_stats[task.model] = {\n",
    "                \"count\": 0,\n",
    "                \"total_time\": 0,\n",
    "                \"total_tokens\": 0\n",
    "            }\n",
    "        \n",
    "        self.model_stats[task.model][\"count\"] += 1\n",
    "        self.model_stats[task.model][\"total_time\"] += actual_time\n",
    "        self.model_stats[task.model][\"total_tokens\"] += tokens_used\n",
    "        \n",
    "        return InferenceResult(\n",
    "            task_id=task.id,\n",
    "            response=response,\n",
    "            model=task.model,\n",
    "            tokens_used=tokens_used,\n",
    "            processing_time=actual_time,\n",
    "            worker_id=worker_id\n",
    "        )\n",
    "    \n",
    "    def get_inference_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æ¨ç†ç»Ÿè®¡\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        for model, data in self.model_stats.items():\n",
    "            if data[\"count\"] > 0:\n",
    "                avg_time = data[\"total_time\"] / data[\"count\"]\n",
    "                avg_tokens = data[\"total_tokens\"] / data[\"count\"]\n",
    "            else:\n",
    "                avg_time = avg_tokens = 0\n",
    "            \n",
    "            stats[model] = {\n",
    "                \"count\": data[\"count\"],\n",
    "                \"average_time\": avg_time,\n",
    "                \"average_tokens\": avg_tokens,\n",
    "                \"total_tokens\": data[\"total_tokens\"]\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"model_stats\": stats,\n",
    "            \"pool_stats\": self.worker_pool.get_pool_stats()\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… LangChainæ•°æ®å¤„ç†å¹¶å‘æ¨¡å¼å®Œæˆ\")\n",
    "print(f\"      - LangChainTextProcessor: å¹¶å‘æ–‡æœ¬å¤„ç†\")\n",
    "print(f\"      - LangChainInferencePool: å¹¶å‘æ¨¡å‹æ¨ç†\")\n",
    "\n",
    "# 2. æ€§èƒ½å¯¹æ¯”å’Œä¼˜åŒ–\n",
    "print(f\"\\n   âš¡ 2. æ€§èƒ½å¯¹æ¯”å’Œä¼˜åŒ–:\")\n",
    "\n",
    "async def demonstrate_concurrent_performance():\n",
    "    \"\"\"æ¼”ç¤ºå¹¶å‘æ€§èƒ½å¯¹æ¯”\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¹¶å‘æ€§èƒ½å¯¹æ¯”æ¼”ç¤º:\")\n",
    "    \n",
    "    # 2.1 ç”Ÿäº§è€…æ¶ˆè´¹è€… vs é¡ºåºå¤„ç†\n",
    "    print(f\"\\n      2.1 ç”Ÿäº§è€…æ¶ˆè´¹è€… vs é¡ºåºå¤„ç†:\")\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡\n",
    "    test_tasks = [\n",
    "        TaskItem(\n",
    "            id=f\"task-{i}\",\n",
    "            data={\"content\": f\"Test data {i}\", \"size\": i * 10},\n",
    "            priority=random.randint(0, 2)\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    \n",
    "    # é¡ºåºå¤„ç†åŸºå‡†\n",
    "    print(f\"\\n        é¡ºåºå¤„ç†åŸºå‡†æµ‹è¯•...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sequential_results = []\n",
    "    for task in test_tasks:\n",
    "        # æ¨¡æ‹Ÿé¡ºåºå¤„ç†\n",
    "        processing_time = random.uniform(0.1, 0.5)\n",
    "        await asyncio.sleep(processing_time)\n",
    "        \n",
    "        result = {\n",
    "            \"task_id\": task.id,\n",
    "            \"processed\": True,\n",
    "            \"time\": processing_time\n",
    "        }\n",
    "        sequential_results.append(result)\n",
    "    \n",
    "    sequential_time = time.time() - start_time\n",
    "    print(f\"        é¡ºåºå¤„ç†å®Œæˆ: {len(sequential_results)} ä¸ªä»»åŠ¡ ({sequential_time:.3f}s)\")\n",
    "    \n",
    "    # ç”Ÿäº§è€…æ¶ˆè´¹è€…å¤„ç†\n",
    "    print(f\"\\n        ç”Ÿäº§è€…æ¶ˆè´¹è€…å¤„ç†æµ‹è¯•...\")\n",
    "    \n",
    "    pc_system = AsyncProducerConsumer(max_queue_size=50, max_workers=5)\n",
    "    await pc_system.start()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # æäº¤æ‰€æœ‰ä»»åŠ¡\n",
    "    for task in test_tasks:\n",
    "        await pc_system.produce(task)\n",
    "    \n",
    "    # æ”¶é›†ç»“æœ\n",
    "    pc_results = []\n",
    "    while len(pc_results) < len(test_tasks):\n",
    "        result = await pc_system.consume()\n",
    "        if result:\n",
    "            pc_results.append(result)\n",
    "    \n",
    "    pc_time = time.time() - start_time\n",
    "    pc_stats = pc_system.get_stats()\n",
    "    \n",
    "    await pc_system.stop()\n",
    "    \n",
    "    print(f\"        ç”Ÿäº§è€…æ¶ˆè´¹è€…å¤„ç†å®Œæˆ: {len(pc_results)} ä¸ªä»»åŠ¡ ({pc_time:.3f}s)\")\n",
    "    \n",
    "    # æ€§èƒ½å¯¹æ¯”\n",
    "    speedup = sequential_time / pc_time\n",
    "    print(f\"\\n        æ€§èƒ½å¯¹æ¯”ç»“æœ:\")\n",
    "    print(f\"          é¡ºåºå¤„ç†æ—¶é—´: {sequential_time:.3f}s\")\n",
    "    print(f\"          å¹¶å‘å¤„ç†æ—¶é—´: {pc_time:.3f}s\")\n",
    "    print(f\"          åŠ é€Ÿæ¯”: {speedup:.2f}x\")\n",
    "    print(f\"          æˆåŠŸç‡: {pc_stats['consumed_tasks']}/{pc_stats['produced_tasks']} ({pc_stats['consumed_tasks']/pc_stats['produced_tasks']*100:.1f}%)\")\n",
    "    \n",
    "    # 2.2 å·¥ä½œæ±  vs æ‰‡å‡ºæ‰‡å…¥\n",
    "    print(f\"\\n      2.2 å·¥ä½œæ±  vs æ‰‡å‡ºæ‰‡å…¥:\")\n",
    "    \n",
    "    # åˆ›å»ºè®¡ç®—å¯†é›†å‹ä»»åŠ¡\n",
    "    def cpu_intensive_task(n: int) -> int:\n",
    "        \"\"\"CPUå¯†é›†å‹ä»»åŠ¡\"\"\"\n",
    "        result = 0\n",
    "        for i in range(n):\n",
    "            result += i * i\n",
    "        return result\n",
    "    \n",
    "    cpu_tasks = [1000, 2000, 1500, 3000, 1200, 2500, 1800, 2200]\n",
    "    \n",
    "    # å·¥ä½œæ± å¤„ç†\n",
    "    print(f\"\\n        å·¥ä½œæ± å¤„ç†æµ‹è¯•...\")\n",
    "    \n",
    "    thread_pool = ThreadPoolWorkerPool(max_workers=4)\n",
    "    await thread_pool.start()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # æäº¤CPUå¯†é›†å‹ä»»åŠ¡\n",
    "    pool_futures = [\n",
    "        await thread_pool.submit(cpu_intensive_task, n)\n",
    "        for n in cpu_tasks\n",
    "    ]\n",
    "    \n",
    "    # ç­‰å¾…ç»“æœ\n",
    "    pool_results = []\n",
    "    for future in pool_futures:\n",
    "        pool_results.append(await future)\n",
    "    \n",
    "    pool_time = time.time() - start_time\n",
    "    pool_stats = thread_pool.get_stats()\n",
    "    \n",
    "    await thread_pool.stop()\n",
    "    \n",
    "    print(f\"        å·¥ä½œæ± å¤„ç†å®Œæˆ: {len(pool_results)} ä¸ªä»»åŠ¡ ({pool_time:.3f}s)\")\n",
    "    \n",
    "    # æ‰‡å‡ºæ‰‡å…¥å¤„ç†\n",
    "    print(f\"\\n        æ‰‡å‡ºæ‰‡å…¥å¤„ç†æµ‹è¯•...\")\n",
    "    \n",
    "    fan_out_fan_in = FanOutFanIn(max_concurrent=4)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # åˆ›å»ºä»»åŠ¡å‡½æ•°\n",
    "    fan_tasks = [\n",
    "        lambda n=n: cpu_intensive_task(n)\n",
    "        for n in cpu_tasks\n",
    "    ]\n",
    "    \n",
    "    # æ‰‡å‡ºæ‰‡å…¥å¤„ç†\n",
    "    fan_results = await fan_out_fan_in.process_batch(\n",
    "        [None] * len(cpu_tasks),  # å ä½ç¬¦\n",
    "        lambda _, n=n: cpu_intensive_task(n)  # å®é™…å¤„ç†å‡½æ•°\n",
    "    )\n",
    "    \n",
    "    fan_time = time.time() - start_time\n",
    "    fan_stats = fan_out_fan_in.get_stats()\n",
    "    \n",
    "    print(f\"        æ‰‡å‡ºæ‰‡å…¥å¤„ç†å®Œæˆ: {len(fan_results)} ä¸ªä»»åŠ¡ ({fan_time:.3f}s)\")\n",
    "    \n",
    "    # æ€§èƒ½å¯¹æ¯”\n",
    "    print(f\"\\n        CPUå¯†é›†å‹ä»»åŠ¡æ€§èƒ½å¯¹æ¯”:\")\n",
    "    print(f\"          å·¥ä½œæ± å¤„ç†æ—¶é—´: {pool_time:.3f}s\")\n",
    "    print(f\"          æ‰‡å‡ºæ‰‡å…¥å¤„ç†æ—¶é—´: {fan_time:.3f}s\")\n",
    "    print(f\"          å·¥ä½œæ± æˆåŠŸç‡: {pool_stats['success_rate']}\")\n",
    "    print(f\"          æ‰‡å‡ºæ‰‡å…¥æˆåŠŸç‡: {fan_stats['success_rate']}\")\n",
    "    \n",
    "    return {\n",
    "        \"sequential_vs_concurrent\": {\n",
    "            \"sequential_time\": sequential_time,\n",
    "            \"concurrent_time\": pc_time,\n",
    "            \"speedup\": speedup\n",
    "        },\n",
    "        \"pool_vs_fan\": {\n",
    "            \"pool_time\": pool_time,\n",
    "            \"fan_time\": fan_time\n",
    "        }\n",
    "    }\n",
    "\n",
    "# è¿è¡Œæ€§èƒ½å¯¹æ¯”æ¼”ç¤º\n",
    "performance_comparison = await demonstrate_concurrent_performance()\n",
    "print(f\"\\n   ğŸ å¹¶å‘æ€§èƒ½å¯¹æ¯”æ¼”ç¤ºå®Œæˆ\")\n",
    "\n",
    "print(f\"\\nâœ… å¹¶å‘æ¨¡å¼å®æˆ˜åº”ç”¨å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡å¹¶å‘æ¨¡å¼çš„å®é™…åº”ç”¨åœºæ™¯\")\n",
    "print(f\"   âœ“ å­¦ä¼šå¹¶å‘æ€§èƒ½è°ƒä¼˜å’Œç›‘æ§\")\n",
    "print(f\"   âœ“ ç†è§£å¹¶å‘æ¨¡å¼çš„å±€é™æ€§å’Œé€‚ç”¨æ¡ä»¶\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿè®¾è®¡é«˜æ•ˆçš„å¹¶å‘è§£å†³æ–¹æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### âœ… çŸ¥è¯†æ¸…å•è¾¾æˆæƒ…å†µéªŒè¯\n",
    "\n",
    "**6.6 å¹¶å‘ç¼–ç¨‹æ¨¡å¼ [â­â­è¿›é˜¶]**\n",
    "- âœ… æŒæ¡ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼çš„å¼‚æ­¥å®ç°\n",
    "- âœ… å­¦ä¼šå·¥ä½œæ± å’Œçº¿ç¨‹æ± çš„å¹¶å‘ç®¡ç†\n",
    "- âœ… ç†è§£æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼çš„æ•°æ®å¤„ç†æµç¨‹\n",
    "- âœ… èƒ½å¤Ÿåº”ç”¨å¹¶å‘æ¨¡å¼è§£å†³å®é™…é—®é¢˜\n",
    "- âœ… æŒæ¡å¹¶å‘æ¨¡å¼çš„å®é™…åº”ç”¨åœºæ™¯\n",
    "- âœ… å­¦ä¼šå¹¶å‘æ€§èƒ½è°ƒä¼˜å’Œç›‘æ§\n",
    "- âœ… ç†è§£å¹¶å‘æ¨¡å¼çš„å±€é™æ€§å’Œé€‚ç”¨æ¡ä»¶\n",
    "- âœ… èƒ½å¤Ÿè®¾è®¡é«˜æ•ˆçš„å¹¶å‘è§£å†³æ–¹æ¡ˆ\n",
    "- âœ… èƒ½ç‹¬ç«‹è®¾è®¡å’Œå®ç°å¹¶å‘è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "### ğŸ¯ ä¸LangChainå­¦ä¹ çš„å…³è”\n",
    "\n",
    "**å¹¶å‘ç¼–ç¨‹æ¨¡å¼é‡è¦æ€§**ï¼š\n",
    "- ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼ä¼˜åŒ–LangChainçš„æ•°æ®å¤„ç†æµç¨‹\n",
    "- å·¥ä½œæ± æ¨¡å¼æå‡LangChainçš„å¹¶å‘æ¨ç†èƒ½åŠ›\n",
    "- æ‰‡å‡ºæ‰‡å…¥æ¨¡å¼å¢å¼ºLangChainçš„å¹¶è¡Œå¤„ç†æ•ˆç‡\n",
    "- å¹¶å‘æ¨¡å¼ä¸ºLangChainçš„åˆ†å¸ƒå¼éƒ¨ç½²æä¾›åŸºç¡€\n",
    "- æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯æå‡LangChainçš„å¤§è§„æ¨¡å¤„ç†èƒ½åŠ›\n",
    "\n",
    "**å®é™…åº”ç”¨åœºæ™¯**ï¼š\n",
    "- LangChainçš„å¹¶å‘æ–‡æœ¬å¤„ç†å’Œåˆ†æ\n",
    "- LangChainçš„å¤šæ¨¡å‹å¹¶è¡Œæ¨ç†ç³»ç»Ÿ\n",
    "- LangChainçš„æ‰¹é‡æ•°æ®å¤„ç†ç®¡é“\n",
    "- LangChainçš„å®æ—¶æµå¼å¤„ç†æ¶æ„\n",
    "- LangChainçš„åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ\n",
    "\n",
    "### ğŸ“š è¿›é˜¶å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **ç»ƒä¹ å»ºè®®**ï¼š\n",
    "   - æ·±å…¥ç»ƒä¹ å¤æ‚å¹¶å‘æ¨¡å¼çš„è®¾è®¡å’Œå®ç°\n",
    "   - æŒæ¡å¹¶å‘æ€§èƒ½è°ƒä¼˜å’Œç“¶é¢ˆåˆ†ææŠ€æœ¯\n",
    "   - å­¦ä¹ åˆ†å¸ƒå¼å¹¶å‘å’Œå¾®æœåŠ¡æ¶æ„\n",
    "\n",
    "2. **æ‰©å±•å­¦ä¹ **ï¼š\n",
    "   - äº†è§£å¹¶å‘ç¼–ç¨‹çš„ç†è®ºåŸºç¡€å’Œç®—æ³•\n",
    "   - å­¦ä¹ é«˜çº§å¹¶å‘æ¨¡å¼å’Œè®¾è®¡æ¨¡å¼\n",
    "   - æ¢ç´¢å¹¶å‘ç³»ç»Ÿçš„ç›‘æ§å’Œè°ƒè¯•æŠ€æœ¯\n",
    "\n",
    "3. **å®é™…åº”ç”¨**ï¼š\n",
    "   - æ„å»ºé«˜æ€§èƒ½LangChainå¹¶å‘å¤„ç†ç³»ç»Ÿ\n",
    "   - å¼€å‘åˆ†å¸ƒå¼AIæ¨¡å‹æ¨ç†å¹³å°\n",
    "   - å®ç°å®æ—¶å¤§æ•°æ®å¤„ç†å’Œåˆ†æç³»ç»Ÿ\n",
    "\n",
    "### ğŸ”§ å¸¸è§é”™è¯¯ä¸æ³¨æ„äº‹é¡¹\n",
    "\n",
    "1. **å¹¶å‘ç«äº‰æ¡ä»¶**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ²¡æœ‰é€‚å½“çš„åŒæ­¥æœºåˆ¶\n",
    "   shared_data = []\n",
    "   \n",
    "   async def process_data(item):\n",
    "       # å¤šä¸ªåç¨‹åŒæ—¶ä¿®æ”¹å…±äº«æ•°æ®\n",
    "       shared_data.append(item)  # å¯èƒ½å¯¼è‡´æ•°æ®ç«äº‰\n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ•°æ®ç»“æ„æˆ–é”\n",
    "   import asyncio\n",
    "   shared_data = []\n",
    "   data_lock = asyncio.Lock()\n",
    "   \n",
    "   async def process_data(item):\n",
    "       async with data_lock:\n",
    "           shared_data.append(item)\n",
    "   \n",
    "   # æˆ–è€…ä½¿ç”¨é˜Ÿåˆ—\n",
    "   from asyncio import Queue\n",
    "   data_queue = Queue()\n",
    "   \n",
    "   async def process_data(item):\n",
    "       await data_queue.put(item)\n",
    "   ```\n",
    "\n",
    "2. **è¿‡åº¦å¹¶å‘å¯¼è‡´èµ„æºè€—å°½**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ— é™åˆ¶å¹¶å‘\n",
    "   async def unlimited_concurrent(tasks):\n",
    "       # å¯èƒ½åˆ›å»ºè¿‡å¤šåç¨‹ï¼Œè€—å°½ç³»ç»Ÿèµ„æº\n",
    "       return await asyncio.gather(*[\n",
    "           asyncio.create_task(process(task))\n",
    "           for task in tasks\n",
    "       ])\n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°\n",
    "   async def limited_concurrent(tasks, max_concurrent=10):\n",
    "       semaphore = asyncio.Semaphore(max_concurrent)\n",
    "       \n",
    "       async def process_with_semaphore(task):\n",
    "           async with semaphore:\n",
    "               return await process(task)\n",
    "       \n",
    "       return await asyncio.gather(*[\n",
    "           asyncio.create_task(process_with_semaphore(task))\n",
    "           for task in tasks\n",
    "       ])\n",
    "   ```\n",
    "\n",
    "3. **é˜»å¡æ“ä½œåœ¨å¼‚æ­¥ç¯å¢ƒä¸­**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šåœ¨å¼‚æ­¥å‡½æ•°ä¸­ä½¿ç”¨é˜»å¡æ“ä½œ\n",
    "   async def bad_async_function():\n",
    "       time.sleep(1)  # é˜»å¡æ•´ä¸ªäº‹ä»¶å¾ªç¯\n",
    "       result = some_blocking_io()  # é˜»å¡I/Oæ“ä½œ\n",
    "       return result\n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨å¼‚æ­¥æ“ä½œæˆ–åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ\n",
    "   import asyncio\n",
    "   from concurrent.futures import ThreadPoolExecutor\n",
    "   \n",
    "   async def good_async_function():\n",
    "       await asyncio.sleep(1)  # å¼‚æ­¥ç¡çœ \n",
    "       \n",
    "       # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œé˜»å¡æ“ä½œ\n",
    "       loop = asyncio.get_event_loop()\n",
    "       result = await loop.run_in_executor(None, some_blocking_io)\n",
    "       return result\n",
    "   ```\n",
    "\n",
    "4. **é”™è¯¯å¤„ç†ä¸å½“**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šå¿½ç•¥å¹¶å‘ä»»åŠ¡ä¸­çš„å¼‚å¸¸\n",
    "   async def process_concurrent_tasks(tasks):\n",
    "       # å¼‚å¸¸è¢«å¿½ç•¥ï¼Œå¯èƒ½å¯¼è‡´é™é»˜å¤±è´¥\n",
    "       await asyncio.gather(*[\n",
    "           asyncio.create_task(process(task))\n",
    "           for task in tasks\n",
    "       ])\n",
    "   \n",
    "   # æ­£ç¡®ï¼šé€‚å½“çš„é”™è¯¯å¤„ç†\n",
    "   async def process_concurrent_tasks(tasks):\n",
    "       results = await asyncio.gather(*[\n",
    "           asyncio.create_task(process(task))\n",
    "           for task in tasks\n",
    "       ], return_exceptions=True)\n",
    "       \n",
    "       successful_results = []\n",
    "       errors = []\n",
    "       \n",
    "       for i, result in enumerate(results):\n",
    "           if isinstance(result, Exception):\n",
    "               errors.append((i, result))\n",
    "               print(f\"ä»»åŠ¡ {i} å¤±è´¥: {result}\")\n",
    "           else:\n",
    "               successful_results.append(result)\n",
    "       \n",
    "       return successful_results, errors\n",
    "   ```\n",
    "\n",
    "5. **å†…å­˜æ³„æ¼é£é™©**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šä»»åŠ¡é˜Ÿåˆ—æ— é™å¢é•¿\n",
    "   class BadProducerConsumer:\n",
    "       def __init__(self):\n",
    "           self.task_queue = asyncio.Queue()  # æ— å¤§å°é™åˆ¶\n",
    "       \n",
    "       async def produce(self, task):\n",
    "           await self.task_queue.put(task)  # å¯èƒ½æ— é™å¢é•¿\n",
    "   \n",
    "   # æ­£ç¡®ï¼šé™åˆ¶é˜Ÿåˆ—å¤§å°å¹¶å¤„ç†æ»¡é˜Ÿåˆ—æƒ…å†µ\n",
    "   class GoodProducerConsumer:\n",
    "       def __init__(self, max_queue_size=100):\n",
    "           self.task_queue = asyncio.Queue(maxsize=max_queue_size)\n",
    "       \n",
    "       async def produce(self, task):\n",
    "           try:\n",
    "               await self.task_queue.put(task)\n",
    "               return True\n",
    "           except asyncio.QueueFull:\n",
    "               print(\"é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä»»åŠ¡\")\n",
    "               return False\n",
    "   ```\n",
    "\n",
    "6. **ä¸å…¬å¹³çš„ä»»åŠ¡è°ƒåº¦**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šé•¿ä»»åŠ¡é˜»å¡çŸ­ä»»åŠ¡\n",
    "   async def unfair_scheduler():\n",
    "       while True:\n",
    "           task = await queue.get()  # FIFOï¼Œé•¿ä»»åŠ¡å¯èƒ½é˜»å¡çŸ­ä»»åŠ¡\n",
    "           await process(task)  # é•¿ä»»åŠ¡ä¼šå ç”¨å·¥ä½œè¿›ç¨‹\n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—æˆ–ä»»åŠ¡åˆ†ç‰‡\n",
    "   async def fair_scheduler():\n",
    "       priority_queue = asyncio.PriorityQueue()\n",
    "       \n",
    "       while True:\n",
    "           priority, task = await priority_queue.get()\n",
    "           \n",
    "           # ä¸ºé•¿ä»»åŠ¡è®¾ç½®è¾ƒä½ä¼˜å…ˆçº§\n",
    "           if is_long_task(task):\n",
    "               priority = 2\n",
    "           else:\n",
    "               priority = 0\n",
    "           \n",
    "           await priority_queue.put((priority, task))\n",
    "   ```\n",
    "\n",
    "### ğŸŒ æ€§èƒ½ä¼˜åŒ–å»ºè®®\n",
    "\n",
    "**å¹¶å‘æ¨¡å¼ä¼˜åŒ–**ï¼š\n",
    "- æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„å¹¶å‘æ¨¡å¼\n",
    "- åˆç†è®¾ç½®å·¥ä½œè¿›ç¨‹æ•°é‡å’Œé˜Ÿåˆ—å¤§å°\n",
    "- ä½¿ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—ä¼˜åŒ–ä»»åŠ¡è°ƒåº¦\n",
    "- å®ç°åŠ¨æ€è´Ÿè½½å‡è¡¡å’Œèµ„æºåˆ†é…\n",
    "\n",
    "**ç³»ç»Ÿä¼˜åŒ–**ï¼š\n",
    "- ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ\n",
    "- å®ç°ä¼˜é›…é™çº§å’Œæ•…éšœæ¢å¤\n",
    "- ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—\n",
    "- ä¼˜åŒ–æ•°æ®ç»“æ„å’Œç®—æ³•å¤æ‚åº¦\n",
    "\n",
    "**ç›‘æ§å’Œè°ƒè¯•**ï¼š\n",
    "- å®ç°è¯¦ç»†çš„æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—\n",
    "- ä½¿ç”¨åˆ†æå·¥å…·è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ\n",
    "- å»ºç«‹å‘Šè­¦æœºåˆ¶å’Œè‡ªåŠ¨æ‰©å±•\n",
    "- å®šæœŸè¿›è¡Œæ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆå¹¶å‘ç¼–ç¨‹æ¨¡å¼å­¦ä¹ ï¼**\n",
    "\n",
    "ä½ å·²ç»å…¨é¢æŒæ¡äº†å¹¶å‘ç¼–ç¨‹æ¨¡å¼çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œèƒ½å¤Ÿç³»ç»Ÿæ€§åœ°è¿›è¡Œç”Ÿäº§è€…æ¶ˆè´¹è€…ã€å·¥ä½œæ± ã€æ‰‡å‡ºæ‰‡å…¥ç­‰æ¨¡å¼çš„è®¾è®¡å’Œå®ç°ï¼Œä¸ºLangChainæ™ºèƒ½åº”ç”¨æä¾›äº†å¼ºå¤§çš„å¹¶å‘å¤„ç†åŸºç¡€ã€‚\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ é¢„å‘Š\n",
    "\n",
    "**ç¬¬å…­èŠ‚ï¼šå¼‚æ­¥ç¼–ç¨‹ - è¿›è¡Œä¸­** ğŸ”„\n",
    "- 6.1 å¼‚æ­¥ç¼–ç¨‹åŸºç¡€ âœ…\n",
    "- 6.2 åç¨‹ä¸äº‹ä»¶å¾ªç¯ âœ…\n",
    "- 6.3 å¼‚æ­¥I/Oæ“ä½œ âœ…\n",
    "- 6.4 å¼‚æ­¥ç½‘ç»œç¼–ç¨‹ âœ…\n",
    "- 6.5 å¼‚æ­¥Webæ¡†æ¶ âœ…\n",
    "- 6.6 å¹¶å‘ç¼–ç¨‹æ¨¡å¼ âœ…\n",
    "- 6.7 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ— â³\n",
    "- 6.8 å¼‚æ­¥æ€§èƒ½ä¼˜åŒ– â³\n",
    "- 6.9 å¼‚æ­¥æœ€ä½³å®è·µ â³\n",
    "\n",
    "**ç»§ç»­ç¬¬å…­èŠ‚ï¼šå¼‚æ­¥ç¼–ç¨‹**\n",
    "- ä¸‹ä¸€ä¸ªï¼š6.7 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—\n",
    "- æ·±å…¥å­¦ä¹ ä»»åŠ¡é˜Ÿåˆ—å’Œåˆ†å¸ƒå¼å¤„ç†\n",
    "- æŒæ¡Celeryç±»ä¼¼çš„å¼‚æ­¥ä»»åŠ¡ç³»ç»Ÿ\n",
    "\n",
    "**åç»­ç« èŠ‚é¢„å‘Š**ï¼š\n",
    "- Webå¼€å‘æŠ€æœ¯\n",
    "- é¡¹ç›®å·¥ç¨‹å®è·µ\n",
    "\n",
    "ç»§ç»­åŠ æ²¹ï¼Œå¹¶å‘ç¼–ç¨‹æ¨¡å¼å·²ç»æŒæ¡ï¼å‡†å¤‡æ·±å…¥å­¦ä¹ å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
