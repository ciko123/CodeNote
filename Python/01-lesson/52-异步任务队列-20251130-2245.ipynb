{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 52-å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—\n",
    "\n",
    "## ğŸ“š ç”¨é€”è¯´æ˜\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "- æŒæ¡å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—çš„æ ¸å¿ƒæ¦‚å¿µå’Œå®ç°\n",
    "- å­¦ä¼šä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†å’Œè°ƒåº¦ç­–ç•¥\n",
    "- ç†è§£ä»»åŠ¡é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†\n",
    "- èƒ½å¤Ÿæ„å»ºåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\n",
    "\n",
    "**å‰ç½®è¦æ±‚**ï¼š\n",
    "- å·²å®Œæˆå¹¶å‘ç¼–ç¨‹æ¨¡å¼å­¦ä¹ \n",
    "- ç†Ÿç»ƒæŒæ¡ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼\n",
    "- äº†è§£åŸºæœ¬çš„é˜Ÿåˆ—æ•°æ®ç»“æ„\n",
    "- ç†è§£å¼‚æ­¥ç¼–ç¨‹å’Œäº‹ä»¶å¾ªç¯æœºåˆ¶\n",
    "\n",
    "**ä¸LangChainå…³è”**ï¼š\n",
    "- ä»»åŠ¡é˜Ÿåˆ—ä¼˜åŒ–LangChainçš„æ‰¹é‡å¤„ç†èƒ½åŠ›\n",
    "- ä¼˜å…ˆçº§ç®¡ç†æå‡LangChainçš„ä»»åŠ¡è°ƒåº¦æ•ˆç‡\n",
    "- é‡è¯•æœºåˆ¶ç¡®ä¿LangChainçš„å¯é æ€§\n",
    "- åˆ†å¸ƒå¼é˜Ÿåˆ—æ”¯æŒLangChainçš„æ°´å¹³æ‰©å±•\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ çŸ¥è¯†ç‚¹è¦†ç›–\n",
    "\n",
    "### 6.7 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ— [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—æ˜¯æ„å»ºé«˜æ€§èƒ½ã€å¯é å¼‚æ­¥ç³»ç»Ÿçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œå¯¹äºLangChainçš„å¤§è§„æ¨¡ä»»åŠ¡å¤„ç†å’Œåˆ†å¸ƒå¼éƒ¨ç½²å…·æœ‰é‡è¦æ„ä¹‰ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—çš„æ ¸å¿ƒæ¦‚å¿µå’Œå®ç°\n",
    "- å­¦ä¼šä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†å’Œè°ƒåº¦ç­–ç•¥\n",
    "- ç†è§£ä»»åŠ¡é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†\n",
    "- èƒ½å¤Ÿæ„å»ºåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\n",
    "- è¿›è¡Œä»»åŠ¡é˜Ÿåˆ—æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–\n",
    "- åº”ç”¨ä»»åŠ¡é˜Ÿåˆ—è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è®¾è®¡å’Œå®ç°ä»»åŠ¡é˜Ÿåˆ—è§£å†³æ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import asyncio\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import pickle\n",
    "import hashlib\n",
    "from typing import List, Dict, Any, Optional, Callable, Union\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from enum import Enum\n",
    "from collections import deque\n",
    "import weakref\n",
    "\n",
    "print(f\"âœ… Pythonç‰ˆæœ¬: {__import__('sys').version}\")\n",
    "print(f\"âœ… å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—åŸºç¡€\n",
    "print(f\"ğŸ“ 1. å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—åŸºç¡€:\")\n",
    "\n",
    "# 1.1 ä»»åŠ¡çŠ¶æ€å’Œç±»å‹å®šä¹‰\n",
    "print(f\"\\n   ğŸ” 1.1 ä»»åŠ¡çŠ¶æ€å’Œç±»å‹å®šä¹‰:\")\n",
    "\n",
    "class TaskStatus(Enum):\n",
    "    \"\"\"ä»»åŠ¡çŠ¶æ€æšä¸¾\"\"\"\n",
    "    PENDING = \"pending\"      # ç­‰å¾…æ‰§è¡Œ\n",
    "    RUNNING = \"running\"      # æ­£åœ¨æ‰§è¡Œ\n",
    "    COMPLETED = \"completed\"  # æ‰§è¡Œå®Œæˆ\n",
    "    FAILED = \"failed\"        # æ‰§è¡Œå¤±è´¥\n",
    "    RETRYING = \"retrying\"    # é‡è¯•ä¸­\n",
    "    CANCELLED = \"cancelled\"  # å·²å–æ¶ˆ\n",
    "\n",
    "class TaskPriority(Enum):\n",
    "    \"\"\"ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾\"\"\"\n",
    "    LOW = 3      # ä½ä¼˜å…ˆçº§\n",
    "    NORMAL = 2   # æ™®é€šä¼˜å…ˆçº§\n",
    "    HIGH = 1     # é«˜ä¼˜å…ˆçº§\n",
    "    URGENT = 0   # ç´§æ€¥ä¼˜å…ˆçº§\n",
    "\n",
    "@dataclass\n",
    "class AsyncTask:\n",
    "    \"\"\"å¼‚æ­¥ä»»åŠ¡\"\"\"\n",
    "    id: str\n",
    "    func: Callable\n",
    "    args: tuple = field(default_factory=tuple)\n",
    "    kwargs: dict = field(default_factory=dict)\n",
    "    priority: TaskPriority = TaskPriority.NORMAL\n",
    "    max_retries: int = 3\n",
    "    timeout: float = 30.0\n",
    "    created_at: float = field(default_factory=time.time)\n",
    "    scheduled_at: float = field(default_factory=time.time)\n",
    "    \n",
    "    # è¿è¡Œæ—¶çŠ¶æ€\n",
    "    status: TaskStatus = TaskStatus.PENDING\n",
    "    retry_count: int = 0\n",
    "    started_at: Optional[float] = None\n",
    "    completed_at: Optional[float] = None\n",
    "    result: Any = None\n",
    "    error: Optional[str] = None\n",
    "    worker_id: Optional[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.id:\n",
    "            self.id = str(uuid.uuid4())\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºåºåˆ—åŒ–ï¼‰\"\"\"\n",
    "        data = asdict(self)\n",
    "        # è½¬æ¢æšä¸¾ä¸ºå­—ç¬¦ä¸²\n",
    "        data['priority'] = self.priority.value\n",
    "        data['status'] = self.status.value\n",
    "        # å‡½æ•°å¯¹è±¡æ— æ³•åºåˆ—åŒ–ï¼Œå­˜å‚¨å‡½æ•°å\n",
    "        data['func_name'] = self.func.__name__ if hasattr(self.func, '__name__') else str(self.func)\n",
    "        data.pop('func', None)\n",
    "        return data\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict[str, Any], func: Callable) -> 'AsyncTask':\n",
    "        \"\"\"ä»å­—å…¸åˆ›å»ºä»»åŠ¡\"\"\"\n",
    "        # è½¬æ¢å­—ç¬¦ä¸²ä¸ºæšä¸¾\n",
    "        data['priority'] = TaskPriority(data['priority'])\n",
    "        data['status'] = TaskStatus(data['status'])\n",
    "        data['func'] = func\n",
    "        data.pop('func_name', None)\n",
    "        return cls(**data)\n",
    "\n",
    "@dataclass\n",
    "class TaskResult:\n",
    "    \"\"\"ä»»åŠ¡ç»“æœ\"\"\"\n",
    "    task_id: str\n",
    "    status: TaskStatus\n",
    "    result: Any = None\n",
    "    error: Optional[str] = None\n",
    "    execution_time: float = 0.0\n",
    "    worker_id: Optional[str] = None\n",
    "    completed_at: float = field(default_factory=time.time)\n",
    "\n",
    "print(f\"   âœ… ä»»åŠ¡çŠ¶æ€å’Œç±»å‹å®šä¹‰å®Œæˆ\")\n",
    "print(f\"      - TaskStatus: {', '.join([s.value for s in TaskStatus])}\")\n",
    "print(f\"      - TaskPriority: {', '.join([p.name for p in TaskPriority])}\")\n",
    "print(f\"      - AsyncTask: å¼‚æ­¥ä»»åŠ¡æ•°æ®ç»“æ„\")\n",
    "print(f\"      - TaskResult: ä»»åŠ¡ç»“æœæ•°æ®ç»“æ„\")\n",
    "\n",
    "# 1.2 åŸºç¡€å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—\n",
    "print(f\"\\n   ğŸ—ï¸ 1.2 åŸºç¡€å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—:\")\n",
    "\n",
    "class AsyncTaskQueue:\n",
    "    \"\"\"åŸºç¡€å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "    \n",
    "    def __init__(self, max_queue_size: int = 1000, max_workers: int = 5):\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.max_workers = max_workers\n",
    "        \n",
    "        # ä¼˜å…ˆçº§é˜Ÿåˆ—\n",
    "        self.task_queue = asyncio.PriorityQueue(maxsize=max_queue_size)\n",
    "        self.result_queue = asyncio.Queue(maxsize=max_queue_size)\n",
    "        \n",
    "        # ä»»åŠ¡å­˜å‚¨\n",
    "        self.tasks: Dict[str, AsyncTask] = {}\n",
    "        self.task_results: Dict[str, TaskResult] = {}\n",
    "        \n",
    "        # å·¥ä½œè¿›ç¨‹\n",
    "        self.workers: List[asyncio.Task] = []\n",
    "        self.running = False\n",
    "        \n",
    "        # ç»Ÿè®¡ä¿¡æ¯\n",
    "        self.stats = {\n",
    "            \"total_tasks\": 0,\n",
    "            \"completed_tasks\": 0,\n",
    "            \"failed_tasks\": 0,\n",
    "            \"retry_count\": 0,\n",
    "            \"total_execution_time\": 0.0\n",
    "        }\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨ä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "        if self.running:\n",
    "            return\n",
    "        \n",
    "        self.running = True\n",
    "        \n",
    "        # å¯åŠ¨å·¥ä½œè¿›ç¨‹\n",
    "        self.workers = [\n",
    "            asyncio.create_task(self._worker(f\"worker-{i}\"))\n",
    "            for i in range(self.max_workers)\n",
    "        ]\n",
    "        \n",
    "        print(f\"      ğŸš€ å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å¯åŠ¨ ({self.max_workers} ä¸ªå·¥ä½œè¿›ç¨‹)\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢ä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "        if not self.running:\n",
    "            return\n",
    "        \n",
    "        self.running = False\n",
    "        \n",
    "        # å–æ¶ˆæ‰€æœ‰å·¥ä½œè¿›ç¨‹\n",
    "        for worker in self.workers:\n",
    "            worker.cancel()\n",
    "        \n",
    "        # ç­‰å¾…å·¥ä½œè¿›ç¨‹å®Œæˆ\n",
    "        await asyncio.gather(*self.workers, return_exceptions=True)\n",
    "        \n",
    "        print(f\"      ğŸ›‘ å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—åœæ­¢\")\n",
    "    \n",
    "    async def submit(self, func: Callable, *args, \n",
    "                     priority: TaskPriority = TaskPriority.NORMAL,\n",
    "                     max_retries: int = 3, \n",
    "                     timeout: float = 30.0,\n",
    "                     **kwargs) -> str:\n",
    "        \"\"\"æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—\"\"\"\n",
    "        task = AsyncTask(\n",
    "            id=str(uuid.uuid4()),\n",
    "            func=func,\n",
    "            args=args,\n",
    "            kwargs=kwargs,\n",
    "            priority=priority,\n",
    "            max_retries=max_retries,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            await self.task_queue.put((task.priority.value, task.id))\n",
    "            self.tasks[task.id] = task\n",
    "            self.stats[\"total_tasks\"] += 1\n",
    "            \n",
    "            print(f\"      ğŸ“¤ ä»»åŠ¡æäº¤: {task.id} (ä¼˜å…ˆçº§: {task.priority.name})\")\n",
    "            return task.id\n",
    "            \n",
    "        except asyncio.QueueFull:\n",
    "            raise Exception(\"ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡\")\n",
    "    \n",
    "    async def get_result(self, task_id: str, timeout: float = None) -> Optional[TaskResult]:\n",
    "        \"\"\"è·å–ä»»åŠ¡ç»“æœ\"\"\"\n",
    "        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰ç»“æœ\n",
    "        if task_id in self.task_results:\n",
    "            return self.task_results[task_id]\n",
    "        \n",
    "        # ç­‰å¾…ç»“æœ\n",
    "        try:\n",
    "            if timeout:\n",
    "                result = await asyncio.wait_for(self.result_queue.get(), timeout=timeout)\n",
    "            else:\n",
    "                result = await self.result_queue.get()\n",
    "            \n",
    "            self.task_results[result.task_id] = result\n",
    "            \n",
    "            if result.task_id == task_id:\n",
    "                return result\n",
    "            else:\n",
    "                # ä¸æ˜¯æˆ‘ä»¬è¦çš„ç»“æœï¼Œæ”¾å›é˜Ÿåˆ—\n",
    "                await self.result_queue.put(result)\n",
    "                return None\n",
    "                \n",
    "        except asyncio.TimeoutError:\n",
    "            return None\n",
    "    \n",
    "    async def cancel_task(self, task_id: str) -> bool:\n",
    "        \"\"\"å–æ¶ˆä»»åŠ¡\"\"\"\n",
    "        if task_id in self.tasks:\n",
    "            task = self.tasks[task_id]\n",
    "            if task.status in [TaskStatus.PENDING, TaskStatus.RETRYING]:\n",
    "                task.status = TaskStatus.CANCELLED\n",
    "                print(f\"      âŒ ä»»åŠ¡å–æ¶ˆ: {task_id}\")\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    async def _worker(self, worker_id: str):\n",
    "        \"\"\"å·¥ä½œè¿›ç¨‹\"\"\"\n",
    "        print(f\"      ğŸ‘· {worker_id} å¼€å§‹å·¥ä½œ\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # è·å–ä»»åŠ¡\n",
    "                priority, task_id = await asyncio.wait_for(\n",
    "                    self.task_queue.get(), \n",
    "                    timeout=1.0\n",
    "                )\n",
    "                \n",
    "                if task_id not in self.tasks:\n",
    "                    continue\n",
    "                \n",
    "                task = self.tasks[task_id]\n",
    "                \n",
    "                # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€\n",
    "                if task.status == TaskStatus.CANCELLED:\n",
    "                    continue\n",
    "                \n",
    "                # æ£€æŸ¥è°ƒåº¦æ—¶é—´\n",
    "                if task.scheduled_at > time.time():\n",
    "                    # é‡æ–°æ”¾å›é˜Ÿåˆ—\n",
    "                    await self.task_queue.put((task.priority.value, task.id))\n",
    "                    await asyncio.sleep(0.1)\n",
    "                    continue\n",
    "                \n",
    "                # æ‰§è¡Œä»»åŠ¡\n",
    "                await self._execute_task(task, worker_id)\n",
    "                \n",
    "            except asyncio.TimeoutError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ {worker_id} å·¥ä½œè¿›ç¨‹é”™è¯¯: {e}\")\n",
    "        \n",
    "        print(f\"      ğŸ‘· {worker_id} åœæ­¢å·¥ä½œ\")\n",
    "    \n",
    "    async def _execute_task(self, task: AsyncTask, worker_id: str):\n",
    "        \"\"\"æ‰§è¡Œä»»åŠ¡\"\"\"\n",
    "        task.status = TaskStatus.RUNNING\n",
    "        task.started_at = time.time()\n",
    "        task.worker_id = worker_id\n",
    "        \n",
    "        try:\n",
    "            # æ‰§è¡Œä»»åŠ¡\n",
    "            if asyncio.iscoroutinefunction(task.func):\n",
    "                result = await asyncio.wait_for(\n",
    "                    task.func(*task.args, **task.kwargs),\n",
    "                    timeout=task.timeout\n",
    "                )\n",
    "            else:\n",
    "                # åŒæ­¥å‡½æ•°åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ\n",
    "                loop = asyncio.get_event_loop()\n",
    "                result = await asyncio.wait_for(\n",
    "                    loop.run_in_executor(None, task.func, *task.args, **task.kwargs),\n",
    "                    timeout=task.timeout\n",
    "                )\n",
    "            \n",
    "            # ä»»åŠ¡æˆåŠŸ\n",
    "            task.status = TaskStatus.COMPLETED\n",
    "            task.completed_at = time.time()\n",
    "            task.result = result\n",
    "            \n",
    "            execution_time = task.completed_at - task.started_at\n",
    "            \n",
    "            # åˆ›å»ºç»“æœ\n",
    "            task_result = TaskResult(\n",
    "                task_id=task.id,\n",
    "                status=TaskStatus.COMPLETED,\n",
    "                result=result,\n",
    "                execution_time=execution_time,\n",
    "                worker_id=worker_id\n",
    "            )\n",
    "            \n",
    "            await self.result_queue.put(task_result)\n",
    "            \n",
    "            # æ›´æ–°ç»Ÿè®¡\n",
    "            self.stats[\"completed_tasks\"] += 1\n",
    "            self.stats[\"total_execution_time\"] += execution_time\n",
    "            \n",
    "            print(f\"      âœ… {worker_id} å®Œæˆä»»åŠ¡: {task.id} ({execution_time:.3f}s)\")\n",
    "            \n",
    "        except asyncio.TimeoutError:\n",
    "            # ä»»åŠ¡è¶…æ—¶\n",
    "            await self._handle_task_failure(task, \"ä»»åŠ¡æ‰§è¡Œè¶…æ—¶\", worker_id)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # ä»»åŠ¡å¤±è´¥\n",
    "            await self._handle_task_failure(task, str(e), worker_id)\n",
    "    \n",
    "    async def _handle_task_failure(self, task: AsyncTask, error: str, worker_id: str):\n",
    "        \"\"\"å¤„ç†ä»»åŠ¡å¤±è´¥\"\"\"\n",
    "        task.error = error\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•\n",
    "        if task.retry_count < task.max_retries:\n",
    "            task.retry_count += 1\n",
    "            task.status = TaskStatus.RETRYING\n",
    "            task.scheduled_at = time.time() + (2 ** task.retry_count)  # æŒ‡æ•°é€€é¿\n",
    "            \n",
    "            # é‡æ–°æ”¾å…¥é˜Ÿåˆ—\n",
    "            await self.task_queue.put((task.priority.value, task.id))\n",
    "            \n",
    "            self.stats[\"retry_count\"] += 1\n",
    "            print(f\"      ğŸ”„ {worker_id} ä»»åŠ¡é‡è¯•: {task.id} (ç¬¬{task.retry_count}æ¬¡)\")\n",
    "            \n",
    "        else:\n",
    "            # ä»»åŠ¡æœ€ç»ˆå¤±è´¥\n",
    "            task.status = TaskStatus.FAILED\n",
    "            task.completed_at = time.time()\n",
    "            \n",
    "            execution_time = task.completed_at - task.started_at if task.started_at else 0\n",
    "            \n",
    "            task_result = TaskResult(\n",
    "                task_id=task.id,\n",
    "                status=TaskStatus.FAILED,\n",
    "                error=error,\n",
    "                execution_time=execution_time,\n",
    "                worker_id=worker_id\n",
    "            )\n",
    "            \n",
    "            await self.result_queue.put(task_result)\n",
    "            \n",
    "            self.stats[\"failed_tasks\"] += 1\n",
    "            print(f\"      âŒ {worker_id} ä»»åŠ¡å¤±è´¥: {task.id} - {error}\")\n",
    "    \n",
    "    def get_queue_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        stats = self.stats.copy()\n",
    "        \n",
    "        # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´\n",
    "        if stats[\"completed_tasks\"] > 0:\n",
    "            stats[\"average_execution_time\"] = (\n",
    "                stats[\"total_execution_time\"] / stats[\"completed_tasks\"]\n",
    "            )\n",
    "        else:\n",
    "            stats[\"average_execution_time\"] = 0\n",
    "        \n",
    "        # è®¡ç®—æˆåŠŸç‡\n",
    "        total_processed = stats[\"completed_tasks\"] + stats[\"failed_tasks\"]\n",
    "        if total_processed > 0:\n",
    "            stats[\"success_rate\"] = f\"{stats['completed_tasks']/total_processed*100:.1f}%\"\n",
    "        else:\n",
    "            stats[\"success_rate\"] = \"0%\"\n",
    "        \n",
    "        stats[\"queue_size\"] = self.task_queue.qsize()\n",
    "        stats[\"result_queue_size\"] = self.result_queue.qsize()\n",
    "        stats[\"active_workers\"] = len(self.workers)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def get_task_status(self, task_id: str) -> Optional[TaskStatus]:\n",
    "        \"\"\"è·å–ä»»åŠ¡çŠ¶æ€\"\"\"\n",
    "        if task_id in self.tasks:\n",
    "            return self.tasks[task_id].status\n",
    "        return None\n",
    "\n",
    "print(f\"   âœ… åŸºç¡€å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å®Œæˆ\")\n",
    "print(f\"      - AsyncTaskQueue: æ ¸å¿ƒä»»åŠ¡é˜Ÿåˆ—å®ç°\")\n",
    "print(f\"      - æ”¯æŒä¼˜å…ˆçº§ã€é‡è¯•ã€è¶…æ—¶æœºåˆ¶\")\n",
    "print(f\"      - å®Œæ•´çš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†\")\n",
    "\n",
    "print(f\"\\nâœ… å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—åŸºç¡€å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—çš„æ ¸å¿ƒæ¦‚å¿µå’Œå®ç°\")\n",
    "print(f\"   âœ“ å­¦ä¼šä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†å’Œè°ƒåº¦ç­–ç•¥\")\n",
    "print(f\"   âœ“ ç†è§£ä»»åŠ¡é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿæ„å»ºåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é«˜çº§ä»»åŠ¡é˜Ÿåˆ—ç‰¹æ€§ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šé«˜çº§ä»»åŠ¡é˜Ÿåˆ—ç‰¹æ€§æ˜¯æ„å»ºç”Ÿäº§çº§å¼‚æ­¥ç³»ç»Ÿçš„å…³é”®ï¼Œå¯¹äºLangChainçš„ä¼ä¸šçº§éƒ¨ç½²å’Œé«˜å¯é æ€§è¦æ±‚å…·æœ‰é‡è¦æ„ä¹‰ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡ä»»åŠ¡æŒä¹…åŒ–å’Œæ¢å¤æœºåˆ¶\n",
    "- å­¦ä¼šåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—è®¾è®¡\n",
    "- ç†è§£ä»»åŠ¡ç›‘æ§å’Œè°ƒè¯•æŠ€æœ¯\n",
    "- èƒ½å¤Ÿå®ç°é«˜å¯ç”¨ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—\n",
    "- è¿›è¡Œä»»åŠ¡é˜Ÿåˆ—é«˜å¯ç”¨æµ‹è¯•\n",
    "- åº”ç”¨é«˜çº§ç‰¹æ€§è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è®¾è®¡ä¼ä¸šçº§ä»»åŠ¡é˜Ÿåˆ—è§£å†³æ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸš€ é«˜çº§ä»»åŠ¡é˜Ÿåˆ—ç‰¹æ€§:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 2. åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—\n",
    "print(f\"ğŸ“ 2. åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—:\")\n",
    "\n",
    "# 2.1 ä»»åŠ¡æŒä¹…åŒ–\n",
    "print(f\"\\n   ğŸ” 2.1 ä»»åŠ¡æŒä¹…åŒ–:\")\n",
    "\n",
    "class TaskPersistence:\n",
    "    \"\"\"ä»»åŠ¡æŒä¹…åŒ–ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, storage_path: str = \"./task_storage\"):\n",
    "        self.storage_path = storage_path\n",
    "        self.task_files = {}\n",
    "        self.result_files = {}\n",
    "    \n",
    "    async def save_task(self, task: AsyncTask) -> bool:\n",
    "        \"\"\"ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            filename = f\"{self.storage_path}/task_{task.id}.json\"\n",
    "            \n",
    "            # åºåˆ—åŒ–ä»»åŠ¡æ•°æ®\n",
    "            task_data = task.to_dict()\n",
    "            \n",
    "            # å†™å…¥æ–‡ä»¶ï¼ˆæ¨¡æ‹ŸæŒä¹…åŒ–ï¼‰\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(task_data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            self.task_files[task.id] = filename\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ ä¿å­˜ä»»åŠ¡å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def load_task(self, task_id: str, func_registry: Dict[str, Callable]) -> Optional[AsyncTask]:\n",
    "        \"\"\"ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡\"\"\"\n",
    "        try:\n",
    "            filename = f\"{self.storage_path}/task_{task_id}.json\"\n",
    "            \n",
    "            if not os.path.exists(filename):\n",
    "                return None\n",
    "            \n",
    "            # è¯»å–æ–‡ä»¶\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                task_data = json.load(f)\n",
    "            \n",
    "            # è·å–å‡½æ•°\n",
    "            func_name = task_data.get('func_name')\n",
    "            if func_name not in func_registry:\n",
    "                print(f\"      âš ï¸ å‡½æ•° {func_name} æœªæ³¨å†Œ\")\n",
    "                return None\n",
    "            \n",
    "            # é‡å»ºä»»åŠ¡\n",
    "            task = AsyncTask.from_dict(task_data, func_registry[func_name])\n",
    "            \n",
    "            self.task_files[task_id] = filename\n",
    "            return task\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ åŠ è½½ä»»åŠ¡å¤±è´¥: {e}\")\n",
    "            return None\n",
    "    \n",
    "    async def save_result(self, result: TaskResult) -> bool:\n",
    "        \"\"\"ä¿å­˜ç»“æœåˆ°æ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            filename = f\"{self.storage_path}/result_{result.task_id}.json\"\n",
    "            \n",
    "            result_data = asdict(result)\n",
    "            result_data['status'] = result.status.value\n",
    "            \n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(result_data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            self.result_files[result.task_id] = filename\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def load_pending_tasks(self, func_registry: Dict[str, Callable]) -> List[AsyncTask]:\n",
    "        \"\"\"åŠ è½½æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡\"\"\"\n",
    "        pending_tasks = []\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(self.storage_path):\n",
    "                os.makedirs(self.storage_path)\n",
    "                return pending_tasks\n",
    "            \n",
    "            # æ‰«æä»»åŠ¡æ–‡ä»¶\n",
    "            for filename in os.listdir(self.storage_path):\n",
    "                if filename.startswith(\"task_\") and filename.endswith(\".json\"):\n",
    "                    task_id = filename[5:-5]  # æå–ä»»åŠ¡ID\n",
    "                    \n",
    "                    task = await self.load_task(task_id, func_registry)\n",
    "                    if task and task.status in [TaskStatus.PENDING, TaskStatus.RETRYING]:\n",
    "                        pending_tasks.append(task)\n",
    "            \n",
    "            print(f\"      ğŸ“‚ åŠ è½½äº† {len(pending_tasks)} ä¸ªå¾…å¤„ç†ä»»åŠ¡\")\n",
    "            return pending_tasks\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ åŠ è½½å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: {e}\")\n",
    "            return pending_tasks\n",
    "    \n",
    "    async def delete_task(self, task_id: str) -> bool:\n",
    "        \"\"\"åˆ é™¤ä»»åŠ¡æ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            if task_id in self.task_files:\n",
    "                os.remove(self.task_files[task_id])\n",
    "                del self.task_files[task_id]\n",
    "            \n",
    "            if task_id in self.result_files:\n",
    "                os.remove(self.result_files[task_id])\n",
    "                del self.result_files[task_id]\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ åˆ é™¤ä»»åŠ¡æ–‡ä»¶å¤±è´¥: {e}\")\n",
    "            return False\n",
    "\n",
    "# 2.2 åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—\n",
    "print(f\"\\n   ğŸŒ 2.2 åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—:\")\n",
    "\n",
    "class DistributedTaskQueue:\n",
    "    \"\"\"åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str, max_workers: int = 5, \n",
    "                 storage_path: str = \"./distributed_tasks\"):\n",
    "        self.node_id = node_id\n",
    "        self.max_workers = max_workers\n",
    "        \n",
    "        # åŸºç¡€é˜Ÿåˆ—\n",
    "        self.task_queue = AsyncTaskQueue(\n",
    "            max_queue_size=1000, \n",
    "            max_workers=max_workers\n",
    "        )\n",
    "        \n",
    "        # æŒä¹…åŒ–\n",
    "        self.persistence = TaskPersistence(storage_path)\n",
    "        \n",
    "        # å‡½æ•°æ³¨å†Œè¡¨\n",
    "        self.func_registry: Dict[str, Callable] = {}\n",
    "        \n",
    "        # èŠ‚ç‚¹ç®¡ç†\n",
    "        self.active_nodes: Dict[str, Dict[str, Any]] = {}\n",
    "        self.node_heartbeat_interval = 30.0\n",
    "        \n",
    "        # ä»»åŠ¡åˆ†å‘\n",
    "        self.task_distribution = {}\n",
    "        self.load_balancer = LoadBalancer()\n",
    "        \n",
    "        # ç›‘æ§\n",
    "        self.monitor = TaskMonitor()\n",
    "    \n",
    "    def register_function(self, name: str, func: Callable):\n",
    "        \"\"\"æ³¨å†Œå¯æ‰§è¡Œå‡½æ•°\"\"\"\n",
    "        self.func_registry[name] = func\n",
    "        print(f\"      ğŸ“ æ³¨å†Œå‡½æ•°: {name}\")\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "        print(f\"      ğŸš€ å¯åŠ¨åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—èŠ‚ç‚¹: {self.node_id}\")\n",
    "        \n",
    "        # å¯åŠ¨åŸºç¡€é˜Ÿåˆ—\n",
    "        await self.task_queue.start()\n",
    "        \n",
    "        # åŠ è½½æŒä¹…åŒ–ä»»åŠ¡\n",
    "        pending_tasks = await self.persistence.load_pending_tasks(self.func_registry)\n",
    "        \n",
    "        # é‡æ–°æäº¤å¾…å¤„ç†ä»»åŠ¡\n",
    "        for task in pending_tasks:\n",
    "            await self.task_queue.task_queue.put((task.priority.value, task.id))\n",
    "            self.task_queue.tasks[task.id] = task\n",
    "        \n",
    "        # å¯åŠ¨å¿ƒè·³\n",
    "        asyncio.create_task(self._heartbeat_loop())\n",
    "        \n",
    "        # å¯åŠ¨ç›‘æ§\n",
    "        asyncio.create_task(self._monitor_loop())\n",
    "        \n",
    "        print(f\"      âœ… åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—å¯åŠ¨å®Œæˆ\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "        print(f\"      ğŸ›‘ åœæ­¢åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—èŠ‚ç‚¹: {self.node_id}\")\n",
    "        \n",
    "        await self.task_queue.stop()\n",
    "        \n",
    "        print(f\"      âœ… åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—åœæ­¢å®Œæˆ\")\n",
    "    \n",
    "    async def submit_task(self, func_name: str, *args, \n",
    "                          priority: TaskPriority = TaskPriority.NORMAL,\n",
    "                          **kwargs) -> str:\n",
    "        \"\"\"æäº¤åˆ†å¸ƒå¼ä»»åŠ¡\"\"\"\n",
    "        if func_name not in self.func_registry:\n",
    "            raise ValueError(f\"å‡½æ•° {func_name} æœªæ³¨å†Œ\")\n",
    "        \n",
    "        # åˆ›å»ºä»»åŠ¡\n",
    "        task_id = await self.task_queue.submit(\n",
    "            self.func_registry[func_name],\n",
    "            *args,\n",
    "            priority=priority,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # æŒä¹…åŒ–ä»»åŠ¡\n",
    "        task = self.task_queue.tasks[task_id]\n",
    "        await self.persistence.save_task(task)\n",
    "        \n",
    "        # è®°å½•åˆ†å‘ä¿¡æ¯\n",
    "        self.task_distribution[task_id] = {\n",
    "            \"submitted_by\": self.node_id,\n",
    "            \"submitted_at\": time.time(),\n",
    "            \"func_name\": func_name\n",
    "        }\n",
    "        \n",
    "        return task_id\n",
    "    \n",
    "    async def get_task_result(self, task_id: str, timeout: float = None) -> Optional[TaskResult]:\n",
    "        \"\"\"è·å–ä»»åŠ¡ç»“æœ\"\"\"\n",
    "        # é¦–å…ˆå°è¯•ä»å†…å­˜è·å–\n",
    "        result = await self.task_queue.get_result(task_id, timeout)\n",
    "        if result:\n",
    "            # æŒä¹…åŒ–ç»“æœ\n",
    "            await self.persistence.save_result(result)\n",
    "            return result\n",
    "        \n",
    "        # å°è¯•ä»æŒä¹…åŒ–å­˜å‚¨è·å–\n",
    "        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä»æ–‡ä»¶åŠ è½½\n",
    "        return None\n",
    "    \n",
    "    async def add_node(self, node_id: str, node_info: Dict[str, Any]):\n",
    "        \"\"\"æ·»åŠ èŠ‚ç‚¹\"\"\"\n",
    "        self.active_nodes[node_id] = {\n",
    "            **node_info,\n",
    "            \"last_heartbeat\": time.time(),\n",
    "            \"status\": \"active\"\n",
    "        }\n",
    "        print(f\"      ğŸ”— æ·»åŠ èŠ‚ç‚¹: {node_id}\")\n",
    "    \n",
    "    async def remove_node(self, node_id: str):\n",
    "        \"\"\"ç§»é™¤èŠ‚ç‚¹\"\"\"\n",
    "        if node_id in self.active_nodes:\n",
    "            self.active_nodes[node_id][\"status\"] = \"inactive\"\n",
    "            print(f\"      âŒ ç§»é™¤èŠ‚ç‚¹: {node_id}\")\n",
    "    \n",
    "    async def _heartbeat_loop(self):\n",
    "        \"\"\"å¿ƒè·³å¾ªç¯\"\"\"\n",
    "        while self.task_queue.running:\n",
    "            try:\n",
    "                # æ›´æ–°è‡ªå·±çš„å¿ƒè·³\n",
    "                self.active_nodes[self.node_id] = {\n",
    "                    \"last_heartbeat\": time.time(),\n",
    "                    \"status\": \"active\",\n",
    "                    \"queue_size\": self.task_queue.task_queue.qsize(),\n",
    "                    \"workers\": self.task_queue.max_workers\n",
    "                }\n",
    "                \n",
    "                # æ£€æŸ¥å…¶ä»–èŠ‚ç‚¹å¿ƒè·³\n",
    "                current_time = time.time()\n",
    "                inactive_nodes = []\n",
    "                \n",
    "                for node_id, node_info in self.active_nodes.items():\n",
    "                    if node_id != self.node_id:\n",
    "                        if current_time - node_info[\"last_heartbeat\"] > self.node_heartbeat_interval * 2:\n",
    "                            inactive_nodes.append(node_id)\n",
    "                \n",
    "                # ç§»é™¤ä¸æ´»è·ƒèŠ‚ç‚¹\n",
    "                for node_id in inactive_nodes:\n",
    "                    await self.remove_node(node_id)\n",
    "                \n",
    "                await asyncio.sleep(self.node_heartbeat_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ å¿ƒè·³å¾ªç¯é”™è¯¯: {e}\")\n",
    "                await asyncio.sleep(5)\n",
    "    \n",
    "    async def _monitor_loop(self):\n",
    "        \"\"\"ç›‘æ§å¾ªç¯\"\"\"\n",
    "        while self.task_queue.running:\n",
    "            try:\n",
    "                # æ”¶é›†ç›‘æ§æ•°æ®\n",
    "                stats = self.task_queue.get_queue_stats()\n",
    "                \n",
    "                # æ›´æ–°ç›‘æ§å™¨\n",
    "                self.monitor.update_stats(self.node_id, stats)\n",
    "                \n",
    "                # æ£€æŸ¥å‘Šè­¦æ¡ä»¶\n",
    "                await self._check_alerts(stats)\n",
    "                \n",
    "                await asyncio.sleep(10)  # æ¯10ç§’ç›‘æ§ä¸€æ¬¡\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ ç›‘æ§å¾ªç¯é”™è¯¯: {e}\")\n",
    "                await asyncio.sleep(5)\n",
    "    \n",
    "    async def _check_alerts(self, stats: Dict[str, Any]):\n",
    "        \"\"\"æ£€æŸ¥å‘Šè­¦æ¡ä»¶\"\"\"\n",
    "        # é˜Ÿåˆ—ç§¯å‹å‘Šè­¦\n",
    "        if stats[\"queue_size\"] > 100:\n",
    "            print(f\"      ğŸš¨ å‘Šè­¦: ä»»åŠ¡é˜Ÿåˆ—ç§¯å‹ä¸¥é‡ ({stats['queue_size']} ä¸ªä»»åŠ¡)\")\n",
    "        \n",
    "        # å¤±è´¥ç‡å‘Šè­¦\n",
    "        total_processed = stats[\"completed_tasks\"] + stats[\"failed_tasks\"]\n",
    "        if total_processed > 10:\n",
    "            failure_rate = stats[\"failed_tasks\"] / total_processed\n",
    "            if failure_rate > 0.1:  # å¤±è´¥ç‡è¶…è¿‡10%\n",
    "                print(f\"      ğŸš¨ å‘Šè­¦: ä»»åŠ¡å¤±è´¥ç‡è¿‡é«˜ ({failure_rate*100:.1f}%)\")\n",
    "        \n",
    "        # æ‰§è¡Œæ—¶é—´å‘Šè­¦\n",
    "        if stats[\"average_execution_time\"] > 30.0:\n",
    "            print(f\"      ğŸš¨ å‘Šè­¦: å¹³å‡æ‰§è¡Œæ—¶é—´è¿‡é•¿ ({stats['average_execution_time']:.1f}s)\")\n",
    "    \n",
    "    def get_cluster_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–é›†ç¾¤ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        return {\n",
    "            \"node_id\": self.node_id,\n",
    "            \"active_nodes\": len(self.active_nodes),\n",
    "            \"node_list\": list(self.active_nodes.keys()),\n",
    "            \"queue_stats\": self.task_queue.get_queue_stats(),\n",
    "            \"registered_functions\": list(self.func_registry.keys()),\n",
    "            \"monitor_data\": self.monitor.get_summary()\n",
    "        }\n",
    "\n",
    "# 2.3 è´Ÿè½½å‡è¡¡å™¨\n",
    "print(f\"\\n   âš–ï¸ 2.3 è´Ÿè½½å‡è¡¡å™¨:\")\n",
    "\n",
    "class LoadBalancer:\n",
    "    \"\"\"ä»»åŠ¡è´Ÿè½½å‡è¡¡å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.node_weights: Dict[str, float] = {}\n",
    "        self.task_assignments: Dict[str, str] = {}  # task_id -> node_id\n",
    "    \n",
    "    def select_node(self, available_nodes: List[str], \n",
    "                    task_priority: TaskPriority = TaskPriority.NORMAL) -> Optional[str]:\n",
    "        \"\"\"é€‰æ‹©æ‰§è¡ŒèŠ‚ç‚¹\"\"\"\n",
    "        if not available_nodes:\n",
    "            return None\n",
    "        \n",
    "        # ç®€å•çš„è½®è¯¢ç­–ç•¥\n",
    "        # å®é™…åº”è¯¥æ ¹æ®èŠ‚ç‚¹è´Ÿè½½ã€ä»»åŠ¡ç±»å‹ç­‰é€‰æ‹©\n",
    "        \n",
    "        # è®¡ç®—æƒé‡\n",
    "        weights = []\n",
    "        for node_id in available_nodes:\n",
    "            weight = self.node_weights.get(node_id, 1.0)\n",
    "            weights.append(weight)\n",
    "        \n",
    "        # é€‰æ‹©æƒé‡æœ€é«˜çš„èŠ‚ç‚¹\n",
    "        max_weight_index = weights.index(max(weights))\n",
    "        selected_node = available_nodes[max_weight_index]\n",
    "        \n",
    "        # æ›´æ–°æƒé‡ï¼ˆé™ä½é€‰ä¸­èŠ‚ç‚¹çš„æƒé‡ï¼‰\n",
    "        self.node_weights[selected_node] = max(0.1, weight - 0.1)\n",
    "        \n",
    "        # æ¢å¤å…¶ä»–èŠ‚ç‚¹æƒé‡\n",
    "        for node_id in available_nodes:\n",
    "            if node_id != selected_node:\n",
    "                self.node_weights[node_id] = min(2.0, self.node_weights.get(node_id, 1.0) + 0.05)\n",
    "        \n",
    "        return selected_node\n",
    "    \n",
    "    def assign_task(self, task_id: str, node_id: str):\n",
    "        \"\"\"åˆ†é…ä»»åŠ¡åˆ°èŠ‚ç‚¹\"\"\"\n",
    "        self.task_assignments[task_id] = node_id\n",
    "    \n",
    "    def get_node_load(self, node_id: str) -> int:\n",
    "        \"\"\"è·å–èŠ‚ç‚¹è´Ÿè½½\"\"\"\n",
    "        return sum(1 for assigned_node in self.task_assignments.values() \n",
    "                  if assigned_node == node_id)\n",
    "\n",
    "# 2.4 ä»»åŠ¡ç›‘æ§å™¨\n",
    "print(f\"\\n   ğŸ“Š 2.4 ä»»åŠ¡ç›‘æ§å™¨:\")\n",
    "\n",
    "class TaskMonitor:\n",
    "    \"\"\"ä»»åŠ¡ç›‘æ§å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics_history: Dict[str, List[Dict[str, Any]]] = {}\n",
    "        self.alerts: List[Dict[str, Any]] = []\n",
    "        self.max_history = 1000\n",
    "    \n",
    "    def update_stats(self, node_id: str, stats: Dict[str, Any]):\n",
    "        \"\"\"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        timestamp = time.time()\n",
    "        \n",
    "        if node_id not in self.metrics_history:\n",
    "            self.metrics_history[node_id] = []\n",
    "        \n",
    "        metrics = {\n",
    "            \"timestamp\": timestamp,\n",
    "            **stats\n",
    "        }\n",
    "        \n",
    "        self.metrics_history[node_id].append(metrics)\n",
    "        \n",
    "        # é™åˆ¶å†å²è®°å½•é•¿åº¦\n",
    "        if len(self.metrics_history[node_id]) > self.max_history:\n",
    "            self.metrics_history[node_id] = self.metrics_history[node_id][-self.max_history:]\n",
    "    \n",
    "    def add_alert(self, alert_type: str, message: str, severity: str = \"warning\"):\n",
    "        \"\"\"æ·»åŠ å‘Šè­¦\"\"\"\n",
    "        alert = {\n",
    "            \"type\": alert_type,\n",
    "            \"message\": message,\n",
    "            \"severity\": severity,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        \n",
    "        self.alerts.append(alert)\n",
    "        \n",
    "        # é™åˆ¶å‘Šè­¦å†å²\n",
    "        if len(self.alerts) > 100:\n",
    "            self.alerts = self.alerts[-100:]\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ç›‘æ§æ‘˜è¦\"\"\"\n",
    "        return {\n",
    "            \"monitored_nodes\": len(self.metrics_history),\n",
    "            \"total_alerts\": len(self.alerts),\n",
    "            \"recent_alerts\": self.alerts[-10:],\n",
    "            \"node_metrics\": {\n",
    "                node_id: len(history) \n",
    "                for node_id, history in self.metrics_history.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "# åˆ›å»ºå­˜å‚¨ç›®å½•\n",
    "import os\n",
    "if not os.path.exists(\"./distributed_tasks\"):\n",
    "    os.makedirs(\"./distributed_tasks\")\n",
    "\n",
    "print(f\"   âœ… åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—å®Œæˆ\")\n",
    "print(f\"      - TaskPersistence: ä»»åŠ¡æŒä¹…åŒ–ç®¡ç†\")\n",
    "print(f\"      - DistributedTaskQueue: åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—\")\n",
    "print(f\"      - LoadBalancer: è´Ÿè½½å‡è¡¡å™¨\")\n",
    "print(f\"      - TaskMonitor: ä»»åŠ¡ç›‘æ§å™¨\")\n",
    "\n",
    "print(f\"\\nâœ… é«˜çº§ä»»åŠ¡é˜Ÿåˆ—ç‰¹æ€§å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡ä»»åŠ¡æŒä¹…åŒ–å’Œæ¢å¤æœºåˆ¶\")\n",
    "print(f\"   âœ“ å­¦ä¼šåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—è®¾è®¡\")\n",
    "print(f\"   âœ“ ç†è§£ä»»åŠ¡ç›‘æ§å’Œè°ƒè¯•æŠ€æœ¯\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå®ç°é«˜å¯ç”¨ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChainä»»åŠ¡é˜Ÿåˆ—åº”ç”¨ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šLangChainä»»åŠ¡é˜Ÿåˆ—åº”ç”¨æ˜¯æŒæ¡AIç³»ç»Ÿå¼‚æ­¥å¤„ç†çš„å…³é”®ï¼Œå¯¹äºLangChainçš„å¤§è§„æ¨¡æ¨¡å‹æ¨ç†å’Œæ•°æ®å¤„ç†å…·æœ‰é‡è¦æ„ä¹‰ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡LangChainä»»åŠ¡çš„å¼‚æ­¥å¤„ç†æ¨¡å¼\n",
    "- å­¦ä¼šAIæ¨¡å‹æ¨ç†çš„é˜Ÿåˆ—ç®¡ç†\n",
    "- ç†è§£LangChainå·¥ä½œæµçš„å¼‚æ­¥ç¼–æ’\n",
    "- èƒ½å¤Ÿæ„å»ºé«˜æ€§èƒ½LangChainå¤„ç†ç³»ç»Ÿ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„LangChainä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\n",
    "- è¿›è¡ŒAIå·¥ä½œæµçš„å¼‚æ­¥ç¼–æ’\n",
    "- åº”ç”¨ä»»åŠ¡é˜Ÿåˆ—è§£å†³LangChainå®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è®¾è®¡é«˜æ€§èƒ½AIå¼‚æ­¥å¤„ç†ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ¤– LangChainä»»åŠ¡é˜Ÿåˆ—åº”ç”¨:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 3. LangChainå¼‚æ­¥ä»»åŠ¡å¤„ç†\n",
    "print(f\"ğŸ“ 3. LangChainå¼‚æ­¥ä»»åŠ¡å¤„ç†:\")\n",
    "\n",
    "# 3.1 AIæ¨¡å‹æ¨ç†ä»»åŠ¡\n",
    "print(f\"\\n   ğŸ” 3.1 AIæ¨¡å‹æ¨ç†ä»»åŠ¡:\")\n",
    "\n",
    "@dataclass\n",
    "class LLMInferenceTask:\n",
    "    \"\"\"LLMæ¨ç†ä»»åŠ¡\"\"\"\n",
    "    task_id: str\n",
    "    prompt: str\n",
    "    model_name: str\n",
    "    max_tokens: int = 1000\n",
    "    temperature: float = 0.7\n",
    "    context: Dict[str, Any] = field(default_factory=dict)\n",
    "    priority: TaskPriority = TaskPriority.NORMAL\n",
    "    \n",
    "@dataclass\n",
    "class LLMInferenceResult:\n",
    "    \"\"\"LLMæ¨ç†ç»“æœ\"\"\"\n",
    "    task_id: str\n",
    "    response: str\n",
    "    model_name: str\n",
    "    tokens_used: int\n",
    "    processing_time: float\n",
    "    confidence: float\n",
    "    worker_id: str\n",
    "\n",
    "class LangChainTaskQueue:\n",
    "    \"\"\"LangChainä¸“ç”¨ä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = 3):\n",
    "        self.base_queue = AsyncTaskQueue(max_workers=max_workers)\n",
    "        self.model_pools: Dict[str, List[str]] = {}\n",
    "        self.request_limits: Dict[str, Dict[str, float]] = {}\n",
    "        self.inference_stats = {\n",
    "            \"total_requests\": 0,\n",
    "            \"successful_requests\": 0,\n",
    "            \"failed_requests\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"total_response_time\": 0.0\n",
    "        }\n",
    "    \n",
    "    async def start(self):\n",
    "        \"\"\"å¯åŠ¨LangChainä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "        await self.base_queue.start()\n",
    "        \n",
    "        # åˆå§‹åŒ–æ¨¡å‹æ± \n",
    "        self.model_pools = {\n",
    "            \"gpt-4\": [f\"gpt-4-worker-{i}\" for i in range(2)],\n",
    "            \"gpt-3.5-turbo\": [f\"gpt-3.5-worker-{i}\" for i in range(3)],\n",
    "            \"claude-3\": [f\"claude-3-worker-{i}\" for i in range(2)]\n",
    "        }\n",
    "        \n",
    "        # åˆå§‹åŒ–è¯·æ±‚é™åˆ¶\n",
    "        self.request_limits = {\n",
    "            \"gpt-4\": {\"rate_limit\": 10.0, \"last_request\": 0},\n",
    "            \"gpt-3.5-turbo\": {\"rate_limit\": 20.0, \"last_request\": 0},\n",
    "            \"claude-3\": {\"rate_limit\": 15.0, \"last_request\": 0}\n",
    "        }\n",
    "        \n",
    "        print(f\"      ğŸš€ LangChainä»»åŠ¡é˜Ÿåˆ—å¯åŠ¨\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"åœæ­¢LangChainä»»åŠ¡é˜Ÿåˆ—\"\"\"\n",
    "        await self.base_queue.stop()\n",
    "        print(f\"      ğŸ›‘ LangChainä»»åŠ¡é˜Ÿåˆ—åœæ­¢\")\n",
    "    \n",
    "    async def submit_inference(self, llm_task: LLMInferenceTask) -> str:\n",
    "        \"\"\"æäº¤LLMæ¨ç†ä»»åŠ¡\"\"\"\n",
    "        # æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§\n",
    "        if llm_task.model_name not in self.model_pools:\n",
    "            raise ValueError(f\"ä¸æ”¯æŒçš„æ¨¡å‹: {llm_task.model_name}\")\n",
    "        \n",
    "        # æ£€æŸ¥è¯·æ±‚é™åˆ¶\n",
    "        await self._check_rate_limit(llm_task.model_name)\n",
    "        \n",
    "        # åˆ›å»ºæ¨ç†å‡½æ•°\n",
    "        inference_func = self._create_inference_function(llm_task)\n",
    "        \n",
    "        # æäº¤ä»»åŠ¡\n",
    "        task_id = await self.base_queue.submit(\n",
    "            inference_func,\n",
    "            priority=llm_task.priority,\n",
    "            timeout=60.0  # LLMæ¨ç†è¶…æ—¶æ—¶é—´\n",
    "        )\n",
    "        \n",
    "        # å­˜å‚¨ä»»åŠ¡æ˜ å°„\n",
    "        self.base_queue.tasks[task_id].context = {\n",
    "            \"llm_task\": llm_task,\n",
    "            \"original_task_id\": llm_task.task_id\n",
    "        }\n",
    "        \n",
    "        self.inference_stats[\"total_requests\"] += 1\n",
    "        \n",
    "        print(f\"      ğŸ“¤ æäº¤LLMæ¨ç†ä»»åŠ¡: {llm_task.task_id} (æ¨¡å‹: {llm_task.model_name})\")\n",
    "        return task_id\n",
    "    \n",
    "    async def get_inference_result(self, task_id: str, timeout: float = None) -> Optional[LLMInferenceResult]:\n",
    "        \"\"\"è·å–æ¨ç†ç»“æœ\"\"\"\n",
    "        result = await self.base_queue.get_result(task_id, timeout)\n",
    "        \n",
    "        if result and result.status == TaskStatus.COMPLETED:\n",
    "            return result.result\n",
    "        elif result and result.status == TaskStatus.FAILED:\n",
    "            self.inference_stats[\"failed_requests\"] += 1\n",
    "            return None\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _create_inference_function(self, llm_task: LLMInferenceTask) -> Callable:\n",
    "        \"\"\"åˆ›å»ºæ¨ç†å‡½æ•°\"\"\"\n",
    "        async def inference_function():\n",
    "            return await self._perform_llm_inference(llm_task)\n",
    "        \n",
    "        return inference_function\n",
    "    \n",
    "    async def _perform_llm_inference(self, llm_task: LLMInferenceTask) -> LLMInferenceResult:\n",
    "        \"\"\"æ‰§è¡ŒLLMæ¨ç†\"\"\"\n",
    "        start_time = time.time()\n",
    "        worker_id = f\"llm-worker-{random.randint(1, 100)}\"\n",
    "        \n",
    "        # æ¨¡æ‹Ÿä¸åŒæ¨¡å‹çš„æ¨ç†æ—¶é—´\n",
    "        if llm_task.model_name == \"gpt-4\":\n",
    "            processing_time = random.uniform(2.0, 5.0)\n",
    "        elif llm_task.model_name == \"gpt-3.5-turbo\":\n",
    "            processing_time = random.uniform(1.0, 3.0)\n",
    "        elif llm_task.model_name == \"claude-3\":\n",
    "            processing_time = random.uniform(1.5, 4.0)\n",
    "        else:\n",
    "            processing_time = random.uniform(1.0, 2.0)\n",
    "        \n",
    "        await asyncio.sleep(processing_time)\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ¨ç†ç»“æœ\n",
    "        response_length = min(llm_task.max_tokens, random.randint(100, 800))\n",
    "        response = f\"Model {llm_task.model_name} response to '{llm_task.prompt[:50]}...' \"\n",
    "        response += f\"with {response_length} tokens of comprehensive analysis. \"\n",
    "        response += f\"Temperature {llm_task.temperature} applied for creativity.\"\n",
    "        \n",
    "        tokens_used = response_length + len(llm_task.prompt.split())\n",
    "        confidence = random.uniform(0.8, 0.95)\n",
    "        \n",
    "        actual_time = time.time() - start_time\n",
    "        \n",
    "        # æ›´æ–°ç»Ÿè®¡\n",
    "        self.inference_stats[\"successful_requests\"] += 1\n",
    "        self.inference_stats[\"total_tokens\"] += tokens_used\n",
    "        self.inference_stats[\"total_response_time\"] += actual_time\n",
    "        \n",
    "        return LLMInferenceResult(\n",
    "            task_id=llm_task.task_id,\n",
    "            response=response,\n",
    "            model_name=llm_task.model_name,\n",
    "            tokens_used=tokens_used,\n",
    "            processing_time=actual_time,\n",
    "            confidence=confidence,\n",
    "            worker_id=worker_id\n",
    "        )\n",
    "    \n",
    "    async def _check_rate_limit(self, model_name: str):\n",
    "        \"\"\"æ£€æŸ¥è¯·æ±‚é™åˆ¶\"\"\"\n",
    "        if model_name not in self.request_limits:\n",
    "            return\n",
    "        \n",
    "        limit_info = self.request_limits[model_name]\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…\n",
    "        time_since_last = current_time - limit_info[\"last_request\"]\n",
    "        min_interval = 60.0 / limit_info[\"rate_limit\"]  # æ¯ç§’è¯·æ±‚æ•°è½¬æ¢ä¸ºé—´éš”\n",
    "        \n",
    "        if time_since_last < min_interval:\n",
    "            wait_time = min_interval - time_since_last\n",
    "            await asyncio.sleep(wait_time)\n",
    "        \n",
    "        limit_info[\"last_request\"] = time.time()\n",
    "    \n",
    "    def get_inference_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æ¨ç†ç»Ÿè®¡\"\"\"\n",
    "        stats = self.inference_stats.copy()\n",
    "        \n",
    "        # è®¡ç®—å¹³å‡å€¼\n",
    "        if stats[\"successful_requests\"] > 0:\n",
    "            stats[\"average_tokens\"] = stats[\"total_tokens\"] / stats[\"successful_requests\"]\n",
    "            stats[\"average_response_time\"] = stats[\"total_response_time\"] / stats[\"successful_requests\"]\n",
    "        else:\n",
    "            stats[\"average_tokens\"] = 0\n",
    "            stats[\"average_response_time\"] = 0\n",
    "        \n",
    "        # è®¡ç®—æˆåŠŸç‡\n",
    "        total = stats[\"total_requests\"]\n",
    "        if total > 0:\n",
    "            stats[\"success_rate\"] = f\"{stats['successful_requests']/total*100:.1f}%\"\n",
    "        else:\n",
    "            stats[\"success_rate\"] = \"0%\"\n",
    "        \n",
    "        stats[\"queue_stats\"] = self.base_queue.get_queue_stats()\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# 3.2 LangChainå·¥ä½œæµç¼–æ’\n",
    "print(f\"\\n   ğŸ”„ 3.2 LangChainå·¥ä½œæµç¼–æ’:\")\n",
    "\n",
    "@dataclass\n",
    "class WorkflowStep:\n",
    "    \"\"\"å·¥ä½œæµæ­¥éª¤\"\"\"\n",
    "    step_id: str\n",
    "    name: str\n",
    "    func: Callable\n",
    "    depends_on: List[str] = field(default_factory=list)\n",
    "    retry_count: int = 3\n",
    "    timeout: float = 30.0\n",
    "\n",
    "@dataclass\n",
    "class Workflow:\n",
    "    \"\"\"å·¥ä½œæµå®šä¹‰\"\"\"\n",
    "    workflow_id: str\n",
    "    name: str\n",
    "    steps: List[WorkflowStep]\n",
    "    created_at: float = field(default_factory=time.time)\n",
    "\n",
    "@dataclass\n",
    "class WorkflowExecution:\n",
    "    \"\"\"å·¥ä½œæµæ‰§è¡Œ\"\"\"\n",
    "    execution_id: str\n",
    "    workflow_id: str\n",
    "    step_results: Dict[str, Any] = field(default_factory=dict)\n",
    "    step_status: Dict[str, TaskStatus] = field(default_factory=dict)\n",
    "    started_at: float = field(default_factory=time.time)\n",
    "    completed_at: Optional[float] = None\n",
    "    status: TaskStatus = TaskStatus.PENDING\n",
    "\n",
    "class LangChainWorkflowEngine:\n",
    "    \"\"\"LangChainå·¥ä½œæµå¼•æ“\"\"\"\n",
    "    \n",
    "    def __init__(self, task_queue: LangChainTaskQueue):\n",
    "        self.task_queue = task_queue\n",
    "        self.workflows: Dict[str, Workflow] = {}\n",
    "        self.executions: Dict[str, WorkflowExecution] = {}\n",
    "        self.workflow_stats = {\n",
    "            \"total_workflows\": 0,\n",
    "            \"completed_workflows\": 0,\n",
    "            \"failed_workflows\": 0,\n",
    "            \"total_steps\": 0,\n",
    "            \"completed_steps\": 0\n",
    "        }\n",
    "    \n",
    "    def register_workflow(self, workflow: Workflow):\n",
    "        \"\"\"æ³¨å†Œå·¥ä½œæµ\"\"\"\n",
    "        self.workflows[workflow.workflow_id] = workflow\n",
    "        print(f\"      ğŸ“ æ³¨å†Œå·¥ä½œæµ: {workflow.name} ({len(workflow.steps)} ä¸ªæ­¥éª¤)\")\n",
    "    \n",
    "    async def execute_workflow(self, workflow_id: str, \n",
    "                               context: Dict[str, Any] = None) -> str:\n",
    "        \"\"\"æ‰§è¡Œå·¥ä½œæµ\"\"\"\n",
    "        if workflow_id not in self.workflows:\n",
    "            raise ValueError(f\"å·¥ä½œæµ {workflow_id} æœªæ³¨å†Œ\")\n",
    "        \n",
    "        workflow = self.workflows[workflow_id]\n",
    "        execution_id = str(uuid.uuid4())\n",
    "        \n",
    "        # åˆ›å»ºæ‰§è¡Œå®ä¾‹\n",
    "        execution = WorkflowExecution(\n",
    "            execution_id=execution_id,\n",
    "            workflow_id=workflow_id\n",
    "        )\n",
    "        \n",
    "        self.executions[execution_id] = execution\n",
    "        self.workflow_stats[\"total_workflows\"] += 1\n",
    "        self.workflow_stats[\"total_steps\"] += len(workflow.steps)\n",
    "        \n",
    "        print(f\"      ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow.name}\")\n",
    "        \n",
    "        # æ‰§è¡Œå·¥ä½œæµ\n",
    "        try:\n",
    "            await self._execute_workflow_steps(workflow, execution, context or {})\n",
    "            \n",
    "            execution.status = TaskStatus.COMPLETED\n",
    "            execution.completed_at = time.time()\n",
    "            \n",
    "            self.workflow_stats[\"completed_workflows\"] += 1\n",
    "            print(f\"      âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {workflow.name} ({execution.completed_at - execution.started_at:.3f}s)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution.status = TaskStatus.FAILED\n",
    "            execution.completed_at = time.time()\n",
    "            \n",
    "            self.workflow_stats[\"failed_workflows\"] += 1\n",
    "            print(f\"      âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {workflow.name} - {e}\")\n",
    "        \n",
    "        return execution_id\n",
    "    \n",
    "    async def _execute_workflow_steps(self, workflow: Workflow, \n",
    "                                      execution: WorkflowExecution, \n",
    "                                      context: Dict[str, Any]):\n",
    "        \"\"\"æ‰§è¡Œå·¥ä½œæµæ­¥éª¤\"\"\"\n",
    "        # æ„å»ºä¾èµ–å›¾\n",
    "        dependency_graph = self._build_dependency_graph(workflow)\n",
    "        \n",
    "        # æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œæ­¥éª¤\n",
    "        executed_steps = set()\n",
    "        \n",
    "        while len(executed_steps) < len(workflow.steps):\n",
    "            # æ‰¾åˆ°å¯ä»¥æ‰§è¡Œçš„æ­¥éª¤\n",
    "            ready_steps = []\n",
    "            \n",
    "            for step in workflow.steps:\n",
    "                if step.step_id not in executed_steps:\n",
    "                    # æ£€æŸ¥ä¾èµ–æ˜¯å¦å®Œæˆ\n",
    "                    dependencies_met = all(\n",
    "                        dep in executed_steps \n",
    "                        for dep in step.depends_on\n",
    "                    )\n",
    "                    \n",
    "                    if dependencies_met:\n",
    "                        ready_steps.append(step)\n",
    "            \n",
    "            if not ready_steps:\n",
    "                raise Exception(\"å·¥ä½œæµä¾èµ–å¾ªç¯æˆ–æœªæ»¡è¶³çš„ä¾èµ–\")\n",
    "            \n",
    "            # å¹¶å‘æ‰§è¡Œå°±ç»ªçš„æ­¥éª¤\n",
    "            step_tasks = []\n",
    "            \n",
    "            for step in ready_steps:\n",
    "                execution.step_status[step.step_id] = TaskStatus.RUNNING\n",
    "                \n",
    "                step_task = asyncio.create_task(\n",
    "                    self._execute_workflow_step(step, execution, context)\n",
    "                )\n",
    "                step_tasks.append(step_task)\n",
    "            \n",
    "            # ç­‰å¾…æ‰€æœ‰æ­¥éª¤å®Œæˆ\n",
    "            step_results = await asyncio.gather(*step_tasks, return_exceptions=True)\n",
    "            \n",
    "            # å¤„ç†ç»“æœ\n",
    "            for i, result in enumerate(step_results):\n",
    "                step = ready_steps[i]\n",
    "                \n",
    "                if isinstance(result, Exception):\n",
    "                    execution.step_status[step.step_id] = TaskStatus.FAILED\n",
    "                    raise result\n",
    "                else:\n",
    "                    execution.step_results[step.step_id] = result\n",
    "                    execution.step_status[step.step_id] = TaskStatus.COMPLETED\n",
    "                    executed_steps.add(step.step_id)\n",
    "                    self.workflow_stats[\"completed_steps\"] += 1\n",
    "                    \n",
    "                    print(f\"      âœ… æ­¥éª¤å®Œæˆ: {step.name}\")\n",
    "    \n",
    "    async def _execute_workflow_step(self, step: WorkflowStep, \n",
    "                                     execution: WorkflowExecution, \n",
    "                                     context: Dict[str, Any]) -> Any:\n",
    "        \"\"\"æ‰§è¡Œå•ä¸ªå·¥ä½œæµæ­¥éª¤\"\"\"\n",
    "        try:\n",
    "            # å‡†å¤‡æ­¥éª¤å‚æ•°\n",
    "            step_context = {\n",
    "                **context,\n",
    "                \"step_results\": execution.step_results,\n",
    "                \"workflow_execution\": execution\n",
    "            }\n",
    "            \n",
    "            # æ‰§è¡Œæ­¥éª¤\n",
    "            if asyncio.iscoroutinefunction(step.func):\n",
    "                result = await asyncio.wait_for(\n",
    "                    step.func(step_context),\n",
    "                    timeout=step.timeout\n",
    "                )\n",
    "            else:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                result = await asyncio.wait_for(\n",
    "                    loop.run_in_executor(None, step.func, step_context),\n",
    "                    timeout=step.timeout\n",
    "                )\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except asyncio.TimeoutError:\n",
    "            raise Exception(f\"æ­¥éª¤ {step.name} æ‰§è¡Œè¶…æ—¶\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"æ­¥éª¤ {step.name} æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "    \n",
    "    def _build_dependency_graph(self, workflow: Workflow) -> Dict[str, List[str]]:\n",
    "        \"\"\"æ„å»ºä¾èµ–å›¾\"\"\"\n",
    "        graph = {}\n",
    "        \n",
    "        for step in workflow.steps:\n",
    "            graph[step.step_id] = step.depends_on.copy()\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def get_workflow_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–å·¥ä½œæµç»Ÿè®¡\"\"\"\n",
    "        stats = self.workflow_stats.copy()\n",
    "        \n",
    "        # è®¡ç®—æˆåŠŸç‡\n",
    "        total = stats[\"total_workflows\"]\n",
    "        if total > 0:\n",
    "            stats[\"workflow_success_rate\"] = f\"{stats['completed_workflows']/total*100:.1f}%\"\n",
    "        else:\n",
    "            stats[\"workflow_success_rate\"] = \"0%\"\n",
    "        \n",
    "        # è®¡ç®—æ­¥éª¤æˆåŠŸç‡\n",
    "        total_steps = stats[\"total_steps\"]\n",
    "        if total_steps > 0:\n",
    "            stats[\"step_success_rate\"] = f\"{stats['completed_steps']/total_steps*100:.1f}%\"\n",
    "        else:\n",
    "            stats[\"step_success_rate\"] = \"0%\"\n",
    "        \n",
    "        stats[\"registered_workflows\"] = len(self.workflows)\n",
    "        stats[\"active_executions\"] = len([\n",
    "            e for e in self.executions.values() \n",
    "            if e.status == TaskStatus.RUNNING\n",
    "        ])\n",
    "        \n",
    "        return stats\n",
    "\n",
    "print(f\"   âœ… LangChainä»»åŠ¡é˜Ÿåˆ—åº”ç”¨å®Œæˆ\")\n",
    "print(f\"      - LangChainTaskQueue: LangChainä¸“ç”¨ä»»åŠ¡é˜Ÿåˆ—\")\n",
    "print(f\"      - LangChainWorkflowEngine: å·¥ä½œæµç¼–æ’å¼•æ“\")\n",
    "print(f\"      - æ”¯æŒLLMæ¨ç†ä»»åŠ¡å’Œå¤æ‚å·¥ä½œæµ\")\n",
    "\n",
    "print(f\"\\nâœ… LangChainä»»åŠ¡é˜Ÿåˆ—åº”ç”¨å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡LangChainä»»åŠ¡çš„å¼‚æ­¥å¤„ç†æ¨¡å¼\")\n",
    "print(f\"   âœ“ å­¦ä¼šAIæ¨¡å‹æ¨ç†çš„é˜Ÿåˆ—ç®¡ç†\")\n",
    "print(f\"   âœ“ ç†è§£LangChainå·¥ä½œæµçš„å¼‚æ­¥ç¼–æ’\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿæ„å»ºé«˜æ€§èƒ½LangChainå¤„ç†ç³»ç»Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### âœ… çŸ¥è¯†æ¸…å•è¾¾æˆæƒ…å†µéªŒè¯\n",
    "\n",
    "**6.7 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ— [â­â­è¿›é˜¶]**\n",
    "- âœ… æŒæ¡å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—çš„æ ¸å¿ƒæ¦‚å¿µå’Œå®ç°\n",
    "- âœ… å­¦ä¼šä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†å’Œè°ƒåº¦ç­–ç•¥\n",
    "- âœ… ç†è§£ä»»åŠ¡é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†\n",
    "- âœ… èƒ½å¤Ÿæ„å»ºåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\n",
    "- âœ… æŒæ¡ä»»åŠ¡æŒä¹…åŒ–å’Œæ¢å¤æœºåˆ¶\n",
    "- âœ… å­¦ä¼šåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—è®¾è®¡\n",
    "- âœ… ç†è§£ä»»åŠ¡ç›‘æ§å’Œè°ƒè¯•æŠ€æœ¯\n",
    "- âœ… èƒ½å¤Ÿå®ç°é«˜å¯ç”¨ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ\n",
    "- âœ… æŒæ¡LangChainä»»åŠ¡çš„å¼‚æ­¥å¤„ç†æ¨¡å¼\n",
    "- âœ… å­¦ä¼šAIæ¨¡å‹æ¨ç†çš„é˜Ÿåˆ—ç®¡ç†\n",
    "- âœ… ç†è§£LangChainå·¥ä½œæµçš„å¼‚æ­¥ç¼–æ’\n",
    "- âœ… èƒ½å¤Ÿæ„å»ºé«˜æ€§èƒ½LangChainå¤„ç†ç³»ç»Ÿ\n",
    "- âœ… èƒ½ç‹¬ç«‹è®¾è®¡å’Œå®ç°ä»»åŠ¡é˜Ÿåˆ—è§£å†³æ–¹æ¡ˆ\n",
    "- âœ… èƒ½ç‹¬ç«‹è®¾è®¡ä¼ä¸šçº§ä»»åŠ¡é˜Ÿåˆ—è§£å†³æ–¹æ¡ˆ\n",
    "- âœ… èƒ½ç‹¬ç«‹è®¾è®¡é«˜æ€§èƒ½AIå¼‚æ­¥å¤„ç†ç³»ç»Ÿ\n",
    "\n",
    "### ğŸ¯ ä¸LangChainå­¦ä¹ çš„å…³è”\n",
    "\n",
    "**å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—é‡è¦æ€§**ï¼š\n",
    "- ä»»åŠ¡é˜Ÿåˆ—ä¼˜åŒ–LangChainçš„æ‰¹é‡å¤„ç†èƒ½åŠ›\n",
    "- ä¼˜å…ˆçº§ç®¡ç†æå‡LangChainçš„ä»»åŠ¡è°ƒåº¦æ•ˆç‡\n",
    "- é‡è¯•æœºåˆ¶ç¡®ä¿LangChainçš„å¯é æ€§\n",
    "- åˆ†å¸ƒå¼é˜Ÿåˆ—æ”¯æŒLangChainçš„æ°´å¹³æ‰©å±•\n",
    "- å·¥ä½œæµç¼–æ’å¢å¼ºLangChainçš„å¤æ‚ä»»åŠ¡å¤„ç†\n",
    "\n",
    "**å®é™…åº”ç”¨åœºæ™¯**ï¼š\n",
    "- LangChainçš„å¤§è§„æ¨¡æ¨¡å‹æ¨ç†é˜Ÿåˆ—\n",
    "- LangChainçš„æ–‡æ¡£å¤„ç†å’Œåˆ†ææµæ°´çº¿\n",
    "- LangChainçš„å¤šæ­¥éª¤AIå·¥ä½œæµè‡ªåŠ¨åŒ–\n",
    "- LangChainçš„å®æ—¶å¯¹è¯å’Œå“åº”ç³»ç»Ÿ\n",
    "- LangChainçš„åˆ†å¸ƒå¼AIæœåŠ¡éƒ¨ç½²\n",
    "\n",
    "### ğŸ“š è¿›é˜¶å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **ç»ƒä¹ å»ºè®®**ï¼š\n",
    "   - æ·±å…¥ç»ƒä¹ å¤æ‚ä»»åŠ¡é˜Ÿåˆ—çš„è®¾è®¡å’Œå®ç°\n",
    "   - æŒæ¡åˆ†å¸ƒå¼ç³»ç»Ÿçš„åè°ƒå’Œé€šä¿¡æœºåˆ¶\n",
    "   - å­¦ä¹ å¤§è§„æ¨¡ä»»åŠ¡è°ƒåº¦å’Œè´Ÿè½½å‡è¡¡ç®—æ³•\n",
    "\n",
    "2. **æ‰©å±•å­¦ä¹ **ï¼š\n",
    "   - äº†è§£æ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿï¼ˆRabbitMQã€Kafkaï¼‰\n",
    "   - å­¦ä¹ å®¹å™¨åŒ–å’Œå¾®æœåŠ¡æ¶æ„\n",
    "   - æ¢ç´¢äº‘åŸç”Ÿä»»åŠ¡è°ƒåº¦å¹³å°\n",
    "\n",
    "3. **å®é™…åº”ç”¨**ï¼š\n",
    "   - æ„å»ºç”Ÿäº§çº§LangChainä»»åŠ¡å¤„ç†ç³»ç»Ÿ\n",
    "   - å¼€å‘åˆ†å¸ƒå¼AIæ¨¡å‹æ¨ç†å¹³å°\n",
    "   - å®ç°ä¼ä¸šçº§å·¥ä½œæµè‡ªåŠ¨åŒ–ç³»ç»Ÿ\n",
    "\n",
    "### ğŸ”§ å¸¸è§é”™è¯¯ä¸æ³¨æ„äº‹é¡¹\n",
    "\n",
    "1. **ä»»åŠ¡é˜Ÿåˆ—é˜»å¡**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šåŒæ­¥ä»»åŠ¡é˜»å¡å¼‚æ­¥é˜Ÿåˆ—\n",
    "   async def bad_task_processor():\n",
    "       while True:\n",
    "           task = await queue.get()\n",
    "           result = sync_heavy_computation(task.data)  # é˜»å¡äº‹ä»¶å¾ªç¯\n",
    "           await process_result(result)\n",
    "   \n",
    "   # æ­£ç¡®ï¼šåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥ä»»åŠ¡\n",
    "   async def good_task_processor():\n",
    "       loop = asyncio.get_event_loop()\n",
    "       while True:\n",
    "           task = await queue.get()\n",
    "           result = await loop.run_in_executor(\n",
    "               None, sync_heavy_computation, task.data\n",
    "           )\n",
    "           await process_result(result)\n",
    "   ```\n",
    "\n",
    "2. **ä»»åŠ¡ä¸¢å¤±é£é™©**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ²¡æœ‰æŒä¹…åŒ–æœºåˆ¶\n",
    "   class BadTaskQueue:\n",
    "       def __init__(self):\n",
    "           self.tasks = []  # å†…å­˜å­˜å‚¨ï¼Œé‡å¯ä¸¢å¤±\n",
    "       \n",
    "       async def add_task(self, task):\n",
    "           self.tasks.append(task)  # ç³»ç»Ÿå´©æºƒæ—¶ä¸¢å¤±\n",
    "   \n",
    "   # æ­£ç¡®ï¼šå®ç°æŒä¹…åŒ–æœºåˆ¶\n",
    "   class GoodTaskQueue:\n",
    "       def __init__(self, storage_backend):\n",
    "           self.memory_tasks = []\n",
    "           self.storage = storage_backend\n",
    "       \n",
    "       async def add_task(self, task):\n",
    "           # å…ˆæŒä¹…åŒ–ï¼Œå†æ·»åŠ åˆ°å†…å­˜\n",
    "           await self.storage.save_task(task)\n",
    "           self.memory_tasks.append(task)\n",
    "   ```\n",
    "\n",
    "3. **æ— é™é‡è¯•å¾ªç¯**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ²¡æœ‰é‡è¯•é™åˆ¶æˆ–é€€é¿ç­–ç•¥\n",
    "   async def bad_retry_handler(task):\n",
    "       while True:\n",
    "           try:\n",
    "               await execute_task(task)\n",
    "               break\n",
    "           except Exception:\n",
    "               await asyncio.sleep(0.1)  # ç«‹å³é‡è¯•ï¼Œå¯èƒ½å¯¼è‡´é£æš´\n",
    "   \n",
    "   # æ­£ç¡®ï¼šå®ç°æŒ‡æ•°é€€é¿å’Œé‡è¯•é™åˆ¶\n",
    "   async def good_retry_handler(task, max_retries=3):\n",
    "       for attempt in range(max_retries):\n",
    "           try:\n",
    "               await execute_task(task)\n",
    "               return\n",
    "           except Exception as e:\n",
    "               if attempt == max_retries - 1:\n",
    "                   raise e\n",
    "               \n",
    "               # æŒ‡æ•°é€€é¿\n",
    "               wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "               await asyncio.sleep(wait_time)\n",
    "   ```\n",
    "\n",
    "4. **èµ„æºè€—å°½é—®é¢˜**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ— é™åˆ¶ä»»åŠ¡æäº¤\n",
    "   async def bad_task_submitter():\n",
    "       while True:\n",
    "           task = create_task()\n",
    "           await queue.submit(task)  # å¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º\n",
    "   \n",
    "   # æ­£ç¡®ï¼šå®ç°èƒŒå‹æœºåˆ¶\n",
    "   async def good_task_submitter():\n",
    "       while True:\n",
    "           # æ£€æŸ¥é˜Ÿåˆ—å¤§å°\n",
    "           if queue.size() < MAX_QUEUE_SIZE:\n",
    "               task = create_task()\n",
    "               await queue.submit(task)\n",
    "           else:\n",
    "               # é˜Ÿåˆ—æ»¡æ—¶ç­‰å¾…æˆ–ä¸¢å¼ƒä»»åŠ¡\n",
    "               await asyncio.sleep(1)\n",
    "   ```\n",
    "\n",
    "5. **ä»»åŠ¡ä¾èµ–ç®¡ç†æ··ä¹±**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ²¡æœ‰ä¾èµ–æ£€æŸ¥\n",
    "   async def bad_workflow_executor():\n",
    "       # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ­¥éª¤ï¼Œå¿½ç•¥ä¾èµ–å…³ç³»\n",
    "       await asyncio.gather(*[execute_step(step) for step in steps])\n",
    "   \n",
    "   # æ­£ç¡®ï¼šæ„å»ºä¾èµ–å›¾å¹¶æŒ‰åºæ‰§è¡Œ\n",
    "   async def good_workflow_executor():\n",
    "       dependency_graph = build_dependency_graph(steps)\n",
    "       execution_order = topological_sort(dependency_graph)\n",
    "       \n",
    "       for step_group in execution_order:\n",
    "           # å¹¶å‘æ‰§è¡Œæ— ä¾èµ–çš„æ­¥éª¤ç»„\n",
    "           await asyncio.gather(*[execute_step(step) for step in step_group])\n",
    "   ```\n",
    "\n",
    "6. **ç›‘æ§å’Œå¯è§‚æµ‹æ€§ä¸è¶³**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ²¡æœ‰ç›‘æ§æœºåˆ¶\n",
    "   class BadTaskQueue:\n",
    "       async def process_tasks(self):\n",
    "           while True:\n",
    "               task = await self.get_task()\n",
    "               await self.execute_task(task)  # æ²¡æœ‰æ—¥å¿—å’Œç›‘æ§\n",
    "   \n",
    "   # æ­£ç¡®ï¼šå®ç°å…¨é¢çš„ç›‘æ§\n",
    "   class GoodTaskQueue:\n",
    "       def __init__(self):\n",
    "           self.metrics = TaskMetrics()\n",
    "           self.logger = setup_logger()\n",
    "       \n",
    "       async def process_tasks(self):\n",
    "           while True:\n",
    "               task = await self.get_task()\n",
    "               \n",
    "               start_time = time.time()\n",
    "               try:\n",
    "                   result = await self.execute_task(task)\n",
    "                   self.metrics.record_success(task, time.time() - start_time)\n",
    "                   self.logger.info(f\"Task {task.id} completed successfully\")\n",
    "               except Exception as e:\n",
    "                   self.metrics.record_failure(task, e)\n",
    "                   self.logger.error(f\"Task {task.id} failed: {e}\")\n",
    "   ```\n",
    "\n",
    "### ğŸŒ æ€§èƒ½ä¼˜åŒ–å»ºè®®\n",
    "\n",
    "**ä»»åŠ¡é˜Ÿåˆ—ä¼˜åŒ–**ï¼š\n",
    "- æ ¹æ®ä»»åŠ¡ç‰¹æ€§é€‰æ‹©åˆé€‚çš„é˜Ÿåˆ—ç±»å‹\n",
    "- å®ç°æ™ºèƒ½ä»»åŠ¡è°ƒåº¦å’Œè´Ÿè½½å‡è¡¡\n",
    "- ä½¿ç”¨æ‰¹å¤„ç†å‡å°‘ç³»ç»Ÿå¼€é”€\n",
    "- å®ç°åŠ¨æ€å·¥ä½œè¿›ç¨‹è°ƒæ•´\n",
    "\n",
    "**åˆ†å¸ƒå¼ä¼˜åŒ–**ï¼š\n",
    "- ä¼˜åŒ–ç½‘ç»œé€šä¿¡å’Œæ•°æ®åºåˆ—åŒ–\n",
    "- å®ç°æœ¬åœ°æ€§è°ƒåº¦å‡å°‘ç½‘ç»œå»¶è¿Ÿ\n",
    "- ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œåˆ†é…ä»»åŠ¡\n",
    "- å®ç°æ•…éšœè½¬ç§»å’Œè‡ªåŠ¨æ¢å¤\n",
    "\n",
    "**LangChainä¼˜åŒ–**ï¼š\n",
    "- å®ç°æ¨¡å‹ç‰¹å®šçš„ä¼˜åŒ–ç­–ç•¥\n",
    "- ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤æ¨ç†\n",
    "- å®ç°è¯·æ±‚åˆå¹¶å’Œæ‰¹å¤„ç†\n",
    "- ä¼˜åŒ–å·¥ä½œæµä¾èµ–å’Œå¹¶è¡Œåº¦\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å­¦ä¹ ï¼**\n",
    "\n",
    "ä½ å·²ç»å…¨é¢æŒæ¡äº†å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œèƒ½å¤Ÿç³»ç»Ÿæ€§åœ°è¿›è¡Œä»»åŠ¡é˜Ÿåˆ—è®¾è®¡ã€åˆ†å¸ƒå¼éƒ¨ç½²ã€å·¥ä½œæµç¼–æ’ç­‰ï¼Œä¸ºLangChainæ™ºèƒ½åº”ç”¨æä¾›äº†å¼ºå¤§çš„ä»»åŠ¡å¤„ç†åŸºç¡€ã€‚\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ é¢„å‘Š\n",
    "\n",
    "**ç¬¬å…­èŠ‚ï¼šå¼‚æ­¥ç¼–ç¨‹ - è¿›è¡Œä¸­** ğŸ”„\n",
    "- 6.1 å¼‚æ­¥ç¼–ç¨‹åŸºç¡€ âœ…\n",
    "- 6.2 åç¨‹ä¸äº‹ä»¶å¾ªç¯ âœ…\n",
    "- 6.3 å¼‚æ­¥I/Oæ“ä½œ âœ…\n",
    "- 6.4 å¼‚æ­¥ç½‘ç»œç¼–ç¨‹ âœ…\n",
    "- 6.5 å¼‚æ­¥Webæ¡†æ¶ âœ…\n",
    "- 6.6 å¹¶å‘ç¼–ç¨‹æ¨¡å¼ âœ…\n",
    "- 6.7 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ— âœ…\n",
    "- 6.8 å¼‚æ­¥æ€§èƒ½ä¼˜åŒ– â³\n",
    "- 6.9 å¼‚æ­¥æœ€ä½³å®è·µ â³\n",
    "\n",
    "**ç»§ç»­ç¬¬å…­èŠ‚ï¼šå¼‚æ­¥ç¼–ç¨‹**\n",
    "- ä¸‹ä¸€ä¸ªï¼š6.8 å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–\n",
    "- æ·±å…¥å­¦ä¹ å¼‚æ­¥æ€§èƒ½åˆ†æå’Œä¼˜åŒ–æŠ€æœ¯\n",
    "- æŒæ¡å¼‚æ­¥ç³»ç»Ÿçš„æ€§èƒ½è°ƒä¼˜æ–¹æ³•\n",
    "\n",
    "**åç»­ç« èŠ‚é¢„å‘Š**ï¼š\n",
    "- Webå¼€å‘æŠ€æœ¯\n",
    "- é¡¹ç›®å·¥ç¨‹å®è·µ\n",
    "\n",
    "ç»§ç»­åŠ æ²¹ï¼Œå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å·²ç»æŒæ¡ï¼å‡†å¤‡æ·±å…¥å­¦ä¹ å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
