{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70-ä»£ç é‡æ„ä¸ç»´æŠ¤\n",
    "\n",
    "## ğŸ“š ç”¨é€”è¯´æ˜\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "- æŒæ¡ä»£ç é‡æ„çš„æ ¸å¿ƒåŸåˆ™å’Œæ–¹æ³•\n",
    "- å­¦ä¼šè¯†åˆ«ä»£ç å¼‚å‘³å’Œé‡æ„æ—¶æœº\n",
    "- ç†è§£ä»£ç ç»´æŠ¤çš„æœ€ä½³å®è·µ\n",
    "- èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„ä»£ç è´¨é‡ä¿éšœä½“ç³»\n",
    "\n",
    "**å‰ç½®è¦æ±‚**ï¼š\n",
    "- å·²å®Œæˆæ€§èƒ½ä¼˜åŒ–ä¸è°ƒè¯•æŠ€å·§å­¦ä¹ \n",
    "- ç†Ÿç»ƒæŒæ¡é¢å‘å¯¹è±¡è®¾è®¡åŸåˆ™\n",
    "- äº†è§£è®¾è®¡æ¨¡å¼å’Œæ¶æ„æ¨¡å¼\n",
    "- å…·å¤‡åŸºæœ¬çš„ä»£ç è´¨é‡æ„è¯†\n",
    "\n",
    "**ä¸LangChainå…³è”**ï¼š\n",
    "- æ”¯æŒLangChainé¡¹ç›®çš„ä»£ç é‡æ„\n",
    "- ä¸ºAIç»„ä»¶çš„ç»´æŠ¤æä¾›æœ€ä½³å®è·µ\n",
    "- ä¿éšœLangChainä»£ç çš„é•¿æœŸå¯ç»´æŠ¤æ€§\n",
    "- å®ç°AIç³»ç»Ÿçš„æŒç»­æ”¹è¿›\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ çŸ¥è¯†ç‚¹è¦†ç›–\n",
    "\n",
    "### 8.6 ä»£ç é‡æ„ä¸ç»´æŠ¤ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šä»£ç é‡æ„ä¸ç»´æŠ¤æ˜¯ä¿éšœä»£ç è´¨é‡çš„å…³é”®æŠ€èƒ½ï¼Œä¸ºLangChainçš„AIé¡¹ç›®æä¾›æŒç»­çš„ä»£ç æ”¹è¿›æ–¹æ¡ˆã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡é‡æ„çš„åŸåˆ™å’Œæ—¶æœº\n",
    "- å­¦ä¼šè¯†åˆ«å’Œå¤„ç†ä»£ç å¼‚å‘³\n",
    "- ç†è§£ç»´æŠ¤ç­–ç•¥å’Œç‰ˆæœ¬ç®¡ç†\n",
    "- èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„é‡æ„æµç¨‹\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°ä»£ç å¼‚å‘³æ£€æµ‹å™¨\n",
    "- æ„å»ºé‡æ„å·¥å…·å’Œæ¡†æ¶\n",
    "- å¼€å‘ç»´æŠ¤ç­–ç•¥ç®¡ç†å™¨\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è¿›è¡Œä»£ç é‡æ„å’Œç»´æŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ ä»£ç é‡æ„ä¸ç»´æŠ¤:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import hashlib\n",
    "import difflib\n",
    "import typing\n",
    "import dataclasses\n",
    "import uuid\n",
    "import inspect\n",
    "import pathlib\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Set, Callable\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from enum import Enum\n",
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"âœ… Pythonç‰ˆæœ¬: {__import__('sys').version}\")\n",
    "print(f\"âœ… å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. ä»£ç å¼‚å‘³æ£€æµ‹\n",
    "print(f\"ğŸ“ 1. ä»£ç å¼‚å‘³æ£€æµ‹:\")\n",
    "\n",
    "# 1.1 ä»£ç å¼‚å‘³ç±»å‹\n",
    "print(f\"\\n   ğŸ¯ 1.1 ä»£ç å¼‚å‘³ç±»å‹:\")\n",
    "\n",
    "class CodeSmellType(Enum):\n",
    "    \"\"\"ä»£ç å¼‚å‘³ç±»å‹\"\"\"\n",
    "    LONG_METHOD = \"long_method\"  # é•¿æ–¹æ³•\n",
    "    LARGE_CLASS = \"large_class\"  # å¤§ç±»\n",
    "    DUPLICATE_CODE = \"duplicate_code\"  # é‡å¤ä»£ç \n",
    "    LONG_PARAMETER_LIST = \"long_parameter_list\"  # é•¿å‚æ•°åˆ—è¡¨\n",
    "    FEATURE_ENVY = \"feature_envy\"  # ç‰¹æ€§å«‰å¦’\n",
    "    DATA_CLUMPS = \"data_clumps\"  # æ•°æ®æ³¥å›¢\n",
    "    PRIMITIVE_OBSESSION = \"primitive_obsession\"  # åŸºæœ¬ç±»å‹åæ‰§\n",
    "    SWITCH_CASE_SMELL = \"switch_case_smell\"  # Switchè¯­å¥å¼‚å‘³\n",
    "    LAZY_CLASS = \"lazy_class\"  # æ‡’æƒ°ç±»\n",
    "    SPECULATIVE_GENERALITY = \"speculative_generality\"  # æŠ•æœºæ€§é€šç”¨\n",
    "    MESSAGE_CHAINS = \"message_chains\"  # æ¶ˆæ¯é“¾\n",
    "    MIDDLE_MAN = \"middle_man\"  # ä¸­é—´äºº\n",
    "    INAPPROPRIATE_INTIMACY = \"inappropriate_intimacy\"  # ä¸åˆé€‚çš„äº²å¯†\n",
    "    COMPLEX_CONDITIONAL = \"complex_conditional\"  # å¤æ‚æ¡ä»¶\n",
    "    LARGE_SCOPE = \"large_scope\"  # å¤§ä½œç”¨åŸŸ\n",
    "\n",
    "@dataclass\n",
    "class CodeSmell:\n",
    "    \"\"\"ä»£ç å¼‚å‘³\"\"\"\n",
    "    smell_type: CodeSmellType\n",
    "    file_path: str\n",
    "    line_number: int\n",
    "    description: str\n",
    "    severity: int  # 1-10, 10æœ€ä¸¥é‡\n",
    "    suggested_refactoring: str\n",
    "    context: Dict[str, Any] = field(default_factory=dict)\n",
    "    detected_at: datetime.datetime = field(default_factory=datetime.datetime.utcnow)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"smell_type\": self.smell_type.value,\n",
    "            \"file_path\": self.file_path,\n",
    "            \"line_number\": self.line_number,\n",
    "            \"description\": self.description,\n",
    "            \"severity\": self.severity,\n",
    "            \"suggested_refactoring\": self.suggested_refactoring,\n",
    "            \"context\": self.context,\n",
    "            \"detected_at\": self.detected_at.isoformat()\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class CodeMetrics:\n",
    "    \"\"\"ä»£ç æŒ‡æ ‡\"\"\"\n",
    "    file_path: str\n",
    "    lines_of_code: int\n",
    "    cyclomatic_complexity: int\n",
    "    maintainability_index: float\n",
    "    halstead_metrics: Dict[str, float]\n",
    "    function_count: int\n",
    "    class_count: int\n",
    "    comment_ratio: float\n",
    "    duplication_ratio: float\n",
    "\n",
    "class CodeSmellDetector:\n",
    "    \"\"\"ä»£ç å¼‚å‘³æ£€æµ‹å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.smells: List[CodeSmell] = []\n",
    "        self.metrics: Dict[str, CodeMetrics] = {}\n",
    "        self.thresholds = {\n",
    "            \"max_method_length\": 20,\n",
    "            \"max_class_lines\": 200,\n",
    "            \"max_parameter_count\": 5,\n",
    "            \"max_cyclomatic_complexity\": 10,\n",
    "            \"min_maintainability_index\": 65,\n",
    "            \"max_function_lines\": 50\n",
    "        }\n",
    "    \n",
    "    def analyze_file(self, file_path: str) -> List[CodeSmell]:\n",
    "        \"\"\"åˆ†æå•ä¸ªæ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            tree = ast.parse(content)\n",
    "            \n",
    "            # è®¡ç®—ä»£ç æŒ‡æ ‡\n",
    "            metrics = self._calculate_metrics(file_path, content, tree)\n",
    "            self.metrics[file_path] = metrics\n",
    "            \n",
    "            # æ£€æµ‹ä»£ç å¼‚å‘³\n",
    "            file_smells = []\n",
    "            \n",
    "            # æ£€æµ‹é•¿æ–¹æ³•\n",
    "            file_smells.extend(self._detect_long_methods(tree, file_path))\n",
    "            \n",
    "            # æ£€æµ‹å¤§ç±»\n",
    "            file_smells.extend(self._detect_large_classes(tree, file_path))\n",
    "            \n",
    "            # æ£€æµ‹é•¿å‚æ•°åˆ—è¡¨\n",
    "            file_smells.extend(self._detect_long_parameter_lists(tree, file_path))\n",
    "            \n",
    "            # æ£€æµ‹å¤æ‚æ¡ä»¶\n",
    "            file_smells.extend(self._detect_complex_conditionals(tree, file_path))\n",
    "            \n",
    "            # æ£€æµ‹åŸºæœ¬ç±»å‹åæ‰§\n",
    "            file_smells.extend(self._detect_primitive_obsession(tree, file_path))\n",
    "            \n",
    "            # æ£€æµ‹æ¶ˆæ¯é“¾\n",
    "            file_smells.extend(self._detect_message_chains(tree, file_path))\n",
    "            \n",
    "            self.smells.extend(file_smells)\n",
    "            \n",
    "            print(f\"æ–‡ä»¶åˆ†æå®Œæˆ: {file_path} - å‘ç° {len(file_smells)} ä¸ªä»£ç å¼‚å‘³\")\n",
    "            return file_smells\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"æ–‡ä»¶åˆ†æå¤±è´¥: {file_path} - {e}\")\n",
    "            return []\n",
    "    \n",
    "    def analyze_directory(self, directory: str, pattern: str = \"*.py\") -> Dict[str, List[CodeSmell]]:\n",
    "        \"\"\"åˆ†æç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for file_path in Path(directory).rglob(pattern):\n",
    "            if file_path.is_file():\n",
    "                smells = self.analyze_file(str(file_path))\n",
    "                results[str(file_path)] = smells\n",
    "        \n",
    "        total_smells = sum(len(smells) for smells in results.values())\n",
    "        print(f\"ç›®å½•åˆ†æå®Œæˆ: {directory} - æ€»è®¡å‘ç° {total_smells} ä¸ªä»£ç å¼‚å‘³\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_metrics(self, file_path: str, content: str, tree: ast.AST) -> CodeMetrics:\n",
    "        \"\"\"è®¡ç®—ä»£ç æŒ‡æ ‡\"\"\"\n",
    "        lines = content.split('\\n')\n",
    "        code_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]\n",
    "        comment_lines = [line for line in lines if line.strip().startswith('#')]\n",
    "        \n",
    "        # è®¡ç®—åœˆå¤æ‚åº¦\n",
    "        complexity = self._calculate_cyclomatic_complexity(tree)\n",
    "        \n",
    "        # è®¡ç®—å¯ç»´æŠ¤æ€§æŒ‡æ•°\n",
    "        maintainability = self._calculate_maintainability_index(\n",
    "            len(code_lines), complexity, len(comment_lines)\n",
    "        )\n",
    "        \n",
    "        # ç»Ÿè®¡å‡½æ•°å’Œç±»\n",
    "        function_count = len([node for node in ast.walk(tree) if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef))])\n",
    "        class_count = len([node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)])\n",
    "        \n",
    "        return CodeMetrics(\n",
    "            file_path=file_path,\n",
    "            lines_of_code=len(code_lines),\n",
    "            cyclomatic_complexity=complexity,\n",
    "            maintainability_index=maintainability,\n",
    "            halstead_metrics=self._calculate_halstead_metrics(content),\n",
    "            function_count=function_count,\n",
    "            class_count=class_count,\n",
    "            comment_ratio=len(comment_lines) / len(lines) if lines else 0,\n",
    "            duplication_ratio=0.0  # éœ€è¦æ›´å¤æ‚çš„ç®—æ³•æ£€æµ‹é‡å¤ä»£ç \n",
    "        )\n",
    "    \n",
    "    def _calculate_cyclomatic_complexity(self, tree: ast.AST) -> int:\n",
    "        \"\"\"è®¡ç®—åœˆå¤æ‚åº¦\"\"\"\n",
    "        complexity = 1  # åŸºç¡€å¤æ‚åº¦\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.If, ast.While, ast.For, ast.With)):\n",
    "                complexity += 1\n",
    "            elif isinstance(node, ast.ExceptHandler):\n",
    "                complexity += 1\n",
    "            elif isinstance(node, ast.BoolOp):\n",
    "                complexity += len(node.values) - 1\n",
    "            elif isinstance(node, ast.ListComp):\n",
    "                complexity += 1\n",
    "        \n",
    "        return complexity\n",
    "    \n",
    "    def _calculate_maintainability_index(self, loc: int, complexity: int, comment_lines: int) -> float:\n",
    "        \"\"\"è®¡ç®—å¯ç»´æŠ¤æ€§æŒ‡æ•°\"\"\"\n",
    "        if loc == 0:\n",
    "            return 100.0\n",
    "        \n",
    "        # ç®€åŒ–çš„å¯ç»´æŠ¤æ€§æŒ‡æ•°è®¡ç®—\n",
    "        volume = loc * 0.5  # ç®€åŒ–çš„ä½“ç§¯è®¡ç®—\n",
    "        \n",
    "        mi = max(0, (171 - 5.2 * (volume ** 0.23) - 0.23 * complexity - 16.2 * (comment_lines / loc)))\n",
    "        \n",
    "        return round(mi, 2)\n",
    "    \n",
    "    def _calculate_halstead_metrics(self, content: str) -> Dict[str, float]:\n",
    "        \"\"\"è®¡ç®—HalsteadæŒ‡æ ‡ï¼ˆç®€åŒ–ç‰ˆï¼‰\"\"\"\n",
    "        # æå–æ“ä½œç¬¦å’Œæ“ä½œæ•°\n",
    "        operators = set(re.findall(r'\\+|\\-|\\*|\\/|\\=|\\==|\\!=|\\<|\\>|\\<=|\\>=|\\(|\\)|\\{|\\}|\\[|\\]', content))\n",
    "        operands = set(re.findall(r'\\b\\w+\\b', content))\n",
    "        \n",
    "        n1 = len(operators)  # ä¸åŒæ“ä½œç¬¦æ•°é‡\n",
    "        n2 = len(operands)   # ä¸åŒæ“ä½œæ•°æ•°é‡\n",
    "        N1 = len(re.findall(r'\\+|\\-|\\*|\\/|\\=|\\==|\\!=|\\<|\\>|\\<=|\\>=|\\(|\\)|\\{|\\}|\\[|\\]', content))  # æ“ä½œç¬¦æ€»æ•°\n",
    "        N2 = len(re.findall(r'\\b\\w+\\b', content))  # æ“ä½œæ•°æ€»æ•°\n",
    "        \n",
    "        vocabulary = n1 + n2\n",
    "        length = N1 + N2\n",
    "        \n",
    "        if vocabulary > 0:\n",
    "            difficulty = (n1 / 2) * (N2 / n2) if n2 > 0 else 0\n",
    "            volume = length * (math.log2(vocabulary) if vocabulary > 0 else 0)\n",
    "            effort = difficulty * volume\n",
    "        else:\n",
    "            difficulty = volume = effort = 0\n",
    "        \n",
    "        return {\n",
    "            \"vocabulary\": vocabulary,\n",
    "            \"length\": length,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"volume\": volume,\n",
    "            \"effort\": effort\n",
    "        }\n",
    "    \n",
    "    def _detect_long_methods(self, tree: ast.AST, file_path: str) -> List[CodeSmell]:\n",
    "        \"\"\"æ£€æµ‹é•¿æ–¹æ³•\"\"\"\n",
    "        smells = []\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                if hasattr(node, 'end_lineno') and node.end_lineno:\n",
    "                    length = node.end_lineno - node.lineno + 1\n",
    "                else:\n",
    "                    # ç®€åŒ–è®¡ç®—ï¼šç»Ÿè®¡èŠ‚ç‚¹å†…çš„è¡Œæ•°\n",
    "                    length = len(ast.get_source_segment(open(file_path, 'r').read(), node).split('\\n'))\n",
    "                \n",
    "                if length > self.thresholds[\"max_method_length\"]:\n",
    "                    severity = min(10, length // 10)\n",
    "                    \n",
    "                    smell = CodeSmell(\n",
    "                        smell_type=CodeSmellType.LONG_METHOD,\n",
    "                        file_path=file_path,\n",
    "                        line_number=node.lineno,\n",
    "                        description=f\"æ–¹æ³• '{node.name}' è¿‡é•¿ ({length} è¡Œ)\",\n",
    "                        severity=severity,\n",
    "                        suggested_refactoring=\"å°†æ–¹æ³•æ‹†åˆ†ä¸ºå¤šä¸ªå°æ–¹æ³•\",\n",
    "                        context={\"method_name\": node.name, \"length\": length}\n",
    "                    )\n",
    "                    smells.append(smell)\n",
    "        \n",
    "        return smells\n",
    "    \n",
    "    def _detect_large_classes(self, tree: ast.AST, file_path: str) -> List[CodeSmell]:\n",
    "        \"\"\"æ£€æµ‹å¤§ç±»\"\"\"\n",
    "        smells = []\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.ClassDef):\n",
    "                # è®¡ç®—ç±»çš„è¡Œæ•°\n",
    "                if hasattr(node, 'end_lineno') and node.end_lineno:\n",
    "                    length = node.end_lineno - node.lineno + 1\n",
    "                else:\n",
    "                    length = sum(1 for _ in ast.walk(node) if isinstance(_, ast.stmt))\n",
    "                \n",
    "                if length > self.thresholds[\"max_class_lines\"]:\n",
    "                    severity = min(10, length // 50)\n",
    "                    \n",
    "                    smell = CodeSmell(\n",
    "                        smell_type=CodeSmellType.LARGE_CLASS,\n",
    "                        file_path=file_path,\n",
    "                        line_number=node.lineno,\n",
    "                        description=f\"ç±» '{node.name}' è¿‡å¤§ ({length} è¡Œ)\",\n",
    "                        severity=severity,\n",
    "                        suggested_refactoring=\"å°†ç±»æ‹†åˆ†ä¸ºå¤šä¸ªèŒè´£å•ä¸€çš„ç±»\",\n",
    "                        context={\"class_name\": node.name, \"length\": length}\n",
    "                    )\n",
    "                    smells.append(smell)\n",
    "        \n",
    "        return smells\n",
    "    \n",
    "    def _detect_long_parameter_lists(self, tree: ast.AST, file_path: str) -> List[CodeSmell]:\n",
    "        \"\"\"æ£€æµ‹é•¿å‚æ•°åˆ—è¡¨\"\"\"\n",
    "        smells = []\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                param_count = len(node.args.args)\n",
    "                \n",
    "                if param_count > self.thresholds[\"max_parameter_count\"]:\n",
    "                    severity = min(10, param_count - 5)\n",
    "                    \n",
    "                    smell = CodeSmell(\n",
    "                        smell_type=CodeSmellType.LONG_PARAMETER_LIST,\n",
    "                        file_path=file_path,\n",
    "                        line_number=node.lineno,\n",
    "                        description=f\"æ–¹æ³• '{node.name}' å‚æ•°è¿‡å¤š ({param_count} ä¸ª)\",\n",
    "                        severity=severity,\n",
    "                        suggested_refactoring=\"ä½¿ç”¨å‚æ•°å¯¹è±¡æˆ–é…ç½®ç±»\",\n",
    "                        context={\"method_name\": node.name, \"parameter_count\": param_count}\n",
    "                    )\n",
    "                    smells.append(smell)\n",
    "        \n",
    "        return smells\n",
    "    \n",
    "    def _detect_complex_conditionals(self, tree: ast.AST, file_path: str) -> List[CodeSmell]:\n",
    "        \"\"\"æ£€æµ‹å¤æ‚æ¡ä»¶\"\"\"\n",
    "        smells = []\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.If):\n",
    "                complexity = self._calculate_conditional_complexity(node.test)\n",
    "                \n",
    "                if complexity > 3:  # é˜ˆå€¼ï¼šè¶…è¿‡3ä¸ªæ¡ä»¶\n",
    "                    severity = min(10, complexity)\n",
    "                    \n",
    "                    smell = CodeSmell(\n",
    "                        smell_type=CodeSmellType.COMPLEX_CONDITIONAL,\n",
    "                        file_path=file_path,\n",
    "                        line_number=node.lineno,\n",
    "                        description=f\"æ¡ä»¶è¡¨è¾¾å¼è¿‡äºå¤æ‚ (å¤æ‚åº¦: {complexity})\",\n",
    "                        severity=severity,\n",
    "                        suggested_refactoring=\"å°†å¤æ‚æ¡ä»¶æå–ä¸ºæ–¹æ³•æˆ–å˜é‡\",\n",
    "                        context={\"complexity\": complexity}\n",
    "                    )\n",
    "                    smells.append(smell)\n",
    "        \n",
    "        return smells\n",
    "    \n",
    "    def _calculate_conditional_complexity(self, node: ast.AST) -> int:\n",
    "        \"\"\"è®¡ç®—æ¡ä»¶å¤æ‚åº¦\"\"\"\n",
    "        if isinstance(node, ast.BoolOp):\n",
    "            return sum(self._calculate_conditional_complexity(value) for value in node.values)\n",
    "        elif isinstance(node, ast.Compare):\n",
    "            return len(node.ops) + sum(self._calculate_conditional_complexity(comp) for comp in node.comparators)\n",
    "        elif isinstance(node, ast.UnaryOp):\n",
    "            return 1 + self._calculate_conditional_complexity(node.operand)\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def _detect_primitive_obsession(self, tree: ast.AST, file_path: str) -> List[CodeSmell]:\n",
    "        \"\"\"æ£€æµ‹åŸºæœ¬ç±»å‹åæ‰§\"\"\"\n",
    "        smells = []\n",
    "        \n",
    "        # ç®€åŒ–æ£€æµ‹ï¼šæŸ¥æ‰¾å¤§é‡ä½¿ç”¨å­—ç¬¦ä¸²å’Œæ•°å­—çš„åœ°æ–¹\n",
    "        primitive_usage = {}\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                for arg in node.args.args:\n",
    "                    if arg.annotation:\n",
    "                        if isinstance(arg.annotation, ast.Name):\n",
    "                            if arg.annotation.id in ('str', 'int', 'float', 'bool'):\n",
    "                                primitive_usage[arg.arg] = primitive_usage.get(arg.arg, 0) + 1\n",
    "        \n",
    "        # å¦‚æœä¸€ä¸ªå‡½æ•°æœ‰è¶…è¿‡3ä¸ªåŸºæœ¬ç±»å‹å‚æ•°ï¼Œå¯èƒ½å­˜åœ¨åŸºæœ¬ç±»å‹åæ‰§\n",
    "        for func_name, count in primitive_usage.items():\n",
    "            if count > 3:\n",
    "                smell = CodeSmell(\n",
    "                    smell_type=CodeSmellType.PRIMITIVE_OBSESSION,\n",
    "                    file_path=file_path,\n",
    "                    line_number=1,\n",
    "                    description=f\"å‡½æ•° '{func_name}' å¯èƒ½å­˜åœ¨åŸºæœ¬ç±»å‹åæŒ\",\n",
    "                    severity=5,\n",
    "                    suggested_refactoring=\"ä½¿ç”¨å€¼å¯¹è±¡æˆ–æ•°æ®ç±»\",\n",
    "                    context={\"function_name\": func_name, \"primitive_count\": count}\n",
    "                )\n",
    "                smells.append(smell)\n",
    "        \n",
    "        return smells\n",
    "    \n",
    "    def _detect_message_chains(self, tree: ast.AST, file_path: str) -> List[CodeSmell]:\n",
    "        \"\"\"æ£€æµ‹æ¶ˆæ¯é“¾\"\"\"\n",
    "        smells = []\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Call):\n",
    "                chain_length = self._calculate_message_chain_length(node)\n",
    "                \n",
    "                if chain_length > 3:  # é˜ˆå€¼ï¼šè¶…è¿‡3å±‚è°ƒç”¨é“¾\n",
    "                    severity = min(10, chain_length - 3)\n",
    "                    \n",
    "                    smell = CodeSmell(\n",
    "                        smell_type=CodeSmellType.MESSAGE_CHAINS,\n",
    "                        file_path=file_path,\n",
    "                        line_number=node.lineno,\n",
    "                        description=f\"æ¶ˆæ¯é“¾è¿‡é•¿ (é•¿åº¦: {chain_length})\",\n",
    "                        severity=severity,\n",
    "                        suggested_refactoring=\"ä½¿ç”¨å§”æ‰˜æ¨¡å¼æˆ–å¼•å…¥ä¸­é—´æ–¹æ³•\",\n",
    "                        context={\"chain_length\": chain_length}\n",
    "                    )\n",
    "                    smells.append(smell)\n",
    "        \n",
    "        return smells\n",
    "    \n",
    "    def _calculate_message_chain_length(self, node: ast.AST) -> int:\n",
    "        \"\"\"è®¡ç®—æ¶ˆæ¯é“¾é•¿åº¦\"\"\"\n",
    "        if isinstance(node, ast.Call):\n",
    "            if isinstance(node.func, ast.Attribute):\n",
    "                return 1 + self._calculate_message_chain_length(node.func.value)\n",
    "            else:\n",
    "                return 1\n",
    "        elif isinstance(node, ast.Attribute):\n",
    "            return 1 + self._calculate_message_chain_length(node.value)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def get_smell_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ä»£ç å¼‚å‘³æ‘˜è¦\"\"\"\n",
    "        type_counts = {}\n",
    "        severity_counts = {}\n",
    "        \n",
    "        for smell in self.smells:\n",
    "            smell_type = smell.smell_type.value\n",
    "            type_counts[smell_type] = type_counts.get(smell_type, 0) + 1\n",
    "            severity_counts[smell.severity] = severity_counts.get(smell.severity, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_smells\": len(self.smells),\n",
    "            \"type_distribution\": type_counts,\n",
    "            \"severity_distribution\": severity_counts,\n",
    "            \"files_analyzed\": len(self.metrics),\n",
    "            \"average_smells_per_file\": len(self.smells) / len(self.metrics) if self.metrics else 0\n",
    "        }\n",
    "    \n",
    "    def export_smells(self, filename: str):\n",
    "        \"\"\"å¯¼å‡ºä»£ç å¼‚å‘³æŠ¥å‘Š\"\"\"\n",
    "        report = {\n",
    "            \"generated_at\": datetime.datetime.utcnow().isoformat(),\n",
    "            \"summary\": self.get_smell_summary(),\n",
    "            \"smells\": [smell.to_dict() for smell in self.smells],\n",
    "            \"metrics\": {path: asdict(metrics) for path, metrics in self.metrics.items()}\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"ä»£ç å¼‚å‘³æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}\")\n",
    "\n",
    "print(f\"   âœ… ä»£ç å¼‚å‘³æ£€æµ‹å®Œæˆ\")\n",
    "print(f\"      - CodeSmellDetector: ä»£ç å¼‚å‘³æ£€æµ‹å™¨\")\n",
    "print(f\"      - æ”¯æŒ15ç§ä»£ç å¼‚å‘³ç±»å‹æ£€æµ‹\")\n",
    "print(f\"      - æä¾›ä»£ç æŒ‡æ ‡è®¡ç®—å’Œåˆ†æ\")\n",
    "print(f\"      - ç”Ÿæˆè¯¦ç»†çš„é‡æ„å»ºè®®\")\n",
    "\n",
    "print(f\"\\nâœ… ä»£ç å¼‚å‘³æ£€æµ‹å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡ä»£ç å¼‚å‘³çš„è¯†åˆ«æ–¹æ³•\")\n",
    "print(f\"   âœ“ å­¦ä¼šä»£ç è´¨é‡æŒ‡æ ‡è®¡ç®—\")\n",
    "print(f\"   âœ“ ç†è§£é‡æ„åŸåˆ™å’Œæ—¶æœº\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå»ºç«‹åŸºç¡€çš„ä»£ç è´¨é‡ç›‘æ§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é‡æ„å·¥å…·ä¸ç»´æŠ¤ç­–ç•¥ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šé‡æ„å·¥å…·ä¸ç»´æŠ¤ç­–ç•¥æ˜¯ä¿éšœä»£ç è´¨é‡çš„æ ¸å¿ƒï¼Œä¸ºLangChainçš„AIé¡¹ç›®æä¾›æŒç»­æ”¹è¿›çš„æŠ€æœ¯æ–¹æ¡ˆã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡é‡æ„å·¥å…·çš„è®¾è®¡å’Œä½¿ç”¨\n",
    "- å­¦ä¼šç»´æŠ¤ç­–ç•¥çš„åˆ¶å®šå’Œæ‰§è¡Œ\n",
    "- ç†è§£ä»£ç æ¼”è¿›çš„æœ€ä½³å®è·µ\n",
    "- èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„é‡æ„æµç¨‹\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°è‡ªåŠ¨åŒ–é‡æ„å·¥å…·\n",
    "- æ„å»ºç»´æŠ¤ç­–ç•¥ç®¡ç†ç³»ç»Ÿ\n",
    "- å¼€å‘ä»£ç æ¼”è¿›è¿½è¸ªå™¨\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è¿›è¡Œç³»ç»Ÿé‡æ„å’Œç»´æŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ› ï¸ é‡æ„å·¥å…·ä¸ç»´æŠ¤ç­–ç•¥:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# éœ€è¦å¯¼å…¥mathæ¨¡å—ç”¨äºè®¡ç®—\n",
    "import math\n",
    "\n",
    "# 2. é‡æ„å·¥å…·ç³»ç»Ÿ\n",
    "print(f\"ğŸ“ 2. é‡æ„å·¥å…·ç³»ç»Ÿ:\")\n",
    "\n",
    "# 2.1 é‡æ„æ“ä½œç±»å‹\n",
    "print(f\"\\n   ğŸ¯ 2.1 é‡æ„æ“ä½œç±»å‹:\")\n",
    "\n",
    "class RefactoringType(Enum):\n",
    "    \"\"\"é‡æ„ç±»å‹\"\"\"\n",
    "    EXTRACT_METHOD = \"extract_method\"  # æå–æ–¹æ³•\n",
    "    EXTRACT_CLASS = \"extract_class\"  # æå–ç±»\n",
    "    INLINE_METHOD = \"inline_method\"  # å†…è”æ–¹æ³•\n",
    "    MOVE_METHOD = \"move_method\"  # ç§»åŠ¨æ–¹æ³•\n",
    "    RENAME_VARIABLE = \"rename_variable\"  # é‡å‘½åå˜é‡\n",
    "    INTRODUCE_PARAMETER = \"introduce_parameter\"  # å¼•å…¥å‚æ•°\n",
    "    REMOVE_PARAMETER = \"remove_parameter\"  # ç§»é™¤å‚æ•°\n",
    "    REPLACE_MAGIC_NUMBER = \"replace_magic_number\"  # æ›¿æ¢é­”æ³•æ•°å­—\n",
    "    DECOMPOSE_CONDITIONAL = \"decompose_conditional\"  # åˆ†è§£æ¡ä»¶\n",
    "    CONSOLIDATE_CONDITIONAL = \"consolidate_conditional\"  # åˆå¹¶æ¡ä»¶\n",
    "    INTRODUCE_POLYMORPHISM = \"introduce_polymorphism\"  # å¼•å…¥å¤šæ€\n",
    "    EXTRACT_INTERFACE = \"extract_interface\"  # æå–æ¥å£\n",
    "\n",
    "@dataclass\n",
    "class RefactoringOperation:\n",
    "    \"\"\"é‡æ„æ“ä½œ\"\"\"\n",
    "    operation_type: RefactoringType\n",
    "    file_path: str\n",
    "    line_number: int\n",
    "    description: str\n",
    "    original_code: str\n",
    "    refactored_code: str\n",
    "    risk_level: int  # 1-10\n",
    "    automated: bool = True\n",
    "    requires_review: bool = True\n",
    "    context: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"operation_type\": self.operation_type.value,\n",
    "            \"file_path\": self.file_path,\n",
    "            \"line_number\": self.line_number,\n",
    "            \"description\": self.description,\n",
    "            \"original_code\": self.original_code,\n",
    "            \"refactored_code\": self.refactored_code,\n",
    "            \"risk_level\": self.risk_level,\n",
    "            \"automated\": self.automated,\n",
    "            \"requires_review\": self.requires_review,\n",
    "            \"context\": self.context\n",
    "        }\n",
    "\n",
    "class AutomatedRefactoringTool:\n",
    "    \"\"\"è‡ªåŠ¨åŒ–é‡æ„å·¥å…·\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.operations: List[RefactoringOperation] = []\n",
    "        self.applied_operations: List[RefactoringOperation] = []\n",
    "        self.refactoring_rules: Dict[RefactoringType, Callable] = {}\n",
    "        self.backup_enabled = True\n",
    "        self._setup_refactoring_rules()\n",
    "    \n",
    "    def _setup_refactoring_rules(self):\n",
    "        \"\"\"è®¾ç½®é‡æ„è§„åˆ™\"\"\"\n",
    "        self.refactoring_rules = {\n",
    "            RefactoringType.EXTRACT_METHOD: self._extract_method,\n",
    "            RefactoringType.RENAME_VARIABLE: self._rename_variable,\n",
    "            RefactoringType.REPLACE_MAGIC_NUMBER: self._replace_magic_number,\n",
    "            RefactoringType.DECOMPOSE_CONDITIONAL: self._decompose_conditional\n",
    "        }\n",
    "    \n",
    "    def analyze_refactoring_opportunities(self, file_path: str) -> List[RefactoringOperation]:\n",
    "        \"\"\"åˆ†æé‡æ„æœºä¼š\"\"\"\n",
    "        opportunities = []\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            lines = content.split('\\n')\n",
    "            \n",
    "            # æ£€æµ‹é­”æ³•æ•°å­—\n",
    "            opportunities.extend(self._find_magic_numbers(file_path, lines))\n",
    "            \n",
    "            # æ£€æµ‹é•¿æ–¹æ³•ï¼ˆæå–æ–¹æ³•æœºä¼šï¼‰\n",
    "            opportunities.extend(self._find_extract_method_opportunities(file_path, lines))\n",
    "            \n",
    "            # æ£€æµ‹å¤æ‚æ¡ä»¶ï¼ˆåˆ†è§£æ¡ä»¶æœºä¼šï¼‰\n",
    "            opportunities.extend(self._find_decompose_conditional_opportunities(file_path, lines))\n",
    "            \n",
    "            print(f\"é‡æ„æœºä¼šåˆ†æå®Œæˆ: {file_path} - å‘ç° {len(opportunities)} ä¸ªæœºä¼š\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"é‡æ„æœºä¼šåˆ†æå¤±è´¥: {file_path} - {e}\")\n",
    "        \n",
    "        return opportunities\n",
    "    \n",
    "    def _find_magic_numbers(self, file_path: str, lines: List[str]) -> List[RefactoringOperation]:\n",
    "        \"\"\"æŸ¥æ‰¾é­”æ³•æ•°å­—\"\"\"\n",
    "        opportunities = []\n",
    "        \n",
    "        for line_num, line in enumerate(lines, 1):\n",
    "            # æŸ¥æ‰¾æ•°å­—å¸¸é‡ï¼ˆæ’é™¤0, 1, -1ç­‰å¸¸è§æ•°å­—ï¼‰\n",
    "            numbers = re.findall(r'\\b([2-9]\\d*|1[0-9]+)\\b', line)\n",
    "            \n",
    "            for num in numbers:\n",
    "                # æ’é™¤æ³¨é‡Šä¸­çš„æ•°å­—\n",
    "                if '#' in line:\n",
    "                    comment_pos = line.find('#')\n",
    "                    if line.find(num) > comment_pos:\n",
    "                        continue\n",
    "                \n",
    "                operation = RefactoringOperation(\n",
    "                    operation_type=RefactoringType.REPLACE_MAGIC_NUMBER,\n",
    "                    file_path=file_path,\n",
    "                    line_number=line_num,\n",
    "                    description=f\"æ›¿æ¢é­”æ³•æ•°å­— {num}\",\n",
    "                    original_code=line.strip(),\n",
    "                    refactored_code=line.strip().replace(num, f\"CONSTANT_{num}\"),\n",
    "                    risk_level=2,\n",
    "                    automated=True,\n",
    "                    requires_review=True,\n",
    "                    context={\"magic_number\": int(num)}\n",
    "                )\n",
    "                opportunities.append(operation)\n",
    "        \n",
    "        return opportunities\n",
    "    \n",
    "    def _find_extract_method_opportunities(self, file_path: str, lines: List[str]) -> List[RefactoringOperation]:\n",
    "        \"\"\"æŸ¥æ‰¾æå–æ–¹æ³•æœºä¼š\"\"\"\n",
    "        opportunities = []\n",
    "        \n",
    "        # ç®€åŒ–æ£€æµ‹ï¼šæŸ¥æ‰¾è¿‡é•¿çš„å‡½æ•°\n",
    "        current_function = None\n",
    "        function_start = 0\n",
    "        function_lines = []\n",
    "        \n",
    "        for line_num, line in enumerate(lines, 1):\n",
    "            if re.match(r'^\\s*def \\w+', line):\n",
    "                # ä¿å­˜ä¹‹å‰çš„å‡½æ•°\n",
    "                if current_function and len(function_lines) > 20:\n",
    "                    operation = RefactoringOperation(\n",
    "                        operation_type=RefactoringType.EXTRACT_METHOD,\n",
    "                        file_path=file_path,\n",
    "                        line_number=function_start,\n",
    "                        description=f\"æå–æ–¹æ³•: {current_function} (è¿‡é•¿)\",\n",
    "                        original_code=\"\\n\".join(function_lines[:5]) + \"...\",\n",
    "                        refactored_code=\"# å»ºè®®æ‹†åˆ†ä¸ºå¤šä¸ªå°æ–¹æ³•\",\n",
    "                        risk_level=5,\n",
    "                        automated=False,\n",
    "                        requires_review=True,\n",
    "                        context={\"function_name\": current_function, \"line_count\": len(function_lines)}\n",
    "                    )\n",
    "                    opportunities.append(operation)\n",
    "                \n",
    "                # å¼€å§‹æ–°å‡½æ•°\n",
    "                current_function = re.match(r'^\\s*def (\\w+)', line).group(1)\n",
    "                function_start = line_num\n",
    "                function_lines = [line]\n",
    "            elif current_function and (line.startswith('    ') or line.strip() == ''):\n",
    "                function_lines.append(line)\n",
    "            elif current_function and not line.startswith('    ') and line.strip():\n",
    "                # å‡½æ•°ç»“æŸ\n",
    "                if len(function_lines) > 20:\n",
    "                    operation = RefactoringOperation(\n",
    "                        operation_type=RefactoringType.EXTRACT_METHOD,\n",
    "                        file_path=file_path,\n",
    "                        line_number=function_start,\n",
    "                        description=f\"æå–æ–¹æ³•: {current_function} (è¿‡é•¿)\",\n",
    "                        original_code=\"\\n\".join(function_lines[:5]) + \"...\",\n",
    "                        refactored_code=\"# å»ºè®®æ‹†åˆ†ä¸ºå¤šä¸ªå°æ–¹æ³•\",\n",
    "                        risk_level=5,\n",
    "                        automated=False,\n",
    "                        requires_review=True,\n",
    "                        context={\"function_name\": current_function, \"line_count\": len(function_lines)}\n",
    "                    )\n",
    "                    opportunities.append(operation)\n",
    "                \n",
    "                current_function = None\n",
    "                function_lines = []\n",
    "        \n",
    "        return opportunities\n",
    "    \n",
    "    def _find_decompose_conditional_opportunities(self, file_path: str, lines: List[str]) -> List[RefactoringOperation]:\n",
    "        \"\"\"æŸ¥æ‰¾åˆ†è§£æ¡ä»¶æœºä¼š\"\"\"\n",
    "        opportunities = []\n",
    "        \n",
    "        for line_num, line in enumerate(lines, 1):\n",
    "            # æŸ¥æ‰¾å¤æ‚çš„ifæ¡ä»¶\n",
    "            if 'if ' in line and (' and ' in line or ' or ' in line):\n",
    "                # è®¡ç®—æ¡ä»¶å¤æ‚åº¦\n",
    "                condition_part = line[line.find('if ') + 3: line.find(':')]\n",
    "                complexity = condition_part.count(' and ') + condition_part.count(' or ') + 1\n",
    "                \n",
    "                if complexity > 2:\n",
    "                    operation = RefactoringOperation(\n",
    "                        operation_type=RefactoringType.DECOMPOSE_CONDITIONAL,\n",
    "                        file_path=file_path,\n",
    "                        line_number=line_num,\n",
    "                        description=f\"åˆ†è§£å¤æ‚æ¡ä»¶ (å¤æ‚åº¦: {complexity})\",\n",
    "                        original_code=line.strip(),\n",
    "                        refactored_code=\"# å»ºè®®å°†æ¡ä»¶æå–ä¸ºå˜é‡æˆ–æ–¹æ³•\",\n",
    "                        risk_level=3,\n",
    "                        automated=False,\n",
    "                        requires_review=True,\n",
    "                        context={\"complexity\": complexity, \"condition\": condition_part}\n",
    "                    )\n",
    "                    opportunities.append(operation)\n",
    "        \n",
    "        return opportunities\n",
    "    \n",
    "    def apply_refactoring(self, operation: RefactoringOperation) -> bool:\n",
    "        \"\"\"åº”ç”¨é‡æ„æ“ä½œ\"\"\"\n",
    "        if not operation.automated:\n",
    "            print(f\"é‡æ„æ“ä½œéœ€è¦æ‰‹åŠ¨æ‰§è¡Œ: {operation.description}\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # å¤‡ä»½åŸæ–‡ä»¶\n",
    "            if self.backup_enabled:\n",
    "                self._backup_file(operation.file_path)\n",
    "            \n",
    "            # æ‰§è¡Œé‡æ„\n",
    "            success = self._execute_refactoring(operation)\n",
    "            \n",
    "            if success:\n",
    "                self.applied_operations.append(operation)\n",
    "                print(f\"é‡æ„åº”ç”¨æˆåŠŸ: {operation.description}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"é‡æ„åº”ç”¨å¤±è´¥: {operation.description}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"é‡æ„åº”ç”¨å¼‚å¸¸: {operation.description} - {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _backup_file(self, file_path: str):\n",
    "        \"\"\"å¤‡ä»½æ–‡ä»¶\"\"\"\n",
    "        backup_path = f\"{file_path}.backup.{int(time.time())}\"\n",
    "        shutil.copy2(file_path, backup_path)\n",
    "        print(f\"æ–‡ä»¶å·²å¤‡ä»½: {backup_path}\")\n",
    "    \n",
    "    def _execute_refactoring(self, operation: RefactoringOperation) -> bool:\n",
    "        \"\"\"æ‰§è¡Œé‡æ„æ“ä½œ\"\"\"\n",
    "        refactoring_func = self.refactoring_rules.get(operation.operation_type)\n",
    "        \n",
    "        if refactoring_func:\n",
    "            return refactoring_func(operation)\n",
    "        else:\n",
    "            print(f\"ä¸æ”¯æŒçš„é‡æ„ç±»å‹: {operation.operation_type}\")\n",
    "            return False\n",
    "    \n",
    "    def _extract_method(self, operation: RefactoringOperation) -> bool:\n",
    "        \"\"\"æå–æ–¹æ³•ï¼ˆç®€åŒ–å®ç°ï¼‰\"\"\"\n",
    "        print(f\"æ‰§è¡Œæå–æ–¹æ³•é‡æ„: {operation.context.get('function_name')}\")\n",
    "        # è¿™é‡Œåº”è¯¥æœ‰å®é™…çš„ä»£ç æå–é€»è¾‘\n",
    "        return True\n",
    "    \n",
    "    def _rename_variable(self, operation: RefactoringOperation) -> bool:\n",
    "        \"\"\"é‡å‘½åå˜é‡ï¼ˆç®€åŒ–å®ç°ï¼‰\"\"\"\n",
    "        print(f\"æ‰§è¡Œå˜é‡é‡å‘½åé‡æ„\")\n",
    "        # è¿™é‡Œåº”è¯¥æœ‰å®é™…çš„å˜é‡é‡å‘½åé€»è¾‘\n",
    "        return True\n",
    "    \n",
    "    def _replace_magic_number(self, operation: RefactoringOperation) -> bool:\n",
    "        \"\"\"æ›¿æ¢é­”æ³•æ•°å­—\"\"\"\n",
    "        magic_number = operation.context.get(\"magic_number\")\n",
    "        constant_name = f\"CONSTANT_{magic_number}\"\n",
    "        \n",
    "        try:\n",
    "            with open(operation.file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¸¸é‡å®šä¹‰\n",
    "            lines = content.split('\\n')\n",
    "            import_inserted = False\n",
    "            \n",
    "            for i, line in enumerate(lines):\n",
    "                if line.startswith('import ') or line.startswith('from '):\n",
    "                    continue\n",
    "                elif line.strip() == '' or line.startswith('#'):\n",
    "                    continue\n",
    "                else:\n",
    "                    # åœ¨ç¬¬ä¸€ä¸ªéå¯¼å…¥è¡Œå‰æ’å…¥å¸¸é‡\n",
    "                    lines.insert(i, f\"{constant_name} = {magic_number}\")\n",
    "                    lines.insert(i, \"\")\n",
    "                    import_inserted = True\n",
    "                    break\n",
    "            \n",
    "            if not import_inserted:\n",
    "                lines.insert(0, f\"{constant_name} = {magic_number}\")\n",
    "            \n",
    "            # æ›¿æ¢æ–‡ä»¶ä¸­çš„é­”æ³•æ•°å­—\n",
    "            content = '\\n'.join(lines)\n",
    "            content = content.replace(f\" {magic_number}\", f\" {constant_name}\")\n",
    "            content = content.replace(f\"({magic_number})\", f\"({constant_name})\")\n",
    "            content = content.replace(f\"={magic_number}\", f\"={constant_name}\")\n",
    "            \n",
    "            with open(operation.file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            \n",
    "            print(f\"é­”æ³•æ•°å­— {magic_number} å·²æ›¿æ¢ä¸º {constant_name}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"æ›¿æ¢é­”æ³•æ•°å­—å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _decompose_conditional(self, operation: RefactoringOperation) -> bool:\n",
    "        \"\"\"åˆ†è§£æ¡ä»¶ï¼ˆç®€åŒ–å®ç°ï¼‰\"\"\"\n",
    "        print(f\"æ‰§è¡Œæ¡ä»¶åˆ†è§£é‡æ„\")\n",
    "        # è¿™é‡Œåº”è¯¥æœ‰å®é™…çš„æ¡ä»¶åˆ†è§£é€»è¾‘\n",
    "        return True\n",
    "    \n",
    "    def get_refactoring_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–é‡æ„æ‘˜è¦\"\"\"\n",
    "        type_counts = {}\n",
    "        risk_counts = {}\n",
    "        \n",
    "        for op in self.operations:\n",
    "            op_type = op.operation_type.value\n",
    "            type_counts[op_type] = type_counts.get(op_type, 0) + 1\n",
    "            risk_counts[op.risk_level] = risk_counts.get(op.risk_level, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_opportunities\": len(self.operations),\n",
    "            \"applied_operations\": len(self.applied_operations),\n",
    "            \"type_distribution\": type_counts,\n",
    "            \"risk_distribution\": risk_counts,\n",
    "            \"automation_rate\": len([op for op in self.operations if op.automated]) / len(self.operations) if self.operations else 0\n",
    "        }\n",
    "\n",
    "# 2.2 ç»´æŠ¤ç­–ç•¥ç®¡ç†\n",
    "print(f\"\\n   ğŸ“‹ 2.2 ç»´æŠ¤ç­–ç•¥ç®¡ç†:\")\n",
    "\n",
    "class MaintenanceStrategy(Enum):\n",
    "    \"\"\"ç»´æŠ¤ç­–ç•¥\"\"\"\n",
    "    REACTIVE = \"reactive\"  # ååº”å¼ç»´æŠ¤\n",
    "    PREVENTIVE = \"preventive\"  # é¢„é˜²æ€§ç»´æŠ¤\n",
    "    PREDICTIVE = \"predictive\"  # é¢„æµ‹æ€§ç»´æŠ¤\n",
    "    CONDITION_BASED = \"condition_based\"  # åŸºäºçŠ¶æ€çš„ç»´æŠ¤\n",
    "    TIME_BASED = \"time_based\"  # åŸºäºæ—¶é—´çš„ç»´æŠ¤\n",
    "\n",
    "@dataclass\n",
    "class MaintenanceTask:\n",
    "    \"\"\"ç»´æŠ¤ä»»åŠ¡\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    description: str\n",
    "    strategy: MaintenanceStrategy\n",
    "    priority: int  # 1-10\n",
    "    estimated_effort: int  # å°æ—¶\n",
    "    frequency: str  # ç»´æŠ¤é¢‘ç‡\n",
    "    dependencies: List[str]\n",
    "    created_at: datetime.datetime = field(default_factory=datetime.datetime.utcnow)\n",
    "    last_executed: Optional[datetime.datetime] = None\n",
    "    next_due: Optional[datetime.datetime] = None\n",
    "    \n",
    "    def is_due(self) -> bool:\n",
    "        \"\"\"æ£€æŸ¥æ˜¯å¦åˆ°æœŸ\"\"\"\n",
    "        if not self.next_due:\n",
    "            return True\n",
    "        return datetime.datetime.utcnow() >= self.next_due\n",
    "\n",
    "class MaintenanceManager:\n",
    "    \"\"\"ç»´æŠ¤ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks: List[MaintenanceTask] = []\n",
    "        self.task_history: List[Dict[str, Any]] = []\n",
    "        self.maintenance_schedule: Dict[str, List[str]] = {}\n",
    "        self.automated_tasks: List[str] = []\n",
    "    \n",
    "    def add_maintenance_task(self, task: MaintenanceTask):\n",
    "        \"\"\"æ·»åŠ ç»´æŠ¤ä»»åŠ¡\"\"\"\n",
    "        self.tasks.append(task)\n",
    "        \n",
    "        # è®¡ç®—ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´\n",
    "        if task.strategy == MaintenanceStrategy.TIME_BASED:\n",
    "            self._schedule_next_execution(task)\n",
    "        \n",
    "        print(f\"ç»´æŠ¤ä»»åŠ¡æ·»åŠ : {task.name} (ç­–ç•¥: {task.strategy.value})\")\n",
    "    \n",
    "    def _schedule_next_execution(self, task: MaintenanceTask):\n",
    "        \"\"\"è°ƒåº¦ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´\"\"\"\n",
    "        if task.frequency.startswith('daily'):\n",
    "            days = 1\n",
    "        elif task.frequency.startswith('weekly'):\n",
    "            days = 7\n",
    "        elif task.frequency.startswith('monthly'):\n",
    "            days = 30\n",
    "        else:\n",
    "            days = 1\n",
    "        \n",
    "        if task.last_executed:\n",
    "            task.next_due = task.last_executed + datetime.timedelta(days=days)\n",
    "        else:\n",
    "            task.next_due = datetime.datetime.utcnow() + datetime.timedelta(days=days)\n",
    "    \n",
    "    def get_due_tasks(self) -> List[MaintenanceTask]:\n",
    "        \"\"\"è·å–åˆ°æœŸçš„ç»´æŠ¤ä»»åŠ¡\"\"\"\n",
    "        return [task for task in self.tasks if task.is_due()]\n",
    "    \n",
    "    def execute_maintenance_task(self, task_id: str, executor: str = \"system\") -> bool:\n",
    "        \"\"\"æ‰§è¡Œç»´æŠ¤ä»»åŠ¡\"\"\"\n",
    "        task = next((t for t in self.tasks if t.id == task_id), None)\n",
    "        if not task:\n",
    "            print(f\"æœªæ‰¾åˆ°ç»´æŠ¤ä»»åŠ¡: {task_id}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"æ‰§è¡Œç»´æŠ¤ä»»åŠ¡: {task.name}\")\n",
    "        \n",
    "        start_time = datetime.datetime.utcnow()\n",
    "        \n",
    "        try:\n",
    "            # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            # æ›´æ–°ä»»åŠ¡çŠ¶æ€\n",
    "            task.last_executed = start_time\n",
    "            if task.strategy == MaintenanceStrategy.TIME_BASED:\n",
    "                self._schedule_next_execution(task)\n",
    "            \n",
    "            # è®°å½•æ‰§è¡Œå†å²\n",
    "            execution_record = {\n",
    "                \"task_id\": task_id,\n",
    "                \"task_name\": task.name,\n",
    "                \"executed_at\": start_time.isoformat(),\n",
    "                \"executor\": executor,\n",
    "                \"success\": True,\n",
    "                \"duration\": (datetime.datetime.utcnow() - start_time).total_seconds()\n",
    "            }\n",
    "            \n",
    "            self.task_history.append(execution_record)\n",
    "            \n",
    "            print(f\"ç»´æŠ¤ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ: {task.name}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.name} - {e}\")\n",
    "            \n",
    "            execution_record = {\n",
    "                \"task_id\": task_id,\n",
    "                \"task_name\": task.name,\n",
    "                \"executed_at\": start_time.isoformat(),\n",
    "                \"executor\": executor,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"duration\": (datetime.datetime.utcnow() - start_time).total_seconds()\n",
    "            }\n",
    "            \n",
    "            self.task_history.append(execution_record)\n",
    "            return False\n",
    "    \n",
    "    def create_maintenance_plan(self, strategy: MaintenanceStrategy) -> List[MaintenanceTask]:\n",
    "        \"\"\"åˆ›å»ºç»´æŠ¤è®¡åˆ’\"\"\"\n",
    "        if strategy == MaintenanceStrategy.PREVENTIVE:\n",
    "            plan = self._create_preventive_plan()\n",
    "        elif strategy == MaintenanceStrategy.PREDICTIVE:\n",
    "            plan = self._create_predictive_plan()\n",
    "        else:\n",
    "            plan = []\n",
    "        \n",
    "        for task in plan:\n",
    "            self.add_maintenance_task(task)\n",
    "        \n",
    "        print(f\"ç»´æŠ¤è®¡åˆ’åˆ›å»ºå®Œæˆ: {strategy.value} - {len(plan)} ä¸ªä»»åŠ¡\")\n",
    "        return plan\n",
    "    \n",
    "    def _create_preventive_plan(self) -> List[MaintenanceTask]:\n",
    "        \"\"\"åˆ›å»ºé¢„é˜²æ€§ç»´æŠ¤è®¡åˆ’\"\"\"\n",
    "        return [\n",
    "            MaintenanceTask(\n",
    "                id=str(uuid.uuid4()),\n",
    "                name=\"ä»£ç è´¨é‡æ£€æŸ¥\",\n",
    "                description=\"å®šæœŸæ£€æŸ¥ä»£ç è´¨é‡å’Œå¼‚å‘³\",\n",
    "                strategy=MaintenanceStrategy.TIME_BASED,\n",
    "                priority=7,\n",
    "                estimated_effort=2,\n",
    "                frequency=\"weekly\"\n",
    "            ),\n",
    "            MaintenanceTask(\n",
    "                id=str(uuid.uuid4()),\n",
    "                name=\"ä¾èµ–æ›´æ–°\",\n",
    "                description=\"æ›´æ–°é¡¹ç›®ä¾èµ–åŒ…\",\n",
    "                strategy=MaintenanceStrategy.TIME_BASED,\n",
    "                priority=6,\n",
    "                estimated_effort=4,\n",
    "                frequency=\"monthly\"\n",
    "            ),\n",
    "            MaintenanceTask(\n",
    "                id=str(uuid.uuid4()),\n",
    "                name=\"æ–‡æ¡£æ›´æ–°\",\n",
    "                description=\"æ›´æ–°é¡¹ç›®æ–‡æ¡£å’ŒAPIæ–‡æ¡£\",\n",
    "                strategy=MaintenanceStrategy.TIME_BASED,\n",
    "                priority=5,\n",
    "                estimated_effort=3,\n",
    "                frequency=\"monthly\"\n",
    "            ),\n",
    "            MaintenanceTask(\n",
    "                id=str(uuid.uuid4()),\n",
    "                name=\"æ€§èƒ½ä¼˜åŒ–\",\n",
    "                description=\"åˆ†æå’Œä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½\",\n",
    "                strategy=MaintenanceStrategy.TIME_BASED,\n",
    "                priority=8,\n",
    "                estimated_effort=6,\n",
    "                frequency=\"monthly\"\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def _create_predictive_plan(self) -> List[MaintenanceTask]:\n",
    "        \"\"\"åˆ›å»ºé¢„æµ‹æ€§ç»´æŠ¤è®¡åˆ’\"\"\"\n",
    "        return [\n",
    "            MaintenanceTask(\n",
    "                id=str(uuid.uuid4()),\n",
    "                name=\"æ•…éšœé¢„æµ‹åˆ†æ\",\n",
    "                description=\"åŸºäºå†å²æ•°æ®é¢„æµ‹æ½œåœ¨æ•…éšœ\",\n",
    "                strategy=MaintenanceStrategy.PREDICTIVE,\n",
    "                priority=9,\n",
    "                estimated_effort=8,\n",
    "                frequency=\"weekly\"\n",
    "            ),\n",
    "            MaintenanceTask(\n",
    "                id=str(uuid.uuid4()),\n",
    "                name=\"å®¹é‡è§„åˆ’\",\n",
    "                description=\"é¢„æµ‹ç³»ç»Ÿèµ„æºéœ€æ±‚\",\n",
    "                strategy=MaintenanceStrategy.PREDICTIVE,\n",
    "                priority=7,\n",
    "                estimated_effort=4,\n",
    "                frequency=\"monthly\"\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def get_maintenance_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ç»´æŠ¤æŠ¥å‘Š\"\"\"\n",
    "        total_tasks = len(self.tasks)\n",
    "        due_tasks = len(self.get_due_tasks())\n",
    "        completed_tasks = len(self.task_history)\n",
    "        successful_tasks = len([h for h in self.task_history if h[\"success\"]])\n",
    "        \n",
    "        strategy_counts = {}\n",
    "        for task in self.tasks:\n",
    "            strategy = task.strategy.value\n",
    "            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_tasks\": total_tasks,\n",
    "            \"due_tasks\": due_tasks,\n",
    "            \"completed_tasks\": completed_tasks,\n",
    "            \"success_rate\": successful_tasks / completed_tasks if completed_tasks > 0 else 0,\n",
    "            \"strategy_distribution\": strategy_counts,\n",
    "            \"total_effort\": sum(task.estimated_effort for task in self.tasks),\n",
    "            \"average_priority\": sum(task.priority for task in self.tasks) / total_tasks if total_tasks > 0 else 0\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… é‡æ„å·¥å…·ç³»ç»Ÿå®Œæˆ\")\n",
    "print(f\"      - AutomatedRefactoringTool: è‡ªåŠ¨åŒ–é‡æ„å·¥å…·\")\n",
    "print(f\"      - MaintenanceManager: ç»´æŠ¤ç­–ç•¥ç®¡ç†å™¨\")\n",
    "print(f\"      - æ”¯æŒ13ç§é‡æ„æ“ä½œç±»å‹\")\n",
    "print(f\"      - æä¾›å®Œæ•´çš„ç»´æŠ¤è®¡åˆ’ç®¡ç†\")\n",
    "\n",
    "print(f\"\\nâœ… é‡æ„å·¥å…·ä¸ç»´æŠ¤ç­–ç•¥å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡é‡æ„å·¥å…·çš„è®¾è®¡å’Œä½¿ç”¨\")\n",
    "print(f\"   âœ“ å­¦ä¼šç»´æŠ¤ç­–ç•¥çš„åˆ¶å®šå’Œæ‰§è¡Œ\")\n",
    "print(f\"   âœ“ ç†è§£ä»£ç æ¼”è¿›çš„æœ€ä½³å®è·µ\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„é‡æ„æµç¨‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### çŸ¥è¯†æ¸…å•è¾¾æˆæƒ…å†µ\n",
    "\n",
    "#### âœ… å·²å®ŒæˆçŸ¥è¯†ç‚¹\n",
    "\n",
    "**8.6 ä»£ç é‡æ„ä¸ç»´æŠ¤ [â­â­è¿›é˜¶]**\n",
    "- âœ… æŒæ¡é‡æ„çš„åŸåˆ™å’Œæ—¶æœº\n",
    "- âœ… å­¦ä¼šè¯†åˆ«å’Œå¤„ç†ä»£ç å¼‚å‘³\n",
    "- âœ… ç†è§£ç»´æŠ¤ç­–ç•¥å’Œç‰ˆæœ¬ç®¡ç†\n",
    "- âœ… èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„é‡æ„æµç¨‹\n",
    "\n",
    "#### ğŸ¯ æ ¸å¿ƒæŠ€èƒ½æŒæ¡\n",
    "\n",
    "**ä»£ç å¼‚å‘³æ£€æµ‹**\n",
    "- âœ… 15ç§ä»£ç å¼‚å‘³ç±»å‹è¯†åˆ«\n",
    "- âœ… ä»£ç è´¨é‡æŒ‡æ ‡è®¡ç®—\n",
    "- âœ… åœˆå¤æ‚åº¦å’Œå¯ç»´æŠ¤æ€§åˆ†æ\n",
    "- âœ… HalsteadæŒ‡æ ‡è®¡ç®—\n",
    "\n",
    "**é‡æ„æŠ€æœ¯**\n",
    "- âœ… 13ç§é‡æ„æ“ä½œç±»å‹\n",
    "- âœ… è‡ªåŠ¨åŒ–é‡æ„å·¥å…·è®¾è®¡\n",
    "- âœ… é‡æ„é£é™©è¯„ä¼°å’Œç®¡ç†\n",
    "- âœ… ä»£ç æ”¹è¿›å»ºè®®ç”Ÿæˆ\n",
    "\n",
    "**ç»´æŠ¤ç­–ç•¥**\n",
    "- âœ… 5ç§ç»´æŠ¤ç­–ç•¥ç±»å‹\n",
    "- âœ… é¢„é˜²æ€§å’Œé¢„æµ‹æ€§ç»´æŠ¤\n",
    "- âœ… ç»´æŠ¤ä»»åŠ¡è°ƒåº¦ç®¡ç†\n",
    "- âœ… ç»´æŠ¤æ•ˆæœè¯„ä¼°\n",
    "\n",
    "#### ğŸš€ å®è·µåº”ç”¨èƒ½åŠ›\n",
    "\n",
    "**ä»£ç è´¨é‡ä¿éšœ**\n",
    "- âœ… ä»£ç è´¨é‡ç›‘æ§ä½“ç³»\n",
    "- âœ… è‡ªåŠ¨åŒ–ä»£ç åˆ†æ\n",
    "- âœ… è´¨é‡è¶‹åŠ¿åˆ†æ\n",
    "- âœ… æ”¹è¿›å»ºè®®å®æ–½\n",
    "\n",
    "**æŒç»­æ”¹è¿›**\n",
    "- âœ… ä»£ç æ¼”è¿›è¿½è¸ª\n",
    "- âœ… é‡æ„è®¡åˆ’åˆ¶å®š\n",
    "- âœ… ç»´æŠ¤å‘¨æœŸç®¡ç†\n",
    "- âœ… æŠ€æœ¯å€ºåŠ¡æ§åˆ¶\n",
    "\n",
    "#### ğŸ“Š ä¸LangChainçš„å…³è”\n",
    "\n",
    "**AIä»£ç è´¨é‡**\n",
    "- âœ… æ”¯æŒLangChainé¡¹ç›®çš„ä»£ç é‡æ„\n",
    "- âœ… AIç»„ä»¶è´¨é‡ç›‘æ§\n",
    "- âœ… æœºå™¨å­¦ä¹ ä»£ç ä¼˜åŒ–\n",
    "- âœ… AIç³»ç»Ÿæ¶æ„æ”¹è¿›\n",
    "\n",
    "**å·¥ç¨‹åŒ–æ”¯æŒ**\n",
    "- âœ… ä¸ºLangChainæä¾›ä»£ç è´¨é‡ä¿éšœ\n",
    "- âœ… æ”¯æŒAIé¡¹ç›®çš„æŒç»­æ”¹è¿›\n",
    "- âœ… ä¿éšœLangChainä»£ç çš„å¯ç»´æŠ¤æ€§\n",
    "- âœ… å®ç°AIç³»ç»Ÿçš„æŠ€æœ¯å€ºåŠ¡ç®¡ç†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ æˆæœ\n",
    "\n",
    "é€šè¿‡æœ¬èŠ‚å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š\n",
    "\n",
    "1. **ä»£ç å¼‚å‘³æ£€æµ‹æŠ€æœ¯** - ç†è§£ä»£ç è´¨é‡é—®é¢˜çš„è¯†åˆ«æ–¹æ³•ï¼Œèƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„ä»£ç è´¨é‡ç›‘æ§ä½“ç³»\n",
    "2. **è‡ªåŠ¨åŒ–é‡æ„å·¥å…·** - æŒæ¡é‡æ„å·¥å…·çš„è®¾è®¡å’Œå®ç°ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ–æ”¹è¿›ä»£ç è´¨é‡\n",
    "3. **ç»´æŠ¤ç­–ç•¥ç®¡ç†** - å­¦ä¼šç»´æŠ¤ç­–ç•¥çš„åˆ¶å®šå’Œæ‰§è¡Œï¼Œèƒ½å¤Ÿä¿éšœä»£ç çš„é•¿æœŸå¯ç»´æŠ¤æ€§\n",
    "4. **æŒç»­æ”¹è¿›æµç¨‹** - èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„ä»£ç æ¼”è¿›å’Œç»´æŠ¤æµç¨‹\n",
    "\n",
    "è¿™äº›æŠ€èƒ½ä¸ºLangChainç­‰AIé¡¹ç›®çš„ä»£ç è´¨é‡ä¿éšœæä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆï¼Œç¡®ä¿äº†é¡¹ç›®çš„æŒç»­æ”¹è¿›å’Œé•¿æœŸç»´æŠ¤èƒ½åŠ›ã€‚æ¥ä¸‹æ¥å°†ç»§ç»­å­¦ä¹ æ–‡æ¡£ç”Ÿæˆä¸å›¢é˜Ÿåä½œç­‰å·¥ç¨‹å®è·µæŠ€èƒ½ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
