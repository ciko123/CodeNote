{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 48-å¼‚æ­¥I/Oæ“ä½œ\n",
    "\n",
    "## ğŸ“š ç”¨é€”è¯´æ˜\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "- æŒæ¡å¼‚æ­¥æ–‡ä»¶I/Oæ“ä½œçš„æ ¸å¿ƒæŠ€æœ¯\n",
    "- å­¦ä¼šä½¿ç”¨aiofilesè¿›è¡Œé«˜æ•ˆçš„å¼‚æ­¥æ–‡ä»¶å¤„ç†\n",
    "- ç†è§£å¼‚æ­¥æµå¼æ•°æ®å¤„ç†å’Œç¼“å†²æœºåˆ¶\n",
    "- èƒ½å¤Ÿæ„å»ºé«˜æ€§èƒ½çš„å¼‚æ­¥I/Oåº”ç”¨ç³»ç»Ÿ\n",
    "\n",
    "**å‰ç½®è¦æ±‚**ï¼š\n",
    "- å·²å®Œæˆåç¨‹ä¸äº‹ä»¶å¾ªç¯å­¦ä¹ \n",
    "- ç†Ÿç»ƒæŒæ¡async/awaitè¯­æ³•å’Œåç¨‹æœºåˆ¶\n",
    "- äº†è§£åŸºæœ¬çš„æ–‡ä»¶æ“ä½œå’ŒI/Oæ¦‚å¿µ\n",
    "- ç†è§£å¼‚æ­¥ç¼–ç¨‹çš„æ€§èƒ½ä¼˜åŠ¿\n",
    "\n",
    "**ä¸LangChainå…³è”**ï¼š\n",
    "- å¼‚æ­¥I/Oä¼˜åŒ–LangChainçš„å¤§æ–‡ä»¶å¤„ç†èƒ½åŠ›\n",
    "- æµå¼I/Oæ”¯æŒLangChainçš„å®æ—¶æ•°æ®å¤„ç†\n",
    "- å¼‚æ­¥æ–‡ä»¶æ“ä½œæå‡LangChainçš„å“åº”æ€§èƒ½\n",
    "- I/Oç¼“å†²æœºåˆ¶ä¼˜åŒ–LangChainçš„èµ„æºåˆ©ç”¨\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ çŸ¥è¯†ç‚¹è¦†ç›–\n",
    "\n",
    "### 6.3 å¼‚æ­¥I/Oæ“ä½œ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šå¼‚æ­¥I/Oæ“ä½œæ˜¯é«˜æ€§èƒ½å¼‚æ­¥ç¼–ç¨‹çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œå¯¹äºæ„å»ºé«˜æ•ˆçš„LangChainåº”ç”¨è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡å¼‚æ­¥æ–‡ä»¶I/Oæ“ä½œçš„æ ¸å¿ƒæŠ€æœ¯\n",
    "- å­¦ä¼šä½¿ç”¨aiofilesè¿›è¡Œé«˜æ•ˆçš„å¼‚æ­¥æ–‡ä»¶å¤„ç†\n",
    "- ç†è§£å¼‚æ­¥æµå¼æ•°æ®å¤„ç†å’Œç¼“å†²æœºåˆ¶\n",
    "- èƒ½å¤Ÿæ„å»ºé«˜æ€§èƒ½çš„å¼‚æ­¥I/Oåº”ç”¨ç³»ç»Ÿ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„å¼‚æ­¥æ–‡ä»¶å¤„ç†ç³»ç»Ÿ\n",
    "- è¿›è¡Œå¼‚æ­¥I/Oæ€§èƒ½å¯¹æ¯”åˆ†æ\n",
    "- åº”ç”¨å¼‚æ­¥æµå¼å¤„ç†è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹ä¼˜åŒ–å¼‚æ­¥I/Oæ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ’¾ å¼‚æ­¥I/Oæ“ä½œ:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import asyncio\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import tempfile\n",
    "import shutil\n",
    "from typing import List, Dict, Any, Optional, AsyncGenerator\n",
    "from dataclasses import dataclass, asdict\n",
    "import aiofiles\n",
    "import aiofiles.os\n",
    "import nest_asyncio\n",
    "\n",
    "# å…è®¸åœ¨Jupyterä¸­è¿è¡Œå¼‚æ­¥ä»£ç \n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(f\"âœ… Pythonç‰ˆæœ¬: {__import__('sys').version}\")\n",
    "print(f\"âœ… aiofilesç‰ˆæœ¬: {aiofiles.__version__}\")\n",
    "print(f\"âœ… å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. å¼‚æ­¥æ–‡ä»¶åŸºç¡€æ“ä½œ\n",
    "print(f\"ğŸ“ 1. å¼‚æ­¥æ–‡ä»¶åŸºç¡€æ“ä½œ:\")\n",
    "\n",
    "# 1.1 å¼‚æ­¥æ–‡ä»¶è¯»å†™\n",
    "print(f\"\\n   ğŸ” 1.1 å¼‚æ­¥æ–‡ä»¶è¯»å†™:\")\n",
    "\n",
    "async def demonstrate_async_file_operations():\n",
    "    \"\"\"æ¼”ç¤ºå¼‚æ­¥æ–‡ä»¶åŸºç¡€æ“ä½œ\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¼‚æ­¥æ–‡ä»¶æ“ä½œæ¼”ç¤º:\")\n",
    "    \n",
    "    # åˆ›å»ºä¸´æ—¶ç›®å½•\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    test_file = os.path.join(temp_dir, \"test_async.txt\")\n",
    "    \n",
    "    try:\n",
    "        # å¼‚æ­¥å†™å…¥æ–‡ä»¶\n",
    "        content = \"è¿™æ˜¯å¼‚æ­¥å†™å…¥çš„æµ‹è¯•å†…å®¹\\n\" * 10\n",
    "        print(f\"      å¼‚æ­¥å†™å…¥æ–‡ä»¶: {test_file}\")\n",
    "        \n",
    "        async with aiofiles.open(test_file, 'w', encoding='utf-8') as f:\n",
    "            await f.write(content)\n",
    "            print(f\"      å†™å…¥å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\")\n",
    "        \n",
    "        # å¼‚æ­¥è¯»å–æ–‡ä»¶\n",
    "        print(f\"\\n      å¼‚æ­¥è¯»å–æ–‡ä»¶:\")\n",
    "        async with aiofiles.open(test_file, 'r', encoding='utf-8') as f:\n",
    "            read_content = await f.read()\n",
    "            print(f\"      è¯»å–å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(read_content)} å­—ç¬¦\")\n",
    "            print(f\"      å†…å®¹åŒ¹é…: {content == read_content}\")\n",
    "        \n",
    "        # å¼‚æ­¥è¿½åŠ å†…å®¹\n",
    "        print(f\"\\n      å¼‚æ­¥è¿½åŠ å†…å®¹:\")\n",
    "        append_content = \"\\nè¿™æ˜¯è¿½åŠ çš„å†…å®¹\\n\"\n",
    "        async with aiofiles.open(test_file, 'a', encoding='utf-8') as f:\n",
    "            await f.write(append_content)\n",
    "        \n",
    "        # éªŒè¯è¿½åŠ ç»“æœ\n",
    "        async with aiofiles.open(test_file, 'r', encoding='utf-8') as f:\n",
    "            final_content = await f.read()\n",
    "            print(f\"      æœ€ç»ˆæ–‡ä»¶é•¿åº¦: {len(final_content)} å­—ç¬¦\")\n",
    "            print(f\"      åŒ…å«è¿½åŠ å†…å®¹: {append_content in final_content}\")\n",
    "        \n",
    "        return \"å¼‚æ­¥æ–‡ä»¶åŸºç¡€æ“ä½œå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        if os.path.exists(test_file):\n",
    "            os.remove(test_file)\n",
    "        os.rmdir(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥æ–‡ä»¶æ“ä½œæ¼”ç¤º\n",
    "file_ops_result = await demonstrate_async_file_operations()\n",
    "print(f\"   {file_ops_result}\")\n",
    "\n",
    "# 1.2 å¼‚æ­¥æ–‡ä»¶è¡Œæ“ä½œ\n",
    "print(f\"\\n   ğŸ“„ 1.2 å¼‚æ­¥æ–‡ä»¶è¡Œæ“ä½œ:\")\n",
    "\n",
    "async def demonstrate_async_line_operations():\n",
    "    \"\"\"æ¼”ç¤ºå¼‚æ­¥æ–‡ä»¶è¡Œæ“ä½œ\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¼‚æ­¥è¡Œæ“ä½œæ¼”ç¤º:\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    lines_file = os.path.join(temp_dir, \"lines_test.txt\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "        test_lines = [\n",
    "            f\"ç¬¬{i+1}è¡Œï¼šè¿™æ˜¯æµ‹è¯•æ•°æ®{i}\" \n",
    "            for i in range(20)\n",
    "        ]\n",
    "        \n",
    "        # å¼‚æ­¥å†™å…¥å¤šè¡Œ\n",
    "        print(f\"      å¼‚æ­¥å†™å…¥{len(test_lines)}è¡Œæ•°æ®:\")\n",
    "        async with aiofiles.open(lines_file, 'w', encoding='utf-8') as f:\n",
    "            for line in test_lines:\n",
    "                await f.write(line + '\\n')\n",
    "        \n",
    "        # å¼‚æ­¥é€è¡Œè¯»å–\n",
    "        print(f\"\\n      å¼‚æ­¥é€è¡Œè¯»å–:\")\n",
    "        line_count = 0\n",
    "        async with aiofiles.open(lines_file, 'r', encoding='utf-8') as f:\n",
    "            async for line in f:\n",
    "                line_count += 1\n",
    "                if line_count <= 3 or line_count > 17:  # åªæ˜¾ç¤ºå‰3è¡Œå’Œå3è¡Œ\n",
    "                    print(f\"        {line.strip()}\")\n",
    "                elif line_count == 4:\n",
    "                    print(f\"        ... (çœç•¥ä¸­é—´è¡Œ) ...\")\n",
    "        \n",
    "        print(f\"      æ€»å…±è¯»å–: {line_count} è¡Œ\")\n",
    "        \n",
    "        # å¼‚æ­¥è¯»å–æŒ‡å®šè¡Œ\n",
    "        print(f\"\\n      å¼‚æ­¥è¯»å–æŒ‡å®šè¡Œ:\")\n",
    "        async with aiofiles.open(lines_file, 'r', encoding='utf-8') as f:\n",
    "            lines = await f.readlines()\n",
    "            \n",
    "            # è¯»å–ç¬¬5è¡Œ\n",
    "            line_5 = lines[4].strip()\n",
    "            print(f\"        ç¬¬5è¡Œ: {line_5}\")\n",
    "            \n",
    "            # è¯»å–æœ€å3è¡Œ\n",
    "            last_3_lines = [line.strip() for line in lines[-3:]]\n",
    "            print(f\"        æœ€å3è¡Œ: {last_3_lines}\")\n",
    "        \n",
    "        return \"å¼‚æ­¥æ–‡ä»¶è¡Œæ“ä½œå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        if os.path.exists(lines_file):\n",
    "            os.remove(lines_file)\n",
    "        os.rmdir(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥è¡Œæ“ä½œæ¼”ç¤º\n",
    "line_ops_result = await demonstrate_async_line_operations()\n",
    "print(f\"   {line_ops_result}\")\n",
    "\n",
    "# 1.3 å¼‚æ­¥äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œ\n",
    "print(f\"\\n   ğŸ”¢ 1.3 å¼‚æ­¥äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œ:\")\n",
    "\n",
    "async def demonstrate_async_binary_operations():\n",
    "    \"\"\"æ¼”ç¤ºå¼‚æ­¥äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œ\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¼‚æ­¥äºŒè¿›åˆ¶æ“ä½œæ¼”ç¤º:\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    binary_file = os.path.join(temp_dir, \"binary_test.bin\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºäºŒè¿›åˆ¶æ•°æ®\n",
    "        binary_data = bytes(range(256)) * 4  # 1KBçš„äºŒè¿›åˆ¶æ•°æ®\n",
    "        print(f\"      åˆ›å»ºäºŒè¿›åˆ¶æ•°æ®: {len(binary_data)} å­—èŠ‚\")\n",
    "        \n",
    "        # å¼‚æ­¥å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶\n",
    "        print(f\"      å¼‚æ­¥å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶:\")\n",
    "        async with aiofiles.open(binary_file, 'wb') as f:\n",
    "            await f.write(binary_data)\n",
    "        \n",
    "        # å¼‚æ­¥è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶\n",
    "        print(f\"\\n      å¼‚æ­¥è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶:\")\n",
    "        async with aiofiles.open(binary_file, 'rb') as f:\n",
    "            read_data = await f.read()\n",
    "            print(f\"      è¯»å–æ•°æ®é•¿åº¦: {len(read_data)} å­—èŠ‚\")\n",
    "            print(f\"      æ•°æ®åŒ¹é…: {binary_data == read_data}\")\n",
    "            print(f\"      å‰16å­—èŠ‚: {list(read_data[:16])}\")\n",
    "        \n",
    "        # åˆ†å—è¯»å†™äºŒè¿›åˆ¶æ–‡ä»¶\n",
    "        print(f\"\\n      åˆ†å—è¯»å†™æ¼”ç¤º:\")\n",
    "        chunk_size = 64\n",
    "        chunked_file = os.path.join(temp_dir, \"chunked_test.bin\")\n",
    "        \n",
    "        # åˆ†å—å†™å…¥\n",
    "        async with aiofiles.open(chunked_file, 'wb') as f:\n",
    "            for i in range(0, len(binary_data), chunk_size):\n",
    "                chunk = binary_data[i:i+chunk_size]\n",
    "                await f.write(chunk)\n",
    "        \n",
    "        # åˆ†å—è¯»å–\n",
    "        chunk_count = 0\n",
    "        total_read = 0\n",
    "        async with aiofiles.open(chunked_file, 'rb') as f:\n",
    "            while True:\n",
    "                chunk = await f.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                chunk_count += 1\n",
    "                total_read += len(chunk)\n",
    "        \n",
    "        print(f\"      åˆ†å—è¯»å–å®Œæˆ: {chunk_count} å—, {total_read} å­—èŠ‚\")\n",
    "        \n",
    "        return \"å¼‚æ­¥äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        for file_path in [binary_file, chunked_file]:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "        os.rmdir(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥äºŒè¿›åˆ¶æ“ä½œæ¼”ç¤º\n",
    "binary_ops_result = await demonstrate_async_binary_operations()\n",
    "print(f\"   {binary_ops_result}\")\n",
    "\n",
    "print(f\"\\nâœ… å¼‚æ­¥æ–‡ä»¶åŸºç¡€æ“ä½œå®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡å¼‚æ­¥æ–‡ä»¶I/Oæ“ä½œçš„æ ¸å¿ƒæŠ€æœ¯\")\n",
    "print(f\"   âœ“ å­¦ä¼šä½¿ç”¨aiofilesè¿›è¡Œé«˜æ•ˆçš„å¼‚æ­¥æ–‡ä»¶å¤„ç†\")\n",
    "print(f\"   âœ“ ç†è§£å¼‚æ­¥æ–‡ä»¶è¯»å†™å’Œè¡Œæ“ä½œ\")\n",
    "print(f\"   âœ“ æŒæ¡å¼‚æ­¥äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¼‚æ­¥æµå¼æ•°æ®å¤„ç† [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šå¼‚æ­¥æµå¼æ•°æ®å¤„ç†æ˜¯å¤„ç†å¤§é‡æ•°æ®çš„é«˜æ•ˆæ–¹å¼ï¼Œå¯¹äºLangChainçš„å®æ—¶æ•°æ®å¤„ç†éå¸¸é‡è¦ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡å¼‚æ­¥æµå¼è¯»å–å’Œå†™å…¥æŠ€æœ¯\n",
    "- ç†è§£å¼‚æ­¥ç¼“å†²å’Œåˆ†å—å¤„ç†æœºåˆ¶\n",
    "- å­¦ä¼šå¼‚æ­¥æ•°æ®ç®¡é“æ„å»º\n",
    "- èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„æµå¼æ•°æ®å¤„ç†\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„å¼‚æ­¥æµå¼å¤„ç†ç³»ç»Ÿ\n",
    "- è¿›è¡Œæµå¼å¤„ç†æ€§èƒ½åˆ†æ\n",
    "- åº”ç”¨æµå¼å¤„ç†è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹ä¼˜åŒ–æµå¼å¤„ç†æ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸŒŠ å¼‚æ­¥æµå¼æ•°æ®å¤„ç†:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. å¼‚æ­¥æµå¼æ–‡ä»¶å¤„ç†\n",
    "print(f\"ğŸ“ 1. å¼‚æ­¥æµå¼æ–‡ä»¶å¤„ç†:\")\n",
    "\n",
    "# 1.1 å¼‚æ­¥æµå¼è¯»å–\n",
    "print(f\"\\n   ğŸ” 1.1 å¼‚æ­¥æµå¼è¯»å–:\")\n",
    "\n",
    "async def async_stream_reader(file_path: str, chunk_size: int = 1024) -> AsyncGenerator[bytes, None]:\n",
    "    \"\"\"å¼‚æ­¥æµå¼æ–‡ä»¶è¯»å–å™¨\"\"\"\n",
    "    async with aiofiles.open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            chunk = await f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "\n",
    "async def async_text_stream_reader(file_path: str, line_count: int = 10) -> AsyncGenerator[str, None]:\n",
    "    \"\"\"å¼‚æ­¥æ–‡æœ¬æµå¼è¯»å–å™¨\"\"\"\n",
    "    async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines_read = 0\n",
    "        async for line in f:\n",
    "            if lines_read >= line_count:\n",
    "                break\n",
    "            yield line.strip()\n",
    "            lines_read += 1\n",
    "\n",
    "async def demonstrate_stream_reading():\n",
    "    \"\"\"æ¼”ç¤ºå¼‚æ­¥æµå¼è¯»å–\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¼‚æ­¥æµå¼è¯»å–æ¼”ç¤º:\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    stream_file = os.path.join(temp_dir, \"stream_test.txt\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶\n",
    "        test_content = \"\\n\".join([\n",
    "            f\"è¿™æ˜¯ç¬¬{i+1}è¡Œæµ‹è¯•æ•°æ®ï¼ŒåŒ…å«ä¸€äº›éšæœºæ•°å­—: {random.randint(1000, 9999)}\"\n",
    "            for i in range(100)\n",
    "        ])\n",
    "        \n",
    "        async with aiofiles.open(stream_file, 'w', encoding='utf-8') as f:\n",
    "            await f.write(test_content)\n",
    "        \n",
    "        print(f\"      åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {len(test_content)} å­—ç¬¦\")\n",
    "        \n",
    "        # æ–‡æœ¬æµå¼è¯»å–\n",
    "        print(f\"\\n      æ–‡æœ¬æµå¼è¯»å– (å‰20è¡Œ):\")\n",
    "        line_count = 0\n",
    "        async for line in async_text_stream_reader(stream_file, 20):\n",
    "            line_count += 1\n",
    "            print(f\"        {line_count:2d}: {line}\")\n",
    "            \n",
    "            # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ\n",
    "            await asyncio.sleep(0.01)\n",
    "        \n",
    "        # äºŒè¿›åˆ¶æµå¼è¯»å–\n",
    "        print(f\"\\n      äºŒè¿›åˆ¶æµå¼è¯»å– (å‰5ä¸ªå—):\")\n",
    "        chunk_count = 0\n",
    "        async for chunk in async_stream_reader(stream_file, chunk_size=50):\n",
    "            chunk_count += 1\n",
    "            if chunk_count <= 5:\n",
    "                print(f\"        å—{chunk_count}: {len(chunk)} å­—èŠ‚\")\n",
    "                print(f\"          å†…å®¹: {chunk[:50]}...\")\n",
    "            elif chunk_count == 6:\n",
    "                print(f\"        ... (ç»§ç»­è¯»å–å‰©ä½™å—) ...\")\n",
    "                break\n",
    "        \n",
    "        return \"å¼‚æ­¥æµå¼è¯»å–æ¼”ç¤ºå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        if os.path.exists(stream_file):\n",
    "            os.remove(stream_file)\n",
    "        os.rmdir(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œæµå¼è¯»å–æ¼”ç¤º\n",
    "stream_read_result = await demonstrate_stream_reading()\n",
    "print(f\"   {stream_read_result}\")\n",
    "\n",
    "# 1.2 å¼‚æ­¥æµå¼å†™å…¥\n",
    "print(f\"\\n   âœï¸ 1.2 å¼‚æ­¥æµå¼å†™å…¥:\")\n",
    "\n",
    "async def async_stream_writer(file_path: str, data_generator: AsyncGenerator[str, None]):\n",
    "    \"\"\"å¼‚æ­¥æµå¼æ–‡ä»¶å†™å…¥å™¨\"\"\"\n",
    "    async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:\n",
    "        async for data in data_generator:\n",
    "            await f.write(data + '\\n')\n",
    "            await f.flush()  # ç¡®ä¿æ•°æ®å†™å…¥ç£ç›˜\n",
    "\n",
    "async def data_stream_generator(count: int, delay: float = 0.01) -> AsyncGenerator[str, None]:\n",
    "    \"\"\"æ•°æ®æµç”Ÿæˆå™¨\"\"\"\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(delay)\n",
    "        yield f\"æµå¼æ•°æ®é¡¹{i+1}: æ—¶é—´æˆ³={time.time():.3f}, éšæœºå€¼={random.randint(1, 100)}\"\n",
    "\n",
    "async def demonstrate_stream_writing():\n",
    "    \"\"\"æ¼”ç¤ºå¼‚æ­¥æµå¼å†™å…¥\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¼‚æ­¥æµå¼å†™å…¥æ¼”ç¤º:\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    stream_write_file = os.path.join(temp_dir, \"stream_write.txt\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºæ•°æ®æµ\n",
    "        data_stream = data_stream_generator(15, 0.02)\n",
    "        \n",
    "        print(f\"      å¼€å§‹æµå¼å†™å…¥15ä¸ªæ•°æ®é¡¹...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # å¼‚æ­¥æµå¼å†™å…¥\n",
    "        await async_stream_writer(stream_write_file, data_stream)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"      æµå¼å†™å…¥å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.3f} ç§’\")\n",
    "        \n",
    "        # éªŒè¯å†™å…¥ç»“æœ\n",
    "        async with aiofiles.open(stream_write_file, 'r', encoding='utf-8') as f:\n",
    "            lines = await f.readlines()\n",
    "            print(f\"      å†™å…¥è¡Œæ•°: {len(lines)}\")\n",
    "            print(f\"      å‰3è¡Œå†…å®¹:\")\n",
    "            for i, line in enumerate(lines[:3]):\n",
    "                print(f\"        {i+1}: {line.strip()}\")\n",
    "            print(f\"      æœ€å3è¡Œå†…å®¹:\")\n",
    "            for i, line in enumerate(lines[-3:], len(lines)-2):\n",
    "                print(f\"        {i}: {line.strip()}\")\n",
    "        \n",
    "        return \"å¼‚æ­¥æµå¼å†™å…¥æ¼”ç¤ºå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        if os.path.exists(stream_write_file):\n",
    "            os.remove(stream_write_file)\n",
    "        os.rmdir(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œæµå¼å†™å…¥æ¼”ç¤º\n",
    "stream_write_result = await demonstrate_stream_writing()\n",
    "print(f\"   {stream_write_result}\")\n",
    "\n",
    "# 1.3 å¼‚æ­¥æ•°æ®å¤„ç†ç®¡é“\n",
    "print(f\"\\n   ğŸ”„ 1.3 å¼‚æ­¥æ•°æ®å¤„ç†ç®¡é“:\")\n",
    "\n",
    "@dataclass\n",
    "class DataItem:\n",
    "    \"\"\"æ•°æ®é¡¹\"\"\"\n",
    "    id: int\n",
    "    content: str\n",
    "    timestamp: float\n",
    "    processed: bool = False\n",
    "\n",
    "async def data_source_generator(count: int) -> AsyncGenerator[DataItem, None]:\n",
    "    \"\"\"æ•°æ®æºç”Ÿæˆå™¨\"\"\"\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå»¶è¿Ÿ\n",
    "        yield DataItem(\n",
    "            id=i+1,\n",
    "            content=f\"åŸå§‹æ•°æ®{i+1}\",\n",
    "            timestamp=time.time()\n",
    "        )\n",
    "\n",
    "async def data_processor(data_stream: AsyncGenerator[DataItem, None]) -> AsyncGenerator[DataItem, None]:\n",
    "    \"\"\"æ•°æ®å¤„ç†å™¨\"\"\"\n",
    "    async for item in data_stream:\n",
    "        await asyncio.sleep(0.005)  # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ\n",
    "        \n",
    "        # å¤„ç†æ•°æ®\n",
    "        processed_item = DataItem(\n",
    "            id=item.id,\n",
    "            content=f\"å·²å¤„ç†_{item.content}\",\n",
    "            timestamp=item.timestamp,\n",
    "            processed=True\n",
    "        )\n",
    "        \n",
    "        yield processed_item\n",
    "\n",
    "async def data_sink(data_stream: AsyncGenerator[DataItem, None], output_file: str):\n",
    "    \"\"\"æ•°æ®è¾“å‡ºå™¨\"\"\"\n",
    "    processed_count = 0\n",
    "    \n",
    "    async with aiofiles.open(output_file, 'w', encoding='utf-8') as f:\n",
    "        async for item in data_stream:\n",
    "            await asyncio.sleep(0.003)  # æ¨¡æ‹Ÿå†™å…¥å»¶è¿Ÿ\n",
    "            \n",
    "            # å†™å…¥å¤„ç†åçš„æ•°æ®\n",
    "            line = f\"{json.dumps(asdict(item), ensure_ascii=False)}\\n\"\n",
    "            await f.write(line)\n",
    "            processed_count += 1\n",
    "    \n",
    "    return processed_count\n",
    "\n",
    "async def demonstrate_data_pipeline():\n",
    "    \"\"\"æ¼”ç¤ºå¼‚æ­¥æ•°æ®å¤„ç†ç®¡é“\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¼‚æ­¥æ•°æ®å¤„ç†ç®¡é“æ¼”ç¤º:\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    pipeline_file = os.path.join(temp_dir, \"pipeline_output.json\")\n",
    "    \n",
    "    try:\n",
    "        # æ„å»ºæ•°æ®å¤„ç†ç®¡é“\n",
    "        data_source = data_source_generator(10)\n",
    "        processed_stream = data_processor(data_source)\n",
    "        \n",
    "        print(f\"      å¯åŠ¨æ•°æ®å¤„ç†ç®¡é“...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # è¿è¡Œç®¡é“\n",
    "        processed_count = await data_sink(processed_stream, pipeline_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"      ç®¡é“å¤„ç†å®Œæˆ:\")\n",
    "        print(f\"        å¤„ç†æ•°æ®é¡¹: {processed_count}\")\n",
    "        print(f\"        æ€»è€—æ—¶: {end_time - start_time:.3f} ç§’\")\n",
    "        print(f\"        å¹³å‡å¤„ç†æ—¶é—´: {(end_time - start_time)/processed_count:.3f} ç§’/é¡¹\")\n",
    "        \n",
    "        # éªŒè¯è¾“å‡ºç»“æœ\n",
    "        print(f\"\\n      è¾“å‡ºæ–‡ä»¶å†…å®¹ (å‰3é¡¹):\")\n",
    "        async with aiofiles.open(pipeline_file, 'r', encoding='utf-8') as f:\n",
    "            line_count = 0\n",
    "            async for line in f:\n",
    "                line_count += 1\n",
    "                if line_count <= 3:\n",
    "                    data = json.loads(line.strip())\n",
    "                    print(f\"        é¡¹{data['id']}: {data['content']} (å·²å¤„ç†: {data['processed']})\")\n",
    "                elif line_count == 4:\n",
    "                    print(f\"        ... (å…±{processed_count}é¡¹) ...\")\n",
    "                    break\n",
    "        \n",
    "        return \"å¼‚æ­¥æ•°æ®å¤„ç†ç®¡é“æ¼”ç¤ºå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        if os.path.exists(pipeline_file):\n",
    "            os.remove(pipeline_file)\n",
    "        os.rmdir(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œæ•°æ®å¤„ç†ç®¡é“æ¼”ç¤º\n",
    "pipeline_result = await demonstrate_data_pipeline()\n",
    "print(f\"   {pipeline_result}\")\n",
    "\n",
    "print(f\"\\nâœ… å¼‚æ­¥æµå¼æ•°æ®å¤„ç†å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡å¼‚æ­¥æµå¼è¯»å–å’Œå†™å…¥æŠ€æœ¯\")\n",
    "print(f\"   âœ“ ç†è§£å¼‚æ­¥ç¼“å†²å’Œåˆ†å—å¤„ç†æœºåˆ¶\")\n",
    "print(f\"   âœ“ å­¦ä¼šå¼‚æ­¥æ•°æ®ç®¡é“æ„å»º\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„æµå¼æ•°æ®å¤„ç†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¼‚æ­¥I/Oæ€§èƒ½ä¼˜åŒ– [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šå¼‚æ­¥I/Oæ€§èƒ½ä¼˜åŒ–æ˜¯æ„å»ºé«˜æ€§èƒ½åº”ç”¨çš„å…³é”®ï¼Œå¯¹äºLangChainçš„å¤§è§„æ¨¡æ•°æ®å¤„ç†è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡å¼‚æ­¥I/Oæ€§èƒ½åˆ†æå’Œä¼˜åŒ–æŠ€æœ¯\n",
    "- ç†è§£ç¼“å†²ç­–ç•¥å’Œå¹¶å‘æ§åˆ¶æœºåˆ¶\n",
    "- å­¦ä¼šå¼‚æ­¥I/Oèµ„æºç®¡ç†å’Œç›‘æ§\n",
    "- èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„å¼‚æ­¥I/Oç³»ç»Ÿ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„å¼‚æ­¥I/Oæ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿ\n",
    "- è¿›è¡ŒI/Oæ€§èƒ½å¯¹æ¯”å’Œåˆ†æ\n",
    "- åº”ç”¨ä¼˜åŒ–æŠ€æœ¯è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹ä¼˜åŒ–å¼‚æ­¥I/Oæ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš¡ å¼‚æ­¥I/Oæ€§èƒ½ä¼˜åŒ–:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. æ€§èƒ½å¯¹æ¯”åˆ†æ\n",
    "print(f\"ğŸ“ 1. æ€§èƒ½å¯¹æ¯”åˆ†æ:\")\n",
    "\n",
    "# 1.1 åŒæ­¥vså¼‚æ­¥I/Oæ€§èƒ½å¯¹æ¯”\n",
    "print(f\"\\n   ğŸ” 1.1 åŒæ­¥vså¼‚æ­¥I/Oæ€§èƒ½å¯¹æ¯”:\")\n",
    "\n",
    "def sync_file_operations(file_count: int, file_size: int):\n",
    "    \"\"\"åŒæ­¥æ–‡ä»¶æ“ä½œ\"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        files_created = []\n",
    "        \n",
    "        # åŒæ­¥å†™å…¥æ–‡ä»¶\n",
    "        for i in range(file_count):\n",
    "            file_path = os.path.join(temp_dir, f\"sync_file_{i}.txt\")\n",
    "            content = f\"åŒæ­¥æ–‡ä»¶{i}çš„å†…å®¹\\n\" * (file_size // 20)\n",
    "            \n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            files_created.append(file_path)\n",
    "        \n",
    "        # åŒæ­¥è¯»å–æ–‡ä»¶\n",
    "        total_content = 0\n",
    "        for file_path in files_created:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                total_content += len(content)\n",
    "        \n",
    "        return total_content\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†æ–‡ä»¶\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "async def async_file_operations(file_count: int, file_size: int):\n",
    "    \"\"\"å¼‚æ­¥æ–‡ä»¶æ“ä½œ\"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        # å¼‚æ­¥å†™å…¥æ–‡ä»¶\n",
    "        async def write_file_async(i: int):\n",
    "            file_path = os.path.join(temp_dir, f\"async_file_{i}.txt\")\n",
    "            content = f\"å¼‚æ­¥æ–‡ä»¶{i}çš„å†…å®¹\\n\" * (file_size // 20)\n",
    "            \n",
    "            async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:\n",
    "                await f.write(content)\n",
    "            return file_path\n",
    "        \n",
    "        # å¹¶å‘å†™å…¥æ‰€æœ‰æ–‡ä»¶\n",
    "        write_tasks = [write_file_async(i) for i in range(file_count)]\n",
    "        files_created = await asyncio.gather(*write_tasks)\n",
    "        \n",
    "        # å¼‚æ­¥è¯»å–æ–‡ä»¶\n",
    "        async def read_file_async(file_path: str):\n",
    "            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = await f.read()\n",
    "                return len(content)\n",
    "        \n",
    "        # å¹¶å‘è¯»å–æ‰€æœ‰æ–‡ä»¶\n",
    "        read_tasks = [read_file_async(file_path) for file_path in files_created]\n",
    "        content_lengths = await asyncio.gather(*read_tasks)\n",
    "        \n",
    "        return sum(content_lengths)\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†æ–‡ä»¶\n",
    "        await aiofiles.os.rmtree(temp_dir)\n",
    "\n",
    "async def demonstrate_performance_comparison():\n",
    "    \"\"\"æ¼”ç¤ºæ€§èƒ½å¯¹æ¯”\"\"\"\n",
    "    print(f\"   ğŸ”¸ åŒæ­¥vså¼‚æ­¥I/Oæ€§èƒ½å¯¹æ¯”:\")\n",
    "    \n",
    "    file_count = 10\n",
    "    file_size = 1000  # æ¯ä¸ªæ–‡ä»¶1000å­—ç¬¦\n",
    "    \n",
    "    print(f\"      æµ‹è¯•é…ç½®: {file_count}ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ª{file_size}å­—ç¬¦\")\n",
    "    \n",
    "    # åŒæ­¥æ“ä½œæ€§èƒ½æµ‹è¯•\n",
    "    print(f\"\\n      åŒæ­¥I/Oæ“ä½œ:\")\n",
    "    sync_start = time.time()\n",
    "    sync_result = sync_file_operations(file_count, file_size)\n",
    "    sync_end = time.time()\n",
    "    sync_time = sync_end - sync_start\n",
    "    \n",
    "    print(f\"        å¤„ç†æ—¶é—´: {sync_time:.3f} ç§’\")\n",
    "    print(f\"        å¤„ç†å†…å®¹: {sync_result} å­—ç¬¦\")\n",
    "    print(f\"        å¤„ç†é€Ÿåº¦: {sync_result/sync_time:.1f} å­—ç¬¦/ç§’\")\n",
    "    \n",
    "    # å¼‚æ­¥æ“ä½œæ€§èƒ½æµ‹è¯•\n",
    "    print(f\"\\n      å¼‚æ­¥I/Oæ“ä½œ:\")\n",
    "    async_start = time.time()\n",
    "    async_result = await async_file_operations(file_count, file_size)\n",
    "    async_end = time.time()\n",
    "    async_time = async_end - async_start\n",
    "    \n",
    "    print(f\"        å¤„ç†æ—¶é—´: {async_time:.3f} ç§’\")\n",
    "    print(f\"        å¤„ç†å†…å®¹: {async_result} å­—ç¬¦\")\n",
    "    print(f\"        å¤„ç†é€Ÿåº¦: {async_result/async_time:.1f} å­—ç¬¦/ç§’\")\n",
    "    \n",
    "    # æ€§èƒ½å¯¹æ¯”\n",
    "    print(f\"\\n      æ€§èƒ½å¯¹æ¯”ç»“æœ:\")\n",
    "    speedup = sync_time / async_time\n",
    "    print(f\"        å¼‚æ­¥åŠ é€Ÿæ¯”: {speedup:.2f}x\")\n",
    "    print(f\"        æ—¶é—´èŠ‚çœ: {((sync_time - async_time) / sync_time * 100):.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'sync_time': sync_time,\n",
    "        'async_time': async_time,\n",
    "        'speedup': speedup\n",
    "    }\n",
    "\n",
    "# è¿è¡Œæ€§èƒ½å¯¹æ¯”æ¼”ç¤º\n",
    "performance_comparison = await demonstrate_performance_comparison()\n",
    "\n",
    "# 1.2 ç¼“å†²ç­–ç•¥ä¼˜åŒ–\n",
    "print(f\"\\n   ğŸ§  1.2 ç¼“å†²ç­–ç•¥ä¼˜åŒ–:\")\n",
    "\n",
    "async def buffered_file_writer(file_path: str, data_stream: AsyncGenerator[str, None], buffer_size: int = 10):\n",
    "    \"\"\"ç¼“å†²æ–‡ä»¶å†™å…¥å™¨\"\"\"\n",
    "    buffer = []\n",
    "    \n",
    "    async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:\n",
    "        async for data in data_stream:\n",
    "            buffer.append(data)\n",
    "            \n",
    "            # å½“ç¼“å†²åŒºæ»¡æ—¶ï¼Œæ‰¹é‡å†™å…¥\n",
    "            if len(buffer) >= buffer_size:\n",
    "                batch_content = '\\n'.join(buffer) + '\\n'\n",
    "                await f.write(batch_content)\n",
    "                await f.flush()\n",
    "                buffer.clear()\n",
    "        \n",
    "        # å†™å…¥å‰©ä½™æ•°æ®\n",
    "        if buffer:\n",
    "            batch_content = '\\n'.join(buffer) + '\\n'\n",
    "            await f.write(batch_content)\n",
    "            await f.flush()\n",
    "\n",
    "async def demonstrate_buffer_optimization():\n",
    "    \"\"\"æ¼”ç¤ºç¼“å†²ä¼˜åŒ–\"\"\"\n",
    "    print(f\"   ğŸ”¸ ç¼“å†²ç­–ç•¥ä¼˜åŒ–æ¼”ç¤º:\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºæ•°æ®æµ\n",
    "        async def large_data_stream():\n",
    "            for i in range(50):\n",
    "                await asyncio.sleep(0.001)  # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ\n",
    "                yield f\"æ•°æ®é¡¹{i+1}: å†…å®¹{'x' * 100}\"  # æ¯é¡¹çº¦100å­—ç¬¦\n",
    "        \n",
    "        data_stream = large_data_stream()\n",
    "        \n",
    "        # æµ‹è¯•ä¸åŒç¼“å†²å¤§å°\n",
    "        buffer_sizes = [1, 5, 10, 20]\n",
    "        \n",
    "        for buffer_size in buffer_sizes:\n",
    "            file_path = os.path.join(temp_dir, f\"buffer_{buffer_size}.txt\")\n",
    "            \n",
    "            print(f\"\\n      æµ‹è¯•ç¼“å†²å¤§å°: {buffer_size}\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # é‡æ–°åˆ›å»ºæ•°æ®æµ\n",
    "            data_stream = large_data_stream()\n",
    "            await buffered_file_writer(file_path, data_stream, buffer_size)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            write_time = end_time - start_time\n",
    "            \n",
    "            # éªŒè¯æ–‡ä»¶å¤§å°\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            \n",
    "            print(f\"        å†™å…¥æ—¶é—´: {write_time:.3f} ç§’\")\n",
    "            print(f\"        æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚\")\n",
    "            print(f\"        å†™å…¥é€Ÿåº¦: {file_size/write_time:.1f} å­—èŠ‚/ç§’\")\n",
    "        \n",
    "        return \"ç¼“å†²ç­–ç•¥ä¼˜åŒ–æ¼”ç¤ºå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        shutil.rmtree(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œç¼“å†²ä¼˜åŒ–æ¼”ç¤º\n",
    "buffer_optimization_result = await demonstrate_buffer_optimization()\n",
    "print(f\"   {buffer_optimization_result}\")\n",
    "\n",
    "# 1.3 å¹¶å‘æ§åˆ¶ä¼˜åŒ–\n",
    "print(f\"\\n   ğŸ® 1.3 å¹¶å‘æ§åˆ¶ä¼˜åŒ–:\")\n",
    "\n",
    "class AsyncSemaphore:\n",
    "    \"\"\"å¼‚æ­¥ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent: int):\n",
    "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        self.max_concurrent = max_concurrent\n",
    "    \n",
    "    async def limited_operation(self, operation_func, *args, **kwargs):\n",
    "        \"\"\"é™åˆ¶å¹¶å‘çš„æ“ä½œ\"\"\"\n",
    "        async with self.semaphore:\n",
    "            return await operation_func(*args, **kwargs)\n",
    "\n",
    "async def demonstrate_concurrency_control():\n",
    "    \"\"\"æ¼”ç¤ºå¹¶å‘æ§åˆ¶ä¼˜åŒ–\"\"\"\n",
    "    print(f\"   ğŸ”¸ å¹¶å‘æ§åˆ¶ä¼˜åŒ–æ¼”ç¤º:\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºæ–‡ä»¶æ“ä½œå‡½æ•°\n",
    "        async def create_and_process_file(file_id: int):\n",
    "            file_path = os.path.join(temp_dir, f\"concurrent_file_{file_id}.txt\")\n",
    "            \n",
    "            # æ¨¡æ‹Ÿæ–‡ä»¶åˆ›å»ºå’Œå¤„ç†\n",
    "            content = f\"å¹¶å‘æ–‡ä»¶{file_id}çš„å†…å®¹\\n\" * 50\n",
    "            \n",
    "            async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:\n",
    "                await f.write(content)\n",
    "            \n",
    "            await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "            \n",
    "            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:\n",
    "                read_content = await f.read()\n",
    "            \n",
    "            return len(read_content)\n",
    "        \n",
    "        file_count = 20\n",
    "        \n",
    "        # æµ‹è¯•ä¸åŒå¹¶å‘çº§åˆ«\n",
    "        concurrency_levels = [1, 5, 10, 20]\n",
    "        \n",
    "        for max_concurrent in concurrency_levels:\n",
    "            print(f\"\\n      æµ‹è¯•å¹¶å‘çº§åˆ«: {max_concurrent}\")\n",
    "            \n",
    "            # æ¸…ç†ä¹‹å‰çš„æ–‡ä»¶\n",
    "            for file in os.listdir(temp_dir):\n",
    "                os.remove(os.path.join(temp_dir, file))\n",
    "            \n",
    "            # åˆ›å»ºå¹¶å‘æ§åˆ¶å™¨\n",
    "            semaphore = AsyncSemaphore(max_concurrent)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # ä½¿ç”¨å¹¶å‘æ§åˆ¶æ‰§è¡Œä»»åŠ¡\n",
    "            tasks = [\n",
    "                semaphore.limited_operation(create_and_process_file, i)\n",
    "                for i in range(file_count)\n",
    "            ]\n",
    "            \n",
    "            results = await asyncio.gather(*tasks)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "            total_content = sum(results)\n",
    "            \n",
    "            print(f\"        å¤„ç†æ—¶é—´: {processing_time:.3f} ç§’\")\n",
    "            print(f\"        å¤„ç†æ–‡ä»¶: {len(results)} ä¸ª\")\n",
    "            print(f\"        æ€»å†…å®¹: {total_content} å­—ç¬¦\")\n",
    "            print(f\"        å¤„ç†é€Ÿåº¦: {total_content/processing_time:.1f} å­—ç¬¦/ç§’\")\n",
    "            print(f\"        å¹¶å‘æ•ˆç‡: {file_count/processing_time:.1f} æ–‡ä»¶/ç§’\")\n",
    "        \n",
    "        return \"å¹¶å‘æ§åˆ¶ä¼˜åŒ–æ¼”ç¤ºå®Œæˆ\"\n",
    "    \n",
    "    finally:\n",
    "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "        shutil.rmtree(temp_dir)\n",
    "        print(f\"      ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "\n",
    "# è¿è¡Œå¹¶å‘æ§åˆ¶æ¼”ç¤º\n",
    "concurrency_control_result = await demonstrate_concurrency_control()\n",
    "print(f\"   {concurrency_control_result}\")\n",
    "\n",
    "print(f\"\\nâœ… å¼‚æ­¥I/Oæ€§èƒ½ä¼˜åŒ–å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡å¼‚æ­¥I/Oæ€§èƒ½åˆ†æå’Œä¼˜åŒ–æŠ€æœ¯\")\n",
    "print(f\"   âœ“ ç†è§£ç¼“å†²ç­–ç•¥å’Œå¹¶å‘æ§åˆ¶æœºåˆ¶\")\n",
    "print(f\"   âœ“ å­¦ä¼šå¼‚æ­¥I/Oèµ„æºç®¡ç†å’Œç›‘æ§\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„å¼‚æ­¥I/Oç³»ç»Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### âœ… çŸ¥è¯†æ¸…å•è¾¾æˆæƒ…å†µéªŒè¯\n",
    "\n",
    "**6.3 å¼‚æ­¥I/Oæ“ä½œ [â­â­è¿›é˜¶]**\n",
    "- âœ… æŒæ¡å¼‚æ­¥æ–‡ä»¶I/Oæ“ä½œçš„æ ¸å¿ƒæŠ€æœ¯\n",
    "- âœ… å­¦ä¼šä½¿ç”¨aiofilesè¿›è¡Œé«˜æ•ˆçš„å¼‚æ­¥æ–‡ä»¶å¤„ç†\n",
    "- âœ… ç†è§£å¼‚æ­¥æ–‡ä»¶è¯»å†™å’Œè¡Œæ“ä½œ\n",
    "- âœ… æŒæ¡å¼‚æ­¥äºŒè¿›åˆ¶æ–‡ä»¶æ“ä½œ\n",
    "- âœ… æŒæ¡å¼‚æ­¥æµå¼è¯»å–å’Œå†™å…¥æŠ€æœ¯\n",
    "- âœ… ç†è§£å¼‚æ­¥ç¼“å†²å’Œåˆ†å—å¤„ç†æœºåˆ¶\n",
    "- âœ… å­¦ä¼šå¼‚æ­¥æ•°æ®ç®¡é“æ„å»º\n",
    "- âœ… èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„æµå¼æ•°æ®å¤„ç†\n",
    "- âœ… æŒæ¡å¼‚æ­¥I/Oæ€§èƒ½åˆ†æå’Œä¼˜åŒ–æŠ€æœ¯\n",
    "- âœ… ç†è§£ç¼“å†²ç­–ç•¥å’Œå¹¶å‘æ§åˆ¶æœºåˆ¶\n",
    "- âœ… å­¦ä¼šå¼‚æ­¥I/Oèµ„æºç®¡ç†å’Œç›‘æ§\n",
    "- âœ… èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„å¼‚æ­¥I/Oç³»ç»Ÿ\n",
    "- âœ… èƒ½ç‹¬ç«‹ä¼˜åŒ–å¼‚æ­¥I/Oæ€§èƒ½\n",
    "\n",
    "### ğŸ¯ ä¸LangChainå­¦ä¹ çš„å…³è”\n",
    "\n",
    "**å¼‚æ­¥I/Oé‡è¦æ€§**ï¼š\n",
    "- å¼‚æ­¥I/Oä¼˜åŒ–LangChainçš„å¤§æ–‡ä»¶å¤„ç†èƒ½åŠ›\n",
    "- æµå¼I/Oæ”¯æŒLangChainçš„å®æ—¶æ•°æ®å¤„ç†\n",
    "- å¼‚æ­¥æ–‡ä»¶æ“ä½œæå‡LangChainçš„å“åº”æ€§èƒ½\n",
    "- I/Oç¼“å†²æœºåˆ¶ä¼˜åŒ–LangChainçš„èµ„æºåˆ©ç”¨\n",
    "- å¹¶å‘I/Oæ“ä½œå¢å¼ºLangChainçš„ååèƒ½åŠ›\n",
    "\n",
    "**å®é™…åº”ç”¨åœºæ™¯**ï¼š\n",
    "- LangChainçš„å¼‚æ­¥æ–‡æ¡£å¤„ç†å’Œç´¢å¼•æ„å»º\n",
    "- LangChainçš„æµå¼æ•°æ®è¯»å–å’Œå®æ—¶åˆ†æ\n",
    "- LangChainçš„å¹¶å‘æ–‡ä»¶ä¸Šä¼ å’Œä¸‹è½½å¤„ç†\n",
    "- LangChainçš„å¼‚æ­¥ç¼“å­˜å’ŒæŒä¹…åŒ–å­˜å‚¨\n",
    "- LangChainçš„æ‰¹é‡æ•°æ®å¤„ç†å’Œè½¬æ¢\n",
    "\n",
    "### ğŸ“š è¿›é˜¶å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **ç»ƒä¹ å»ºè®®**ï¼š\n",
    "   - æ·±å…¥ç»ƒä¹ å¼‚æ­¥æ•°æ®åº“æ“ä½œå’Œè¿æ¥æ± \n",
    "   - æŒæ¡å¼‚æ­¥ç½‘ç»œI/Oå’Œåè®®å¤„ç†\n",
    "   - å­¦ä¹ å¼‚æ­¥æ¶ˆæ¯é˜Ÿåˆ—å’Œæµå¤„ç†æ¡†æ¶\n",
    "\n",
    "2. **æ‰©å±•å­¦ä¹ **ï¼š\n",
    "   - äº†è§£å¼‚æ­¥I/Oçš„åº•å±‚å®ç°æœºåˆ¶\n",
    "   - å­¦ä¹ å¼‚æ­¥æ€§èƒ½ç›‘æ§å’Œè°ƒè¯•å·¥å…·\n",
    "   - æ¢ç´¢åˆ†å¸ƒå¼å¼‚æ­¥I/Oç³»ç»Ÿè®¾è®¡\n",
    "\n",
    "3. **å®é™…åº”ç”¨**ï¼š\n",
    "   - æ„å»ºé«˜æ€§èƒ½å¼‚æ­¥æ•°æ®å¤„ç†ç®¡é“\n",
    "   - å¼€å‘å®æ—¶å¼‚æ­¥æ–‡ä»¶ç›‘æ§ç³»ç»Ÿ\n",
    "   - å®ç°å¼‚æ­¥æ•°æ®å¤‡ä»½å’ŒåŒæ­¥ç³»ç»Ÿ\n",
    "\n",
    "### ğŸ”§ å¸¸è§é”™è¯¯ä¸æ³¨æ„äº‹é¡¹\n",
    "\n",
    "1. **å¼‚æ­¥æ–‡ä»¶æ“ä½œé”™è¯¯**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šåœ¨å¼‚æ­¥å‡½æ•°ä¸­ä½¿ç”¨åŒæ­¥æ–‡ä»¶æ“ä½œ\n",
    "   async def bad_file_operation():\n",
    "       with open('file.txt', 'r') as f:  # é˜»å¡æ“ä½œ\n",
    "           content = f.read()\n",
    "       return content\n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨å¼‚æ­¥æ–‡ä»¶æ“ä½œ\n",
    "   async def good_file_operation():\n",
    "       async with aiofiles.open('file.txt', 'r') as f:\n",
    "           content = await f.read()\n",
    "       return content\n",
    "   ```\n",
    "\n",
    "2. **æµå¼å¤„ç†å†…å­˜æ³„æ¼**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šä¸€æ¬¡æ€§è¯»å–å¤§æ–‡ä»¶åˆ°å†…å­˜\n",
    "   async def bad_stream_processing():\n",
    "       async with aiofiles.open('large_file.txt', 'r') as f:\n",
    "           content = await f.read()  # å¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º\n",
    "       return content\n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨æµå¼å¤„ç†\n",
    "   async def good_stream_processing():\n",
    "       results = []\n",
    "       async with aiofiles.open('large_file.txt', 'r') as f:\n",
    "           async for line in f:\n",
    "               results.append(process_line(line))\n",
    "               if len(results) >= 1000:  # æ§åˆ¶å†…å­˜ä½¿ç”¨\n",
    "                   yield results\n",
    "                   results = []\n",
    "   ```\n",
    "\n",
    "3. **å¹¶å‘æ§åˆ¶ä¸å½“**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ— é™åˆ¶å¹¶å‘å¯èƒ½å¯¼è‡´èµ„æºè€—å°½\n",
    "   async def bad_concurrency():\n",
    "       tasks = [process_file(file) for file in file_list]\n",
    "       results = await asyncio.gather(*tasks)  # å¯èƒ½æ‰“å¼€è¿‡å¤šæ–‡ä»¶\n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘\n",
    "   async def good_concurrency():\n",
    "       semaphore = asyncio.Semaphore(10)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°\n",
    "       \n",
    "       async def limited_process(file):\n",
    "           async with semaphore:\n",
    "               return await process_file(file)\n",
    "       \n",
    "       tasks = [limited_process(file) for file in file_list]\n",
    "       results = await asyncio.gather(*tasks)\n",
    "   ```\n",
    "\n",
    "4. **å¼‚å¸¸å¤„ç†ä¸å®Œæ•´**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šæ²¡æœ‰æ­£ç¡®å¤„ç†å¼‚æ­¥æ–‡ä»¶å¼‚å¸¸\n",
    "   async def bad_exception_handling():\n",
    "       async with aiofiles.open('file.txt', 'r') as f:\n",
    "           content = await f.read()\n",
    "           # å¦‚æœè¿™é‡Œå‘ç”Ÿå¼‚å¸¸ï¼Œæ–‡ä»¶å¯èƒ½ä¸ä¼šæ­£ç¡®å…³é—­\n",
    "           process_content(content)\n",
    "   \n",
    "   # æ­£ç¡®ï¼šå®Œæ•´çš„å¼‚å¸¸å¤„ç†\n",
    "   async def good_exception_handling():\n",
    "       try:\n",
    "           async with aiofiles.open('file.txt', 'r') as f:\n",
    "               content = await f.read()\n",
    "               process_content(content)\n",
    "       except FileNotFoundError:\n",
    "           print(\"æ–‡ä»¶ä¸å­˜åœ¨\")\n",
    "       except PermissionError:\n",
    "           print(\"æƒé™ä¸è¶³\")\n",
    "       except Exception as e:\n",
    "           print(f\"æœªçŸ¥é”™è¯¯: {e}\")\n",
    "   ```\n",
    "\n",
    "5. **ç¼“å†²åŒºä½¿ç”¨ä¸å½“**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šç¼“å†²åŒºè¿‡å¤§å¯èƒ½å¯¼è‡´å†…å­˜é—®é¢˜\n",
    "   async def bad_buffering():\n",
    "       buffer = []\n",
    "       async for data in data_stream:\n",
    "           buffer.append(data)  # æ— é™åˆ¶å¢é•¿\n",
    "       \n",
    "       # ä¸€æ¬¡æ€§å†™å…¥æ‰€æœ‰æ•°æ®\n",
    "       async with aiofiles.open('output.txt', 'w') as f:\n",
    "           await f.write('\\n'.join(buffer))\n",
    "   \n",
    "   # æ­£ç¡®ï¼šåˆç†çš„ç¼“å†²ç­–ç•¥\n",
    "   async def good_buffering():\n",
    "       buffer_size = 1000\n",
    "       buffer = []\n",
    "       \n",
    "       async with aiofiles.open('output.txt', 'w') as f:\n",
    "           async for data in data_stream:\n",
    "               buffer.append(data)\n",
    "               \n",
    "               if len(buffer) >= buffer_size:\n",
    "                   await f.write('\\n'.join(buffer) + '\\n')\n",
    "                   buffer.clear()\n",
    "           \n",
    "           # å†™å…¥å‰©ä½™æ•°æ®\n",
    "           if buffer:\n",
    "               await f.write('\\n'.join(buffer) + '\\n')\n",
    "   ```\n",
    "\n",
    "6. **èµ„æºæ¸…ç†ä¸å½»åº•**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šä¸´æ—¶æ–‡ä»¶å¯èƒ½ä¸ä¼šè¢«æ¸…ç†\n",
    "   async def bad_resource_cleanup():\n",
    "       temp_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "       temp_file.close()\n",
    "       \n",
    "       # å¼‚æ­¥æ“ä½œæ–‡ä»¶\n",
    "       async with aiofiles.open(temp_file.name, 'w') as f:\n",
    "           await f.write('data')\n",
    "       \n",
    "       # å¦‚æœè¿™é‡Œå‘ç”Ÿå¼‚å¸¸ï¼Œä¸´æ—¶æ–‡ä»¶ä¸ä¼šè¢«åˆ é™¤\n",
    "       os.remove(temp_file.name)\n",
    "   \n",
    "   # æ­£ç¡®ï¼šç¡®ä¿èµ„æºæ¸…ç†\n",
    "   async def good_resource_cleanup():\n",
    "       temp_dir = tempfile.mkdtemp()\n",
    "       \n",
    "       try:\n",
    "           temp_file = os.path.join(temp_dir, 'temp.txt')\n",
    "           async with aiofiles.open(temp_file, 'w') as f:\n",
    "               await f.write('data')\n",
    "       finally:\n",
    "           # ç¡®ä¿æ¸…ç†ä¸´æ—¶ç›®å½•\n",
    "           shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "   ```\n",
    "\n",
    "### ğŸŒ æ€§èƒ½ä¼˜åŒ–å»ºè®®\n",
    "\n",
    "**I/Oæ“ä½œä¼˜åŒ–**ï¼š\n",
    "- ä½¿ç”¨é€‚å½“çš„ç¼“å†²åŒºå¤§å°å¹³è¡¡å†…å­˜å’Œæ€§èƒ½\n",
    "- å®ç°å¹¶å‘æ§åˆ¶é¿å…èµ„æºè€—å°½\n",
    "- é€‰æ‹©åˆé€‚çš„æ–‡ä»¶è¯»å†™æ¨¡å¼\n",
    "- ä½¿ç”¨æµå¼å¤„ç†å¤„ç†å¤§æ–‡ä»¶\n",
    "\n",
    "**å¹¶å‘ä¼˜åŒ–**ï¼š\n",
    "- æ ¹æ®ç³»ç»Ÿèµ„æºè®¾ç½®åˆç†çš„å¹¶å‘æ•°\n",
    "- ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘è®¿é—®\n",
    "- å®ç°ä»»åŠ¡é˜Ÿåˆ—å’Œè´Ÿè½½å‡è¡¡\n",
    "- ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ\n",
    "\n",
    "**å†…å­˜ä¼˜åŒ–**ï¼š\n",
    "- é¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§æ–‡ä»¶åˆ°å†…å­˜\n",
    "- ä½¿ç”¨ç”Ÿæˆå™¨å’Œæµå¼å¤„ç†\n",
    "- åŠæ—¶é‡Šæ”¾ä¸å†ä½¿ç”¨çš„èµ„æº\n",
    "- å®ç°å†…å­˜ä½¿ç”¨ç›‘æ§å’Œé™åˆ¶\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆå¼‚æ­¥I/Oæ“ä½œå­¦ä¹ ï¼**\n",
    "\n",
    "ä½ å·²ç»å…¨é¢æŒæ¡äº†å¼‚æ­¥I/Oæ“ä½œçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œèƒ½å¤Ÿç³»ç»Ÿæ€§åœ°è¿›è¡Œé«˜æ€§èƒ½å¼‚æ­¥æ–‡ä»¶å¤„ç†ã€æµå¼æ•°æ®å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–ï¼Œä¸ºLangChainæ™ºèƒ½åº”ç”¨æä¾›äº†å¼ºå¤§çš„I/Oå¤„ç†åŸºç¡€ã€‚\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ é¢„å‘Š\n",
    "\n",
    "**ç¬¬å…­èŠ‚ï¼šå¼‚æ­¥ç¼–ç¨‹ - è¿›è¡Œä¸­** ğŸ”„\n",
    "- 6.1 å¼‚æ­¥ç¼–ç¨‹åŸºç¡€ âœ…\n",
    "- 6.2 åç¨‹ä¸äº‹ä»¶å¾ªç¯ âœ…\n",
    "- 6.3 å¼‚æ­¥I/Oæ“ä½œ âœ…\n",
    "- 6.4 å¼‚æ­¥ç½‘ç»œç¼–ç¨‹ â³\n",
    "- 6.5 å¼‚æ­¥Webæ¡†æ¶ â³\n",
    "- 6.6 å¹¶å‘ç¼–ç¨‹æ¨¡å¼ â³\n",
    "- 6.7 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ— â³\n",
    "- 6.8 å¼‚æ­¥æ€§èƒ½ä¼˜åŒ– â³\n",
    "- 6.9 å¼‚æ­¥æœ€ä½³å®è·µ â³\n",
    "\n",
    "**ç»§ç»­ç¬¬å…­èŠ‚ï¼šå¼‚æ­¥ç¼–ç¨‹**\n",
    "- ä¸‹ä¸€ä¸ªï¼š6.4 å¼‚æ­¥ç½‘ç»œç¼–ç¨‹\n",
    "- æ·±å…¥å­¦ä¹ å¼‚æ­¥HTTPå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨\n",
    "- æŒæ¡å¼‚æ­¥ç½‘ç»œé€šä¿¡å’Œåè®®å¤„ç†\n",
    "\n",
    "**åç»­ç« èŠ‚é¢„å‘Š**ï¼š\n",
    "- Webå¼€å‘æŠ€æœ¯\n",
    "- é¡¹ç›®å·¥ç¨‹å®è·µ\n",
    "\n",
    "ç»§ç»­åŠ æ²¹ï¼Œå¼‚æ­¥I/Oæ“ä½œå·²ç»æŒæ¡ï¼å‡†å¤‡æ·±å…¥å­¦ä¹ å¼‚æ­¥ç½‘ç»œç¼–ç¨‹ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
