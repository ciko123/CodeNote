{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64-Webåº”ç”¨éƒ¨ç½²ä¸è¿ç»´\n",
    "\n",
    "## ğŸ“š ç”¨é€”è¯´æ˜\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "- æŒæ¡Webåº”ç”¨çš„éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹\n",
    "- å­¦ä¼šå®¹å™¨åŒ–éƒ¨ç½²å’Œç¼–æ’ç®¡ç†\n",
    "- ç†è§£ç›‘æ§ã€æ—¥å¿—å’Œè¿ç»´è‡ªåŠ¨åŒ–\n",
    "- èƒ½å¤Ÿå®ç°é«˜å¯ç”¨çš„ç”Ÿäº§ç¯å¢ƒ\n",
    "\n",
    "**å‰ç½®è¦æ±‚**ï¼š\n",
    "- å·²å®Œæˆå¾®æœåŠ¡æ¶æ„è®¾è®¡å­¦ä¹ \n",
    "- ç†Ÿç»ƒæŒæ¡FastAPIå’Œå¼‚æ­¥ç¼–ç¨‹\n",
    "- äº†è§£LinuxåŸºç¡€å’Œç³»ç»Ÿç®¡ç†\n",
    "- ç†è§£ç½‘ç»œå’Œæ•°æ®åº“åŸºç¡€\n",
    "\n",
    "**ä¸LangChainå…³è”**ï¼š\n",
    "- éƒ¨ç½²ç­–ç•¥æ”¯æŒLangChainçš„AIæœåŠ¡ç”Ÿäº§åŒ–\n",
    "- å®¹å™¨åŒ–æŠ€æœ¯ä¿éšœLangChainçš„ç¯å¢ƒä¸€è‡´æ€§\n",
    "- ç›‘æ§è¿ç»´ç¡®ä¿LangChainæœåŠ¡çš„ç¨³å®šæ€§\n",
    "- ä¸ºLangChainæä¾›ä¼ä¸šçº§éƒ¨ç½²è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ çŸ¥è¯†ç‚¹è¦†ç›–\n",
    "\n",
    "### 7.9 Webåº”ç”¨éƒ¨ç½²ä¸è¿ç»´ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šWebåº”ç”¨éƒ¨ç½²ä¸è¿ç»´æ˜¯ç”Ÿäº§ç¯å¢ƒçš„æ ¸å¿ƒæŠ€èƒ½ï¼Œä¸ºLangChainçš„AIæœåŠ¡æä¾›ç¨³å®šã€å¯é çš„éƒ¨ç½²å’Œè¿ç»´ä¿éšœã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡Webåº”ç”¨çš„éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹\n",
    "- å­¦ä¼šå®¹å™¨åŒ–éƒ¨ç½²å’Œç¼–æ’ç®¡ç†\n",
    "- ç†è§£ç›‘æ§ã€æ—¥å¿—å’Œè¿ç»´è‡ªåŠ¨åŒ–\n",
    "- èƒ½å¤Ÿå®ç°é«˜å¯ç”¨çš„ç”Ÿäº§ç¯å¢ƒ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„éƒ¨ç½²æµç¨‹\n",
    "- æ„å»ºå®¹å™¨åŒ–å’Œç¼–æ’ç³»ç»Ÿ\n",
    "- å¼€å‘ç›‘æ§å’Œæ—¥å¿—ç®¡ç†\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹éƒ¨ç½²å’Œç®¡ç†ç”Ÿäº§ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ Webåº”ç”¨éƒ¨ç½²ä¸è¿ç»´:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import asyncio\n",
    "import time\n",
    "import datetime\n",
    "import uuid\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import hashlib\n",
    "import logging\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import zipfile\n",
    "import tarfile\n",
    "from typing import List, Dict, Any, Optional, Union, Type, Callable\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from enum import Enum\n",
    "from contextlib import asynccontextmanager\n",
    "from pathlib import Path\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# FastAPIç›¸å…³\n",
    "from fastapi import FastAPI, HTTPException, Depends, status, Request, Response, BackgroundTasks\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel, EmailStr, Field, validator\n",
    "\n",
    "# HTTPå®¢æˆ·ç«¯\n",
    "import aiohttp\n",
    "import requests\n",
    "\n",
    "print(f\"âœ… Pythonç‰ˆæœ¬: {__import__('sys').version}\")\n",
    "print(f\"âœ… å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹\n",
    "print(f\"ğŸ“ 1. éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹:\")\n",
    "\n",
    "# 1.1 éƒ¨ç½²é…ç½®ç®¡ç†\n",
    "print(f\"\\n   âš™ï¸ 1.1 éƒ¨ç½²é…ç½®ç®¡ç†:\")\n",
    "\n",
    "@dataclass\n",
    "class DeploymentConfig:\n",
    "    \"\"\"éƒ¨ç½²é…ç½®\"\"\"\n",
    "    app_name: str\n",
    "    version: str\n",
    "    environment: str  # development, staging, production\n",
    "    host: str = \"localhost\"\n",
    "    port: int = 8000\n",
    "    workers: int = 1\n",
    "    max_memory: str = \"512m\"\n",
    "    max_cpu: str = \"0.5\"\n",
    "    health_check_path: str = \"/health\"\n",
    "    startup_timeout: int = 60\n",
    "    shutdown_timeout: int = 30\n",
    "    restart_policy: str = \"on-failure\"\n",
    "    environment_variables: Dict[str, str] = field(default_factory=dict)\n",
    "    volumes: List[str] = field(default_factory=list)\n",
    "    ports: List[str] = field(default_factory=list)\n",
    "    dependencies: List[str] = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def deployment_id(self) -> str:\n",
    "        return f\"{self.app_name}:{self.version}:{self.environment}\"\n",
    "\n",
    "@dataclass\n",
    "class DeploymentStep:\n",
    "    \"\"\"éƒ¨ç½²æ­¥éª¤\"\"\"\n",
    "    step_id: str\n",
    "    name: str\n",
    "    command: str\n",
    "    timeout: int = 300\n",
    "    retry_count: int = 3\n",
    "    rollback_command: Optional[str] = None\n",
    "    status: str = \"pending\"  # pending, running, completed, failed\n",
    "    output: str = \"\"\n",
    "    error: str = \"\"\n",
    "    started_at: Optional[datetime.datetime] = None\n",
    "    completed_at: Optional[datetime.datetime] = None\n",
    "\n",
    "class DeploymentManager:\n",
    "    \"\"\"éƒ¨ç½²ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.deployments: Dict[str, DeploymentConfig] = {}\n",
    "        self.deployment_history: List[Dict[str, Any]] = []\n",
    "        self.active_deployments: Dict[str, Dict[str, Any]] = {}\n",
    "    \n",
    "    def create_deployment(self, config: DeploymentConfig) -> str:\n",
    "        \"\"\"åˆ›å»ºéƒ¨ç½²\"\"\"\n",
    "        deployment_id = config.deployment_id\n",
    "        self.deployments[deployment_id] = config\n",
    "        return deployment_id\n",
    "    \n",
    "    async def execute_deployment(self, deployment_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"æ‰§è¡Œéƒ¨ç½²\"\"\"\n",
    "        if deployment_id not in self.deployments:\n",
    "            raise Exception(f\"éƒ¨ç½²é…ç½®ä¸å­˜åœ¨: {deployment_id}\")\n",
    "        \n",
    "        config = self.deployments[deployment_id]\n",
    "        deployment_session = {\n",
    "            \"session_id\": str(uuid.uuid4()),\n",
    "            \"deployment_id\": deployment_id,\n",
    "            \"status\": \"starting\",\n",
    "            \"started_at\": datetime.datetime.utcnow(),\n",
    "            \"steps\": []\n",
    "        }\n",
    "        \n",
    "        self.active_deployments[deployment_id] = deployment_session\n",
    "        \n",
    "        try:\n",
    "            # åˆ›å»ºéƒ¨ç½²æ­¥éª¤\n",
    "            steps = self._create_deployment_steps(config)\n",
    "            \n",
    "            # æ‰§è¡Œéƒ¨ç½²æ­¥éª¤\n",
    "            for step in steps:\n",
    "                deployment_session[\"steps\"].append(asdict(step))\n",
    "                \n",
    "                success = await self._execute_step(step)\n",
    "                \n",
    "                if not success:\n",
    "                    # éƒ¨ç½²å¤±è´¥ï¼Œæ‰§è¡Œå›æ»š\n",
    "                    deployment_session[\"status\"] = \"rolling_back\"\n",
    "                    await self._rollback_deployment(deployment_session, steps)\n",
    "                    deployment_session[\"status\"] = \"failed\"\n",
    "                    break\n",
    "            \n",
    "            if deployment_session[\"status\"] != \"failed\":\n",
    "                deployment_session[\"status\"] = \"completed\"\n",
    "            \n",
    "            # è®°å½•éƒ¨ç½²å†å²\n",
    "            self._record_deployment(deployment_session)\n",
    "            \n",
    "            return {\n",
    "                \"session_id\": deployment_session[\"session_id\"],\n",
    "                \"deployment_id\": deployment_id,\n",
    "                \"status\": deployment_session[\"status\"],\n",
    "                \"duration\": (datetime.datetime.utcnow() - deployment_session[\"started_at\"]).total_seconds()\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            deployment_session[\"status\"] = \"failed\"\n",
    "            deployment_session[\"error\"] = str(e)\n",
    "            self._record_deployment(deployment_session)\n",
    "            raise e\n",
    "        \n",
    "        finally:\n",
    "            # æ¸…ç†æ´»è·ƒéƒ¨ç½²\n",
    "            if deployment_id in self.active_deployments:\n",
    "                del self.active_deployments[deployment_id]\n",
    "    \n",
    "    def _create_deployment_steps(self, config: DeploymentConfig) -> List[DeploymentStep]:\n",
    "        \"\"\"åˆ›å»ºéƒ¨ç½²æ­¥éª¤\"\"\"\n",
    "        steps = []\n",
    "        \n",
    "        # 1. ç¯å¢ƒæ£€æŸ¥\n",
    "        steps.append(DeploymentStep(\n",
    "            step_id=\"env_check\",\n",
    "            name=\"ç¯å¢ƒæ£€æŸ¥\",\n",
    "            command=\"echo 'æ£€æŸ¥ç¯å¢ƒä¾èµ–'\",\n",
    "            timeout=60\n",
    "        ))\n",
    "        \n",
    "        # 2. æ„å»ºåº”ç”¨\n",
    "        steps.append(DeploymentStep(\n",
    "            step_id=\"build\",\n",
    "            name=\"æ„å»ºåº”ç”¨\",\n",
    "            command=f\"echo 'æ„å»º {config.app_name} v{config.version}'\",\n",
    "            timeout=300,\n",
    "            rollback_command=\"echo 'æ¸…ç†æ„å»ºæ–‡ä»¶'\"\n",
    "        ))\n",
    "        \n",
    "        # 3. å¥åº·æ£€æŸ¥\n",
    "        steps.append(DeploymentStep(\n",
    "            step_id=\"health_check\",\n",
    "            name=\"å¥åº·æ£€æŸ¥\",\n",
    "            command=f\"echo 'å¥åº·æ£€æŸ¥ {config.host}:{config.port}{config.health_check_path}'\",\n",
    "            timeout=60\n",
    "        ))\n",
    "        \n",
    "        # 4. å¯åŠ¨æœåŠ¡\n",
    "        steps.append(DeploymentStep(\n",
    "            step_id=\"start_service\",\n",
    "            name=\"å¯åŠ¨æœåŠ¡\",\n",
    "            command=f\"echo 'å¯åŠ¨ {config.app_name} æœåŠ¡'\",\n",
    "            timeout=config.startup_timeout,\n",
    "            rollback_command=f\"echo 'åœæ­¢ {config.app_name} æœåŠ¡'\"\n",
    "        ))\n",
    "        \n",
    "        return steps\n",
    "    \n",
    "    async def _execute_step(self, step: DeploymentStep) -> bool:\n",
    "        \"\"\"æ‰§è¡Œéƒ¨ç½²æ­¥éª¤\"\"\"\n",
    "        step.status = \"running\"\n",
    "        step.started_at = datetime.datetime.utcnow()\n",
    "        \n",
    "        for attempt in range(step.retry_count + 1):\n",
    "            try:\n",
    "                # æ¨¡æ‹Ÿæ‰§è¡Œå‘½ä»¤\n",
    "                print(f\"æ‰§è¡Œæ­¥éª¤: {step.name} - {step.command}\")\n",
    "                \n",
    "                # æ¨¡æ‹Ÿå‘½ä»¤æ‰§è¡Œæ—¶é—´\n",
    "                await asyncio.sleep(random.uniform(1, 3))\n",
    "                \n",
    "                # æ¨¡æ‹ŸæˆåŠŸç‡ï¼ˆ90%ï¼‰\n",
    "                if random.random() > 0.1:\n",
    "                    step.status = \"completed\"\n",
    "                    step.output = f\"æ­¥éª¤ {step.name} æ‰§è¡ŒæˆåŠŸ\"\n",
    "                    step.completed_at = datetime.datetime.utcnow()\n",
    "                    return True\n",
    "                else:\n",
    "                    raise Exception(f\"æ­¥éª¤ {step.name} æ‰§è¡Œå¤±è´¥\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                step.error = str(e)\n",
    "                if attempt < step.retry_count:\n",
    "                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿\n",
    "                    continue\n",
    "                else:\n",
    "                    step.status = \"failed\"\n",
    "                    step.completed_at = datetime.datetime.utcnow()\n",
    "                    return False\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    async def _rollback_deployment(self, deployment_session: Dict[str, Any], \n",
    "                                  steps: List[DeploymentStep]):\n",
    "        \"\"\"å›æ»šéƒ¨ç½²\"\"\"\n",
    "        print(f\"å¼€å§‹å›æ»šéƒ¨ç½²: {deployment_session['deployment_id']}\")\n",
    "        \n",
    "        # æŒ‰ç›¸åé¡ºåºæ‰§è¡Œå›æ»š\n",
    "        for step in reversed(steps):\n",
    "            if step.status == \"completed\" and step.rollback_command:\n",
    "                try:\n",
    "                    print(f\"å›æ»šæ­¥éª¤: {step.name} - {step.rollback_command}\")\n",
    "                    await asyncio.sleep(1)  # æ¨¡æ‹Ÿå›æ»šæ—¶é—´\n",
    "                except Exception as e:\n",
    "                    print(f\"å›æ»šå¤±è´¥: {step.name} - {e}\")\n",
    "    \n",
    "    def _record_deployment(self, deployment_session: Dict[str, Any]):\n",
    "        \"\"\"è®°å½•éƒ¨ç½²å†å²\"\"\"\n",
    "        self.deployment_history.append({\n",
    "            **deployment_session,\n",
    "            \"completed_at\": datetime.datetime.utcnow()\n",
    "        })\n",
    "        \n",
    "        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…\n",
    "        if len(self.deployment_history) > 1000:\n",
    "            self.deployment_history = self.deployment_history[-500:]\n",
    "    \n",
    "    def get_deployment_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–éƒ¨ç½²ç»Ÿè®¡\"\"\"\n",
    "        if not self.deployment_history:\n",
    "            return {\"total_deployments\": 0}\n",
    "        \n",
    "        total_deployments = len(self.deployment_history)\n",
    "        completed_deployments = sum(1 for d in self.deployment_history if d[\"status\"] == \"completed\")\n",
    "        failed_deployments = sum(1 for d in self.deployment_history if d[\"status\"] == \"failed\")\n",
    "        \n",
    "        avg_duration = 0\n",
    "        if self.deployment_history:\n",
    "            durations = []\n",
    "            for d in self.deployment_history:\n",
    "                if \"started_at\" in d and \"completed_at\" in d:\n",
    "                    duration = (d[\"completed_at\"] - d[\"started_at\"]).total_seconds()\n",
    "                    durations.append(duration)\n",
    "            \n",
    "            if durations:\n",
    "                avg_duration = sum(durations) / len(durations)\n",
    "        \n",
    "        return {\n",
    "            \"total_deployments\": total_deployments,\n",
    "            \"completed_deployments\": completed_deployments,\n",
    "            \"failed_deployments\": failed_deployments,\n",
    "            \"success_rate\": completed_deployments / total_deployments * 100,\n",
    "            \"average_duration\": avg_duration,\n",
    "            \"active_deployments\": len(self.active_deployments)\n",
    "        }\n",
    "\n",
    "# 1.2 è“ç»¿éƒ¨ç½²å’Œé‡‘ä¸é›€å‘å¸ƒ\n",
    "print(f\"\\n   ğŸ¯ 1.2 è“ç»¿éƒ¨ç½²å’Œé‡‘ä¸é›€å‘å¸ƒ:\")\n",
    "\n",
    "class DeploymentStrategy(Enum):\n",
    "    \"\"\"éƒ¨ç½²ç­–ç•¥\"\"\"\n",
    "    ROLLING = \"rolling\"  # æ»šåŠ¨æ›´æ–°\n",
    "    BLUE_GREEN = \"blue_green\"  # è“ç»¿éƒ¨ç½²\n",
    "    CANARY = \"canary\"  # é‡‘ä¸é›€å‘å¸ƒ\n",
    "    A_B_TESTING = \"ab_testing\"  # A/Bæµ‹è¯•\n",
    "\n",
    "@dataclass\n",
    "class TrafficSplit:\n",
    "    \"\"\"æµé‡åˆ†é…\"\"\"\n",
    "    version_a: str\n",
    "    version_b: str\n",
    "    traffic_percentage_a: float\n",
    "    traffic_percentage_b: float\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if abs(self.traffic_percentage_a + self.traffic_percentage_b - 100.0) > 0.01:\n",
    "            raise ValueError(\"æµé‡åˆ†é…ç™¾åˆ†æ¯”æ€»å’Œå¿…é¡»ä¸º100%\")\n",
    "\n",
    "class AdvancedDeploymentManager:\n",
    "    \"\"\"é«˜çº§éƒ¨ç½²ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_manager = DeploymentManager()\n",
    "        self.active_environments: Dict[str, str] = {}  # environment -> active_version\n",
    "        self.traffic_splits: Dict[str, TrafficSplit] = {}\n",
    "        self.deployment_strategies: Dict[str, DeploymentStrategy] = {}\n",
    "    \n",
    "    async def rolling_update(self, app_name: str, new_version: str, \n",
    "                           batch_size: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"æ»šåŠ¨æ›´æ–°\"\"\"\n",
    "        print(f\"å¼€å§‹æ»šåŠ¨æ›´æ–°: {app_name} -> {new_version}\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ»šåŠ¨æ›´æ–°è¿‡ç¨‹\n",
    "        old_version = self.active_environments.get(app_name, \"v1.0.0\")\n",
    "        \n",
    "        # é€æ­¥æ›´æ–°å®ä¾‹\n",
    "        total_instances = 5  # å‡è®¾æœ‰5ä¸ªå®ä¾‹\n",
    "        updated_instances = 0\n",
    "        \n",
    "        while updated_instances < total_instances:\n",
    "            batch = min(batch_size, total_instances - updated_instances)\n",
    "            print(f\"æ›´æ–°æ‰¹æ¬¡: {batch} ä¸ªå®ä¾‹\")\n",
    "            \n",
    "            # æ¨¡æ‹Ÿæ›´æ–°è¿‡ç¨‹\n",
    "            await asyncio.sleep(2)\n",
    "            updated_instances += batch\n",
    "            \n",
    "            # å¥åº·æ£€æŸ¥\n",
    "            if random.random() > 0.1:  # 90%æˆåŠŸç‡\n",
    "                print(f\"æ‰¹æ¬¡æ›´æ–°æˆåŠŸï¼Œå·²æ›´æ–°: {updated_instances}/{total_instances}\")\n",
    "            else:\n",
    "                print(f\"æ‰¹æ¬¡æ›´æ–°å¤±è´¥ï¼Œå›æ»š\")\n",
    "                return {\"status\": \"failed\", \"updated_instances\": updated_instances}\n",
    "        \n",
    "        self.active_environments[app_name] = new_version\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"completed\",\n",
    "            \"old_version\": old_version,\n",
    "            \"new_version\": new_version,\n",
    "            \"updated_instances\": updated_instances\n",
    "        }\n",
    "    \n",
    "    async def blue_green_deployment(self, app_name: str, new_version: str) -> Dict[str, Any]:\n",
    "        \"\"\"è“ç»¿éƒ¨ç½²\"\"\"\n",
    "        print(f\"å¼€å§‹è“ç»¿éƒ¨ç½²: {app_name} -> {new_version}\")\n",
    "        \n",
    "        old_version = self.active_environments.get(app_name, \"v1.0.0\")\n",
    "        \n",
    "        # 1. éƒ¨ç½²æ–°ç‰ˆæœ¬åˆ°ç»¿è‰²ç¯å¢ƒ\n",
    "        print(f\"éƒ¨ç½²æ–°ç‰ˆæœ¬ {new_version} åˆ°ç»¿è‰²ç¯å¢ƒ\")\n",
    "        await asyncio.sleep(3)\n",
    "        \n",
    "        # 2. ç»¿è‰²ç¯å¢ƒå¥åº·æ£€æŸ¥\n",
    "        print(f\"ç»¿è‰²ç¯å¢ƒå¥åº·æ£€æŸ¥\")\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        if random.random() > 0.1:  # 90%æˆåŠŸç‡\n",
    "            # 3. åˆ‡æ¢æµé‡åˆ°ç»¿è‰²ç¯å¢ƒ\n",
    "            print(f\"åˆ‡æ¢æµé‡åˆ°ç»¿è‰²ç¯å¢ƒ\")\n",
    "            await asyncio.sleep(1)\n",
    "            \n",
    "            self.active_environments[app_name] = new_version\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"completed\",\n",
    "                \"old_version\": old_version,\n",
    "                \"new_version\": new_version,\n",
    "                \"strategy\": \"blue_green\"\n",
    "            }\n",
    "        else:\n",
    "            print(f\"ç»¿è‰²ç¯å¢ƒéƒ¨ç½²å¤±è´¥ï¼Œä¿æŒè“è‰²ç¯å¢ƒ\")\n",
    "            return {\"status\": \"failed\", \"active_version\": old_version}\n",
    "    \n",
    "    async def canary_deployment(self, app_name: str, new_version: str, \n",
    "                               initial_traffic: float = 10.0) -> Dict[str, Any]:\n",
    "        \"\"\"é‡‘ä¸é›€å‘å¸ƒ\"\"\"\n",
    "        print(f\"å¼€å§‹é‡‘ä¸é›€å‘å¸ƒ: {app_name} -> {new_version}\")\n",
    "        \n",
    "        old_version = self.active_environments.get(app_name, \"v1.0.0\")\n",
    "        current_traffic = initial_traffic\n",
    "        \n",
    "        # è®¾ç½®æµé‡åˆ†é…\n",
    "        traffic_split = TrafficSplit(\n",
    "            version_a=old_version,\n",
    "            version_b=new_version,\n",
    "            traffic_percentage_a=100.0 - current_traffic,\n",
    "            traffic_percentage_b=current_traffic\n",
    "        )\n",
    "        \n",
    "        self.traffic_splits[app_name] = traffic_split\n",
    "        \n",
    "        # é€æ­¥å¢åŠ æµé‡\n",
    "        while current_traffic < 100.0:\n",
    "            print(f\"å½“å‰æµé‡åˆ†é…: {old_version} {100.0-current_traffic:.1f}% : {new_version} {current_traffic:.1f}%\")\n",
    "            \n",
    "            # ç›‘æ§æ–°ç‰ˆæœ¬è¡¨ç°\n",
    "            await asyncio.sleep(2)\n",
    "            \n",
    "            # æ¨¡æ‹Ÿç›‘æ§ç»“æœï¼ˆ95%æˆåŠŸç‡ï¼‰\n",
    "            if random.random() > 0.05:\n",
    "                # å¢åŠ æµé‡\n",
    "                current_traffic = min(current_traffic + 20.0, 100.0)\n",
    "                traffic_split.traffic_percentage_a = 100.0 - current_traffic\n",
    "                traffic_split.traffic_percentage_b = current_traffic\n",
    "            else:\n",
    "                print(f\"æ–°ç‰ˆæœ¬è¡¨ç°å¼‚å¸¸ï¼Œå›æ»šåˆ°æ—§ç‰ˆæœ¬\")\n",
    "                traffic_split.traffic_percentage_a = 100.0\n",
    "                traffic_split.traffic_percentage_b = 0.0\n",
    "                return {\"status\": \"failed\", \"active_version\": old_version}\n",
    "        \n",
    "        self.active_environments[app_name] = new_version\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"completed\",\n",
    "            \"old_version\": old_version,\n",
    "            \"new_version\": new_version,\n",
    "            \"strategy\": \"canary\"\n",
    "        }\n",
    "    \n",
    "    def get_traffic_status(self, app_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æµé‡çŠ¶æ€\"\"\"\n",
    "        if app_name not in self.traffic_splits:\n",
    "            return {\"error\": \"åº”ç”¨ä¸å­˜åœ¨æˆ–æœªè®¾ç½®æµé‡åˆ†é…\"}\n",
    "        \n",
    "        split = self.traffic_splits[app_name]\n",
    "        \n",
    "        return {\n",
    "            \"app_name\": app_name,\n",
    "            \"version_a\": split.version_a,\n",
    "            \"version_b\": split.version_b,\n",
    "            \"traffic_percentage_a\": split.traffic_percentage_a,\n",
    "            \"traffic_percentage_b\": split.traffic_percentage_b,\n",
    "            \"active_version\": self.active_environments.get(app_name)\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹å®Œæˆ\")\n",
    "print(f\"      - DeploymentConfig: éƒ¨ç½²é…ç½®\")\n",
    "print(f\"      - DeploymentManager: éƒ¨ç½²ç®¡ç†å™¨\")\n",
    "print(f\"      - AdvancedDeploymentManager: é«˜çº§éƒ¨ç½²ç®¡ç†å™¨\")\n",
    "print(f\"      - æ”¯æŒæ»šåŠ¨æ›´æ–°ã€è“ç»¿éƒ¨ç½²ã€é‡‘ä¸é›€å‘å¸ƒ\")\n",
    "\n",
    "print(f\"\\nâœ… éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡Webåº”ç”¨çš„éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹\")\n",
    "print(f\"   âœ“ å­¦ä¼šå®¹å™¨åŒ–éƒ¨ç½²å’Œç¼–æ’ç®¡ç†\")\n",
    "print(f\"   âœ“ ç†è§£ç›‘æ§ã€æ—¥å¿—å’Œè¿ç»´è‡ªåŠ¨åŒ–\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿå®ç°é«˜å¯ç”¨çš„ç”Ÿäº§ç¯å¢ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®¹å™¨åŒ–éƒ¨ç½²ä¸ç¼–æ’ [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šå®¹å™¨åŒ–éƒ¨ç½²ä¸ç¼–æ’æ˜¯ç°ä»£åº”ç”¨éƒ¨ç½²çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œä¸ºLangChainçš„AIæœåŠ¡æä¾›ç¯å¢ƒä¸€è‡´æ€§å’Œå¯æ‰©å±•æ€§ä¿éšœã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡å®¹å™¨åŒ–æŠ€æœ¯å’ŒDockerä½¿ç”¨\n",
    "- å­¦ä¼šå®¹å™¨ç¼–æ’å’Œç®¡ç†\n",
    "- ç†è§£å¾®æœåŠ¡å®¹å™¨åŒ–éƒ¨ç½²\n",
    "- èƒ½å¤Ÿè®¾è®¡å®¹å™¨åŒ–æ¶æ„æ–¹æ¡ˆ\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„å®¹å™¨åŒ–éƒ¨ç½²\n",
    "- æ„å»ºå®¹å™¨ç¼–æ’ç³»ç»Ÿ\n",
    "- å¼€å‘å®¹å™¨ç›‘æ§å’Œç®¡ç†\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹è®¾è®¡å®¹å™¨åŒ–æ¶æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ³ å®¹å™¨åŒ–éƒ¨ç½²ä¸ç¼–æ’:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 2. å®¹å™¨åŒ–éƒ¨ç½²ä¸ç¼–æ’\n",
    "print(f\"ğŸ“ 2. å®¹å™¨åŒ–éƒ¨ç½²ä¸ç¼–æ’:\")\n",
    "\n",
    "# 2.1 Dockerå®¹å™¨ç®¡ç†\n",
    "print(f\"\\n   ğŸ“¦ 2.1 Dockerå®¹å™¨ç®¡ç†:\")\n",
    "\n",
    "@dataclass\n",
    "class DockerImage:\n",
    "    \"\"\"Dockeré•œåƒ\"\"\"\n",
    "    name: str\n",
    "    tag: str\n",
    "    dockerfile_path: str\n",
    "    build_context: str = \".\"\n",
    "    build_args: Dict[str, str] = field(default_factory=dict)\n",
    "    labels: Dict[str, str] = field(default_factory=dict)\n",
    "    \n",
    "    @property\n",
    "    def full_name(self) -> str:\n",
    "        return f\"{self.name}:{self.tag}\"\n",
    "\n",
    "@dataclass\n",
    "class DockerContainer:\n",
    "    \"\"\"Dockerå®¹å™¨\"\"\"\n",
    "    container_id: str\n",
    "    name: str\n",
    "    image: DockerImage\n",
    "    ports: Dict[str, str] = field(default_factory=dict)  # host:container\n",
    "    volumes: Dict[str, str] = field(default_factory=dict)  # host:container\n",
    "    environment_variables: Dict[str, str] = field(default_factory=dict)\n",
    "    command: Optional[str] = None\n",
    "    status: str = \"created\"  # created, running, stopped, failed\n",
    "    created_at: datetime.datetime = field(default_factory=datetime.datetime.utcnow)\n",
    "    started_at: Optional[datetime.datetime] = None\n",
    "    \n",
    "    @property\n",
    "    def is_running(self) -> bool:\n",
    "        return self.status == \"running\"\n",
    "\n",
    "class DockerManager:\n",
    "    \"\"\"Dockerç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.images: Dict[str, DockerImage] = {}\n",
    "        self.containers: Dict[str, DockerContainer] = {}\n",
    "        self.networks: Dict[str, Dict[str, Any]] = {}\n",
    "        self.volumes: Dict[str, Dict[str, Any]] = {}\n",
    "    \n",
    "    def build_image(self, image: DockerImage) -> bool:\n",
    "        \"\"\"æ„å»ºDockeré•œåƒ\"\"\"\n",
    "        print(f\"æ„å»ºDockeré•œåƒ: {image.full_name}\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ„å»ºè¿‡ç¨‹\n",
    "        build_steps = [\n",
    "            \"å‘é€æ„å»ºä¸Šä¸‹æ–‡\",\n",
    "            \"ä¸‹è½½ä¾èµ–\",\n",
    "            \"æ‰§è¡Œæ„å»ºæŒ‡ä»¤\",\n",
    "            \"æ ‡è®°é•œåƒ\"\n",
    "        ]\n",
    "        \n",
    "        for step in build_steps:\n",
    "            print(f\"  {step}...\")\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ„å»ºæˆåŠŸç‡ï¼ˆ95%ï¼‰\n",
    "        if random.random() > 0.05:\n",
    "            self.images[image.full_name] = image\n",
    "            print(f\"é•œåƒæ„å»ºæˆåŠŸ: {image.full_name}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"é•œåƒæ„å»ºå¤±è´¥: {image.full_name}\")\n",
    "            return False\n",
    "    \n",
    "    def create_container(self, container: DockerContainer) -> bool:\n",
    "        \"\"\"åˆ›å»ºå®¹å™¨\"\"\"\n",
    "        print(f\"åˆ›å»ºå®¹å™¨: {container.name}\")\n",
    "        \n",
    "        # æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨\n",
    "        if container.image.full_name not in self.images:\n",
    "            print(f\"é•œåƒä¸å­˜åœ¨: {container.image.full_name}\")\n",
    "            return False\n",
    "        \n",
    "        # æ¨¡æ‹Ÿåˆ›å»ºè¿‡ç¨‹\n",
    "        print(f\"  ä½¿ç”¨é•œåƒ: {container.image.full_name}\")\n",
    "        \n",
    "        if container.ports:\n",
    "            print(f\"  ç«¯å£æ˜ å°„: {container.ports}\")\n",
    "        \n",
    "        if container.volumes:\n",
    "            print(f\"  å·æŒ‚è½½: {container.volumes}\")\n",
    "        \n",
    "        if container.environment_variables:\n",
    "            print(f\"  ç¯å¢ƒå˜é‡: {list(container.environment_variables.keys())}\")\n",
    "        \n",
    "        self.containers[container.container_id] = container\n",
    "        print(f\"å®¹å™¨åˆ›å»ºæˆåŠŸ: {container.name}\")\n",
    "        return True\n",
    "    \n",
    "    def start_container(self, container_id: str) -> bool:\n",
    "        \"\"\"å¯åŠ¨å®¹å™¨\"\"\"\n",
    "        if container_id not in self.containers:\n",
    "            print(f\"å®¹å™¨ä¸å­˜åœ¨: {container_id}\")\n",
    "            return False\n",
    "        \n",
    "        container = self.containers[container_id]\n",
    "        print(f\"å¯åŠ¨å®¹å™¨: {container.name}\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿå¯åŠ¨è¿‡ç¨‹\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # æ¨¡æ‹Ÿå¯åŠ¨æˆåŠŸç‡ï¼ˆ90%ï¼‰\n",
    "        if random.random() > 0.1:\n",
    "            container.status = \"running\"\n",
    "            container.started_at = datetime.datetime.utcnow()\n",
    "            print(f\"å®¹å™¨å¯åŠ¨æˆåŠŸ: {container.name}\")\n",
    "            return True\n",
    "        else:\n",
    "            container.status = \"failed\"\n",
    "            print(f\"å®¹å™¨å¯åŠ¨å¤±è´¥: {container.name}\")\n",
    "            return False\n",
    "    \n",
    "    def stop_container(self, container_id: str) -> bool:\n",
    "        \"\"\"åœæ­¢å®¹å™¨\"\"\"\n",
    "        if container_id not in self.containers:\n",
    "            print(f\"å®¹å™¨ä¸å­˜åœ¨: {container_id}\")\n",
    "            return False\n",
    "        \n",
    "        container = self.containers[container_id]\n",
    "        print(f\"åœæ­¢å®¹å™¨: {container.name}\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿåœæ­¢è¿‡ç¨‹\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        container.status = \"stopped\"\n",
    "        print(f\"å®¹å™¨åœæ­¢æˆåŠŸ: {container.name}\")\n",
    "        return True\n",
    "    \n",
    "    def remove_container(self, container_id: str) -> bool:\n",
    "        \"\"\"åˆ é™¤å®¹å™¨\"\"\"\n",
    "        if container_id not in self.containers:\n",
    "            print(f\"å®¹å™¨ä¸å­˜åœ¨: {container_id}\")\n",
    "            return False\n",
    "        \n",
    "        container = self.containers[container_id]\n",
    "        \n",
    "        # å…ˆåœæ­¢å®¹å™¨\n",
    "        if container.status == \"running\":\n",
    "            self.stop_container(container_id)\n",
    "        \n",
    "        print(f\"åˆ é™¤å®¹å™¨: {container.name}\")\n",
    "        del self.containers[container_id]\n",
    "        print(f\"å®¹å™¨åˆ é™¤æˆåŠŸ: {container.name}\")\n",
    "        return True\n",
    "    \n",
    "    def get_container_logs(self, container_id: str, lines: int = 100) -> List[str]:\n",
    "        \"\"\"è·å–å®¹å™¨æ—¥å¿—\"\"\"\n",
    "        if container_id not in self.containers:\n",
    "            return []\n",
    "        \n",
    "        container = self.containers[container_id]\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ—¥å¿—\n",
    "        logs = [\n",
    "            f\"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å®¹å™¨ {container.name} å¯åŠ¨\",\n",
    "            f\"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] åˆå§‹åŒ–åº”ç”¨...\",\n",
    "            f\"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] åŠ è½½é…ç½®æ–‡ä»¶\",\n",
    "            f\"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] è¿æ¥æ•°æ®åº“\",\n",
    "            f\"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] åº”ç”¨å¯åŠ¨å®Œæˆ\"\n",
    "        ]\n",
    "        \n",
    "        return logs[-lines:]\n",
    "    \n",
    "    def get_container_stats(self, container_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–å®¹å™¨ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        if container_id not in self.containers:\n",
    "            return {}\n",
    "        \n",
    "        container = self.containers[container_id]\n",
    "        \n",
    "        # æ¨¡æ‹Ÿç»Ÿè®¡ä¿¡æ¯\n",
    "        stats = {\n",
    "            \"container_id\": container_id,\n",
    "            \"name\": container.name,\n",
    "            \"status\": container.status,\n",
    "            \"image\": container.image.full_name,\n",
    "            \"cpu_usage\": f\"{random.uniform(0.1, 2.0):.2f}%\",\n",
    "            \"memory_usage\": f\"{random.uniform(50, 200):.1f}MB\",\n",
    "            \"network_io\": f\"{random.uniform(0.1, 10.0):.2f}MB/s\",\n",
    "            \"disk_io\": f\"{random.uniform(0.1, 5.0):.2f}MB/s\"\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def list_containers(self, all_containers: bool = False) -> List[DockerContainer]:\n",
    "        \"\"\"åˆ—å‡ºå®¹å™¨\"\"\"\n",
    "        containers = list(self.containers.values())\n",
    "        \n",
    "        if not all_containers:\n",
    "            containers = [c for c in containers if c.status == \"running\"]\n",
    "        \n",
    "        return containers\n",
    "\n",
    "# 2.2 å®¹å™¨ç¼–æ’\n",
    "print(f\"\\n   ğŸ¼ 2.2 å®¹å™¨ç¼–æ’:\")\n",
    "\n",
    "@dataclass\n",
    "class ServiceSpec:\n",
    "    \"\"\"æœåŠ¡è§„æ ¼\"\"\"\n",
    "    name: str\n",
    "    image: DockerImage\n",
    "    replicas: int = 1\n",
    "    ports: List[str] = field(default_factory=list)\n",
    "    environment_variables: Dict[str, str] = field(default_factory=dict)\n",
    "    resources: Dict[str, str] = field(default_factory=dict)\n",
    "    health_check: Optional[Dict[str, Any]] = None\n",
    "\n",
    "@dataclass\n",
    "class DeploymentSpec:\n",
    "    \"\"\"éƒ¨ç½²è§„æ ¼\"\"\"\n",
    "    name: str\n",
    "    services: List[ServiceSpec]\n",
    "    networks: List[str] = field(default_factory=list)\n",
    "    volumes: List[str] = field(default_factory=list)\n",
    "    \n",
    "class OrchestrationManager:\n",
    "    \"\"\"ç¼–æ’ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, docker_manager: DockerManager):\n",
    "        self.docker_manager = docker_manager\n",
    "        self.deployments: Dict[str, DeploymentSpec] = {}\n",
    "        self.service_instances: Dict[str, List[str]] = {}  # service_name -> container_ids\n",
    "        self.load_balancers: Dict[str, List[str]] = {}  # service_name -> container_ids\n",
    "    \n",
    "    def create_deployment(self, deployment: DeploymentSpec) -> bool:\n",
    "        \"\"\"åˆ›å»ºéƒ¨ç½²\"\"\"\n",
    "        print(f\"åˆ›å»ºéƒ¨ç½²: {deployment.name}\")\n",
    "        \n",
    "        # æ„å»ºæ‰€æœ‰é•œåƒ\n",
    "        for service in deployment.services:\n",
    "            if not self.docker_manager.build_image(service.image):\n",
    "                print(f\"é•œåƒæ„å»ºå¤±è´¥: {service.image.full_name}\")\n",
    "                return False\n",
    "        \n",
    "        # åˆ›å»ºæœåŠ¡å®ä¾‹\n",
    "        for service in deployment.services:\n",
    "            container_ids = []\n",
    "            \n",
    "            for i in range(service.replicas):\n",
    "                container_name = f\"{deployment.name}-{service.name}-{i}\"\n",
    "                container_id = str(uuid.uuid4())\n",
    "                \n",
    "                # è§£æç«¯å£\n",
    "                ports = {}\n",
    "                if service.ports:\n",
    "                    for port_mapping in service.ports:\n",
    "                        if \":\" in port_mapping:\n",
    "                            host_port, container_port = port_mapping.split(\":\")\n",
    "                            ports[host_port] = container_port\n",
    "                        else:\n",
    "                            # ä½¿ç”¨éšæœºä¸»æœºç«¯å£\n",
    "                            host_port = str(random.randint(30000, 40000))\n",
    "                            ports[host_port] = port_mapping\n",
    "                \n",
    "                container = DockerContainer(\n",
    "                    container_id=container_id,\n",
    "                    name=container_name,\n",
    "                    image=service.image,\n",
    "                    ports=ports,\n",
    "                    environment_variables=service.environment_variables\n",
    "                )\n",
    "                \n",
    "                if self.docker_manager.create_container(container):\n",
    "                    container_ids.append(container_id)\n",
    "                    self.docker_manager.start_container(container_id)\n",
    "                else:\n",
    "                    print(f\"å®¹å™¨åˆ›å»ºå¤±è´¥: {container_name}\")\n",
    "                    return False\n",
    "            \n",
    "            self.service_instances[service.name] = container_ids\n",
    "            self.load_balancers[service.name] = container_ids\n",
    "        \n",
    "        self.deployments[deployment.name] = deployment\n",
    "        print(f\"éƒ¨ç½²åˆ›å»ºæˆåŠŸ: {deployment.name}\")\n",
    "        return True\n",
    "    \n",
    "    def scale_service(self, deployment_name: str, service_name: str, replicas: int) -> bool:\n",
    "        \"\"\"æ‰©ç¼©å®¹æœåŠ¡\"\"\"\n",
    "        if deployment_name not in self.deployments:\n",
    "            print(f\"éƒ¨ç½²ä¸å­˜åœ¨: {deployment_name}\")\n",
    "            return False\n",
    "        \n",
    "        deployment = self.deployments[deployment_name]\n",
    "        service = None\n",
    "        \n",
    "        for s in deployment.services:\n",
    "            if s.name == service_name:\n",
    "                service = s\n",
    "                break\n",
    "        \n",
    "        if not service:\n",
    "            print(f\"æœåŠ¡ä¸å­˜åœ¨: {service_name}\")\n",
    "            return False\n",
    "        \n",
    "        current_replicas = len(self.service_instances.get(service_name, []))\n",
    "        \n",
    "        if replicas > current_replicas:\n",
    "            # æ‰©å®¹\n",
    "            print(f\"æ‰©å®¹æœåŠ¡ {service_name}: {current_replicas} -> {replicas}\")\n",
    "            \n",
    "            for i in range(current_replicas, replicas):\n",
    "                container_name = f\"{deployment_name}-{service_name}-{i}\"\n",
    "                container_id = str(uuid.uuid4())\n",
    "                \n",
    "                container = DockerContainer(\n",
    "                    container_id=container_id,\n",
    "                    name=container_name,\n",
    "                    image=service.image,\n",
    "                    environment_variables=service.environment_variables\n",
    "                )\n",
    "                \n",
    "                if self.docker_manager.create_container(container):\n",
    "                    self.docker_manager.start_container(container_id)\n",
    "                    self.service_instances[service_name].append(container_id)\n",
    "                    self.load_balancers[service_name].append(container_id)\n",
    "                else:\n",
    "                    print(f\"æ‰©å®¹å¤±è´¥: {container_name}\")\n",
    "                    return False\n",
    "        \n",
    "        elif replicas < current_replicas:\n",
    "            # ç¼©å®¹\n",
    "            print(f\"ç¼©å®¹æœåŠ¡ {service_name}: {current_replicas} -> {replicas}\")\n",
    "            \n",
    "            containers_to_remove = current_replicas - replicas\n",
    "            container_ids = self.service_instances[service_name]\n",
    "            \n",
    "            for i in range(containers_to_remove):\n",
    "                container_id = container_ids[-(i+1)]\n",
    "                self.docker_manager.remove_container(container_id)\n",
    "                self.service_instances[service_name].remove(container_id)\n",
    "                self.load_balancers[service_name].remove(container_id)\n",
    "        \n",
    "        print(f\"æœåŠ¡æ‰©ç¼©å®¹å®Œæˆ: {service_name} -> {replicas} ä¸ªå®ä¾‹\")\n",
    "        return True\n",
    "    \n",
    "    def update_service(self, deployment_name: str, service_name: str, new_image: DockerImage) -> bool:\n",
    "        \"\"\"æ›´æ–°æœåŠ¡\"\"\"\n",
    "        if deployment_name not in self.deployments:\n",
    "            print(f\"éƒ¨ç½²ä¸å­˜åœ¨: {deployment_name}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"æ›´æ–°æœåŠ¡ {service_name}: {new_image.full_name}\")\n",
    "        \n",
    "        # æ„å»ºæ–°é•œåƒ\n",
    "        if not self.docker_manager.build_image(new_image):\n",
    "            print(f\"æ–°é•œåƒæ„å»ºå¤±è´¥: {new_image.full_name}\")\n",
    "            return False\n",
    "        \n",
    "        # æ»šåŠ¨æ›´æ–°\n",
    "        container_ids = self.service_instances.get(service_name, []).copy()\n",
    "        \n",
    "        for i, container_id in enumerate(container_ids):\n",
    "            # åˆ›å»ºæ–°å®¹å™¨\n",
    "            old_container = self.docker_manager.containers[container_id]\n",
    "            new_container_id = str(uuid.uuid4())\n",
    "            new_container_name = f\"{deployment_name}-{service_name}-{i}-new\"\n",
    "            \n",
    "            new_container = DockerContainer(\n",
    "                container_id=new_container_id,\n",
    "                name=new_container_name,\n",
    "                image=new_image,\n",
    "                ports=old_container.ports,\n",
    "                environment_variables=old_container.environment_variables\n",
    "            )\n",
    "            \n",
    "            if self.docker_manager.create_container(new_container):\n",
    "                if self.docker_manager.start_container(new_container_id):\n",
    "                    # å¥åº·æ£€æŸ¥\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    if random.random() > 0.1:  # 90%æˆåŠŸç‡\n",
    "                        # åœæ­¢æ—§å®¹å™¨\n",
    "                        self.docker_manager.stop_container(container_id)\n",
    "                        self.docker_manager.remove_container(container_id)\n",
    "                        \n",
    "                        # æ›´æ–°å®¹å™¨åˆ—è¡¨\n",
    "                        self.service_instances[service_name].remove(container_id)\n",
    "                        self.service_instances[service_name].append(new_container_id)\n",
    "                        self.load_balancers[service_name].remove(container_id)\n",
    "                        self.load_balancers[service_name].append(new_container_id)\n",
    "                        \n",
    "                        print(f\"å®ä¾‹ {i} æ›´æ–°æˆåŠŸ\")\n",
    "                    else:\n",
    "                        print(f\"æ–°å®ä¾‹å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œä¿æŒæ—§å®ä¾‹\")\n",
    "                        self.docker_manager.remove_container(new_container_id)\n",
    "                else:\n",
    "                    print(f\"æ–°å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œä¿æŒæ—§å®ä¾‹\")\n",
    "                    self.docker_manager.remove_container(new_container_id)\n",
    "            else:\n",
    "                print(f\"æ–°å®¹å™¨åˆ›å»ºå¤±è´¥ï¼Œä¿æŒæ—§å®ä¾‹\")\n",
    "        \n",
    "        print(f\"æœåŠ¡æ›´æ–°å®Œæˆ: {service_name}\")\n",
    "        return True\n",
    "    \n",
    "    def get_deployment_status(self, deployment_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–éƒ¨ç½²çŠ¶æ€\"\"\"\n",
    "        if deployment_name not in self.deployments:\n",
    "            return {\"error\": \"éƒ¨ç½²ä¸å­˜åœ¨\"}\n",
    "        \n",
    "        deployment = self.deployments[deployment_name]\n",
    "        services_status = {}\n",
    "        \n",
    "        for service in deployment.services:\n",
    "            container_ids = self.service_instances.get(service.name, [])\n",
    "            running_containers = 0\n",
    "            \n",
    "            for container_id in container_ids:\n",
    "                if container_id in self.docker_manager.containers:\n",
    "                    container = self.docker_manager.containers[container_id]\n",
    "                    if container.status == \"running\":\n",
    "                        running_containers += 1\n",
    "            \n",
    "            services_status[service.name] = {\n",
    "                \"desired_replicas\": service.replicas,\n",
    "                \"actual_replicas\": len(container_ids),\n",
    "                \"running_replicas\": running_containers,\n",
    "                \"ready\": running_containers == service.replicas\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"deployment_name\": deployment_name,\n",
    "            \"services\": services_status,\n",
    "            \"ready\": all(status[\"ready\"] for status in services_status.values())\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… å®¹å™¨åŒ–éƒ¨ç½²ä¸ç¼–æ’å®Œæˆ\")\n",
    "print(f\"      - DockerManager: Dockerç®¡ç†å™¨\")\n",
    "print(f\"      - OrchestrationManager: ç¼–æ’ç®¡ç†å™¨\")\n",
    "print(f\"      - æ”¯æŒé•œåƒæ„å»ºã€å®¹å™¨ç®¡ç†ã€æœåŠ¡ç¼–æ’\")\n",
    "print(f\"      - æ”¯æŒæ‰©ç¼©å®¹ã€æ»šåŠ¨æ›´æ–°ã€è´Ÿè½½å‡è¡¡\")\n",
    "\n",
    "print(f\"\\nâœ… å®¹å™¨åŒ–éƒ¨ç½²ä¸ç¼–æ’å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡å®¹å™¨åŒ–æŠ€æœ¯å’ŒDockerä½¿ç”¨\")\n",
    "print(f\"   âœ“ å­¦ä¼šå®¹å™¨ç¼–æ’å’Œç®¡ç†\")\n",
    "print(f\"   âœ“ ç†è§£å¾®æœåŠ¡å®¹å™¨åŒ–éƒ¨ç½²\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿè®¾è®¡å®¹å™¨åŒ–æ¶æ„æ–¹æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç›‘æ§ã€æ—¥å¿—ä¸è¿ç»´è‡ªåŠ¨åŒ– [â­â­è¿›é˜¶]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šç›‘æ§ã€æ—¥å¿—ä¸è¿ç»´è‡ªåŠ¨åŒ–æ˜¯ç”Ÿäº§ç¯å¢ƒè¿ç»´çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œä¸ºLangChainçš„AIæœåŠ¡æä¾›å…¨é¢çš„è¿ç»´ä¿éšœå’Œè‡ªåŠ¨åŒ–ç®¡ç†ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡åº”ç”¨ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†\n",
    "- å­¦ä¼šæ—¥å¿—ç®¡ç†å’Œåˆ†æ\n",
    "- ç†è§£è¿ç»´è‡ªåŠ¨åŒ–å’Œå‘Šè­¦\n",
    "- èƒ½å¤Ÿæ„å»ºå®Œæ•´çš„è¿ç»´ä½“ç³»\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„ç›‘æ§ç³»ç»Ÿ\n",
    "- æ„å»ºæ—¥å¿—ç®¡ç†å¹³å°\n",
    "- å¼€å‘è¿ç»´è‡ªåŠ¨åŒ–å·¥å…·\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹æ„å»ºè¿ç»´ä½“ç³»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š ç›‘æ§ã€æ—¥å¿—ä¸è¿ç»´è‡ªåŠ¨åŒ–:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 3. ç›‘æ§ã€æ—¥å¿—ä¸è¿ç»´è‡ªåŠ¨åŒ–\n",
    "print(f\"ğŸ“ 3. ç›‘æ§ã€æ—¥å¿—ä¸è¿ç»´è‡ªåŠ¨åŒ–:\")\n",
    "\n",
    "# 3.1 åº”ç”¨ç›‘æ§ç³»ç»Ÿ\n",
    "print(f\"\\n   ğŸ“ˆ 3.1 åº”ç”¨ç›‘æ§ç³»ç»Ÿ:\")\n",
    "\n",
    "@dataclass\n",
    "class Metric:\n",
    "    \"\"\"ç›‘æ§æŒ‡æ ‡\"\"\"\n",
    "    name: str\n",
    "    value: float\n",
    "    labels: Dict[str, str] = field(default_factory=dict)\n",
    "    timestamp: datetime.datetime = field(default_factory=datetime.datetime.utcnow)\n",
    "    metric_type: str = \"gauge\"  # gauge, counter, histogram, summary\n",
    "\n",
    "@dataclass\n",
    "class AlertRule:\n",
    "    \"\"\"å‘Šè­¦è§„åˆ™\"\"\"\n",
    "    rule_id: str\n",
    "    name: str\n",
    "    metric_name: str\n",
    "    condition: str  # >, <, >=, <=, ==\n",
    "    threshold: float\n",
    "    duration: int = 300  # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "    severity: str = \"warning\"  # info, warning, critical\n",
    "    enabled: bool = True\n",
    "    \n",
    "    def evaluate(self, metric: Metric) -> bool:\n",
    "        \"\"\"è¯„ä¼°æŒ‡æ ‡æ˜¯å¦è§¦å‘å‘Šè­¦\"\"\"\n",
    "        if metric.name != self.metric_name:\n",
    "            return False\n",
    "        \n",
    "        if self.condition == \">\":\n",
    "            return metric.value > self.threshold\n",
    "        elif self.condition == \"<\":\n",
    "            return metric.value < self.threshold\n",
    "        elif self.condition == \">=\":\n",
    "            return metric.value >= self.threshold\n",
    "        elif self.condition == \"<=\":\n",
    "            return metric.value <= self.threshold\n",
    "        elif self.condition == \"==\":\n",
    "            return metric.value == self.threshold\n",
    "        \n",
    "        return False\n",
    "\n",
    "class MonitoringSystem:\n",
    "    \"\"\"ç›‘æ§ç³»ç»Ÿ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics: List[Metric] = []\n",
    "        self.alert_rules: Dict[str, AlertRule] = {}\n",
    "        self.alerts: List[Dict[str, Any]] = []\n",
    "        self.dashboards: Dict[str, Dict[str, Any]] = {}\n",
    "        self.metric_collectors: Dict[str, Callable] = {}\n",
    "    \n",
    "    def add_metric(self, metric: Metric):\n",
    "        \"\"\"æ·»åŠ æŒ‡æ ‡\"\"\"\n",
    "        self.metrics.append(metric)\n",
    "        \n",
    "        # æ£€æŸ¥å‘Šè­¦è§„åˆ™\n",
    "        self._check_alerts(metric)\n",
    "        \n",
    "        # ä¿æŒæŒ‡æ ‡åœ¨åˆç†èŒƒå›´å†…\n",
    "        if len(self.metrics) > 10000:\n",
    "            self.metrics = self.metrics[-5000:]\n",
    "    \n",
    "    def add_alert_rule(self, rule: AlertRule):\n",
    "        \"\"\"æ·»åŠ å‘Šè­¦è§„åˆ™\"\"\"\n",
    "        self.alert_rules[rule.rule_id] = rule\n",
    "    \n",
    "    def register_collector(self, name: str, collector: Callable):\n",
    "        \"\"\"æ³¨å†ŒæŒ‡æ ‡æ”¶é›†å™¨\"\"\"\n",
    "        self.metric_collectors[name] = collector\n",
    "    \n",
    "    async def collect_metrics(self):\n",
    "        \"\"\"æ”¶é›†æŒ‡æ ‡\"\"\"\n",
    "        for name, collector in self.metric_collectors.items():\n",
    "            try:\n",
    "                metrics = await collector()\n",
    "                if isinstance(metrics, list):\n",
    "                    for metric in metrics:\n",
    "                        self.add_metric(metric)\n",
    "                else:\n",
    "                    self.add_metric(metrics)\n",
    "            except Exception as e:\n",
    "                print(f\"æŒ‡æ ‡æ”¶é›†å¤±è´¥ {name}: {e}\")\n",
    "    \n",
    "    def _check_alerts(self, metric: Metric):\n",
    "        \"\"\"æ£€æŸ¥å‘Šè­¦\"\"\"\n",
    "        for rule in self.alert_rules.values():\n",
    "            if not rule.enabled:\n",
    "                continue\n",
    "            \n",
    "            if rule.evaluate(metric):\n",
    "                self._trigger_alert(rule, metric)\n",
    "    \n",
    "    def _trigger_alert(self, rule: AlertRule, metric: Metric):\n",
    "        \"\"\"è§¦å‘å‘Šè­¦\"\"\"\n",
    "        alert = {\n",
    "            \"alert_id\": str(uuid.uuid4()),\n",
    "            \"rule_id\": rule.rule_id,\n",
    "            \"rule_name\": rule.name,\n",
    "            \"metric_name\": metric.name,\n",
    "            \"metric_value\": metric.value,\n",
    "            \"threshold\": rule.threshold,\n",
    "            \"severity\": rule.severity,\n",
    "            \"timestamp\": datetime.datetime.utcnow(),\n",
    "            \"labels\": metric.labels\n",
    "        }\n",
    "        \n",
    "        self.alerts.append(alert)\n",
    "        \n",
    "        # ä¿æŒå‘Šè­¦åœ¨åˆç†èŒƒå›´å†…\n",
    "        if len(self.alerts) > 1000:\n",
    "            self.alerts = self.alerts[-500:]\n",
    "        \n",
    "        print(f\"ğŸš¨ å‘Šè­¦è§¦å‘: {rule.name} - {metric.name} = {metric.value} (é˜ˆå€¼: {rule.threshold})\")\n",
    "    \n",
    "    def get_metrics_summary(self, metric_name: str = None, \n",
    "                           time_range: int = 3600) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æŒ‡æ ‡æ‘˜è¦\"\"\"\n",
    "        cutoff_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=time_range)\n",
    "        \n",
    "        filtered_metrics = [\n",
    "            metric for metric in self.metrics\n",
    "            if metric.timestamp >= cutoff_time and (not metric_name or metric.name == metric_name)\n",
    "        ]\n",
    "        \n",
    "        if not filtered_metrics:\n",
    "            return {\"count\": 0}\n",
    "        \n",
    "        values = [metric.value for metric in filtered_metrics]\n",
    "        \n",
    "        return {\n",
    "            \"count\": len(values),\n",
    "            \"min\": min(values),\n",
    "            \"max\": max(values),\n",
    "            \"avg\": sum(values) / len(values),\n",
    "            \"latest\": filtered_metrics[-1].value,\n",
    "            \"metric_name\": metric_name or \"all\"\n",
    "        }\n",
    "    \n",
    "    def get_active_alerts(self, severity: str = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"è·å–æ´»è·ƒå‘Šè­¦\"\"\"\n",
    "        # è¿”å›æœ€è¿‘1å°æ—¶çš„å‘Šè­¦\n",
    "        cutoff_time = datetime.datetime.utcnow() - datetime.timedelta(hours=1)\n",
    "        \n",
    "        alerts = [\n",
    "            alert for alert in self.alerts\n",
    "            if alert[\"timestamp\"] >= cutoff_time\n",
    "        ]\n",
    "        \n",
    "        if severity:\n",
    "            alerts = [alert for alert in alerts if alert[\"severity\"] == severity]\n",
    "        \n",
    "        return alerts\n",
    "\n",
    "# 3.2 æ—¥å¿—ç®¡ç†ç³»ç»Ÿ\n",
    "print(f\"\\n   ğŸ“‹ 3.2 æ—¥å¿—ç®¡ç†ç³»ç»Ÿ:\")\n",
    "\n",
    "@dataclass\n",
    "class LogEntry:\n",
    "    \"\"\"æ—¥å¿—æ¡ç›®\"\"\"\n",
    "    timestamp: datetime.datetime\n",
    "    level: str  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n",
    "    message: str\n",
    "    source: str\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"timestamp\": self.timestamp.isoformat(),\n",
    "            \"level\": self.level,\n",
    "            \"message\": self.message,\n",
    "            \"source\": self.source,\n",
    "            \"metadata\": self.metadata\n",
    "        }\n",
    "\n",
    "class LogManager:\n",
    "    \"\"\"æ—¥å¿—ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logs: List[LogEntry] = []\n",
    "        self.log_sources: Dict[str, Dict[str, Any]] = {}\n",
    "        self.log_filters: List[Callable] = []\n",
    "        self.log_handlers: List[Callable] = []\n",
    "    \n",
    "    def add_log(self, log_entry: LogEntry):\n",
    "        \"\"\"æ·»åŠ æ—¥å¿—\"\"\"\n",
    "        # åº”ç”¨è¿‡æ»¤å™¨\n",
    "        for filter_func in self.log_filters:\n",
    "            if not filter_func(log_entry):\n",
    "                return\n",
    "        \n",
    "        self.logs.append(log_entry)\n",
    "        \n",
    "        # åº”ç”¨å¤„ç†å™¨\n",
    "        for handler in self.log_handlers:\n",
    "            try:\n",
    "                handler(log_entry)\n",
    "            except Exception as e:\n",
    "                print(f\"æ—¥å¿—å¤„ç†å™¨é”™è¯¯: {e}\")\n",
    "        \n",
    "        # ä¿æŒæ—¥å¿—åœ¨åˆç†èŒƒå›´å†…\n",
    "        if len(self.logs) > 50000:\n",
    "            self.logs = self.logs[-25000:]\n",
    "    \n",
    "    def register_source(self, source: str, config: Dict[str, Any]):\n",
    "        \"\"\"æ³¨å†Œæ—¥å¿—æº\"\"\"\n",
    "        self.log_sources[source] = config\n",
    "    \n",
    "    def add_filter(self, filter_func: Callable):\n",
    "        \"\"\"æ·»åŠ è¿‡æ»¤å™¨\"\"\"\n",
    "        self.log_filters.append(filter_func)\n",
    "    \n",
    "    def add_handler(self, handler: Callable):\n",
    "        \"\"\"æ·»åŠ å¤„ç†å™¨\"\"\"\n",
    "        self.log_handlers.append(handler)\n",
    "    \n",
    "    def search_logs(self, query: str = None, level: str = None, \n",
    "                    source: str = None, start_time: datetime.datetime = None,\n",
    "                    end_time: datetime.datetime = None, limit: int = 1000) -> List[LogEntry]:\n",
    "        \"\"\"æœç´¢æ—¥å¿—\"\"\"\n",
    "        filtered_logs = self.logs\n",
    "        \n",
    "        if query:\n",
    "            filtered_logs = [log for log in filtered_logs if query.lower() in log.message.lower()]\n",
    "        \n",
    "        if level:\n",
    "            filtered_logs = [log for log in filtered_logs if log.level == level.upper()]\n",
    "        \n",
    "        if source:\n",
    "            filtered_logs = [log for log in filtered_logs if log.source == source]\n",
    "        \n",
    "        if start_time:\n",
    "            filtered_logs = [log for log in filtered_logs if log.timestamp >= start_time]\n",
    "        \n",
    "        if end_time:\n",
    "            filtered_logs = [log for log in filtered_logs if log.timestamp <= end_time]\n",
    "        \n",
    "        # æŒ‰æ—¶é—´å€’åºæ’åˆ—\n",
    "        filtered_logs.sort(key=lambda x: x.timestamp, reverse=True)\n",
    "        \n",
    "        return filtered_logs[:limit]\n",
    "    \n",
    "    def get_log_statistics(self, time_range: int = 3600) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æ—¥å¿—ç»Ÿè®¡\"\"\"\n",
    "        cutoff_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=time_range)\n",
    "        \n",
    "        recent_logs = [log for log in self.logs if log.timestamp >= cutoff_time]\n",
    "        \n",
    "        if not recent_logs:\n",
    "            return {\"total_logs\": 0}\n",
    "        \n",
    "        level_counts = {}\n",
    "        source_counts = {}\n",
    "        \n",
    "        for log in recent_logs:\n",
    "            level_counts[log.level] = level_counts.get(log.level, 0) + 1\n",
    "            source_counts[log.source] = source_counts.get(log.source, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_logs\": len(recent_logs),\n",
    "            \"level_distribution\": level_counts,\n",
    "            \"source_distribution\": source_counts,\n",
    "            \"logs_per_second\": len(recent_logs) / time_range\n",
    "        }\n",
    "    \n",
    "    def export_logs(self, filename: str, format: str = \"json\",\n",
    "                    query: str = None, limit: int = 10000):\n",
    "        \"\"\"å¯¼å‡ºæ—¥å¿—\"\"\"\n",
    "        logs = self.search_logs(query=query, limit=limit)\n",
    "        \n",
    "        if format.lower() == \"json\":\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump([log.to_dict() for log in logs], f, indent=2, ensure_ascii=False)\n",
    "        elif format.lower() == \"csv\":\n",
    "            import csv\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"timestamp\", \"level\", \"message\", \"source\"])\n",
    "                for log in logs:\n",
    "                    writer.writerow([log.timestamp.isoformat(), log.level, log.message, log.source])\n",
    "        \n",
    "        print(f\"æ—¥å¿—å¯¼å‡ºå®Œæˆ: {filename} ({len(logs)} æ¡è®°å½•)\")\n",
    "\n",
    "# 3.3 è¿ç»´è‡ªåŠ¨åŒ–\n",
    "print(f\"\\n   ğŸ¤– 3.3 è¿ç»´è‡ªåŠ¨åŒ–:\")\n",
    "\n",
    "@dataclass\n",
    "class AutomationTask:\n",
    "    \"\"\"è‡ªåŠ¨åŒ–ä»»åŠ¡\"\"\"\n",
    "    task_id: str\n",
    "    name: str\n",
    "    description: str\n",
    "    schedule: str  # cronè¡¨è¾¾å¼\n",
    "    enabled: bool = True\n",
    "    last_run: Optional[datetime.datetime] = None\n",
    "    next_run: Optional[datetime.datetime] = None\n",
    "    run_count: int = 0\n",
    "    success_count: int = 0\n",
    "    failure_count: int = 0\n",
    "\n",
    "class AutomationManager:\n",
    "    \"\"\"è‡ªåŠ¨åŒ–ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks: Dict[str, AutomationTask] = {}\n",
    "        self.task_functions: Dict[str, Callable] = {}\n",
    "        self.task_history: List[Dict[str, Any]] = []\n",
    "        self.running_tasks: Dict[str, Dict[str, Any]] = {}\n",
    "    \n",
    "    def register_task(self, task: AutomationTask, task_function: Callable):\n",
    "        \"\"\"æ³¨å†Œä»»åŠ¡\"\"\"\n",
    "        self.tasks[task.task_id] = task\n",
    "        self.task_functions[task.task_id] = task_function\n",
    "        \n",
    "        # è®¡ç®—ä¸‹æ¬¡è¿è¡Œæ—¶é—´\n",
    "        task.next_run = self._calculate_next_run(task.schedule)\n",
    "    \n",
    "    async def run_task(self, task_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"è¿è¡Œä»»åŠ¡\"\"\"\n",
    "        if task_id not in self.tasks:\n",
    "            return {\"error\": \"ä»»åŠ¡ä¸å­˜åœ¨\"}\n",
    "        \n",
    "        task = self.tasks[task_id]\n",
    "        \n",
    "        if not task.enabled:\n",
    "            return {\"error\": \"ä»»åŠ¡å·²ç¦ç”¨\"}\n",
    "        \n",
    "        if task_id in self.running_tasks:\n",
    "            return {\"error\": \"ä»»åŠ¡æ­£åœ¨è¿è¡Œ\"}\n",
    "        \n",
    "        run_session = {\n",
    "            \"task_id\": task_id,\n",
    "            \"started_at\": datetime.datetime.utcnow(),\n",
    "            \"status\": \"running\"\n",
    "        }\n",
    "        \n",
    "        self.running_tasks[task_id] = run_session\n",
    "        \n",
    "        try:\n",
    "            # æ‰§è¡Œä»»åŠ¡\n",
    "            result = await self.task_functions[task_id]()\n",
    "            \n",
    "            # æ›´æ–°ä»»åŠ¡ç»Ÿè®¡\n",
    "            task.last_run = datetime.datetime.utcnow()\n",
    "            task.run_count += 1\n",
    "            task.success_count += 1\n",
    "            task.next_run = self._calculate_next_run(task.schedule)\n",
    "            \n",
    "            run_session[\"status\"] = \"completed\"\n",
    "            run_session[\"completed_at\"] = datetime.datetime.utcnow()\n",
    "            run_session[\"result\"] = result\n",
    "            \n",
    "            # è®°å½•å†å²\n",
    "            self._record_task_run(run_session)\n",
    "            \n",
    "            return {\n",
    "                \"task_id\": task_id,\n",
    "                \"status\": \"completed\",\n",
    "                \"result\": result\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            # æ›´æ–°ä»»åŠ¡ç»Ÿè®¡\n",
    "            task.last_run = datetime.datetime.utcnow()\n",
    "            task.run_count += 1\n",
    "            task.failure_count += 1\n",
    "            \n",
    "            run_session[\"status\"] = \"failed\"\n",
    "            run_session[\"completed_at\"] = datetime.datetime.utcnow()\n",
    "            run_session[\"error\"] = str(e)\n",
    "            \n",
    "            # è®°å½•å†å²\n",
    "            self._record_task_run(run_session)\n",
    "            \n",
    "            return {\n",
    "                \"task_id\": task_id,\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "        \n",
    "        finally:\n",
    "            # æ¸…ç†è¿è¡Œä¸­çš„ä»»åŠ¡\n",
    "            if task_id in self.running_tasks:\n",
    "                del self.running_tasks[task_id]\n",
    "    \n",
    "    async def run_scheduled_tasks(self):\n",
    "        \"\"\"è¿è¡Œè®¡åˆ’ä»»åŠ¡\"\"\"\n",
    "        current_time = datetime.datetime.utcnow()\n",
    "        \n",
    "        for task_id, task in self.tasks.items():\n",
    "            if not task.enabled:\n",
    "                continue\n",
    "            \n",
    "            if task.next_run and current_time >= task.next_run:\n",
    "                print(f\"è¿è¡Œè®¡åˆ’ä»»åŠ¡: {task.name}\")\n",
    "                await self.run_task(task_id)\n",
    "    \n",
    "    def _calculate_next_run(self, schedule: str) -> datetime.datetime:\n",
    "        \"\"\"è®¡ç®—ä¸‹æ¬¡è¿è¡Œæ—¶é—´ï¼ˆç®€åŒ–ç‰ˆï¼‰\"\"\"\n",
    "        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è§£æcronè¡¨è¾¾å¼\n",
    "        if schedule == \"every_minute\":\n",
    "            return datetime.datetime.utcnow() + datetime.timedelta(minutes=1)\n",
    "        elif schedule == \"every_hour\":\n",
    "            return datetime.datetime.utcnow() + datetime.timedelta(hours=1)\n",
    "        elif schedule == \"every_day\":\n",
    "            return datetime.datetime.utcnow() + datetime.timedelta(days=1)\n",
    "        else:\n",
    "            return datetime.datetime.utcnow() + datetime.timedelta(hours=1)\n",
    "    \n",
    "    def _record_task_run(self, run_session: Dict[str, Any]):\n",
    "        \"\"\"è®°å½•ä»»åŠ¡è¿è¡Œå†å²\"\"\"\n",
    "        self.task_history.append(run_session)\n",
    "        \n",
    "        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…\n",
    "        if len(self.task_history) > 1000:\n",
    "            self.task_history = self.task_history[-500:]\n",
    "    \n",
    "    def get_task_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ä»»åŠ¡ç»Ÿè®¡\"\"\"\n",
    "        if not self.tasks:\n",
    "            return {\"total_tasks\": 0}\n",
    "        \n",
    "        total_tasks = len(self.tasks)\n",
    "        enabled_tasks = sum(1 for task in self.tasks.values() if task.enabled)\n",
    "        \n",
    "        total_runs = sum(task.run_count for task in self.tasks.values())\n",
    "        total_successes = sum(task.success_count for task in self.tasks.values())\n",
    "        total_failures = sum(task.failure_count for task in self.tasks.values())\n",
    "        \n",
    "        return {\n",
    "            \"total_tasks\": total_tasks,\n",
    "            \"enabled_tasks\": enabled_tasks,\n",
    "            \"total_runs\": total_runs,\n",
    "            \"total_successes\": total_successes,\n",
    "            \"total_failures\": total_failures,\n",
    "            \"success_rate\": total_successes / total_runs * 100 if total_runs > 0 else 0,\n",
    "            \"running_tasks\": len(self.running_tasks)\n",
    "        }\n",
    "\n",
    "print(f\"   âœ… ç›‘æ§ã€æ—¥å¿—ä¸è¿ç»´è‡ªåŠ¨åŒ–å®Œæˆ\")\n",
    "print(f\"      - MonitoringSystem: ç›‘æ§ç³»ç»Ÿ\")\n",
    "print(f\"      - LogManager: æ—¥å¿—ç®¡ç†å™¨\")\n",
    "print(f\"      - AutomationManager: è‡ªåŠ¨åŒ–ç®¡ç†å™¨\")\n",
    "print(f\"      - æ”¯æŒæŒ‡æ ‡æ”¶é›†ã€å‘Šè­¦ç®¡ç†ã€æ—¥å¿—åˆ†æ\")\n",
    "print(f\"      - æ”¯æŒä»»åŠ¡è°ƒåº¦ã€è‡ªåŠ¨åŒ–è¿ç»´\")\n",
    "\n",
    "print(f\"\\nâœ… ç›‘æ§ã€æ—¥å¿—ä¸è¿ç»´è‡ªåŠ¨åŒ–å®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡åº”ç”¨ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†\")\n",
    "print(f\"   âœ“ å­¦ä¼šæ—¥å¿—ç®¡ç†å’Œåˆ†æ\")\n",
    "print(f\"   âœ“ ç†è§£è¿ç»´è‡ªåŠ¨åŒ–å’Œå‘Šè­¦\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿæ„å»ºå®Œæ•´çš„è¿ç»´ä½“ç³»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### çŸ¥è¯†æ¸…å•è¾¾æˆæƒ…å†µ\n",
    "\n",
    "#### âœ… å·²å®ŒæˆçŸ¥è¯†ç‚¹\n",
    "\n",
    "**7.9 Webåº”ç”¨éƒ¨ç½²ä¸è¿ç»´ [â­â­è¿›é˜¶]**\n",
    "- âœ… æŒæ¡Webåº”ç”¨çš„éƒ¨ç½²ç­–ç•¥å’Œæµç¨‹\n",
    "- âœ… å­¦ä¼šå®¹å™¨åŒ–éƒ¨ç½²å’Œç¼–æ’ç®¡ç†\n",
    "- âœ… ç†è§£ç›‘æ§ã€æ—¥å¿—å’Œè¿ç»´è‡ªåŠ¨åŒ–\n",
    "- âœ… èƒ½å¤Ÿå®ç°é«˜å¯ç”¨çš„ç”Ÿäº§ç¯å¢ƒ\n",
    "\n",
    "#### ğŸ¯ æ ¸å¿ƒæŠ€èƒ½æŒæ¡\n",
    "\n",
    "**éƒ¨ç½²ç­–ç•¥**\n",
    "- âœ… æ»šåŠ¨æ›´æ–°å’Œè“ç»¿éƒ¨ç½²\n",
    "- âœ… é‡‘ä¸é›€å‘å¸ƒå’ŒA/Bæµ‹è¯•\n",
    "- âœ… éƒ¨ç½²æµç¨‹è‡ªåŠ¨åŒ–\n",
    "- âœ… å›æ»šå’Œæ•…éšœæ¢å¤\n",
    "\n",
    "**å®¹å™¨åŒ–æŠ€æœ¯**\n",
    "- âœ… Dockeré•œåƒæ„å»ºå’Œç®¡ç†\n",
    "- âœ… å®¹å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†\n",
    "- âœ… æœåŠ¡ç¼–æ’å’Œæ‰©ç¼©å®¹\n",
    "- âœ… å®¹å™¨ç½‘ç»œå’Œå­˜å‚¨\n",
    "\n",
    "**ç›‘æ§è¿ç»´**\n",
    "- âœ… åº”ç”¨æŒ‡æ ‡æ”¶é›†å’Œåˆ†æ\n",
    "- âœ… å‘Šè­¦è§„åˆ™å’Œé€šçŸ¥\n",
    "- âœ… æ—¥å¿—èšåˆå’Œæœç´¢\n",
    "- âœ… è‡ªåŠ¨åŒ–ä»»åŠ¡è°ƒåº¦\n",
    "\n",
    "#### ğŸš€ å®è·µåº”ç”¨èƒ½åŠ›\n",
    "\n",
    "**ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²**\n",
    "- âœ… å®Œæ•´çš„CI/CDæµç¨‹è®¾è®¡\n",
    "- âœ… é«˜å¯ç”¨æ¶æ„éƒ¨ç½²\n",
    "- âœ… æ€§èƒ½ä¼˜åŒ–å’Œè°ƒä¼˜\n",
    "- âœ… å®‰å…¨åŠ å›ºå’Œåˆè§„\n",
    "\n",
    "**è¿ç»´ç®¡ç†**\n",
    "- âœ… ç›‘æ§ä½“ç³»æ„å»º\n",
    "- âœ… æ•…éšœè¯Šæ–­å’Œå¤„ç†\n",
    "- âœ… å®¹é‡è§„åˆ’å’Œæ‰©å®¹\n",
    "- âœ… å¤‡ä»½å’Œç¾éš¾æ¢å¤\n",
    "\n",
    "#### ğŸ“Š ä¸LangChainçš„å…³è”\n",
    "\n",
    "**AIæœåŠ¡éƒ¨ç½²**\n",
    "- âœ… æ”¯æŒLangChainçš„AIæœåŠ¡å®¹å™¨åŒ–éƒ¨ç½²\n",
    "- âœ… ä¸ºLangChainæä¾›è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹\n",
    "- âœ… ä¿éšœLangChainæœåŠ¡çš„é«˜å¯ç”¨æ€§\n",
    "- âœ… å®ç°LangChainç»„ä»¶çš„ç›‘æ§è¿ç»´\n",
    "\n",
    "**ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆ**\n",
    "- âœ… æ»¡è¶³LangChainä¼ä¸šçº§éƒ¨ç½²éœ€æ±‚\n",
    "- âœ… æä¾›AIæœåŠ¡çš„å¯æ‰©å±•è¿ç»´æ–¹æ¡ˆ\n",
    "- âœ… ä¿éšœLangChainç³»ç»Ÿçš„ç¨³å®šè¿è¡Œ\n",
    "- âœ… æ”¯æŒå¤§è§„æ¨¡AIåº”ç”¨çš„ç”Ÿäº§ç®¡ç†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ æˆæœ\n",
    "\n",
    "é€šè¿‡æœ¬èŠ‚å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š\n",
    "\n",
    "1. **Webåº”ç”¨éƒ¨ç½²ç­–ç•¥** - ç†è§£æ»šåŠ¨æ›´æ–°ã€è“ç»¿éƒ¨ç½²ã€é‡‘ä¸é›€å‘å¸ƒç­‰ç°ä»£éƒ¨ç½²æ¨¡å¼\n",
    "2. **å®¹å™¨åŒ–éƒ¨ç½²æŠ€æœ¯** - æŒæ¡Dockerå®¹å™¨ç®¡ç†å’ŒKubernetesç¼–æ’æ¦‚å¿µ\n",
    "3. **ç›‘æ§è¿ç»´ä½“ç³»** - æ„å»ºå®Œæ•´çš„ç›‘æ§ã€æ—¥å¿—å’Œè‡ªåŠ¨åŒ–è¿ç»´ç³»ç»Ÿ\n",
    "4. **ç”Ÿäº§ç¯å¢ƒç®¡ç†** - å®ç°é«˜å¯ç”¨ã€å¯æ‰©å±•çš„ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å’Œè¿ç»´\n",
    "\n",
    "è¿™äº›æŠ€èƒ½ä¸ºåç»­çš„é¡¹ç›®å·¥ç¨‹å­¦ä¹ å’ŒLangChainçš„ä¼ä¸šçº§AIæœåŠ¡éƒ¨ç½²æä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€ï¼Œä¹Ÿæ ‡å¿—ç€Webå¼€å‘éƒ¨åˆ†çš„åœ†æ»¡å®Œæˆã€‚æ¥ä¸‹æ¥å°†è¿›å…¥é¡¹ç›®å·¥ç¨‹é˜¶æ®µï¼Œå­¦ä¹ æ›´é«˜çº§çš„è½¯ä»¶å¼€å‘å’Œé¡¹ç›®ç®¡ç†æŠ€èƒ½ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
