{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31-JSONä¸XMLå¤„ç†\n",
    "\n",
    "## ğŸ“š ç”¨é€”è¯´æ˜\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "- æŒæ¡Python JSONæ•°æ®çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–\n",
    "- ç†Ÿç»ƒä½¿ç”¨xml.etree.ElementTreeå¤„ç†XMLæ•°æ®\n",
    "- ç†è§£JSON schemaéªŒè¯å’Œæ•°æ®ç»“æ„è½¬æ¢\n",
    "- èƒ½å¤Ÿå¤„ç†é…ç½®æ–‡ä»¶ã€APIå“åº”ç­‰å®é™…åº”ç”¨åœºæ™¯\n",
    "\n",
    "**å‰ç½®è¦æ±‚**ï¼š\n",
    "- å·²å®Œæˆ30-æ­£åˆ™è¡¨è¾¾å¼åº”ç”¨å­¦ä¹ \n",
    "- ç†Ÿç»ƒæŒæ¡Pythonå­—å…¸ã€åˆ—è¡¨ç­‰æ•°æ®ç»“æ„\n",
    "- äº†è§£Pythonæ ‡å‡†åº“çš„åŸºæœ¬ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "**ä¸LangChainå…³è”**ï¼š\n",
    "- JSONå¤„ç†æ˜¯LangChainç»“æ„åŒ–è¾“å‡ºçš„åŸºç¡€\n",
    "- XMLå¤„ç†å¯¹äºLangChainçš„æ–‡æ¡£è§£æå’Œé›†æˆè‡³å…³é‡è¦\n",
    "- æ•°æ®åºåˆ—åŒ–å½±å“LangChainçš„ç¼“å­˜å’Œå­˜å‚¨æœºåˆ¶\n",
    "- ä¸ºåç»­å­¦ä¹ LangChainçš„APIæ•°æ®å¤„ç†åšå‡†å¤‡\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ çŸ¥è¯†ç‚¹è¦†ç›–\n",
    "\n",
    "### 4.4 JSONä¸XMLå¤„ç† [â­åŸºç¡€]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šJSONå’ŒXMLæ˜¯å¸¸ç”¨çš„æ•°æ®äº¤æ¢æ ¼å¼ï¼ŒæŒæ¡å®ƒä»¬çš„å¤„ç†æ–¹æ³•å¯¹äºé…ç½®æ–‡ä»¶ç®¡ç†ã€APIæ•°æ®å¤„ç†ã€æ•°æ®æŒä¹…åŒ–ç­‰å®é™…åº”ç”¨åœºæ™¯éå¸¸é‡è¦ã€‚Pythonæä¾›äº†å¼ºå¤§çš„æ ‡å‡†åº“æ¥å¤„ç†è¿™äº›æ ¼å¼ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡jsonæ¨¡å—çš„åŸºæœ¬ç”¨æ³•å’Œæ•°æ®è½¬æ¢\n",
    "- ç†Ÿç»ƒä½¿ç”¨xml.etree.ElementTreeå¤„ç†XMLæ•°æ®\n",
    "- ç†è§£JSON schemaéªŒè¯å’Œé”™è¯¯å¤„ç†\n",
    "- èƒ½å¤Ÿå¤„ç†å¤æ‚çš„æ•°æ®ç»“æ„å’ŒåµŒå¥—æ ¼å¼\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„JSONå’ŒXMLå¤„ç†ç¤ºä¾‹\n",
    "- è¿›è¡Œæ•°æ®åºåˆ—åŒ–å’Œååºåˆ—åŒ–ç»ƒä¹ \n",
    "- åº”ç”¨æ•°æ®å¤„ç†è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹å¤„ç†JSON/XMLæ•°æ®è½¬æ¢ä»»åŠ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ JSONåŸºç¡€æ“ä½œ:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# 1. JSONåŸºæœ¬æ“ä½œ\n",
    "print(f\"ğŸ“ 1. JSONåŸºæœ¬æ“ä½œ:\")\n",
    "\n",
    "# 1.1 JSONåºåˆ—åŒ– (Pythonå¯¹è±¡ -> JSONå­—ç¬¦ä¸²)\n",
    "print(f\"\\n   ğŸ”„ 1.1 JSONåºåˆ—åŒ–:\")\n",
    "\n",
    "# åŸºæœ¬æ•°æ®ç±»å‹\n",
    "python_data = {\n",
    "    \"name\": \"å¼ ä¸‰\",\n",
    "    \"age\": 25,\n",
    "    \"is_student\": True,\n",
    "    \"courses\": [\"Python\", \"JavaScript\", \"SQL\"],\n",
    "    \"address\": {\n",
    "        \"city\": \"åŒ—äº¬\",\n",
    "        \"district\": \"æœé˜³åŒº\"\n",
    "    },\n",
    "    \"scores\": None\n",
    "}\n",
    "\n",
    "# åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²\n",
    "json_str = json.dumps(python_data, ensure_ascii=False, indent=2)\n",
    "print(f\"   Pythonå¯¹è±¡: {python_data}\")\n",
    "print(f\"   JSONå­—ç¬¦ä¸²:\\n{json_str}\")\n",
    "\n",
    "# 1.2 JSONååºåˆ—åŒ– (JSONå­—ç¬¦ä¸² -> Pythonå¯¹è±¡)\n",
    "print(f\"\\n   ğŸ” 1.2 JSONååºåˆ—åŒ–:\")\n",
    "\n",
    "# ä»JSONå­—ç¬¦ä¸²è§£æ\n",
    "parsed_data = json.loads(json_str)\n",
    "print(f\"   JSONå­—ç¬¦ä¸²: {json_str}\")\n",
    "print(f\"   è§£æåçš„Pythonå¯¹è±¡: {parsed_data}\")\n",
    "print(f\"   æ•°æ®ç±»å‹: {type(parsed_data)}\")\n",
    "print(f\"   å§“åç±»å‹: {type(parsed_data['name'])}\")\n",
    "print(f\"   å¹´é¾„ç±»å‹: {type(parsed_data['age'])}\")\n",
    "print(f\"   å­¦ç”Ÿç±»å‹: {type(parsed_data['is_student'])}\")\n",
    "\n",
    "# 1.3 æ–‡ä»¶æ“ä½œ\n",
    "print(f\"\\n   ğŸ“ 1.3 JSONæ–‡ä»¶æ“ä½œ:\")\n",
    "\n",
    "# å†™å…¥JSONæ–‡ä»¶\n",
    "with open('student_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(python_data, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   JSONæ•°æ®å·²å†™å…¥ student_data.json\")\n",
    "\n",
    "# ä»JSONæ–‡ä»¶è¯»å–\n",
    "with open('student_data.json', 'r', encoding='utf-8') as f:\n",
    "    loaded_data = json.load(f)\n",
    "print(f\"   ä»æ–‡ä»¶è¯»å–çš„æ•°æ®: {loaded_data}\")\n",
    "\n",
    "# 1.4 è‡ªå®šä¹‰JSONç¼–ç å™¨\n",
    "print(f\"\\n   ğŸ”§ 1.4 è‡ªå®šä¹‰JSONç¼–ç å™¨:\")\n",
    "\n",
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    \"\"\"è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†datetimeå¯¹è±¡\"\"\"\n",
    "    \n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        elif isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "# åŒ…å«ç‰¹æ®Šå¯¹è±¡çš„Pythonæ•°æ®\n",
    "complex_data = {\n",
    "    \"user_id\": 12345,\n",
    "    \"username\": \"test_user\",\n",
    "    \"created_at\": datetime.now(),\n",
    "    \"tags\": {\"python\", \"json\", \"encoding\"},\n",
    "    \"metadata\": {\n",
    "        \"version\": \"1.0\",\n",
    "        \"last_updated\": datetime(2024, 12, 25, 10, 30, 0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨\n",
    "try:\n",
    "    json_str_complex = json.dumps(complex_data, cls=DateTimeEncoder, ensure_ascii=False, indent=2)\n",
    "    print(f\"   å¤æ‚æ•°æ®JSONåºåˆ—åŒ–æˆåŠŸ\")\n",
    "    print(f\"   åºåˆ—åŒ–ç»“æœ:\\n{json_str_complex}\")\n",
    "except Exception as e:\n",
    "    print(f\"   åºåˆ—åŒ–å¤±è´¥: {e}\")\n",
    "\n",
    "# 1.5 JSONæ•°æ®éªŒè¯\n",
    "print(f\"\\n   âœ… 1.5 JSONæ•°æ®éªŒè¯:\")\n",
    "\n",
    "def validate_json_structure(data: Dict, schema: Dict) -> bool:\n",
    "    \"\"\"ç®€å•çš„JSONç»“æ„éªŒè¯\"\"\"\n",
    "    for key, expected_type in schema.items():\n",
    "        if key not in data:\n",
    "            print(f\"   ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}\")\n",
    "            return False\n",
    "        \n",
    "        if expected_type == 'string' and not isinstance(data[key], str):\n",
    "            print(f\"   å­—æ®µ {key} åº”ä¸ºå­—ç¬¦ä¸²ç±»å‹\")\n",
    "            return False\n",
    "        elif expected_type == 'number' and not isinstance(data[key], (int, float)):\n",
    "            print(f\"   å­—æ®µ {key} åº”ä¸ºæ•°å­—ç±»å‹\")\n",
    "            return False\n",
    "        elif expected_type == 'boolean' and not isinstance(data[key], bool):\n",
    "            print(f\"   å­—æ®µ {key} åº”ä¸ºå¸ƒå°”ç±»å‹\")\n",
    "            return False\n",
    "        elif expected_type == 'array' and not isinstance(data[key], list):\n",
    "            print(f\"   å­—æ®µ {key} åº”ä¸ºæ•°ç»„ç±»å‹\")\n",
    "            return False\n",
    "        elif expected_type == 'object' and not isinstance(data[key], dict):\n",
    "            print(f\"   å­—æ®µ {key} åº”ä¸ºå¯¹è±¡ç±»å‹\")\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# å®šä¹‰æ•°æ®æ¨¡å¼\n",
    "user_schema = {\n",
    "    \"name\": \"string\",\n",
    "    \"age\": \"number\",\n",
    "    \"is_student\": \"boolean\",\n",
    "    \"courses\": \"array\",\n",
    "    \"address\": \"object\"\n",
    "}\n",
    "\n",
    "# éªŒè¯æ•°æ®\n",
    "print(f\"   éªŒè¯ç”¨æˆ·æ•°æ®ç»“æ„:\")\n",
    "is_valid = validate_json_structure(parsed_data, user_schema)\n",
    "print(f\"   éªŒè¯ç»“æœ: {'é€šè¿‡' if is_valid else 'å¤±è´¥'}\")\n",
    "\n",
    "# æµ‹è¯•æ— æ•ˆæ•°æ®\n",
    "invalid_data = {\n",
    "    \"name\": \"æå››\",\n",
    "    \"age\": \"25\",  # é”™è¯¯ï¼šå­—ç¬¦ä¸²è€Œéæ•°å­—\n",
    "    \"is_student\": \"true\",  # é”™è¯¯ï¼šå­—ç¬¦ä¸²è€Œéå¸ƒå°”å€¼\n",
    "    \"courses\": \"Python\",  # é”™è¯¯ï¼šå­—ç¬¦ä¸²è€Œéæ•°ç»„\n",
    "    \"address\": \"åŒ—äº¬å¸‚\"  # é”™è¯¯ï¼šå­—ç¬¦ä¸²è€Œéå¯¹è±¡\n",
    "}\n",
    "\n",
    "print(f\"\\n   éªŒè¯æ— æ•ˆæ•°æ®ç»“æ„:\")\n",
    "is_valid = validate_json_structure(invalid_data, user_schema)\n",
    "print(f\"   éªŒè¯ç»“æœ: {'é€šè¿‡' if is_valid else 'å¤±è´¥'}\")\n",
    "\n",
    "# 2. JSONé«˜çº§æ“ä½œ\n",
    "print(f\"\\nğŸ“ 2. JSONé«˜çº§æ“ä½œ:\")\n",
    "\n",
    "# 2.1 åµŒå¥—æ•°æ®æå–\n",
    "print(f\"\\n   ğŸ” 2.1 åµŒå¥—æ•°æ®æå–:\")\n",
    "\n",
    "def extract_nested_value(data: Dict, path: str, default=None):\n",
    "    \"\"\"ä»åµŒå¥—å­—å…¸ä¸­æå–å€¼\"\"\"\n",
    "    keys = path.split('.')\n",
    "    current = data\n",
    "    \n",
    "    for key in keys:\n",
    "        if isinstance(current, dict) and key in current:\n",
    "            current = current[key]\n",
    "        elif isinstance(current, list) and key.isdigit():\n",
    "            index = int(key)\n",
    "            if 0 <= index < len(current):\n",
    "                current = current[index]\n",
    "            else:\n",
    "                return default\n",
    "        else:\n",
    "            return default\n",
    "    \n",
    "    return current\n",
    "\n",
    "# å¤æ‚åµŒå¥—æ•°æ®\n",
    "nested_data = {\n",
    "    \"company\": {\n",
    "        \"name\": \"ç§‘æŠ€å…¬å¸\",\n",
    "        \"employees\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"å¼ ä¸‰\",\n",
    "                \"department\": {\n",
    "                    \"name\": \"ç ”å‘éƒ¨\",\n",
    "                    \"budget\": 100000\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"name\": \"æå››\",\n",
    "                \"department\": {\n",
    "                    \"name\": \"å¸‚åœºéƒ¨\",\n",
    "                    \"budget\": 80000\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# æå–åµŒå¥—å€¼\n",
    "extracted_values = {\n",
    "    \"å…¬å¸åç§°\": extract_nested_value(nested_data, \"company.name\"),\n",
    "    \"ç¬¬ä¸€ä¸ªå‘˜å·¥å§“å\": extract_nested_value(nested_data, \"company.employees.0.name\"),\n",
    "    \"ç¬¬äºŒä¸ªéƒ¨é—¨é¢„ç®—\": extract_nested_value(nested_data, \"company.employees.1.department.budget\"),\n",
    "    \"ä¸å­˜åœ¨çš„è·¯å¾„\": extract_nested_value(nested_data, \"company.manager.name\", \"é»˜è®¤å€¼\")\n",
    "}\n",
    "\n",
    "print(f\"   åµŒå¥—æ•°æ®: {json.dumps(nested_data, ensure_ascii=False, indent=2)}\")\n",
    "print(f\"\\n   æå–ç»“æœ:\")\n",
    "for key, value in extracted_values.items():\n",
    "    print(f\"     {key}: {value}\")\n",
    "\n",
    "# 2.2 JSONæ•°æ®è½¬æ¢\n",
    "print(f\"\\n   ğŸ”„ 2.2 JSONæ•°æ®è½¬æ¢:\")\n",
    "\n",
    "def flatten_json(data: Dict, parent_key: str = '', sep: str = '.') -> Dict:\n",
    "    \"\"\"å°†åµŒå¥—JSONå±•å¹³\"\"\"\n",
    "    items = []\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            items.extend(flatten_json(value, new_key, sep).items())\n",
    "        elif isinstance(value, list):\n",
    "            for i, item in enumerate(value):\n",
    "                if isinstance(item, dict):\n",
    "                    items.extend(flatten_json(item, f\"{new_key}{sep}{i}\", sep).items())\n",
    "                else:\n",
    "                    items.append((f\"{new_key}{sep}{i}\", item))\n",
    "        else:\n",
    "            items.append((new_key, value))\n",
    "    \n",
    "    return dict(items)\n",
    "\n",
    "# å±•å¹³JSONæ•°æ®\n",
    "flattened_data = flatten_json(nested_data)\n",
    "print(f\"   å±•å¹³åçš„æ•°æ®:\")\n",
    "for key, value in flattened_data.items():\n",
    "    print(f\"     {key}: {value}\")\n",
    "\n",
    "# 2.3 JSONæ•°æ®è¿‡æ»¤\n",
    "print(f\"\\n   ğŸ” 2.3 JSONæ•°æ®è¿‡æ»¤:\")\n",
    "\n",
    "def filter_json(data: Union[Dict, List], filter_func) -> Union[Dict, List]:\n",
    "    \"\"\"æ ¹æ®æ¡ä»¶è¿‡æ»¤JSONæ•°æ®\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: filter_json(v, filter_func) for k, v in data.items() if filter_func(k, v)}\n",
    "    elif isinstance(data, list):\n",
    "        return [filter_json(item, filter_func) for item in data if filter_func(None, item)]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# è¿‡æ»¤å‡½æ•°ç¤ºä¾‹\n",
    "def filter_non_empty(key, value):\n",
    "    \"\"\"è¿‡æ»¤éç©ºå€¼\"\"\"\n",
    "    if value is None or value == \"\":\n",
    "        return False\n",
    "    if isinstance(value, (dict, list)) and len(value) == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def filter_numeric_values(key, value):\n",
    "    \"\"\"åªä¿ç•™æ•°å€¼ç±»å‹\"\"\"\n",
    "    return isinstance(value, (int, float))\n",
    "\n",
    "# æµ‹è¯•æ•°æ®\n",
    "test_data = {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"æµ‹è¯•\",\n",
    "    \"score\": 95.5,\n",
    "    \"empty_field\": \"\",\n",
    "    \"null_field\": None,\n",
    "    \"empty_list\": [],\n",
    "    \"metadata\": {\n",
    "        \"created\": \"2024-12-25\",\n",
    "        \"updated\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"   åŸå§‹æ•°æ®: {json.dumps(test_data, ensure_ascii=False, indent=2)}\")\n",
    "\n",
    "filtered_data = filter_json(test_data, filter_non_empty)\n",
    "print(f\"\\n   è¿‡æ»¤ç©ºå€¼å: {json.dumps(filtered_data, ensure_ascii=False, indent=2)}\")\n",
    "\n",
    "# 3. å®é™…åº”ç”¨ç¤ºä¾‹\n",
    "print(f\"\\nğŸ“ 3. å®é™…åº”ç”¨ç¤ºä¾‹:\")\n",
    "\n",
    "# 3.1 é…ç½®æ–‡ä»¶ç®¡ç†\n",
    "print(f\"\\n   âš™ï¸ 3.1 é…ç½®æ–‡ä»¶ç®¡ç†:\")\n",
    "\n",
    "class ConfigManager:\n",
    "    \"\"\"é…ç½®æ–‡ä»¶ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, config_file: str = 'config.json'):\n",
    "        self.config_file = config_file\n",
    "        self.config = self.load_config()\n",
    "    \n",
    "    def load_config(self) -> Dict:\n",
    "        \"\"\"åŠ è½½é…ç½®æ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            with open(self.config_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            # åˆ›å»ºé»˜è®¤é…ç½®\n",
    "            default_config = {\n",
    "                \"database\": {\n",
    "                    \"host\": \"localhost\",\n",
    "                    \"port\": 5432,\n",
    "                    \"name\": \"myapp\",\n",
    "                    \"user\": \"admin\",\n",
    "                    \"password\": \"password\"\n",
    "                },\n",
    "                \"api\": {\n",
    "                    \"base_url\": \"https://api.example.com\",\n",
    "                    \"timeout\": 30,\n",
    "                    \"retry_count\": 3\n",
    "                },\n",
    "                \"logging\": {\n",
    "                    \"level\": \"INFO\",\n",
    "                    \"file\": \"app.log\",\n",
    "                    \"max_size\": \"10MB\"\n",
    "                }\n",
    "            }\n",
    "            self.save_config(default_config)\n",
    "            return default_config\n",
    "    \n",
    "    def save_config(self, config: Dict = None):\n",
    "        \"\"\"ä¿å­˜é…ç½®æ–‡ä»¶\"\"\"\n",
    "        if config is None:\n",
    "            config = self.config\n",
    "        \n",
    "        with open(self.config_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    def get(self, path: str, default=None):\n",
    "        \"\"\"è·å–é…ç½®å€¼\"\"\"\n",
    "        return extract_nested_value(self.config, path, default)\n",
    "    \n",
    "    def set(self, path: str, value):\n",
    "        \"\"\"è®¾ç½®é…ç½®å€¼\"\"\"\n",
    "        keys = path.split('.')\n",
    "        current = self.config\n",
    "        \n",
    "        for key in keys[:-1]:\n",
    "            if key not in current:\n",
    "                current[key] = {}\n",
    "            current = current[key]\n",
    "        \n",
    "        current[keys[-1]] = value\n",
    "        self.save_config()\n",
    "    \n",
    "    def update(self, updates: Dict):\n",
    "        \"\"\"æ‰¹é‡æ›´æ–°é…ç½®\"\"\"\n",
    "        def deep_update(base_dict, update_dict):\n",
    "            for key, value in update_dict.items():\n",
    "                if isinstance(value, dict) and key in base_dict and isinstance(base_dict[key], dict):\n",
    "                    deep_update(base_dict[key], value)\n",
    "                else:\n",
    "                    base_dict[key] = value\n",
    "        \n",
    "        deep_update(self.config, updates)\n",
    "        self.save_config()\n",
    "\n",
    "# æµ‹è¯•é…ç½®ç®¡ç†å™¨\n",
    "config_manager = ConfigManager()\n",
    "\n",
    "print(f\"   é…ç½®æ–‡ä»¶å·²åˆ›å»º/åŠ è½½\")\n",
    "print(f\"   æ•°æ®åº“ä¸»æœº: {config_manager.get('database.host')}\")\n",
    "print(f\"   APIè¶…æ—¶: {config_manager.get('api.timeout')}\")\n",
    "print(f\"   æ—¥å¿—çº§åˆ«: {config_manager.get('logging.level')}\")\n",
    "\n",
    "# æ›´æ–°é…ç½®\n",
    "config_manager.set('database.port', 3306)\n",
    "config_manager.set('api.timeout', 60)\n",
    "\n",
    "print(f\"\\n   æ›´æ–°åé…ç½®:\")\n",
    "print(f\"   æ•°æ®åº“ç«¯å£: {config_manager.get('database.port')}\")\n",
    "print(f\"   APIè¶…æ—¶: {config_manager.get('api.timeout')}\")\n",
    "\n",
    "# æ‰¹é‡æ›´æ–°\n",
    "config_manager.update({\n",
    "    \"database\": {\n",
    "        \"user\": \"new_user\",\n",
    "        \"password\": \"new_password\"\n",
    "    },\n",
    "    \"new_section\": {\n",
    "        \"feature_enabled\": True,\n",
    "        \"max_connections\": 100\n",
    "    }\n",
    "})\n",
    "\n",
    "print(f\"\\n   æ‰¹é‡æ›´æ–°å:\")\n",
    "print(f\"   æ•°æ®åº“ç”¨æˆ·: {config_manager.get('database.user')}\")\n",
    "print(f\"   æ–°åŠŸèƒ½å¯ç”¨: {config_manager.get('new_section.feature_enabled')}\")\n",
    "\n",
    "print(f\"\\nâœ… JSONåŸºç¡€æ“ä½œå®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡jsonæ¨¡å—çš„åŸºæœ¬ç”¨æ³•å’Œæ•°æ®è½¬æ¢\")\n",
    "print(f\"   âœ“ ç†è§£JSON schemaéªŒè¯å’Œé”™è¯¯å¤„ç†\")\n",
    "print(f\"   âœ“ èƒ½å¤„ç†å¤æ‚çš„æ•°æ®ç»“æ„å’ŒåµŒå¥—æ ¼å¼\")\n",
    "print(f\"   âœ“ æŒæ¡å®é™…åº”ç”¨åœºæ™¯ä¸­çš„é…ç½®æ–‡ä»¶ç®¡ç†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XMLå¤„ç†åŸºç¡€ [â­åŸºç¡€]\n",
    "**çŸ¥è¯†ç‚¹è¯´æ˜**ï¼šXMLæ˜¯å¦ä¸€ç§é‡è¦çš„æ•°æ®äº¤æ¢æ ¼å¼ï¼Œç‰¹åˆ«æ˜¯åœ¨é…ç½®æ–‡ä»¶ã€æ–‡æ¡£å¤„ç†ã€WebæœåŠ¡ç­‰é¢†åŸŸã€‚Pythonçš„xml.etree.ElementTreeæ¨¡å—æä¾›äº†ç®€æ´è€Œå¼ºå¤§çš„XMLå¤„ç†èƒ½åŠ›ã€‚\n",
    "\n",
    "**å­¦ä¹ è¦æ±‚**ï¼š\n",
    "- æŒæ¡ElementTreeçš„åŸºæœ¬æ“ä½œå’Œæ–¹æ³•\n",
    "- ç†Ÿç»ƒè¿›è¡ŒXMLè§£æå’Œæ•°æ®æå–\n",
    "- ç†è§£XMLçš„å±‚çº§ç»“æ„å’Œå‘½åç©ºé—´\n",
    "- èƒ½å¤Ÿåˆ›å»ºå’Œä¿®æ”¹XMLæ–‡æ¡£\n",
    "\n",
    "**æ¡ˆä¾‹è¦æ±‚**ï¼š\n",
    "- å®ç°å®Œæ•´çš„XMLå¤„ç†ç¤ºä¾‹\n",
    "- è¿›è¡ŒXMLè§£æå’Œæ•°æ®æå–ç»ƒä¹ \n",
    "- åº”ç”¨XMLå¤„ç†è§£å†³å®é™…é—®é¢˜\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½ç‹¬ç«‹å¤„ç†XMLæ•°æ®è§£æä»»åŠ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ XMLåŸºç¡€æ“ä½œ:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "import re\n",
    "\n",
    "# 1. XMLåŸºæœ¬æ“ä½œ\n",
    "print(f\"ğŸ“ 1. XMLåŸºæœ¬æ“ä½œ:\")\n",
    "\n",
    "# 1.1 åˆ›å»ºXMLæ–‡æ¡£\n",
    "print(f\"\\n   ğŸ—ï¸ 1.1 åˆ›å»ºXMLæ–‡æ¡£:\")\n",
    "\n",
    "# åˆ›å»ºæ ¹å…ƒç´ \n",
    "root = ET.Element(\"bookstore\")\n",
    "\n",
    "# æ·»åŠ ä¹¦ç±\n",
    "book1 = ET.SubElement(root, \"book\", {\"category\": \"programming\"})\n",
    "ET.SubElement(book1, \"title\").text = \"Pythonç¼–ç¨‹\"\n",
    "ET.SubElement(book1, \"author\").text = \"å¼ ä¸‰\"\n",
    "ET.SubElement(book1, \"year\").text = \"2024\"\n",
    "ET.SubElement(book1, \"price\").text = \"89.90\"\n",
    "\n",
    "book2 = ET.SubElement(root, \"book\", {\"category\": \"data_science\"})\n",
    "ET.SubElement(book2, \"title\").text = \"æ•°æ®åˆ†æå®æˆ˜\"\n",
    "ET.SubElement(book2, \"author\").text = \"æå››\"\n",
    "ET.SubElement(book2, \"year\").text = \"2023\"\n",
    "ET.SubElement(book2, \"price\").text = \"79.90\"\n",
    "\n",
    "# ç”ŸæˆXMLå­—ç¬¦ä¸²\n",
    "xml_str = ET.tostring(root, encoding='unicode')\n",
    "print(f\"   ç”Ÿæˆçš„XML:\\n{xml_str}\")\n",
    "\n",
    "# ç¾åŒ–XMLæ ¼å¼\n",
    "def prettify_xml(element):\n",
    "    \"\"\"ç¾åŒ–XMLæ ¼å¼\"\"\"\n",
    "    rough_string = ET.tostring(element, encoding='unicode')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "pretty_xml = prettify_xml(root)\n",
    "print(f\"\\n   ç¾åŒ–åçš„XML:\\n{pretty_xml}\")\n",
    "\n",
    "# ä¿å­˜XMLæ–‡ä»¶\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write('bookstore.xml', encoding='utf-8', xml_declaration=True)\n",
    "print(f\"\\n   XMLå·²ä¿å­˜åˆ° bookstore.xml\")\n",
    "\n",
    "# 1.2 è§£æXMLæ–‡æ¡£\n",
    "print(f\"\\n   ğŸ” 1.2 è§£æXMLæ–‡æ¡£:\")\n",
    "\n",
    "# ä»æ–‡ä»¶è§£æXML\n",
    "tree = ET.parse('bookstore.xml')\n",
    "parsed_root = tree.getroot()\n",
    "\n",
    "print(f\"   æ ¹å…ƒç´ æ ‡ç­¾: {parsed_root.tag}\")\n",
    "print(f\"   æ ¹å…ƒç´ å±æ€§: {parsed_root.attrib}\")\n",
    "print(f\"   å­å…ƒç´ æ•°é‡: {len(parsed_root)}\")\n",
    "\n",
    "# éå†æ‰€æœ‰ä¹¦ç±\n",
    "print(f\"\\n   æ‰€æœ‰ä¹¦ç±ä¿¡æ¯:\")\n",
    "for book in parsed_root:\n",
    "    category = book.get('category', 'æœªçŸ¥')\n",
    "    title = book.find('title').text\n",
    "    author = book.find('author').text\n",
    "    year = book.find('year').text\n",
    "    price = book.find('price').text\n",
    "    print(f\"     ä¹¦å: {title}, ä½œè€…: {author}, å¹´ä»½: {year}, ä»·æ ¼: {price}, ç±»åˆ«: {category}\")\n",
    "\n",
    "# 1.3 XMLæ•°æ®æå–\n",
    "print(f\"\\n   ğŸ“Š 1.3 XMLæ•°æ®æå–:\")\n",
    "\n",
    "# ä½¿ç”¨XPathæŸ¥æ‰¾å…ƒç´ \n",
    "print(f\"\\n   XPathæŸ¥è¯¢ç¤ºä¾‹:\")\n",
    "\n",
    "# æŸ¥æ‰¾æ‰€æœ‰ä¹¦ç±\n",
    "all_books = parsed_root.findall('book')\n",
    "print(f\"   æ‰€æœ‰ä¹¦ç±æ•°é‡: {len(all_books)}\")\n",
    "\n",
    "# æŸ¥æ‰¾ç¼–ç¨‹ç±»ä¹¦ç±\n",
    "programming_books = parsed_root.findall(\"book[@category='programming']\")\n",
    "print(f\"   ç¼–ç¨‹ç±»ä¹¦ç±æ•°é‡: {len(programming_books)}\")\n",
    "for book in programming_books:\n",
    "    title = book.find('title').text\n",
    "    print(f\"     ç¼–ç¨‹ç±»ä¹¦ç±: {title}\")\n",
    "\n",
    "# æŸ¥æ‰¾æ‰€æœ‰æ ‡é¢˜\n",
    "titles = parsed_root.findall('.//title')\n",
    "print(f\"\\n   æ‰€æœ‰æ ‡é¢˜:\")\n",
    "for title in titles:\n",
    "    print(f\"     {title.text}\")\n",
    "\n",
    "# æŸ¥æ‰¾ä»·æ ¼å¤§äº80çš„ä¹¦ç±\n",
    "expensive_books = []\n",
    "for book in parsed_root.findall('book'):\n",
    "    price_elem = book.find('price')\n",
    "    if price_elem is not None and float(price_elem.text) > 80:\n",
    "        expensive_books.append({\n",
    "            'title': book.find('title').text,\n",
    "            'price': price_elem.text\n",
    "        })\n",
    "\n",
    "print(f\"\\n   ä»·æ ¼å¤§äº80çš„ä¹¦ç±:\")\n",
    "for book in expensive_books:\n",
    "    print(f\"     {book['title']}: {book['price']}\")\n",
    "\n",
    "# 1.4 XMLæ•°æ®ä¿®æ”¹\n",
    "print(f\"\\n   âœï¸ 1.4 XMLæ•°æ®ä¿®æ”¹:\")\n",
    "\n",
    "# ä¿®æ”¹ä¹¦ç±ä»·æ ¼\n",
    "for book in parsed_root.findall('book'):\n",
    "    price_elem = book.find('price')\n",
    "    if price_elem is not None:\n",
    "        current_price = float(price_elem.text)\n",
    "        new_price = current_price * 0.9  # æ‰“9æŠ˜\n",
    "        price_elem.text = f\"{new_price:.2f}\"\n",
    "\n",
    "# æ·»åŠ æ–°å±æ€§\n",
    "for book in parsed_root.findall('book'):\n",
    "    book.set('discounted', 'true')\n",
    "\n",
    "# æ·»åŠ æ–°ä¹¦ç±\n",
    "new_book = ET.SubElement(parsed_root, \"book\", {\"category\": \"web_development\"})\n",
    "ET.SubElement(new_book, \"title\").text = \"Webå¼€å‘å®æˆ˜\"\n",
    "ET.SubElement(new_book, \"author\").text = \"ç‹äº”\"\n",
    "ET.SubElement(new_book, \"year\").text = \"2024\"\n",
    "ET.SubElement(new_book, \"price\").text = \"69.90\"\n",
    "\n",
    "# ä¿å­˜ä¿®æ”¹åçš„XML\n",
    "tree.write('bookstore_updated.xml', encoding='utf-8', xml_declaration=True)\n",
    "print(f\"   ä¿®æ”¹åçš„XMLå·²ä¿å­˜åˆ° bookstore_updated.xml\")\n",
    "\n",
    "# æ˜¾ç¤ºä¿®æ”¹åçš„ç»“æœ\n",
    "print(f\"\\n   ä¿®æ”¹åçš„ä¹¦ç±ä¿¡æ¯:\")\n",
    "for book in parsed_root:\n",
    "    category = book.get('category', 'æœªçŸ¥')\n",
    "    title = book.find('title').text\n",
    "    price = book.find('price').text\n",
    "    discounted = book.get('discounted', 'false')\n",
    "    print(f\"     {title} - {price} ({'å·²æ‰“æŠ˜' if discounted == 'true' else 'åŸä»·'}) - {category}\")\n",
    "\n",
    "# 2. XMLé«˜çº§æ“ä½œ\n",
    "print(f\"\\nğŸ“ 2. XMLé«˜çº§æ“ä½œ:\")\n",
    "\n",
    "# 2.1 XMLä¸Pythonå¯¹è±¡è½¬æ¢\n",
    "print(f\"\\n   ğŸ”„ 2.1 XMLä¸Pythonå¯¹è±¡è½¬æ¢:\")\n",
    "\n",
    "def xml_to_dict(element):\n",
    "    \"\"\"å°†XMLå…ƒç´ è½¬æ¢ä¸ºå­—å…¸\"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    # æ·»åŠ å±æ€§\n",
    "    if element.attrib:\n",
    "        result.update(element.attrib)\n",
    "    \n",
    "    # å¤„ç†å­å…ƒç´ \n",
    "    children = list(element)\n",
    "    if children:\n",
    "        child_dict = {}\n",
    "        for child in children:\n",
    "            child_data = xml_to_dict(child)\n",
    "            \n",
    "            if child.tag in child_dict:\n",
    "                # å¦‚æœå·²å­˜åœ¨ç›¸åŒæ ‡ç­¾ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨\n",
    "                if not isinstance(child_dict[child.tag], list):\n",
    "                    child_dict[child.tag] = [child_dict[child.tag]]\n",
    "                child_dict[child.tag].append(child_data)\n",
    "            else:\n",
    "                child_dict[child.tag] = child_data\n",
    "        \n",
    "        result.update(child_dict)\n",
    "    \n",
    "    # æ·»åŠ æ–‡æœ¬å†…å®¹\n",
    "    if element.text and element.text.strip():\n",
    "        if children or element.attrib:\n",
    "            result['text'] = element.text.strip()\n",
    "        else:\n",
    "            return element.text.strip()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def dict_to_xml(data, root_name='root'):\n",
    "    \"\"\"å°†å­—å…¸è½¬æ¢ä¸ºXMLå…ƒç´ \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        element = ET.Element(root_name)\n",
    "        \n",
    "        for key, value in data.items():\n",
    "            if key == 'text':\n",
    "                element.text = str(value)\n",
    "            elif isinstance(value, dict):\n",
    "                child = dict_to_xml(value, key)\n",
    "                element.append(child)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    child = dict_to_xml(item, key)\n",
    "                    element.append(child)\n",
    "            else:\n",
    "                child = ET.SubElement(element, key)\n",
    "                child.text = str(value)\n",
    "        \n",
    "        return element\n",
    "    else:\n",
    "        element = ET.Element(root_name)\n",
    "        element.text = str(data)\n",
    "        return element\n",
    "\n",
    "# æµ‹è¯•XMLè½¬å­—å…¸\n",
    "xml_dict = xml_to_dict(parsed_root)\n",
    "print(f\"   XMLè½¬å­—å…¸ç»“æœ:\")\n",
    "print(f\"   {json.dumps(xml_dict, ensure_ascii=False, indent=2)}\")\n",
    "\n",
    "# æµ‹è¯•å­—å…¸è½¬XML\n",
    "test_dict = {\n",
    "    \"student\": {\n",
    "        \"name\": \"å¼ ä¸‰\",\n",
    "        \"age\": 20,\n",
    "        \"courses\": {\n",
    "            \"course\": [\n",
    "                {\"name\": \"Python\", \"score\": 90},\n",
    "                {\"name\": \"Math\", \"score\": 85}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "xml_from_dict = dict_to_xml(test_dict, 'students')\n",
    "pretty_dict_xml = prettify_xml(xml_from_dict)\n",
    "print(f\"\\n   å­—å…¸è½¬XMLç»“æœ:\\n{pretty_dict_xml}\")\n",
    "\n",
    "# 2.2 XMLå‘½åç©ºé—´å¤„ç†\n",
    "print(f\"\\n   ğŸ·ï¸ 2.2 XMLå‘½åç©ºé—´å¤„ç†:\")\n",
    "\n",
    "# åˆ›å»ºå¸¦å‘½åç©ºé—´çš„XML\n",
    "ns_xml = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<root xmlns:book=\"http://example.com/book\" \n",
    "      xmlns:author=\"http://example.com/author\">\n",
    "    <book:book category=\"programming\">\n",
    "        <book:title>Pythonç¼–ç¨‹</book:title>\n",
    "        <author:name>å¼ ä¸‰</author:name>\n",
    "    </book:book>\n",
    "</root>'''\n",
    "\n",
    "# è§£æå¸¦å‘½åç©ºé—´çš„XML\n",
    "ns_root = ET.fromstring(ns_xml)\n",
    "\n",
    "# å®šä¹‰å‘½åç©ºé—´\n",
    "namespaces = {\n",
    "    'book': 'http://example.com/book',\n",
    "    'author': 'http://example.com/author'\n",
    "}\n",
    "\n",
    "print(f\"   å¸¦å‘½åç©ºé—´çš„XMLè§£æ:\")\n",
    "print(f\"   æ ¹å…ƒç´ : {ns_root.tag}\")\n",
    "\n",
    "# ä½¿ç”¨å‘½åç©ºé—´æŸ¥æ‰¾å…ƒç´ \n",
    "book_elem = ns_root.find('book:book', namespaces)\n",
    "if book_elem is not None:\n",
    "    title_elem = book_elem.find('book:title', namespaces)\n",
    "    author_elem = book_elem.find('author:name', namespaces)\n",
    "    \n",
    "    print(f\"   ä¹¦å: {title_elem.text if title_elem is not None else 'None'}\")\n",
    "    print(f\"   ä½œè€…: {author_elem.text if author_elem is not None else 'None'}\")\n",
    "\n",
    "# 2.3 XMLæ•°æ®éªŒè¯\n",
    "print(f\"\\n   âœ… 2.3 XMLæ•°æ®éªŒè¯:\")\n",
    "\n",
    "def validate_xml_structure(element, required_elements):\n",
    "    \"\"\"éªŒè¯XMLç»“æ„\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for elem_path, elem_type in required_elements.items():\n",
    "        parts = elem_path.split('/')\n",
    "        current = element\n",
    "        \n",
    "        for part in parts:\n",
    "            found = current.find(part) if current is not None else None\n",
    "            if found is None:\n",
    "                errors.append(f\"ç¼ºå°‘å¿…éœ€å…ƒç´ : {elem_path}\")\n",
    "                break\n",
    "            current = found\n",
    "        \n",
    "        if current is not None:\n",
    "            # éªŒè¯å…ƒç´ ç±»å‹\n",
    "            if elem_type == 'number':\n",
    "                try:\n",
    "                    float(current.text)\n",
    "                except (ValueError, TypeError):\n",
    "                    errors.append(f\"å…ƒç´  {elem_path} åº”ä¸ºæ•°å­—ç±»å‹\")\n",
    "            elif elem_type == 'integer':\n",
    "                try:\n",
    "                    int(current.text)\n",
    "                except (ValueError, TypeError):\n",
    "                    errors.append(f\"å…ƒç´  {elem_path} åº”ä¸ºæ•´æ•°ç±»å‹\")\n",
    "            elif elem_type == 'non_empty':\n",
    "                if not current.text or not current.text.strip():\n",
    "                    errors.append(f\"å…ƒç´  {elem_path} ä¸èƒ½ä¸ºç©º\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "# å®šä¹‰ä¹¦ç±XMLçš„å¿…éœ€ç»“æ„\n",
    "book_schema = {\n",
    "    'book/title': 'non_empty',\n",
    "    'book/author': 'non_empty',\n",
    "    'book/year': 'integer',\n",
    "    'book/price': 'number'\n",
    "}\n",
    "\n",
    "# éªŒè¯ç¬¬ä¸€ä¸ªä¹¦ç±å…ƒç´ \n",
    "first_book = parsed_root.find('book')\n",
    "if first_book is not None:\n",
    "    validation_errors = validate_xml_structure(first_book, book_schema)\n",
    "    \n",
    "    print(f\"   XMLç»“æ„éªŒè¯ç»“æœ:\")\n",
    "    if validation_errors:\n",
    "        for error in validation_errors:\n",
    "            print(f\"     âŒ {error}\")\n",
    "    else:\n",
    "        print(f\"     âœ… éªŒè¯é€šè¿‡\")\n",
    "\n",
    "# 3. å®é™…åº”ç”¨ç¤ºä¾‹\n",
    "print(f\"\\nğŸ“ 3. å®é™…åº”ç”¨ç¤ºä¾‹:\")\n",
    "\n",
    "# 3.1 RSS/Atom feedè§£æ\n",
    "print(f\"\\n   ğŸ“° 3.1 RSS feedè§£æ:\")\n",
    "\n",
    "class RSSParser:\n",
    "    \"\"\"RSSè§£æå™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.namespaces = {\n",
    "            'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "            'dc': 'http://purl.org/dc/elements/1.1/',\n",
    "            'content': 'http://purl.org/rss/1.0/modules/content/'\n",
    "        }\n",
    "    \n",
    "    def parse_rss(self, xml_content: str) -> Dict:\n",
    "        \"\"\"è§£æRSSå†…å®¹\"\"\"\n",
    "        try:\n",
    "            root = ET.fromstring(xml_content)\n",
    "            \n",
    "            # è·å–é¢‘é“ä¿¡æ¯\n",
    "            channel = root.find('channel')\n",
    "            if channel is None:\n",
    "                return {'error': 'Invalid RSS format'}\n",
    "            \n",
    "            feed_info = {\n",
    "                'title': self.get_text(channel, 'title'),\n",
    "                'description': self.get_text(channel, 'description'),\n",
    "                'link': self.get_text(channel, 'link'),\n",
    "                'language': self.get_text(channel, 'language'),\n",
    "                'last_build_date': self.get_text(channel, 'lastBuildDate'),\n",
    "                'items': []\n",
    "            }\n",
    "            \n",
    "            # è·å–æ–‡ç« åˆ—è¡¨\n",
    "            items = channel.findall('item')\n",
    "            for item in items:\n",
    "                item_info = {\n",
    "                    'title': self.get_text(item, 'title'),\n",
    "                    'description': self.get_text(item, 'description'),\n",
    "                    'link': self.get_text(item, 'link'),\n",
    "                    'pub_date': self.get_text(item, 'pubDate'),\n",
    "                    'guid': self.get_text(item, 'guid'),\n",
    "                    'categories': [cat.text for cat in item.findall('category') if cat.text]\n",
    "                }\n",
    "                feed_info['items'].append(item_info)\n",
    "            \n",
    "            return feed_info\n",
    "            \n",
    "        except ET.ParseError as e:\n",
    "            return {'error': f'Parse error: {e}'}\n",
    "        except Exception as e:\n",
    "            return {'error': f'Unexpected error: {e}'}\n",
    "    \n",
    "    def get_text(self, element, tag):\n",
    "        \"\"\"å®‰å…¨è·å–å…ƒç´ æ–‡æœ¬\"\"\"\n",
    "        found = element.find(tag)\n",
    "        return found.text if found is not None and found.text else ''\n",
    "    \n",
    "    def extract_articles_by_category(self, feed_data: Dict, category: str) -> List[Dict]:\n",
    "        \"\"\"æŒ‰åˆ†ç±»æå–æ–‡ç« \"\"\"\n",
    "        filtered_items = []\n",
    "        \n",
    "        for item in feed_data.get('items', []):\n",
    "            if category.lower() in [cat.lower() for cat in item.get('categories', [])]:\n",
    "                filtered_items.append(item)\n",
    "        \n",
    "        return filtered_items\n",
    "\n",
    "# ç¤ºä¾‹RSSå†…å®¹\n",
    "sample_rss = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<rss version=\"2.0\">\n",
    "    <channel>\n",
    "        <title>æŠ€æœ¯åšå®¢</title>\n",
    "        <description>æœ€æ–°æŠ€æœ¯æ–‡ç« </description>\n",
    "        <link>https://techblog.example.com</link>\n",
    "        <language>zh-cn</language>\n",
    "        <lastBuildDate>Tue, 25 Dec 2024 10:30:00 GMT</lastBuildDate>\n",
    "        \n",
    "        <item>\n",
    "            <title>Pythonå¼‚æ­¥ç¼–ç¨‹è¯¦è§£</title>\n",
    "            <description>æ·±å…¥ç†è§£Pythonçš„asyncioåº“å’Œå¼‚æ­¥ç¼–ç¨‹æ¨¡å¼</description>\n",
    "            <link>https://techblog.example.com/python-async</link>\n",
    "            <pubDate>Mon, 24 Dec 2024 09:00:00 GMT</pubDate>\n",
    "            <guid>python-async-001</guid>\n",
    "            <category>Python</category>\n",
    "            <category>å¼‚æ­¥ç¼–ç¨‹</category>\n",
    "        </item>\n",
    "        \n",
    "        <item>\n",
    "            <title>æœºå™¨å­¦ä¹ å…¥é—¨æŒ‡å—</title>\n",
    "            <description>ä»é›¶å¼€å§‹å­¦ä¹ æœºå™¨å­¦ä¹ çš„åŸºç¡€æ¦‚å¿µå’Œå®è·µ</description>\n",
    "            <link>https://techblog.example.com/ml-guide</link>\n",
    "            <pubDate>Sun, 23 Dec 2024 14:30:00 GMT</pubDate>\n",
    "            <guid>ml-guide-001</guid>\n",
    "            <category>æœºå™¨å­¦ä¹ </category>\n",
    "            <category>äººå·¥æ™ºèƒ½</category>\n",
    "        </item>\n",
    "        \n",
    "        <item>\n",
    "            <title>Webå¼€å‘æœ€ä½³å®è·µ</title>\n",
    "            <description>ç°ä»£Webå¼€å‘ä¸­çš„è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µ</description>\n",
    "            <link>https://techblog.example.com/web-best-practices</link>\n",
    "            <pubDate>Sat, 22 Dec 2024 11:15:00 GMT</pubDate>\n",
    "            <guid>web-practices-001</guid>\n",
    "            <category>Webå¼€å‘</category>\n",
    "        </item>\n",
    "    </channel>\n",
    "</rss>'''\n",
    "\n",
    "# è§£æRSS\n",
    "rss_parser = RSSParser()\n",
    "parsed_rss = rss_parser.parse_rss(sample_rss)\n",
    "\n",
    "print(f\"   RSSè§£æç»“æœ:\")\n",
    "print(f\"   é¢‘é“æ ‡é¢˜: {parsed_rss.get('title', 'N/A')}\")\n",
    "print(f\"   æè¿°: {parsed_rss.get('description', 'N/A')}\")\n",
    "print(f\"   æ–‡ç« æ•°é‡: {len(parsed_rss.get('items', []))}\")\n",
    "\n",
    "print(f\"\\n   æ–‡ç« åˆ—è¡¨:\")\n",
    "for item in parsed_rss.get('items', []):\n",
    "    print(f\"     - {item.get('title', 'N/A')} ({', '.join(item.get('categories', []))})\")\n",
    "\n",
    "# æŒ‰åˆ†ç±»æå–æ–‡ç« \n",
    "python_articles = rss_parser.extract_articles_by_category(parsed_rss, 'Python')\n",
    "print(f\"\\n   Pythonç›¸å…³æ–‡ç« : {len(python_articles)} ç¯‡\")\n",
    "for article in python_articles:\n",
    "    print(f\"     - {article.get('title', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nâœ… XMLåŸºç¡€æ“ä½œå®Œæˆ\")\n",
    "print(f\"ğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   âœ“ æŒæ¡ElementTreeçš„åŸºæœ¬æ“ä½œå’Œæ–¹æ³•\")\n",
    "print(f\"   âœ“ ç†Ÿç»ƒè¿›è¡ŒXMLè§£æå’Œæ•°æ®æå–\")\n",
    "print(f\"   âœ“ ç†è§£XMLçš„å±‚çº§ç»“æ„å’Œå‘½åç©ºé—´\")\n",
    "print(f\"   âœ“ èƒ½å¤Ÿåˆ›å»ºå’Œä¿®æ”¹XMLæ–‡æ¡£\")\n",
    "print(f\"   âœ“ æŒæ¡å®é™…åº”ç”¨åœºæ™¯ä¸­çš„RSSè§£æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### âœ… çŸ¥è¯†æ¸…å•è¾¾æˆæƒ…å†µéªŒè¯\n",
    "\n",
    "**4.4 JSONä¸XMLå¤„ç† [â­åŸºç¡€]**\n",
    "- âœ… æŒæ¡jsonæ¨¡å—çš„åŸºæœ¬ç”¨æ³•å’Œæ•°æ®è½¬æ¢\n",
    "- âœ… ç†Ÿç»ƒä½¿ç”¨xml.etree.ElementTreeå¤„ç†XMLæ•°æ®\n",
    "- âœ… ç†è§£JSON schemaéªŒè¯å’Œé”™è¯¯å¤„ç†\n",
    "- âœ… èƒ½å¤Ÿå¤„ç†å¤æ‚çš„æ•°æ®ç»“æ„å’ŒåµŒå¥—æ ¼å¼\n",
    "- âœ… æŒæ¡XMLè§£æã€åˆ›å»ºå’Œä¿®æ”¹çš„æ–¹æ³•\n",
    "- âœ… ç†è§£XMLçš„å±‚çº§ç»“æ„å’Œå‘½åç©ºé—´å¤„ç†\n",
    "- âœ… èƒ½è¿›è¡Œæ•°æ®åºåˆ—åŒ–å’Œååºåˆ—åŒ–æ“ä½œ\n",
    "- âœ… æŒæ¡å®é™…åº”ç”¨åœºæ™¯(é…ç½®æ–‡ä»¶ã€RSSè§£æç­‰)\n",
    "- âœ… èƒ½ç‹¬ç«‹å¤„ç†JSON/XMLæ•°æ®è½¬æ¢ä»»åŠ¡\n",
    "\n",
    "### ğŸ¯ ä¸LangChainå­¦ä¹ çš„å…³è”\n",
    "\n",
    "**æ•°æ®æ ¼å¼å¤„ç†é‡è¦æ€§**ï¼š\n",
    "- JSONå¤„ç†æ˜¯LangChainç»“æ„åŒ–è¾“å‡ºçš„åŸºç¡€\n",
    "- XMLå¤„ç†å¯¹äºLangChainçš„æ–‡æ¡£è§£æå’Œé›†æˆè‡³å…³é‡è¦\n",
    "- æ•°æ®åºåˆ—åŒ–å½±å“LangChainçš„ç¼“å­˜å’Œå­˜å‚¨æœºåˆ¶\n",
    "- æ ¼å¼è½¬æ¢åœ¨LangChainçš„æ•°æ®ç®¡é“ä¸­å‘æŒ¥é‡è¦ä½œç”¨\n",
    "\n",
    "**å®é™…åº”ç”¨åœºæ™¯**ï¼š\n",
    "- LangChainçš„è¾“å‡ºè§£æå™¨éœ€è¦JSONæ ¼å¼å¤„ç†\n",
    "- æ–‡æ¡£åŠ è½½å™¨ä¸­çš„XMLè§£æåŠŸèƒ½\n",
    "- é…ç½®ç®¡ç†å’Œå‚æ•°ä¼ é€’ä½¿ç”¨JSONæ ¼å¼\n",
    "- APIé›†æˆä¸­çš„æ•°æ®æ ¼å¼è½¬æ¢\n",
    "\n",
    "### ğŸ“š è¿›é˜¶å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **ç»ƒä¹ å»ºè®®**ï¼š\n",
    "   - å¤šç»ƒä¹ å¤æ‚JSON/XMLç»“æ„çš„è§£æå’Œè½¬æ¢\n",
    "   - æ·±å…¥å­¦ä¹ æ•°æ®éªŒè¯å’Œé”™è¯¯å¤„ç†æŠ€å·§\n",
    "   - æŒæ¡å¤§æ•°æ®é‡çš„æµå¼å¤„ç†æ–¹æ³•\n",
    "\n",
    "2. **æ‰©å±•å­¦ä¹ **ï¼š\n",
    "   - å­¦ä¹ JSON Schemaè§„èŒƒå’ŒéªŒè¯åº“\n",
    "   - äº†è§£XPathå’ŒXSLTé«˜çº§XMLå¤„ç†æŠ€æœ¯\n",
    "   - æ¢ç´¢YAMLã€TOMLç­‰å…¶ä»–é…ç½®æ ¼å¼\n",
    "\n",
    "3. **å®é™…åº”ç”¨**ï¼š\n",
    "   - æ„å»ºé…ç½®æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ\n",
    "   - å¼€å‘APIæ•°æ®å¤„ç†ç®¡é“\n",
    "   - å®ç°æ–‡æ¡£æ ¼å¼è½¬æ¢å·¥å…·\n",
    "\n",
    "### ğŸ”§ å¸¸è§é”™è¯¯ä¸æ³¨æ„äº‹é¡¹\n",
    "\n",
    "1. **JSONç¼–ç é—®é¢˜**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šå¿½ç•¥ç¼–ç é—®é¢˜\n",
    "   json.dumps({\"name\": \"å¼ ä¸‰\"})  # è¾“å‡ºUnicodeè½¬ä¹‰å­—ç¬¦\n",
    "   \n",
    "   # æ­£ç¡®ï¼šå¤„ç†ä¸­æ–‡ç¼–ç \n",
    "   json.dumps({\"name\": \"å¼ ä¸‰\"}, ensure_ascii=False)\n",
    "   ```\n",
    "\n",
    "2. **XMLç‰¹æ®Šå­—ç¬¦å¤„ç†**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šç›´æ¥åŒ…å«ç‰¹æ®Šå­—ç¬¦\n",
    "   ET.SubElement(root, \"content\").text = \"Hello <world> & everyone\"  # ä¼šå‡ºé”™\n",
    "   \n",
    "   # æ­£ç¡®ï¼šè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦\n",
    "   import html\n",
    "   content = html.escape(\"Hello <world> & everyone\")\n",
    "   ET.SubElement(root, \"content\").text = content\n",
    "   ```\n",
    "\n",
    "3. **å¾ªç¯å¼•ç”¨é—®é¢˜**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šå¾ªç¯å¼•ç”¨å¯¼è‡´åºåˆ—åŒ–å¤±è´¥\n",
    "   data = {}\n",
    "   data['self'] = data\n",
    "   json.dumps(data)  # ValueError: Circular reference detected\n",
    "   \n",
    "   # æ­£ç¡®ï¼šé¿å…å¾ªç¯å¼•ç”¨æˆ–ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨\n",
    "   class SafeEncoder(json.JSONEncoder):\n",
    "       def default(self, obj):\n",
    "           if id(obj) in self.seen:\n",
    "               return \"[Circular Reference]\"\n",
    "           self.seen.add(id(obj))\n",
    "           return super().default(obj)\n",
    "   ```\n",
    "\n",
    "4. **XMLå‘½åç©ºé—´é—®é¢˜**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šå¿½ç•¥å‘½åç©ºé—´\n",
    "   root.find('book')  # æ— æ³•æ‰¾åˆ°å¸¦å‘½åç©ºé—´çš„å…ƒç´ \n",
    "   \n",
    "   # æ­£ç¡®ï¼šä½¿ç”¨å‘½åç©ºé—´å‰ç¼€\n",
    "   namespaces = {'ns': 'http://example.com/namespace'}\n",
    "   root.find('ns:book', namespaces)\n",
    "   ```\n",
    "\n",
    "5. **æ•°æ®ç±»å‹ä¸ä¸€è‡´**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šå‡è®¾JSONæ•°å­—æ€»æ˜¯Python int\n",
    "   data = json.loads('{\"price\": 99.99}')\n",
    "   assert isinstance(data['price'], int)  # AssertionError\n",
    "   \n",
    "   # æ­£ç¡®ï¼šæ£€æŸ¥æ•°å­—ç±»å‹\n",
    "   price = data['price']\n",
    "   if isinstance(price, float):\n",
    "       print(f\"ä»·æ ¼: {price:.2f}\")\n",
    "   ```\n",
    "\n",
    "6. **æ€§èƒ½é—®é¢˜**ï¼š\n",
    "   ```python\n",
    "   # é”™è¯¯ï¼šé¢‘ç¹çš„æ–‡ä»¶è¯»å†™\n",
    "   def save_config(config):\n",
    "       with open('config.json', 'w') as f:\n",
    "           json.dump(config, f)\n",
    "   \n",
    "   # æ­£ç¡®ï¼šæ‰¹é‡æ›´æ–°åä¸€æ¬¡æ€§ä¿å­˜\n",
    "   def update_config(updates):\n",
    "       config = load_config()\n",
    "       config.update(updates)\n",
    "       with open('config.json', 'w') as f:\n",
    "           json.dump(config, f)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®ŒæˆJSONä¸XMLå¤„ç†å­¦ä¹ ï¼**\n",
    "\n",
    "ä½ å·²ç»æŒæ¡äº†Python JSONå’ŒXMLå¤„ç†çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œèƒ½å¤Ÿç†Ÿç»ƒè¿›è¡Œæ•°æ®åºåˆ—åŒ–ã€ååºåˆ—åŒ–ã€æ ¼å¼è½¬æ¢ç­‰æ“ä½œï¼ŒæŒæ¡äº†é…ç½®æ–‡ä»¶ç®¡ç†ã€RSSè§£æç­‰å®é™…åº”ç”¨æŠ€æœ¯ï¼Œä¸ºåç»­å­¦ä¹ LangChainçš„æ•°æ®å¤„ç†åŠŸèƒ½å¥ å®šäº†åšå®åŸºç¡€ã€‚\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ é¢„å‘Š\n",
    "\n",
    "**ç»§ç»­ç¬¬å››èŠ‚ï¼šå¸¸ç”¨æ ‡å‡†åº“**ï¼š\n",
    "- 4.5 ç½‘ç»œè¯·æ±‚å¤„ç† [â­â­è¿›é˜¶]\n",
    "- 4.6 å¤šçº¿ç¨‹ä¸å¤šè¿›ç¨‹ [â­â­è¿›é˜¶]\n",
    "- 4.7 æ•°æ®åºåˆ—åŒ–ä¸å­˜å‚¨ [â­â­è¿›é˜¶]\n",
    "- 4.8 ç³»ç»Ÿä¿¡æ¯è·å– [â­â­è¿›é˜¶]\n",
    "- 4.9 å¸¸ç”¨å·¥å…·æ¨¡å— [â­â­è¿›é˜¶]\n",
    "\n",
    "ç»§ç»­åŠ æ²¹ï¼Œå®ŒæˆPythonæ ‡å‡†åº“çš„å­¦ä¹ ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
