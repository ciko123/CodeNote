{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ¨¡å‹ (Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 é™æ€æ¨¡å‹\n",
    "\n",
    "åˆ›å»ºæ—¶é…ç½®ä¸€æ¬¡ï¼Œä¿æŒä¸å˜ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "# æ–¹å¼1ï¼šé€šè¿‡ æ¨¡å‹å‹å· åˆ›å»º\n",
    "agent = create_agent(\n",
    "    \"gpt-5\",  # æ”¯æŒè‡ªåŠ¨æ¨æ–­ï¼Œå­˜åœ¨æ˜ å°„é…ç½®\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "\n",
    "# æ–¹å¼2ï¼šé€šè¿‡ æ¨¡å‹å¯¹è±¡\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-5\", \n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    "    # ... (other params)\n",
    ")\n",
    "\n",
    "agent = create_agent(model, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 åŠ¨æ€æ¨¡å‹\n",
    "\n",
    "è¿è¡Œæ—¶æ ¹æ®çŠ¶æ€é€‰æ‹©æ¨¡å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "# åŸºç¡€æ¨¡å‹\n",
    "basic_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# é«˜çº§æ¨¡å‹\n",
    "advanced_model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"æ ¹æ®å¯¹è¯å¤æ‚åº¦é€‰æ‹©æ¨¡å‹ã€‚\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 10:\n",
    "        # å¯¹äºè¾ƒé•¿çš„å¯¹è¯ä½¿ç”¨é«˜çº§æ¨¡å‹\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    return handler(request.override(model=model))\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,  # é»˜è®¤æ¨¡å‹\n",
    "    tools=tools,\n",
    "    middleware=[dynamic_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å·¥å…· (Tools)\n",
    "\n",
    "å·¥å…·èµ‹äºˆä»£ç†è¡ŒåŠ¨èƒ½åŠ›ï¼Œæ”¯æŒï¼š\n",
    "- åºåˆ—ä¸­çš„å¤šä¸ªå·¥å…·è°ƒç”¨\n",
    "- å¹¶è¡Œå·¥å…·è°ƒç”¨\n",
    "- åŠ¨æ€å·¥å…·é€‰æ‹©\n",
    "- é”™è¯¯å¤„ç†å’Œé‡è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 å®šä¹‰å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"æœç´¢ä¿¡æ¯ã€‚\"\"\"\n",
    "    return f\"æœç´¢ç»“æœ: {query}\"\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"è·å–ä½ç½®çš„å¤©æ°”ä¿¡æ¯ã€‚\"\"\"\n",
    "    return f\"{location} çš„å¤©æ°”: æ™´å¤©ï¼Œ72Â°F\"\n",
    "\n",
    "model = ChatOpenAI(  model=\"gpt-4o\")\n",
    "agent = create_agent(model, tools=[search, get_weather])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 å·¥å…·é”™è¯¯å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_tool_call\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# @wrap_tool_callï¼šç”¨äºåŒ…è£…å·¥å…·è°ƒç”¨çš„ä¸­é—´ä»¶ï¼Œå¯ä»¥æ‹¦æˆªå’Œå¤„ç†å·¥å…·è°ƒç”¨è¿‡ç¨‹ä¸­çš„é”™è¯¯\n",
    "@wrap_tool_call\n",
    "def handle_tool_errors(request, handler):\n",
    "    \"\"\"ä½¿ç”¨è‡ªå®šä¹‰æ¶ˆæ¯å¤„ç†å·¥å…·æ‰§è¡Œé”™è¯¯ã€‚\"\"\"\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        # å‘æ¨¡å‹è¿”å›è‡ªå®šä¹‰é”™è¯¯æ¶ˆæ¯\n",
    "        return ToolMessage(\n",
    "            content=f\"å·¥å…·é”™è¯¯ï¼šè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å¹¶é‡è¯•ã€‚({str(e)})\",\n",
    "            tool_call_id=request.tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search, get_weather],\n",
    "    middleware=[handle_tool_errors]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç³»ç»Ÿæç¤º (System Prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 åŸºæœ¬ç”¨æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­—ç¬¦ çš„å½¢å¼\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SystemMessage çš„å½¢å¼ \n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# æ–‡å­¦åˆ†æä»£ç†\n",
    "literary_agent = create_agent(\n",
    "    model=\"anthropic:claude-sonnet-4-5\",\n",
    "    system_prompt=SystemMessage(\n",
    "        content=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"æ‚¨æ˜¯ä¸€ä¸ªè´Ÿè´£åˆ†ææ–‡å­¦ä½œå“çš„ AI åŠ©æ‰‹ã€‚\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"<ã€Šå‚²æ…¢ä¸åè§ã€‹çš„å…¨éƒ¨å†…å®¹>\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "result = literary_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"åˆ†æã€Šå‚²æ…¢ä¸åè§ã€‹çš„ä¸»è¦ä¸»é¢˜ã€‚\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 åŠ¨æ€ç³»ç»Ÿæç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·è§’è‰²ç”Ÿæˆç³»ç»Ÿæç¤ºã€‚\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"user\")\n",
    "    base_prompt = \"æ‚¨æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚\"\n",
    "\n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_prompt} æä¾›è¯¦ç»†çš„æŠ€æœ¯å“åº”ã€‚\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_prompt} ç®€å•è§£é‡Šæ¦‚å¿µï¼Œé¿å…æœ¯è¯­ã€‚\"\n",
    "\n",
    "    return base_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[web_search],\n",
    "    middleware=[user_role_prompt],\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# ç³»ç»Ÿæç¤ºå°†æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è®¾ç½®\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"è§£é‡Šæœºå™¨å­¦ä¹ \"}]},\n",
    "    context={\"user_role\": \"expert\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è°ƒç”¨ (Invocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. é«˜çº§æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 ç»“æ„åŒ–è¾“å‡º (Structured Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 ToolStrategyï¼ˆé€šç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "# è”ç³»ä¿¡æ¯æ¨¡å‹\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search_tool],\n",
    "    response_format=ToolStrategy(ContactInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ä»ä»¥ä¸‹ä¿¡æ¯ä¸­æå–è”ç³»ä¿¡æ¯ï¼šJohn Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 ProviderStrategyï¼ˆåŸç”Ÿæ”¯æŒï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.structured_output import ProviderStrategy\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format=ProviderStrategy(ContactInfo)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 è®°å¿† (Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 é€šè¿‡ä¸­é—´ä»¶å®šä¹‰çŠ¶æ€ï¼ˆæ¨èï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from typing import Any\n",
    "\n",
    "# è‡ªå®šä¹‰çŠ¶æ€ç±»\n",
    "class CustomState(AgentState):\n",
    "    user_preferences: dict\n",
    "\n",
    "# è‡ªå®šä¹‰ä¸­é—´ä»¶ç±»\n",
    "class CustomMiddleware(AgentMiddleware):\n",
    "    state_schema = CustomState\n",
    "    tools = [tool1, tool2]\n",
    "\n",
    "    def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n",
    "        ...\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    middleware=[CustomMiddleware()]\n",
    ")\n",
    "\n",
    "# ä»£ç†ç°åœ¨å¯ä»¥è·Ÿè¸ªé™¤æ¶ˆæ¯ä¹‹å¤–çš„é¢å¤–çŠ¶æ€\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘æ›´å–œæ¬¢æŠ€æœ¯è§£é‡Š\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 é€šè¿‡ state_schema å®šä¹‰çŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "\n",
    "# è‡ªå®šä¹‰çŠ¶æ€ç±»\n",
    "class CustomState(AgentState):\n",
    "    user_preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[tool1, tool2],\n",
    "    state_schema=CustomState\n",
    ")\n",
    "# ä»£ç†ç°åœ¨å¯ä»¥è·Ÿè¸ªé™¤æ¶ˆæ¯ä¹‹å¤–çš„é¢å¤–çŠ¶æ€\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘æ›´å–œæ¬¢æŠ€æœ¯è§£é‡Š\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 æµå¼ä¼ è¾“ (Streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æœç´¢ AI æ–°é—»å¹¶æ€»ç»“å‘ç°\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    # æ¯ä¸ª chunk åŒ…å«è¯¥æ—¶é—´ç‚¹çš„å®Œæ•´çŠ¶æ€\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"ä»£ç†: {latest_message.content}\")\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"è°ƒç”¨å·¥å…·: {[tc['name'] for tc in latest_message.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 ä¸­é—´ä»¶ (Middleware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ ä¸­é—´ä»¶åŠŸèƒ½æ¦‚è§ˆï¼š\")\n",
    "print(\"ä¸­é—´ä»¶æä¾›å¼ºå¤§çš„å¯æ‰©å±•æ€§ï¼Œç”¨äºï¼š\")\n",
    "\n",
    "middleware_features = [\n",
    "    \"è°ƒç”¨æ¨¡å‹å‰å¤„ç†çŠ¶æ€ï¼ˆæ¶ˆæ¯ä¿®å‰ªã€ä¸Šä¸‹æ–‡æ³¨å…¥ï¼‰\",\n",
    "    \"ä¿®æ”¹æˆ–éªŒè¯æ¨¡å‹å“åº”ï¼ˆé˜²æŠ¤æœºåˆ¶ã€å†…å®¹è¿‡æ»¤ï¼‰\",\n",
    "    \"è‡ªå®šä¹‰å·¥å…·æ‰§è¡Œé”™è¯¯å¤„ç†\",\n",
    "    \"åŠ¨æ€æ¨¡å‹é€‰æ‹©\",\n",
    "    \"æ·»åŠ æ—¥å¿—è®°å½•ã€ç›‘æ§æˆ–åˆ†æ\"\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(middleware_features, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ä¸»è¦è£…é¥°å™¨ï¼š\")\n",
    "decorators = [\n",
    "    \"@before_model - åœ¨æ¨¡å‹è°ƒç”¨å‰å¤„ç†\",\n",
    "    \"@after_model - åœ¨æ¨¡å‹è°ƒç”¨åå¤„ç†\",\n",
    "    \"@wrap_tool_call - åŒ…è£…å·¥å…·è°ƒç”¨\",\n",
    "    \"@dynamic_prompt - åŠ¨æ€ç”Ÿæˆæç¤º\"\n",
    "]\n",
    "\n",
    "for decorator in decorators:\n",
    "    print(f\"  â€¢ {decorator}\")\n",
    "\n",
    "print(\"\\nâœ… ä¸­é—´ä»¶æ¦‚å¿µä»‹ç»å®Œæˆ\")\n",
    "print(\"ğŸ’¡ æç¤º: ä¸­é—´ä»¶æ˜¯æ‰©å±•ä»£ç†åŠŸèƒ½çš„æ ¸å¿ƒæœºåˆ¶ï¼Œå…è®¸åœ¨ä¸ä¿®æ”¹æ ¸å¿ƒé€»è¾‘çš„æƒ…å†µä¸‹æ·»åŠ å¤æ‚è¡Œä¸º\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
