# æ ¸å¿ƒéƒ¨ä»¶
## ä»£ç† (Agents)

ä»£ç† (Agents) ç»“åˆè¯­è¨€æ¨¡å‹å’Œå·¥å…·æ¥åˆ›å»ºèƒ½å¤Ÿæ¨ç†ä»»åŠ¡ã€å†³å®šä½¿ç”¨å“ªäº›å·¥å…·å¹¶è¿­ä»£åœ°æœç€è§£å†³æ–¹æ¡ˆåŠªåŠ›çš„ç³»ç»Ÿã€‚

`create_agent` æä¾›äº†ç”Ÿäº§å°±ç»ªçš„ä»£ç†å®ç°ï¼ŒåŸºäº LangGraph æ„å»ºå›¾ç»“æ„è¿è¡Œæ—¶ã€‚

![image-20251206145533950](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20251206145533950.png)

## æ ¸å¿ƒç»„ä»¶

### æ¨¡å‹ (Model)

#### é™æ€æ¨¡å‹
åˆ›å»ºæ—¶é…ç½®ä¸€æ¬¡ï¼Œä¿æŒä¸å˜ï¼š

```python
from langchain.agents import create_agent


# æ–¹å¼1ï¼šé€šè¿‡ æ¨¡å‹å‹å· åˆ›å»º
agent = create_agent(
    "gpt-5",  # æ”¯æŒè‡ªåŠ¨æ¨æ–­ï¼Œå­˜åœ¨æ˜ å°„é…ç½®
    tools=tools
)


# æ–¹å¼2ï¼šé€šè¿‡ æ¨¡å‹å¯¹è±¡
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

model = ChatOpenAI(
    model="gpt-5", 
    temperature=0.1,
    max_tokens=1000,å—¯
    timeout=30
    # ... (other params)
)

agent = create_agent(model, tools=tools)
```

#### åŠ¨æ€æ¨¡å‹
è¿è¡Œæ—¶æ ¹æ®çŠ¶æ€é€‰æ‹©æ¨¡å‹ï¼š

```python
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse

# åŸºç¡€æ¨¡å‹
basic_model = ChatOpenAI(model="gpt-4o-mini")
# é«˜çº§æ¨¡å‹
advanced_model = ChatOpenAI(model="gpt-4o")

@wrap_model_call
def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:
    """æ ¹æ®å¯¹è¯å¤æ‚åº¦é€‰æ‹©æ¨¡å‹ã€‚"""
    message_count = len(request.state["messages"])

    if message_count > 10:
        # å¯¹äºè¾ƒé•¿çš„å¯¹è¯ä½¿ç”¨é«˜çº§æ¨¡å‹
        model = advanced_model
    else:
        model = basic_model

    return handler(request.override(model=model))

agent = create_agent(
    model=basic_model,  # é»˜è®¤æ¨¡å‹
    tools=tools,
    middleware=[dynamic_model_selection]
)
```

### å·¥å…· (Tools)

å·¥å…·èµ‹äºˆä»£ç†è¡ŒåŠ¨èƒ½åŠ›ï¼Œæ”¯æŒï¼š
- åºåˆ—ä¸­çš„å¤šä¸ªå·¥å…·è°ƒç”¨
- å¹¶è¡Œå·¥å…·è°ƒç”¨
- åŠ¨æ€å·¥å…·é€‰æ‹©
- é”™è¯¯å¤„ç†å’Œé‡è¯•

#### å®šä¹‰å·¥å…·
```python
from langchain.tools import tool

@tool
def search(query: str) -> str:
    """æœç´¢ä¿¡æ¯ã€‚"""
    return f"æœç´¢ç»“æœ: {query}"

@tool
def get_weather(location: str) -> str:
    """è·å–ä½ç½®çš„å¤©æ°”ä¿¡æ¯ã€‚"""
    return f"{location} çš„å¤©æ°”: æ™´å¤©ï¼Œ72Â°F"

agent = create_agent(model, tools=[search, get_weather])
```

#### å·¥å…·é”™è¯¯å¤„ç†
```python
from langchain.agents.middleware import wrap_tool_call
from langchain.messages import ToolMessage

@wrap_tool_call
def handle_tool_errors(request, handler):
    try:
        return handler(request)
    except Exception as e:
        return ToolMessage(
            content=f"å·¥å…·é”™è¯¯: è¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å¹¶é‡è¯•ã€‚({str(e)})",
            tool_call_id=request.tool_call["id"]
        )

agent = create_agent(
    model="gpt-4o",
    tools=[search, get_weather],
    middleware=[handle_tool_errors]
)
```

### ç³»ç»Ÿæç¤º (System prompt)

#### åŸºæœ¬ç”¨æ³•
```python
agent = create_agent(
    model,
    tools,
    system_prompt="æ‚¨æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚è¯·ç®€æ´å‡†ç¡®ã€‚"
)
```

#### é«˜çº§ç”¨æ³•ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
```python
# SystemMessage çš„å½¢å¼ 

from langchain.agents import create_agent
from langchain.messages import SystemMessage, HumanMessage

# æ–‡å­¦åˆ†æä»£ç†
literary_agent = create_agent(
    model="anthropic:claude-sonnet-4-5",
    system_prompt=SystemMessage(
        content=[
            {
                "type": "text",
                "text": "æ‚¨æ˜¯ä¸€ä¸ªè´Ÿè´£åˆ†ææ–‡å­¦ä½œå“çš„ AI åŠ©æ‰‹ã€‚",
            },
            {
                "type": "text",
                "text": "<ã€Šå‚²æ…¢ä¸åè§ã€‹çš„å…¨éƒ¨å†…å®¹>",
                "cache_control": {"type": "ephemeral"}
            }
        ]
    )
)

result = literary_agent.invoke(
    {"messages": [HumanMessage("åˆ†æã€Šå‚²æ…¢ä¸åè§ã€‹çš„ä¸»è¦ä¸»é¢˜ã€‚")]}
)
```

#### åŠ¨æ€ç³»ç»Ÿæç¤º
```python
@dynamic_prompt
def user_role_prompt(request: ModelRequest) -> str:
    """æ ¹æ®ç”¨æˆ·è§’è‰²ç”Ÿæˆç³»ç»Ÿæç¤ºã€‚"""
    user_role = request.runtime.context.get("user_role", "user")
    base_prompt = "æ‚¨æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"

    if user_role == "expert":
        return f"{base_prompt} æä¾›è¯¦ç»†çš„æŠ€æœ¯å“åº”ã€‚"
    elif user_role == "beginner":
        return f"{base_prompt} ç®€å•è§£é‡Šæ¦‚å¿µï¼Œé¿å…æœ¯è¯­ã€‚"

    return base_prompt

agent = create_agent(
    model="gpt-4o",
    tools=[web_search],
    middleware=[user_role_prompt],
    context_schema=Context
)

# ç³»ç»Ÿæç¤ºå°†æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è®¾ç½®
result = agent.invoke(
    {"messages": [{"role": "user", "content": "è§£é‡Šæœºå™¨å­¦ä¹ "}]},
    context={"user_role": "expert"}
)
```

### è°ƒç”¨ (Invocation)

```python
result = agent.invoke({
    "messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]
})
```

## é«˜çº§æ¦‚å¿µ

### ç»“æ„åŒ–è¾“å‡º (Structured output)

#### ToolStrategyï¼ˆé€šç”¨ï¼‰
```python
from pydantic import BaseModel
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy

# è”ç³»ä¿¡æ¯æ¨¡å‹
class ContactInfo(BaseModel):
    name: str
    email: str
    phone: str

agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_tool],
    response_format=ToolStrategy(ContactInfo)
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "ä»ä»¥ä¸‹ä¿¡æ¯ä¸­æå–è”ç³»ä¿¡æ¯ï¼šJohn Doe, john@example.com, (555) 123-4567"}]
})

result["structured_response"]
# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')
```

#### ProviderStrategyï¼ˆæ¨¡å‹ä¾›åº”å•†æ”¯æŒï¼‰
```python
from langchain.agents.structured_output import ProviderStrategy

agent = create_agent(
    model="gpt-4o",
    response_format=ProviderStrategy(ContactInfo)
)
```

### è®°å¿† (Memory)

ä»£ç†é€šè¿‡æ¶ˆæ¯çŠ¶æ€ç»´æŠ¤å¯¹è¯å†å²ï¼Œæ”¯æŒè‡ªå®šä¹‰çŠ¶æ€æ¶æ„ã€‚

#### é€šè¿‡ä¸­é—´ä»¶å®šä¹‰çŠ¶æ€ï¼ˆæ¨èï¼‰
```python
from langchain.agents import AgentState
from langchain.agents.middleware import AgentMiddleware
from typing import Any

# è‡ªå®šä¹‰çŠ¶æ€ç±»
class CustomState(AgentState):
    user_preferences: dict

# è‡ªå®šä¹‰ä¸­é—´ä»¶ç±»
class CustomMiddleware(AgentMiddleware):
    state_schema = CustomState
    tools = [tool1, tool2]

    def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:
        ...

agent = create_agent(
    model,
    tools=tools,
    middleware=[CustomMiddleware()]
)

# ä»£ç†ç°åœ¨å¯ä»¥è·Ÿè¸ªé™¤æ¶ˆæ¯ä¹‹å¤–çš„é¢å¤–çŠ¶æ€
result = agent.invoke({
    "messages": [{"role": "user", "content": "æˆ‘æ›´å–œæ¬¢æŠ€æœ¯è§£é‡Š"}],
    "user_preferences": {"style": "technical", "verbosity": "detailed"},
})
```

#### é€šè¿‡ state_schema å®šä¹‰çŠ¶æ€
```python
from langchain.agents import AgentState

# è‡ªå®šä¹‰çŠ¶æ€ç±»
class CustomState(AgentState):
    user_preferences: dict

agent = create_agent(
    model,
    tools=[tool1, tool2],
    state_schema=CustomState
)
# ä»£ç†ç°åœ¨å¯ä»¥è·Ÿè¸ªé™¤æ¶ˆæ¯ä¹‹å¤–çš„é¢å¤–çŠ¶æ€
result = agent.invoke({
    "messages": [{"role": "user", "content": "æˆ‘æ›´å–œæ¬¢æŠ€æœ¯è§£é‡Š"}],
    "user_preferences": {"style": "technical", "verbosity": "detailed"},
})
```

### æµå¼ä¼ è¾“ (Streaming)

```python
for chunk in agent.stream({
    "messages": [{"role": "user", "content": "æœç´¢ AI æ–°é—»å¹¶æ€»ç»“å‘ç°"}]
}, stream_mode="values"):
    # æ¯ä¸ª chunk åŒ…å«è¯¥æ—¶é—´ç‚¹çš„å®Œæ•´çŠ¶æ€
    latest_message = chunk["messages"][-1]
    if latest_message.content:
        print(f"ä»£ç†: {latest_message.content}")
    elif latest_message.tool_calls:
        print(f"è°ƒç”¨å·¥å…·: {[tc['name'] for tc in latest_message.tool_calls]}")
```

### ä¸­é—´ä»¶ (Middleware)

ä¸­é—´ä»¶æä¾›å¼ºå¤§çš„å¯æ‰©å±•æ€§ï¼Œç”¨äºï¼š
- è°ƒç”¨æ¨¡å‹å‰å¤„ç†çŠ¶æ€ï¼ˆæ¶ˆæ¯ä¿®å‰ªã€ä¸Šä¸‹æ–‡æ³¨å…¥ï¼‰
- ä¿®æ”¹æˆ–éªŒè¯æ¨¡å‹å“åº”ï¼ˆé˜²æŠ¤æœºåˆ¶ã€å†…å®¹è¿‡æ»¤ï¼‰
- è‡ªå®šä¹‰å·¥å…·æ‰§è¡Œé”™è¯¯å¤„ç†
- åŠ¨æ€æ¨¡å‹é€‰æ‹©
- æ·»åŠ æ—¥å¿—è®°å½•ã€ç›‘æ§æˆ–åˆ†æ

ä¸»è¦è£…é¥°å™¨ï¼š`@before_model`ã€`@after_model`ã€`@wrap_tool_call`ã€`@dynamic_prompt`

```py
print("ğŸ”§ ä¸­é—´ä»¶åŠŸèƒ½æ¦‚è§ˆï¼š")
print("ä¸­é—´ä»¶æä¾›å¼ºå¤§çš„å¯æ‰©å±•æ€§ï¼Œç”¨äºï¼š")

middleware_features = [
    "è°ƒç”¨æ¨¡å‹å‰å¤„ç†çŠ¶æ€ï¼ˆæ¶ˆæ¯ä¿®å‰ªã€ä¸Šä¸‹æ–‡æ³¨å…¥ï¼‰",
    "ä¿®æ”¹æˆ–éªŒè¯æ¨¡å‹å“åº”ï¼ˆé˜²æŠ¤æœºåˆ¶ã€å†…å®¹è¿‡æ»¤ï¼‰",
    "è‡ªå®šä¹‰å·¥å…·æ‰§è¡Œé”™è¯¯å¤„ç†",
    "åŠ¨æ€æ¨¡å‹é€‰æ‹©",
    "æ·»åŠ æ—¥å¿—è®°å½•ã€ç›‘æ§æˆ–åˆ†æ"
]

for i, feature in enumerate(middleware_features, 1):
    print(f"{i}. {feature}")

print("\nğŸ¯ ä¸»è¦è£…é¥°å™¨ï¼š")
decorators = [
    "@before_model - åœ¨æ¨¡å‹è°ƒç”¨å‰å¤„ç†",
    "@after_model - åœ¨æ¨¡å‹è°ƒç”¨åå¤„ç†",
    "@wrap_tool_call - åŒ…è£…å·¥å…·è°ƒç”¨",
    "@dynamic_prompt - åŠ¨æ€ç”Ÿæˆæç¤º"
]

for decorator in decorators:
    print(f"  â€¢ {decorator}")

print("\nâœ… ä¸­é—´ä»¶æ¦‚å¿µä»‹ç»å®Œæˆ")
print("ğŸ’¡ æç¤º: ä¸­é—´ä»¶æ˜¯æ‰©å±•ä»£ç†åŠŸèƒ½çš„æ ¸å¿ƒæœºåˆ¶ï¼Œå…è®¸åœ¨ä¸ä¿®æ”¹æ ¸å¿ƒé€»è¾‘çš„æƒ…å†µä¸‹æ·»åŠ å¤æ‚è¡Œä¸º")
```

