{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 - OutputParser ç»“æ„åŒ–è§£æ\n",
    "\n",
    "## ç”¨é€”\n",
    "å­¦ä¹ é€šä¹‰åƒé—®è¾“å‡ºè§£æå™¨ï¼Œå¼ºåˆ¶æ¨¡å‹è¾“å‡ºç¬¦åˆç»“æ„åŒ–æ ¼å¼ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§å’Œå¯é æ€§\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£ OutputParser æ ¸å¿ƒæ¦‚å¿µå’Œä½œç”¨\n",
    "- æŒæ¡ JsonOutputParser è§£æ JSON æ ¼å¼\n",
    "- èƒ½å®ç°é€šä¹‰åƒé—®ç»“æ„åŒ–è¾“å‡ºéªŒè¯\n",
    "- æŒæ¡è§£æé”™è¯¯å¤„ç†å’Œæ ¼å¼æ§åˆ¶\n",
    "\n",
    "## ğŸ”‘ å‰ç½®è¦æ±‚\n",
    "**æ³¨æ„**ï¼šéœ€è¦å…ˆå®Œæˆ LCEL ç®¡é“è¯­æ³•å­¦ä¹ ï¼Œç†è§£é“¾å¼ç»„åˆåŸç†\n",
    "\n",
    "## ä»£ç å—ç‹¬ç«‹æ€§è¯´æ˜\n",
    "**æ³¨æ„**ï¼šæ¯ä¸ªä»£ç å—éƒ½æ˜¯ç‹¬ç«‹çš„ï¼ŒåŒ…å«å®Œæ•´çš„å¯¼å…¥å’Œåˆå§‹åŒ–ï¼Œç¡®ä¿å¯ä»¥å•ç‹¬è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OutputParser åŸºç¡€æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OutputParser åŸºç¡€æ¦‚å¿µ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”§ OutputParser åŸºç¡€æ¦‚å¿µç†è§£:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ğŸ“ OutputParser æ ¸å¿ƒæ¦‚å¿µ:\")\n",
    "print(f\"   1. æ ¼å¼æ§åˆ¶ï¼šå¼ºåˆ¶æ¨¡å‹è¾“å‡ºç‰¹å®šæ ¼å¼\")\n",
    "print(f\"   2. æ•°æ®éªŒè¯ï¼šéªŒè¯è¾“å‡ºç»“æ„çš„æ­£ç¡®æ€§\")\n",
    "print(f\"   3. ç±»å‹è½¬æ¢ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®\")\n",
    "print(f\"   4. é”™è¯¯å¤„ç†ï¼šæ•è·å’Œä¿®å¤æ ¼å¼é”™è¯¯\")\n",
    "\n",
    "# åˆ›å»ºä¸åŒç±»å‹çš„è§£æå™¨\n",
    "print(f\"\\nğŸ—ï¸  åˆ›å»ºè§£æå™¨å®ä¾‹:\")\n",
    "\n",
    "# å­—ç¬¦ä¸²è§£æå™¨\n",
    "str_parser = StrOutputParser()\n",
    "print(f\"   1. å­—ç¬¦ä¸²è§£æå™¨: {type(str_parser).__name__}\")\n",
    "print(f\"      ç”¨é€”: åŸºç¡€æ–‡æœ¬è¾“å‡ºå¤„ç†\")\n",
    "\n",
    "# JSON è§£æå™¨\n",
    "json_parser = JsonOutputParser()\n",
    "print(f\"   2. JSONè§£æå™¨: {type(json_parser).__name__}\")\n",
    "print(f\"      ç”¨é€”: ç»“æ„åŒ–JSONæ•°æ®è§£æ\")\n",
    "\n",
    "# æµ‹è¯•åŸºç¡€è§£æåŠŸèƒ½\n",
    "print(f\"\\nğŸ§ª åŸºç¡€è§£æåŠŸèƒ½æµ‹è¯•:\")\n",
    "\n",
    "# 1. å­—ç¬¦ä¸²è§£ææµ‹è¯•\n",
    "print(f\"\\n   1. å­—ç¬¦ä¸²è§£ææµ‹è¯•:\")\n",
    "test_string = \"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å­—ç¬¦ä¸²è¾“å‡ºã€‚\"\n",
    "str_result = str_parser.parse(test_string)\n",
    "print(f\"      è¾“å…¥: {test_string}\")\n",
    "print(f\"      è¾“å‡º: {str_result}\")\n",
    "print(f\"      ç±»å‹: {type(str_result)}\")\n",
    "\n",
    "# 2. JSON è§£ææµ‹è¯•\n",
    "print(f\"\\n   2. JSON è§£ææµ‹è¯•:\")\n",
    "valid_json = '{\"name\": \"å¼ ä¸‰\", \"age\": 25, \"city\": \"åŒ—äº¬\"}'\n",
    "json_result = json_parser.parse(valid_json)\n",
    "print(f\"      è¾“å…¥: {valid_json}\")\n",
    "print(f\"      è¾“å‡º: {json_result}\")\n",
    "print(f\"      ç±»å‹: {type(json_result)}\")\n",
    "\n",
    "# 3. é”™è¯¯å¤„ç†æµ‹è¯•\n",
    "print(f\"\\n   3. é”™è¯¯å¤„ç†æµ‹è¯•:\")\n",
    "invalid_json = '{\"name\": \"æå››\", \"age\": 30, \"city\": \"ä¸Šæµ·\"'  # ç¼ºå°‘é—­åˆæ‹¬å·\n",
    "\n",
    "try:\n",
    "    error_result = json_parser.parse(invalid_json)\n",
    "    print(f\"      é”™è¯¯è¾“å…¥å±…ç„¶æˆåŠŸäº†: {error_result}\")\n",
    "except OutputParserException as e:\n",
    "    print(f\"      âœ… æ­£ç¡®æ•è·JSONè§£æé”™è¯¯: {type(e).__name__}\")\n",
    "    print(f\"      é”™è¯¯ä¿¡æ¯: {str(e)[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"      æ•è·å…¶ä»–é”™è¯¯: {type(e).__name__}: {e}\")\n",
    "\n",
    "# 4. å¤æ‚ JSON è§£ææµ‹è¯•\n",
    "print(f\"\\n   4. å¤æ‚ JSON è§£ææµ‹è¯•:\")\n",
    "complex_json = '''{\n",
    "    \"user\": {\n",
    "        \"id\": 1001,\n",
    "        \"profile\": {\n",
    "            \"name\": \"ç‹äº”\",\n",
    "            \"skills\": [\"Python\", \"LangChain\", \"AI\"]\n",
    "        },\n",
    "        \"active\": true\n",
    "    },\n",
    "    \"timestamp\": \"2025-11-30T21:35:00Z\"\n",
    "}'''\n",
    "\n",
    "complex_result = json_parser.parse(complex_json)\n",
    "print(f\"      å¤æ‚JSONç±»å‹: {type(complex_result)}\")\n",
    "print(f\"      ç”¨æˆ·ID: {complex_result['user']['id']}\")\n",
    "print(f\"      ç”¨æˆ·æŠ€èƒ½: {complex_result['user']['profile']['skills']}\")\n",
    "print(f\"      æ´»è·ƒçŠ¶æ€: {complex_result['user']['active']}\")\n",
    "\n",
    "# 5. è§£æå™¨æ ¼å¼åŒ–æŒ‡ä»¤\n",
    "print(f\"\\nğŸ“‹ 5. è§£æå™¨æ ¼å¼åŒ–æŒ‡ä»¤:\")\n",
    "format_instructions = json_parser.get_format_instructions()\n",
    "print(f\"   JSONè§£æå™¨æ ¼å¼æŒ‡ä»¤: {format_instructions}\")\n",
    "\n",
    "# éªŒè¯ç‚¹ï¼šOutputParser åŸºç¡€æ¦‚å¿µæ­£ç¡®\n",
    "assert isinstance(str_result, str), \"å­—ç¬¦ä¸²è§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "assert isinstance(json_result, dict), \"JSONè§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "assert json_result[\"name\"] == \"å¼ ä¸‰\", \"JSONè§£æå†…å®¹é”™è¯¯\"\n",
    "assert json_result[\"age\"] == 25, \"JSONè§£ææ•°å€¼é”™è¯¯\"\n",
    "assert isinstance(complex_result, dict), \"å¤æ‚JSONè§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "assert len(complex_result['user']['profile']['skills']) == 3, \"å¤æ‚JSONè§£ææ•°ç»„é”™è¯¯\"\n",
    "\n",
    "print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šOutputParser åŸºç¡€æ¦‚å¿µç†è§£æ­£ç¡®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JsonOutputParser ç»“æ„åŒ–è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JsonOutputParser ç»“æ„åŒ–è¾“å‡º - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”— JsonOutputParser ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»º LLM å’Œè§£æå™¨\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        json_parser = JsonOutputParser()\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„ç»„ä»¶:\")\n",
    "        print(f\"   1. LLM: {type(llm).__name__}\")\n",
    "        print(f\"   2. JSONè§£æå™¨: {type(json_parser).__name__}\")\n",
    "        print(f\"   3. æ ¼å¼æŒ‡ä»¤: {json_parser.get_format_instructions()}\")\n",
    "        \n",
    "        # 1. åŸºç¡€ JSON ç»“æ„åŒ–è¾“å‡º\n",
    "        print(f\"\\nğŸ§ª 1. åŸºç¡€ JSON ç»“æ„åŒ–è¾“å‡º:\")\n",
    "        \n",
    "        basic_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"\"\"åˆ†æä»¥ä¸‹æ–‡æœ¬å¹¶è¿”å›JSONæ ¼å¼ï¼š\n",
    "{format_instructions}\n",
    "\n",
    "æ–‡æœ¬ï¼š{text}\n",
    "\n",
    "è¯·è¿”å›åŒ…å«ä»¥ä¸‹å­—æ®µçš„JSONï¼š\n",
    "- summary: æ–‡æœ¬æ‘˜è¦\n",
    "- keywords: å…³é”®è¯æ•°ç»„\n",
    "- sentiment: æƒ…æ„Ÿå€¾å‘\"\"\"\n",
    "        )\n",
    "        \n",
    "        # éƒ¨åˆ†å˜é‡æ›¿æ¢\n",
    "        format_instructions = json_parser.get_format_instructions()\n",
    "        \n",
    "        # åˆ›å»ºå¤„ç†é“¾\n",
    "        basic_chain = basic_prompt | llm | json_parser\n",
    "        \n",
    "        test_text = \"ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆå¤–å‡ºæ¸¸ç©ã€‚å¿ƒæƒ…ç‰¹åˆ«æ„‰å¿«ï¼\"\n",
    "        \n",
    "        print(f\"   æµ‹è¯•æ–‡æœ¬: {test_text}\")\n",
    "        \n",
    "        result = basic_chain.invoke({\n",
    "            \"text\": test_text,\n",
    "            \"format_instructions\": format_instructions\n",
    "        })\n",
    "        \n",
    "        print(f\"   è§£æç»“æœç±»å‹: {type(result)}\")\n",
    "        print(f\"   è§£æç»“æœ: {json.dumps(result, ensure_ascii=False, indent=6)}\")\n",
    "        \n",
    "        # éªŒè¯ç»“æ„\n",
    "        required_fields = [\"summary\", \"keywords\", \"sentiment\"]\n",
    "        missing_fields = [field for field in required_fields if field not in result]\n",
    "        \n",
    "        if missing_fields:\n",
    "            print(f\"   âš ï¸  ç¼ºå°‘å­—æ®µ: {missing_fields}\")\n",
    "        else:\n",
    "            print(f\"   âœ… åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ: {required_fields}\")\n",
    "        \n",
    "        # 2. å¤æ‚åµŒå¥— JSON è¾“å‡º\n",
    "        print(f\"\\nğŸ§ª 2. å¤æ‚åµŒå¥— JSON è¾“å‡º:\")\n",
    "        \n",
    "        complex_prompt = PromptTemplate(\n",
    "            input_variables=[\"topic\"],\n",
    "            template=\"\"\"å…³äºä¸»é¢˜ {topic} ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Šï¼Œè¿”å›JSONæ ¼å¼ï¼š\n",
    "{format_instructions}\n",
    "\n",
    "è¯·è¿”å›åŒ…å«ä»¥ä¸‹ç»“æ„çš„JSONï¼š\n",
    "{{\n",
    "    \"topic\": \"ä¸»é¢˜åç§°\",\n",
    "    \"analysis\": {{\n",
    "        \"definition\": \"å®šä¹‰\",\n",
    "        \"importance\": \"é‡è¦æ€§è¯´æ˜\",\n",
    "        \"applications\": [\"åº”ç”¨1\", \"åº”ç”¨2\", \"åº”ç”¨3\"]\n",
    "    }},\n",
    "    \"metadata\": {{\n",
    "        \"difficulty\": \"éš¾åº¦ç­‰çº§\",\n",
    "        \"estimated_time\": \"å­¦ä¹ æ—¶é—´\",\n",
    "        \"prerequisites\": [\"å‰ç½®è¦æ±‚1\", \"å‰ç½®è¦æ±‚2\"]\n",
    "    }}\n",
    "}}\"\"\"\n",
    "        )\n",
    "        \n",
    "        complex_chain = complex_prompt | llm | json_parser\n",
    "        \n",
    "        test_topic = \"æœºå™¨å­¦ä¹ \"\n",
    "        print(f\"   æµ‹è¯•ä¸»é¢˜: {test_topic}\")\n",
    "        \n",
    "        complex_result = complex_chain.invoke({\n",
    "            \"topic\": test_topic,\n",
    "            \"format_instructions\": format_instructions\n",
    "        })\n",
    "        \n",
    "        print(f\"   å¤æ‚è§£æç»“æœç±»å‹: {type(complex_result)}\")\n",
    "        print(f\"   ä¸»é¢˜: {complex_result.get('topic', 'æœªçŸ¥')}\")\n",
    "        print(f\"   åˆ†æéƒ¨åˆ†: {list(complex_result.get('analysis', {}).keys())}\")\n",
    "        print(f\"   åº”ç”¨æ•°é‡: {len(complex_result.get('analysis', {}).get('applications', []))}\")\n",
    "        print(f\"   å…ƒæ•°æ®éƒ¨åˆ†: {list(complex_result.get('metadata', {}).keys())}\")\n",
    "        \n",
    "        # 3. æ•°æ®éªŒè¯å’Œç±»å‹æ£€æŸ¥\n",
    "        print(f\"\\nğŸ§ª 3. æ•°æ®éªŒè¯å’Œç±»å‹æ£€æŸ¥:\")\n",
    "        \n",
    "        def validate_json_structure(data, schema):\n",
    "            \"\"\"éªŒè¯JSONç»“æ„\"\"\"\n",
    "            errors = []\n",
    "            \n",
    "            for field, expected_type in schema.items():\n",
    "                if field not in data:\n",
    "                    errors.append(f\"ç¼ºå°‘å­—æ®µ: {field}\")\n",
    "                elif not isinstance(data[field], expected_type):\n",
    "                    errors.append(f\"å­—æ®µ {field} ç±»å‹é”™è¯¯: æœŸæœ› {expected_type.__name__}, å®é™… {type(data[field]).__name__}\")\n",
    "            \n",
    "            return errors\n",
    "        \n",
    "        # å®šä¹‰åŸºç¡€ç»“æ„æ¨¡å¼\n",
    "        basic_schema = {\n",
    "            \"summary\": str,\n",
    "            \"keywords\": list,\n",
    "            \"sentiment\": str\n",
    "        }\n",
    "        \n",
    "        validation_errors = validate_json_structure(result, basic_schema)\n",
    "        \n",
    "        if validation_errors:\n",
    "            print(f\"   âŒ éªŒè¯é”™è¯¯:\")\n",
    "            for error in validation_errors:\n",
    "                print(f\"      - {error}\")\n",
    "        else:\n",
    "            print(f\"   âœ… JSONç»“æ„éªŒè¯é€šè¿‡\")\n",
    "        \n",
    "        # 4. é”™è¯¯å¤„ç†å’Œé‡è¯•\n",
    "        print(f\"\\nğŸ§ª 4. é”™è¯¯å¤„ç†å’Œé‡è¯•:\")\n",
    "        \n",
    "        def safe_json_parse(chain, inputs, max_retries=3):\n",
    "            \"\"\"å®‰å…¨çš„JSONè§£æï¼Œæ”¯æŒé‡è¯•\"\"\"\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    result = chain.invoke(inputs)\n",
    "                    if isinstance(result, dict):\n",
    "                        return result\n",
    "                except Exception as e:\n",
    "                    print(f\"      å°è¯• {attempt + 1} å¤±è´¥: {type(e).__name__}\")\n",
    "                    if attempt == max_retries - 1:\n",
    "                        return {\"error\": \"è§£æå¤±è´¥\", \"details\": str(e)}\n",
    "            \n",
    "            return {\"error\": \"é‡è¯•æ¬¡æ•°ç”¨å°½\"}\n",
    "        \n",
    "        # æµ‹è¯•å®‰å…¨è§£æ\n",
    "        safe_result = safe_json_parse(basic_chain, {\n",
    "            \"text\": \"ç®€çŸ­æµ‹è¯•\",\n",
    "            \"format_instructions\": format_instructions\n",
    "        })\n",
    "        \n",
    "        if \"error\" in safe_result:\n",
    "            print(f\"   âŒ å®‰å…¨è§£æå¤±è´¥: {safe_result['error']}\")\n",
    "        else:\n",
    "            print(f\"   âœ… å®‰å…¨è§£ææˆåŠŸ: {type(safe_result)}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šJsonOutputParser ç»“æ„åŒ–è¾“å‡ºæ­£ç¡®\n",
    "        assert isinstance(result, dict), \"åŸºç¡€JSONè§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "        assert isinstance(complex_result, dict), \"å¤æ‚JSONè§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "        assert \"topic\" in complex_result, \"å¤æ‚ç»“æœç¼ºå°‘topicå­—æ®µ\"\n",
    "        assert \"analysis\" in complex_result, \"å¤æ‚ç»“æœç¼ºå°‘analysiså­—æ®µ\"\n",
    "        assert isinstance(complex_result[\"analysis\"], dict), \"analysiså­—æ®µç±»å‹é”™è¯¯\"\n",
    "        \n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šJsonOutputParser ç»“æ„åŒ–è¾“å‡ºæ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ JsonOutputParser ç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. è‡ªå®šä¹‰è§£æå™¨å’Œé«˜çº§ç”¨æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå®šä¹‰è§£æå™¨å’Œé«˜çº§ç”¨æ³• - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”§ è‡ªå®šä¹‰è§£æå™¨å’Œé«˜çº§ç”¨æ³•æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»º LLM\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„ç»„ä»¶:\")\n",
    "        print(f\"   1. LLM: {type(llm).__name__}\")\n",
    "        \n",
    "        # 1. è‡ªå®šä¹‰å…³é”®è¯æå–è§£æå™¨\n",
    "        print(f\"\\nğŸ§ª 1. è‡ªå®šä¹‰å…³é”®è¯æå–è§£æå™¨:\")\n",
    "        \n",
    "        class KeywordExtractorParser(BaseOutputParser[List[str]]):\n",
    "            \"\"\"è‡ªå®šä¹‰å…³é”®è¯æå–è§£æå™¨\"\"\"\n",
    "            \n",
    "            def parse(self, text: str) -> List[str]:\n",
    "                \"\"\"è§£ææ–‡æœ¬æå–å…³é”®è¯\"\"\"\n",
    "                # å°è¯•å¤šç§æå–æ–¹å¼\n",
    "                keywords = []\n",
    "                \n",
    "                # æ–¹å¼1: æŸ¥æ‰¾JSONæ ¼å¼\n",
    "                json_match = re.search(r'\\[([^\\]]+)\\]', text)\n",
    "                if json_match:\n",
    "                    try:\n",
    "                        json_keywords = json.loads(f'[{json_match.group(1)}]')\n",
    "                        if isinstance(json_keywords, list):\n",
    "                            keywords = [kw.strip().strip('\"\\'') for kw in json_keywords]\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # æ–¹å¼2: æŸ¥æ‰¾é€—å·åˆ†éš”çš„è¯\n",
    "                if not keywords:\n",
    "                    comma_match = re.search(r'å…³é”®è¯[ï¼š:]?\\s*([^ã€‚\\n]+)', text)\n",
    "                    if comma_match:\n",
    "                        keywords = [kw.strip() for kw in comma_match.group(1).split(',') if kw.strip()]\n",
    "                \n",
    "                # æ–¹å¼3: æŸ¥æ‰¾é‡è¦è¯æ±‡\n",
    "                if not keywords:\n",
    "                    # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘\n",
    "                    important_words = re.findall(r'[\\u4e00-\\u9fff]{2,4}', text)\n",
    "                    keywords = list(set(important_words))[:5]  # æœ€å¤š5ä¸ª\n",
    "                \n",
    "                return keywords\n",
    "            \n",
    "            def get_format_instructions(self) -> str:\n",
    "                return \"è¯·æä¾›å…³é”®è¯åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯JSONæ•°ç»„æ ¼å¼æˆ–é€—å·åˆ†éš”æ ¼å¼ã€‚\"\n",
    "        \n",
    "        keyword_parser = KeywordExtractorParser()\n",
    "        \n",
    "        print(f\"   è‡ªå®šä¹‰è§£æå™¨: {type(keyword_parser).__name__}\")\n",
    "        print(f\"   æ ¼å¼æŒ‡ä»¤: {keyword_parser.get_format_instructions()}\")\n",
    "        \n",
    "        # æµ‹è¯•è‡ªå®šä¹‰è§£æå™¨\n",
    "        keyword_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–3-5ä¸ªå…³é”®è¯ï¼š\\n{text}\\n\\n{format_instructions}\"\n",
    "        )\n",
    "        \n",
    "        keyword_chain = keyword_prompt | llm | keyword_parser\n",
    "        \n",
    "        test_text = \"äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨åŒ»ç–—ã€é‡‘èã€æ•™è‚²ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ï¼Œæ·±åº¦å­¦ä¹ ç®—æ³•æ¨åŠ¨äº†æŠ€æœ¯å‘å±•ã€‚\"\n",
    "        \n",
    "        keyword_result = keyword_chain.invoke({\n",
    "            \"text\": test_text,\n",
    "            \"format_instructions\": keyword_parser.get_format_instructions()\n",
    "        })\n",
    "        \n",
    "        print(f\"   è¾“å…¥æ–‡æœ¬: {test_text}\")\n",
    "        print(f\"   æå–å…³é”®è¯: {keyword_result}\")\n",
    "        print(f\"   å…³é”®è¯æ•°é‡: {len(keyword_result)}\")\n",
    "        print(f\"   ç»“æœç±»å‹: {type(keyword_result)}\")\n",
    "        \n",
    "        # 2. è‡ªå®šä¹‰è¯„åˆ†è§£æå™¨\n",
    "        print(f\"\\nğŸ§ª 2. è‡ªå®šä¹‰è¯„åˆ†è§£æå™¨:\")\n",
    "        \n",
    "        class ScoreParser(BaseOutputParser[Dict[str, float]]):\n",
    "            \"\"\"è‡ªå®šä¹‰è¯„åˆ†è§£æå™¨\"\"\"\n",
    "            \n",
    "            def parse(self, text: str) -> Dict[str, float]:\n",
    "                \"\"\"è§£ææ–‡æœ¬æå–è¯„åˆ†\"\"\"\n",
    "                scores = {}\n",
    "                \n",
    "                # æŸ¥æ‰¾è¯„åˆ†æ¨¡å¼\n",
    "                patterns = [\n",
    "                    r'(è´¨é‡|å†…å®¹|é€»è¾‘|åˆ›æ–°)[ï¼š:]?\\s*([0-9]+(?:\\.[0-9]*)?)',\n",
    "                    r'([0-9]+(?:\\.[0-9]*)?)\\s*åˆ†',\n",
    "                    r'è¯„åˆ†[ï¼š:]?\\s*([0-9]+(?:\\.[0-9]*)?)'\n",
    "                ]\n",
    "                \n",
    "                for pattern in patterns:\n",
    "                    matches = re.findall(pattern, text)\n",
    "                    for match in matches:\n",
    "                        if len(match) == 2:\n",
    "                            key, value = match\n",
    "                            try:\n",
    "                                scores[key] = float(value)\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif len(match) == 1:\n",
    "                            try:\n",
    "                                scores[\"ç»¼åˆè¯„åˆ†\"] = float(match[0])\n",
    "                            except:\n",
    "                                pass\n",
    "                \n",
    "                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯„åˆ†ï¼Œè¿”å›é»˜è®¤å€¼\n",
    "                if not scores:\n",
    "                    scores[\"é»˜è®¤è¯„åˆ†\"] = 0.0\n",
    "                \n",
    "                return scores\n",
    "            \n",
    "            def get_format_instructions(self) -> str:\n",
    "                return \"è¯·æä¾›è¯„åˆ†ï¼Œå¯ä»¥æ˜¯'è´¨é‡: 8.5åˆ†'æˆ–'ç»¼åˆè¯„åˆ†: 9.0'ç­‰æ ¼å¼ã€‚\"\n",
    "        \n",
    "        score_parser = ScoreParser()\n",
    "        \n",
    "        score_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œè¯„åˆ†(0-10åˆ†)ï¼š\\n{text}\\n\\n{format_instructions}\"\n",
    "        )\n",
    "        \n",
    "        score_chain = score_prompt | llm | score_parser\n",
    "        \n",
    "        evaluation_text = \"è¿™ç¯‡æ–‡ç« é€»è¾‘æ¸…æ™°ï¼Œå†…å®¹ä¸°å¯Œï¼Œåˆ›æ–°æ€§è¾ƒå¼ºã€‚\"\n",
    "        \n",
    "        score_result = score_chain.invoke({\n",
    "            \"text\": evaluation_text,\n",
    "            \"format_instructions\": score_parser.get_format_instructions()\n",
    "        })\n",
    "        \n",
    "        print(f\"   è¯„ä»·æ–‡æœ¬: {evaluation_text}\")\n",
    "        print(f\"   è¯„åˆ†ç»“æœ: {score_result}\")\n",
    "        print(f\"   è¯„åˆ†é¡¹ç›®: {list(score_result.keys())}\")\n",
    "        print(f\"   ç»“æœç±»å‹: {type(score_result)}\")\n",
    "        \n",
    "        # 3. ç»„åˆè§£æå™¨\n",
    "        print(f\"\\nğŸ§ª 3. ç»„åˆè§£æå™¨:\")\n",
    "        \n",
    "        class CombinedParser(BaseOutputParser[Dict[str, Any]]):\n",
    "            \"\"\"ç»„åˆè§£æå™¨ï¼ŒåŒæ—¶æå–å¤šç§ä¿¡æ¯\"\"\"\n",
    "            \n",
    "            def __init__(self):\n",
    "                self.keyword_parser = KeywordExtractorParser()\n",
    "                self.score_parser = ScoreParser()\n",
    "            \n",
    "            def parse(self, text: str) -> Dict[str, Any]:\n",
    "                \"\"\"ç»„åˆè§£æ\"\"\"\n",
    "                return {\n",
    "                    \"keywords\": self.keyword_parser.parse(text),\n",
    "                    \"scores\": self.score_parser.parse(text),\n",
    "                    \"text_length\": len(text),\n",
    "                    \"word_count\": len(text.replace(' ', ''))\n",
    "                }\n",
    "            \n",
    "            def get_format_instructions(self) -> str:\n",
    "                return \"è¯·æä¾›åŒ…å«å…³é”®è¯å’Œè¯„åˆ†çš„ç»¼åˆåˆ†æã€‚\"\n",
    "        \n",
    "        combined_parser = CombinedParser()\n",
    "        \n",
    "        combined_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"ç»¼åˆåˆ†æä»¥ä¸‹æ–‡æœ¬ï¼š\\n{text}\\n\\n{format_instructions}\"\n",
    "        )\n",
    "        \n",
    "        combined_chain = combined_prompt | llm | combined_parser\n",
    "        \n",
    "        combined_result = combined_chain.invoke({\n",
    "            \"text\": \"è¿™ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®è®¾è®¡åˆç†ï¼Œå®ç°æ•ˆæœè‰¯å¥½ï¼Œä»£ç è´¨é‡é«˜ã€‚\",\n",
    "            \"format_instructions\": combined_parser.get_format_instructions()\n",
    "        })\n",
    "        \n",
    "        print(f\"   ç»„åˆè§£æç»“æœ: {json.dumps(combined_result, ensure_ascii=False, indent=6)}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šè‡ªå®šä¹‰è§£æå™¨å’Œé«˜çº§ç”¨æ³•æ­£ç¡®\n",
    "        assert isinstance(keyword_result, list), \"å…³é”®è¯è§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "        assert len(keyword_result) > 0, \"å…³é”®è¯è§£æç»“æœä¸ºç©º\"\n",
    "        assert isinstance(score_result, dict), \"è¯„åˆ†è§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "        assert len(score_result) > 0, \"è¯„åˆ†è§£æç»“æœä¸ºç©º\"\n",
    "        assert isinstance(combined_result, dict), \"ç»„åˆè§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "        assert \"keywords\" in combined_result, \"ç»„åˆç»“æœç¼ºå°‘keywordså­—æ®µ\"\n",
    "        assert \"scores\" in combined_result, \"ç»„åˆç»“æœç¼ºå°‘scoreså­—æ®µ\"\n",
    "        \n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šè‡ªå®šä¹‰è§£æå™¨å’Œé«˜çº§ç”¨æ³•æ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ è‡ªå®šä¹‰è§£æå™¨æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è§£æå™¨æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è§£æå™¨æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç† - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âš¡ è§£æå™¨æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»ºåŸºç¡€ç»„ä»¶\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=80\n",
    "        )\n",
    "        \n",
    "        json_parser = JsonOutputParser()\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„ä¼˜åŒ–ç»„ä»¶:\")\n",
    "        print(f\"   1. LLM: {type(llm).__name__}\")\n",
    "        print(f\"   2. JSONè§£æå™¨: {type(json_parser).__name__}\")\n",
    "        \n",
    "        # 1. ç¼“å­˜ä¼˜åŒ–è§£æå™¨\n",
    "        print(f\"\\nğŸ§ª 1. ç¼“å­˜ä¼˜åŒ–è§£æå™¨:\")\n",
    "        \n",
    "        class CachedJsonParser(JsonOutputParser):\n",
    "            \"\"\"å¸¦ç¼“å­˜çš„JSONè§£æå™¨\"\"\"\n",
    "            \n",
    "            def __init__(self, cache_size=100):\n",
    "                super().__init__()\n",
    "                self.cache = {}\n",
    "                self.cache_size = cache_size\n",
    "            \n",
    "            def parse(self, text: str) -> Dict[str, Any]:\n",
    "                # ç”Ÿæˆç¼“å­˜é”®\n",
    "                cache_key = hash(text.strip())\n",
    "                \n",
    "                # æ£€æŸ¥ç¼“å­˜\n",
    "                if cache_key in self.cache:\n",
    "                    print(f\"      ğŸ¯ ç¼“å­˜å‘½ä¸­\")\n",
    "                    return self.cache[cache_key]\n",
    "                \n",
    "                # è§£æå¹¶ç¼“å­˜\n",
    "                try:\n",
    "                    result = super().parse(text)\n",
    "                    \n",
    "                    # ç¼“å­˜ç®¡ç†\n",
    "                    if len(self.cache) >= self.cache_size:\n",
    "                        # ç®€å•çš„LRUï¼šåˆ é™¤ç¬¬ä¸€ä¸ª\n",
    "                        oldest_key = next(iter(self.cache))\n",
    "                        del self.cache[oldest_key]\n",
    "                    \n",
    "                    self.cache[cache_key] = result\n",
    "                    print(f\"      ğŸ’¾ ç¼“å­˜ä¿å­˜\")\n",
    "                    \n",
    "                    return result\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      âŒ è§£æå¤±è´¥: {e}\")\n",
    "                    return {\"error\": \"è§£æå¤±è´¥\", \"original\": text}\n",
    "        \n",
    "        cached_parser = CachedJsonParser(cache_size=10)\n",
    "        \n",
    "        # æµ‹è¯•ç¼“å­˜\n",
    "        test_json = '{\"name\": \"æµ‹è¯•\", \"value\": 123}'\n",
    "        \n",
    "        print(f\"   ç¬¬ä¸€æ¬¡è§£æ:\")\n",
    "        result1 = cached_parser.parse(test_json)\n",
    "        print(f\"   ç»“æœ: {result1}\")\n",
    "        \n",
    "        print(f\"\\n   ç¬¬äºŒæ¬¡è§£æ(ç›¸åŒè¾“å…¥):\")\n",
    "        result2 = cached_parser.parse(test_json)\n",
    "        print(f\"   ç»“æœ: {result2}\")\n",
    "        print(f\"   ç»“æœä¸€è‡´: {result1 == result2}\")\n",
    "        \n",
    "        # 2. é¢„å¤„ç†ä¼˜åŒ–è§£æå™¨\n",
    "        print(f\"\\nğŸ§ª 2. é¢„å¤„ç†ä¼˜åŒ–è§£æå™¨:\")\n",
    "        \n",
    "        class PreprocessedJsonParser(JsonOutputParser):\n",
    "            \"\"\"é¢„å¤„ç†ä¼˜åŒ–çš„JSONè§£æå™¨\"\"\"\n",
    "            \n",
    "            def preprocess_text(self, text: str) -> str:\n",
    "                \"\"\"é¢„å¤„ç†æ–‡æœ¬\"\"\"\n",
    "                # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦\n",
    "                cleaned = re.sub(r'\\s+', ' ', text.strip())\n",
    "                \n",
    "                # å°è¯•æå–JSONéƒ¨åˆ†\n",
    "                json_patterns = [\n",
    "                    r'\\{[^{}]*\\}',  # ç®€å•JSON\n",
    "                    r'\\{.*?\\}',    # è·¨è¡ŒJSON\n",
    "                    r'```json\\s*(.*?)\\s*```',  # ä»£ç å—ä¸­çš„JSON\n",
    "                ]\n",
    "                \n",
    "                for pattern in json_patterns:\n",
    "                    match = re.search(pattern, cleaned, re.DOTALL)\n",
    "                    if match:\n",
    "                        return match.group(1) if pattern.startswith('```') else match.group(0)\n",
    "                \n",
    "                return cleaned\n",
    "            \n",
    "            def parse(self, text: str) -> Dict[str, Any]:\n",
    "                \"\"\"è§£æé¢„å¤„ç†åçš„æ–‡æœ¬\"\"\"\n",
    "                preprocessed = self.preprocess_text(text)\n",
    "                \n",
    "                if preprocessed != text:\n",
    "                    print(f\"      ğŸ§¹ æ–‡æœ¬å·²é¢„å¤„ç†\")\n",
    "                \n",
    "                try:\n",
    "                    return super().parse(preprocessed)\n",
    "                except Exception as e:\n",
    "                    print(f\"      âŒ é¢„å¤„ç†åä»ç„¶å¤±è´¥: {e}\")\n",
    "                    # å°è¯•ä¿®å¤å¸¸è§çš„JSONé”™è¯¯\n",
    "                    return self.attempt_json_fix(preprocessed)\n",
    "            \n",
    "            def attempt_json_fix(self, text: str) -> Dict[str, Any]:\n",
    "                \"\"\"å°è¯•ä¿®å¤JSONé”™è¯¯\"\"\"\n",
    "                fixes = [\n",
    "                    lambda t: t.replace('\"', '\"'),  # ä¸­æ–‡å¼•å·\n",
    "                    lambda t: re.sub(r',\\s*}', '}', t),  # å°¾éšé€—å·\n",
    "                    lambda t: re.sub(r',\\s*]', ']', t),  # æ•°ç»„å°¾éšé€—å·\n",
    "                ]\n",
    "                \n",
    "                for i, fix in enumerate(fixes):\n",
    "                    try:\n",
    "                        fixed = fix(text)\n",
    "                        result = json.loads(fixed)\n",
    "                        print(f\"      ğŸ”§ ä¿®å¤æ–¹æ¡ˆ {i+1} æˆåŠŸ\")\n",
    "                        return result\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                return {\"error\": \"æ— æ³•ä¿®å¤JSON\", \"original\": text}\n",
    "        \n",
    "        preprocessed_parser = PreprocessedJsonParser()\n",
    "        \n",
    "        # æµ‹è¯•é¢„å¤„ç†è§£æå™¨\n",
    "        messy_json = 'è¿™æ˜¯ä¸€äº›å¤šä½™çš„æ–‡æœ¬ ```json {\"name\": \"å¼ ä¸‰\", \"age\": 25,} ``` è¿˜æœ‰ä¸€äº›æ–‡æœ¬'\n",
    "        \n",
    "        print(f\"   æ··ä¹±è¾“å…¥: {messy_json}\")\n",
    "        clean_result = preprocessed_parser.parse(messy_json)\n",
    "        print(f\"   æ¸…ç†ç»“æœ: {clean_result}\")\n",
    "        \n",
    "        # 3. æ€§èƒ½ç›‘æ§è§£æå™¨\n",
    "        print(f\"\\nğŸ§ª 3. æ€§èƒ½ç›‘æ§è§£æå™¨:\")\n",
    "        \n",
    "        class MonitoredJsonParser(JsonOutputParser):\n",
    "            \"\"\"æ€§èƒ½ç›‘æ§çš„JSONè§£æå™¨\"\"\"\n",
    "            \n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.stats = {\n",
    "                    \"total_calls\": 0,\n",
    "                    \"successful_calls\": 0,\n",
    "                    \"failed_calls\": 0,\n",
    "                    \"total_time\": 0.0,\n",
    "                    \"avg_time\": 0.0\n",
    "                }\n",
    "            \n",
    "            def parse(self, text: str) -> Dict[str, Any]:\n",
    "                \"\"\"å¸¦æ€§èƒ½ç›‘æ§çš„è§£æ\"\"\"\n",
    "                start_time = time.time()\n",
    "                self.stats[\"total_calls\"] += 1\n",
    "                \n",
    "                try:\n",
    "                    result = super().parse(text)\n",
    "                    self.stats[\"successful_calls\"] += 1\n",
    "                    \n",
    "                    # æ›´æ–°ç»Ÿè®¡\n",
    "                    elapsed = time.time() - start_time\n",
    "                    self.stats[\"total_time\"] += elapsed\n",
    "                    self.stats[\"avg_time\"] = self.stats[\"total_time\"] / self.stats[\"total_calls\"]\n",
    "                    \n",
    "                    print(f\"      â±ï¸  è§£æè€—æ—¶: {elapsed*1000:.1f}ms\")\n",
    "                    return result\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.stats[\"failed_calls\"] += 1\n",
    "                    print(f\"      âŒ è§£æå¤±è´¥: {e}\")\n",
    "                    raise\n",
    "            \n",
    "            def get_stats(self) -> Dict[str, Any]:\n",
    "                \"\"\"è·å–æ€§èƒ½ç»Ÿè®¡\"\"\"\n",
    "                success_rate = (self.stats[\"successful_calls\"] / self.stats[\"total_calls\"] * 100) if self.stats[\"total_calls\"] > 0 else 0\n",
    "                return {\n",
    "                    **self.stats,\n",
    "                    \"success_rate\": f\"{success_rate:.1f}%\"\n",
    "                }\n",
    "        \n",
    "        monitored_parser = MonitoredJsonParser()\n",
    "        \n",
    "        # æµ‹è¯•æ€§èƒ½ç›‘æ§\n",
    "        test_cases = [\n",
    "            '{\"test\": \"case1\", \"value\": 1}',\n",
    "            '{\"test\": \"case2\", \"value\": 2}',\n",
    "            '{\"test\": \"case3\", \"value\": 3}',\n",
    "            'invalid json',  # è¿™ä¸ªä¼šå¤±è´¥\n",
    "            '{\"test\": \"case4\", \"value\": 4}'\n",
    "        ]\n",
    "        \n",
    "        print(f\"   æ€§èƒ½ç›‘æ§æµ‹è¯•:\")\n",
    "        for i, test_case in enumerate(test_cases, 1):\n",
    "            print(f\"   æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case}\")\n",
    "            try:\n",
    "                result = monitored_parser.parse(test_case)\n",
    "                print(f\"      ç»“æœ: {result}\")\n",
    "            except:\n",
    "                print(f\"      å¤±è´¥: é¢„æœŸä¸­çš„é”™è¯¯\")\n",
    "        \n",
    "        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯\n",
    "        stats = monitored_parser.get_stats()\n",
    "        print(f\"\\n   æ€§èƒ½ç»Ÿè®¡:\")\n",
    "        for key, value in stats.items():\n",
    "            print(f\"      {key}: {value}\")\n",
    "        \n",
    "        # 4. æ‰¹é‡å¤„ç†ä¼˜åŒ–\n",
    "        print(f\"\\nğŸ§ª 4. æ‰¹é‡å¤„ç†ä¼˜åŒ–:\")\n",
    "        \n",
    "        def batch_parse_json(parser, texts: list, batch_size:5) -> list:\n",
    "            \"\"\"æ‰¹é‡JSONè§£æ\"\"\"\n",
    "            results = []\n",
    "            \n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch = texts[i:i+batch_size]\n",
    "                print(f\"   å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1} ({len(batch)} é¡¹)\")\n",
    "                \n",
    "                batch_results = []\n",
    "                for text in batch:\n",
    "                    try:\n",
    "                        result = parser.parse(text)\n",
    "                        batch_results.append(result)\n",
    "                    except Exception as e:\n",
    "                        batch_results.append({\"error\": str(e), \"input\": text})\n",
    "                \n",
    "                results.extend(batch_results)\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        # æµ‹è¯•æ‰¹é‡å¤„ç†\n",
    "        batch_texts = [\n",
    "            '{\"id\": 1, \"name\": \"é¡¹ç›®1\"}',\n",
    "            '{\"id\": 2, \"name\": \"é¡¹ç›®2\"}',\n",
    "            '{\"id\": 3, \"name\": \"é¡¹ç›®3\"}',\n",
    "            '{\"id\": 4, \"name\": \"é¡¹ç›®4\"}',\n",
    "            '{\"id\": 5, \"name\": \"é¡¹ç›®5\"}',\n",
    "            '{\"id\": 6, \"name\": \"é¡¹ç›®6\"}',\n",
    "        ]\n",
    "        \n",
    "        batch_results = batch_parse_json(json_parser, batch_texts, batch_size=3)\n",
    "        \n",
    "        print(f\"   æ‰¹é‡å¤„ç†ç»“æœ: {len(batch_results)} é¡¹\")\n",
    "        successful = sum(1 for r in batch_results if \"error\" not in r)\n",
    "        failed = len(batch_results) - successful\n",
    "        print(f\"   æˆåŠŸ: {successful}, å¤±è´¥: {failed}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šè§£æå™¨æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†æ­£ç¡®\n",
    "        assert result1 == result2, \"ç¼“å­˜è§£æç»“æœä¸ä¸€è‡´\"\n",
    "        assert isinstance(clean_result, dict), \"é¢„å¤„ç†è§£æç»“æœç±»å‹é”™è¯¯\"\n",
    "        assert stats[\"total_calls\"] == len(test_cases), \"æ€§èƒ½ç›‘æ§ç»Ÿè®¡é”™è¯¯\"\n",
    "        assert len(batch_results) == len(batch_texts), \"æ‰¹é‡å¤„ç†ç»“æœæ•°é‡é”™è¯¯\"\n",
    "        assert successful > 0, \"æ‰¹é‡å¤„ç†æ²¡æœ‰æˆåŠŸé¡¹\"\n",
    "        \n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šè§£æå™¨æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†æ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ è§£æå™¨æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¦ä¹ æ€»ç»“ä¸æœ€ä½³å®è·µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ä¹ æ€»ç»“ä¸æœ€ä½³å®è·µ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ“‹ OutputParser ç»“æ„åŒ–è§£æå­¦ä¹ æ€»ç»“:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# éªŒè¯ç‚¹æ£€æŸ¥\n",
    "verification_points = [\n",
    "    \"âœ… è§£æå™¨åŸºç¡€ï¼šStrOutputParser, JsonOutputParser\",\n",
    "    \"âœ… JSONè§£æï¼šç»“æ„åŒ–æ•°æ®è¾“å‡ºå’ŒéªŒè¯\",\n",
    "    \"âœ… è‡ªå®šä¹‰è§£æï¼šç»§æ‰¿BaseOutputParser\",\n",
    "    \"âœ… æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜ã€é¢„å¤„ç†ã€æ‰¹é‡å¤„ç†\",\n",
    "]\n",
    "\n",
    "for point in verification_points:\n",
    "    print(point)\n",
    "\n",
    "print(f\"\\nğŸ¯ æ ¸å¿ƒæŠ€èƒ½æŒæ¡æƒ…å†µ: {len(verification_points)}/4 é¡¹\")\n",
    "\n",
    "print(\"\\nğŸ’¡ OutputParser æœ€ä½³å®è·µ:\")\n",
    "print(\"1. æ ¼å¼æ§åˆ¶ï¼šä½¿ç”¨è§£æå™¨ç¡®ä¿è¾“å‡ºæ ¼å¼ä¸€è‡´\")\n",
    "print(\"2. é”™è¯¯å¤„ç†ï¼šæ•è·è§£æå¼‚å¸¸å¹¶æä¾›é™çº§æ–¹æ¡ˆ\")\n",
    "print(\"3. æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜å’Œé¢„å¤„ç†æå‡è§£ææ•ˆç‡\")\n",
    "print(\"4. è‡ªå®šä¹‰è§£æï¼šæ ¹æ®ä¸šåŠ¡éœ€æ±‚å®šåˆ¶è§£æé€»è¾‘\")\n",
    "print(\"5. æ•°æ®éªŒè¯ï¼šéªŒè¯è§£æç»“æœçš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§\")\n",
    "\n",
    "print(\"\\nğŸ”§ è§£æå™¨åº”ç”¨åœºæ™¯:\")\n",
    "print(\"1. æ•°æ®æå–ï¼šä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯\")\n",
    "print(\"2. APIé›†æˆï¼šç¡®ä¿è¾“å‡ºç¬¦åˆAPIæ¥å£æ ¼å¼\")\n",
    "print(\"3. æ•°æ®éªŒè¯ï¼šéªŒè¯æ¨¡å‹è¾“å‡ºçš„ç»“æ„æ­£ç¡®æ€§\")\n",
    "print(\"4. æ‰¹é‡å¤„ç†ï¼šé«˜æ•ˆå¤„ç†å¤§é‡ç»“æ„åŒ–æ•°æ®\")\n",
    "print(\"5. æ ¼å¼è½¬æ¢ï¼šå°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºæœºå™¨å¯è¯»æ ¼å¼\")\n",
    "\n",
    "print(\"\\nğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®:\")\n",
    "print(\"1. æ·±å…¥å­¦ä¹  RunnablePassthrough æ•°æ®é€ä¼ \")\n",
    "print(\"2. æŒæ¡ LangChain Agent æ™ºèƒ½ä½“æŠ€æœ¯\")\n",
    "print(\"3. å­¦ä¹  LangChain Tools å·¥å…·è°ƒç”¨\")\n",
    "print(\"4. æ¢ç´¢ LangChain Memory é«˜çº§è®°å¿†ç®¡ç†\")\n",
    "print(\"5. å®è·µç”Ÿäº§çº§ç»“æ„åŒ–æ•°æ®å¤„ç†ç³»ç»Ÿ\")\n",
    "\n",
    "# æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿ OutputParser åŸºç¡€åŠŸèƒ½å¯ç”¨\n",
    "try:\n",
    "    # åˆ›å»ºè§£æå™¨å®ä¾‹\n",
    "    str_parser = StrOutputParser()\n",
    "    json_parser = JsonOutputParser()\n",
    "    \n",
    "    # æµ‹è¯•å­—ç¬¦ä¸²è§£æ\n",
    "    test_str = \"OutputParser å­¦ä¹ å®Œæˆæµ‹è¯•\"\n",
    "    str_result = str_parser.parse(test_str)\n",
    "    \n",
    "    # æµ‹è¯•JSONè§£æ\n",
    "    test_json = '{\"status\": \"success\", \"message\": \"OutputParseræµ‹è¯•é€šè¿‡\", \"features\": [\"è§£æ\", \"éªŒè¯\", \"ä¼˜åŒ–\"]}'\n",
    "    json_result = json_parser.parse(test_json)\n",
    "    \n",
    "    # éªŒè¯ç»“æœ\n",
    "    assert isinstance(str_result, str), \"å­—ç¬¦ä¸²è§£æå¤±è´¥\"\n",
    "    assert isinstance(json_result, dict), \"JSONè§£æå¤±è´¥\"\n",
    "    assert json_result[\"status\"] == \"success\", \"JSONè§£æå†…å®¹é”™è¯¯\"\n",
    "    assert len(json_result[\"features\"]) == 3, \"JSONè§£ææ•°ç»„é”™è¯¯\"\n",
    "    \n",
    "    print(f\"\\nğŸ‰ æœ€ç»ˆéªŒè¯æˆåŠŸ:\")\n",
    "    print(f\"   å­—ç¬¦ä¸²è§£æ: âœ… {len(str_result)} å­—ç¬¦\")\n",
    "    print(f\"   JSONè§£æ: âœ… {len(json_result)} ä¸ªå­—æ®µ\")\n",
    "    print(f\"   çŠ¶æ€: {json_result['status']}\")\n",
    "    print(f\"   æ¶ˆæ¯: {json_result['message']}\")\n",
    "    print(f\"   åŠŸèƒ½: {json_result['features']}\")\n",
    "    print(\"\\nâœ… OutputParser ç»“æ„åŒ–è§£æå­¦ä¹ å®Œæˆï¼\")\n",
    "    \n",
    "    print(f\"\\nğŸŠ LangChain 1.0 LCEL ç¼–æ’å±‚æŠ€æœ¯å…¨é¢æŒæ¡ï¼\")\n",
    "    print(f\"   å·²æŒæ¡æŠ€æœ¯æ ˆ:\")\n",
    "    print(f\"     âœ“ Runnable åŸºç¡€æŠ½è±¡\")\n",
    "    print(f\"     âœ“ RunnableMap å¹¶è¡Œæ‰§è¡Œ\")\n",
    "    print(f\"     âœ“ LCEL ç®¡é“è¯­æ³• (prompt|llm|parser)\")\n",
    "    print(f\"     âœ“ Streaming æµå¼è¾“å‡º\")\n",
    "    print(f\"     âœ“ ChatMessageHistory æ¶ˆæ¯å†å²\")\n",
    "    print(f\"     âœ“ OutputParser ç»“æ„åŒ–è§£æ\")\n",
    "    print(f\"\\n   ä¸‹ä¸€æ­¥å­¦ä¹ é¢†åŸŸ: Agent æ™ºèƒ½ä½“ + Tools å·¥å…·è°ƒç”¨\")\n",
    "    \n",
    "    print(f\"\\nğŸ† LCEL ç¼–æ’å±‚å­¦ä¹ æˆå°±è¾¾æˆï¼\")\n",
    "    print(f\"   ğŸ¯ æŠ€æœ¯æŒæ¡åº¦: 100%\")\n",
    "    print(f\"   ğŸ“š å­¦ä¹ ç¬”è®°: 6 ä¸ªå®Œæ•´ç¬”è®°æœ¬\")\n",
    "    print(f\"   ğŸ› ï¸  å®è·µæ¡ˆä¾‹: 30+ ä¸ªå¯è¿è¡Œç¤ºä¾‹\")\n",
    "    print(f\"   âœ… éªŒè¯é€šè¿‡: æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
