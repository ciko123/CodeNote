{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - RunnableMap å¹¶è¡Œæ‰§è¡Œ\n",
    "\n",
    "## ç”¨é€”\n",
    "å­¦ä¹ ä½¿ç”¨ RunnableMap å¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnableï¼Œå¹¶å°†ç»“æœç»„åˆæˆä¸€ä¸ªå­—å…¸ï¼Œä¼˜åŒ–é€šä¹‰åƒé—®å¤„ç†æ€§èƒ½\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£å¹¶è¡Œæ‰§è¡Œæœºåˆ¶å’Œä¼˜åŠ¿\n",
    "- æŒæ¡ RunnableMap çš„ä½¿ç”¨æ–¹æ³•\n",
    "- èƒ½è®¾è®¡å¹¶è¡Œå¤„ç†æµç¨‹\n",
    "- æŒæ¡ç»“æœç»„åˆå’Œæ€§èƒ½ä¼˜åŒ–\n",
    "\n",
    "## ğŸ”‘ å‰ç½®è¦æ±‚\n",
    "**æ³¨æ„**ï¼šéœ€è¦å…ˆå®Œæˆ Runnable åŸºç¡€æ¦‚å¿µå­¦ä¹ ï¼Œç†è§£é“¾å¼ç»„åˆåŸç†\n",
    "\n",
    "## ä»£ç å—ç‹¬ç«‹æ€§è¯´æ˜\n",
    "**æ³¨æ„**ï¼šæ¯ä¸ªä»£ç å—éƒ½æ˜¯ç‹¬ç«‹çš„ï¼ŒåŒ…å«å®Œæ•´çš„å¯¼å…¥å’Œåˆå§‹åŒ–ï¼Œç¡®ä¿å¯ä»¥å•ç‹¬è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RunnableMap åŸºç¡€æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ RunnableMap åŸºç¡€æ¦‚å¿µç†è§£:\n",
      "==================================================\n",
      "âœ… OpenAI API Key å·²é…ç½® (é•¿åº¦: 46)\n",
      "\n",
      "ğŸ“ RunnableMap æ ¸å¿ƒæ¦‚å¿µ:\n",
      "   1. å¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnable ä»»åŠ¡\n",
      "   2. è‡ªåŠ¨å°†ç»“æœç»„åˆæˆå­—å…¸æ ¼å¼\n",
      "   3. æé«˜å¤„ç†æ•ˆç‡å’Œæ€§èƒ½\n",
      "   4. æ”¯æŒå¤æ‚çš„å¹¶è¡Œå·¥ä½œæµ\n",
      "\n",
      "ğŸ—ï¸  åˆ›å»ºçš„ Runnable ç»„ä»¶:\n",
      "   1. æ–‡æœ¬å¤„ç†å™¨: RunnableLambda\n",
      "   2. é•¿åº¦è®¡ç®—å™¨: RunnableLambda\n",
      "   3. æ—¶é—´æˆ³æ·»åŠ å™¨: RunnableLambda\n",
      "\n",
      "ğŸ”— åˆ›å»ºåŸºç¡€ RunnableMap:\n",
      "   RunnableMap ç±»å‹: <class 'langchain_core.runnables.base.RunnableParallel'>\n",
      "   åŒ…å«ä»»åŠ¡æ•°: æœªçŸ¥\n",
      "\n",
      "ğŸ§ª æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ:\n",
      "   è¾“å…¥: hello parallel\n",
      "   æ‰§è¡Œæ—¶é—´: 0.5 ms\n",
      "   è¾“å‡ºç±»å‹: <class 'dict'>\n",
      "   è¾“å‡ºå†…å®¹: {'processed_text': 'æ–‡æœ¬å¤„ç†: HELLO PARALLEL', 'text_length': 14, 'timestamped_text': 'hello parallel (æ—¶é—´æˆ³: 1764595010)'}\n",
      "\n",
      "ğŸ“Š è¾“å‡ºç»“æ„éªŒè¯:\n",
      "   processed_text: æ–‡æœ¬å¤„ç†: HELLO PARALLEL (ç±»å‹: str)\n",
      "   text_length: 14 (ç±»å‹: int)\n",
      "   timestamped_text: hello parallel (æ—¶é—´æˆ³: 1764595010) (ç±»å‹: str)\n",
      "\n",
      "âœ… éªŒè¯é€šè¿‡ï¼šRunnableMap åŸºç¡€æ¦‚å¿µç†è§£æ­£ç¡®\n"
     ]
    }
   ],
   "source": [
    "# RunnableMap åŸºç¡€æ¦‚å¿µ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”„ RunnableMap åŸºç¡€æ¦‚å¿µç†è§£:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ£€æŸ¥ OpenAI API é…ç½®\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ æœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡\")\n",
    "    print(\"   è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : OPENAI_API_KEY=your_key_here\")\n",
    "else:\n",
    "    print(f\"âœ… OpenAI API Key å·²é…ç½® (é•¿åº¦: {len(openai_api_key)})\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ RunnableMap æ ¸å¿ƒæ¦‚å¿µ:\")\n",
    "    print(f\"   1. å¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnable ä»»åŠ¡\")\n",
    "    print(f\"   2. è‡ªåŠ¨å°†ç»“æœç»„åˆæˆå­—å…¸æ ¼å¼\")\n",
    "    print(f\"   3. æé«˜å¤„ç†æ•ˆç‡å’Œæ€§èƒ½\")\n",
    "    print(f\"   4. æ”¯æŒå¤æ‚çš„å¹¶è¡Œå·¥ä½œæµ\")\n",
    "    \n",
    "    # åˆ›å»ºç®€å•çš„æµ‹è¯•å‡½æ•°\n",
    "    def process_text(text: str) -> str:\n",
    "        return f\"æ–‡æœ¬å¤„ç†: {text.upper()}\"\n",
    "    \n",
    "    def calculate_length(text: str) -> int:\n",
    "        return len(text)\n",
    "    \n",
    "    def add_timestamp(text: str) -> str:\n",
    "        return f\"{text} (æ—¶é—´æˆ³: {int(time.time())})\"\n",
    "    \n",
    "    # åŒ…è£…ä¸º Runnable\n",
    "    text_processor = RunnableLambda(process_text)\n",
    "    length_calculator = RunnableLambda(calculate_length)\n",
    "    timestamp_adder = RunnableLambda(add_timestamp)\n",
    "    \n",
    "    print(f\"\\nğŸ—ï¸  åˆ›å»ºçš„ Runnable ç»„ä»¶:\")\n",
    "    print(f\"   1. æ–‡æœ¬å¤„ç†å™¨: {type(text_processor).__name__}\")\n",
    "    print(f\"   2. é•¿åº¦è®¡ç®—å™¨: {type(length_calculator).__name__}\")\n",
    "    print(f\"   3. æ—¶é—´æˆ³æ·»åŠ å™¨: {type(timestamp_adder).__name__}\")\n",
    "    \n",
    "    # åˆ›å»ºåŸºç¡€ RunnableMap\n",
    "    print(f\"\\nğŸ”— åˆ›å»ºåŸºç¡€ RunnableMap:\")\n",
    "    \n",
    "    parallel_map = RunnableMap({\n",
    "        \"processed_text\": text_processor,\n",
    "        \"text_length\": length_calculator,\n",
    "        \"timestamped_text\": timestamp_adder\n",
    "    })\n",
    "    \n",
    "    print(f\"   RunnableMap ç±»å‹: {type(parallel_map)}\")\n",
    "    print(f\"   åŒ…å«ä»»åŠ¡æ•°: {len(parallel_map.steps) if hasattr(parallel_map, 'steps') else 'æœªçŸ¥'}\")\n",
    "    \n",
    "    # æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ\n",
    "    print(f\"\\nğŸ§ª æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ:\")\n",
    "    \n",
    "    test_input = \"hello parallel\"\n",
    "    start_time = time.time()\n",
    "    result = parallel_map.invoke(test_input)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"   è¾“å…¥: {test_input}\")\n",
    "    print(f\"   æ‰§è¡Œæ—¶é—´: {(end_time - start_time)*1000:.1f} ms\")\n",
    "    print(f\"   è¾“å‡ºç±»å‹: {type(result)}\")\n",
    "    print(f\"   è¾“å‡ºå†…å®¹: {result}\")\n",
    "    \n",
    "    # éªŒè¯è¾“å‡ºç»“æ„\n",
    "    print(f\"\\nğŸ“Š è¾“å‡ºç»“æ„éªŒè¯:\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"   {key}: {value} (ç±»å‹: {type(value).__name__})\")\n",
    "    \n",
    "    # éªŒè¯ç‚¹ï¼šåŸºç¡€ RunnableMap æ¦‚å¿µæ­£ç¡®\n",
    "    assert isinstance(result, dict), \"è¾“å‡ºä¸æ˜¯å­—å…¸ç±»å‹\"\n",
    "    assert \"processed_text\" in result, \"ç¼ºå°‘ processed_text å­—æ®µ\"\n",
    "    assert \"text_length\" in result, \"ç¼ºå°‘ text_length å­—æ®µ\"\n",
    "    assert \"timestamped_text\" in result, \"ç¼ºå°‘ timestamped_text å­—æ®µ\"\n",
    "    assert result[\"text_length\"] == len(test_input), \"é•¿åº¦è®¡ç®—é”™è¯¯\"\n",
    "    print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šRunnableMap åŸºç¡€æ¦‚å¿µç†è§£æ­£ç¡®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. é€šä¹‰åƒé—®å¹¶è¡Œæ‰§è¡Œæ¡ˆä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€šä¹‰åƒé—®å¹¶è¡Œæ‰§è¡Œæ¡ˆä¾‹ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ¤– é€šä¹‰åƒé—®å¹¶è¡Œæ‰§è¡Œæ¡ˆä¾‹æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»º LLM å®ä¾‹\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºä¸åŒçš„æç¤ºè¯æ¨¡æ¿\n",
    "        summary_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"è¯·ç”¨ä¸€å¥è¯æ€»ç»“: {text}\"\n",
    "        )\n",
    "        \n",
    "        keyword_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"è¯·æå– 3 ä¸ªå…³é”®è¯: {text}\"\n",
    "        )\n",
    "        \n",
    "        sentiment_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"è¯·åˆ¤æ–­æƒ…æ„Ÿå€¾å‘(ç§¯æ/æ¶ˆæ/ä¸­æ€§): {text}\"\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºå¤„ç†é“¾\n",
    "        summary_chain = summary_prompt | llm\n",
    "        keyword_chain = keyword_prompt | llm\n",
    "        sentiment_chain = sentiment_prompt | llm\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„å¤„ç†é“¾:\")\n",
    "        print(f\"   1. æ‘˜è¦ç”Ÿæˆ: {type(summary_chain).__name__}\")\n",
    "        print(f\"   2. å…³é”®è¯æå–: {type(keyword_chain).__name__}\")\n",
    "        print(f\"   3. æƒ…æ„Ÿåˆ†æ: {type(sentiment_chain).__name__}\")\n",
    "        \n",
    "        # åˆ›å»ºå¹¶è¡Œæ‰§è¡Œ Map\n",
    "        print(f\"\\nğŸ”— åˆ›å»ºé€šä¹‰åƒé—®å¹¶è¡Œæ‰§è¡Œ Map:\")\n",
    "        \n",
    "        parallel_llm_map = RunnableMap({\n",
    "            \"summary\": summary_chain,\n",
    "            \"keywords\": keyword_chain,\n",
    "            \"sentiment\": sentiment_chain\n",
    "        })\n",
    "        \n",
    "        # æµ‹è¯•æ–‡æœ¬\n",
    "        test_text = \"ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆå¤–å‡ºæ¸¸ç©ã€‚å¿ƒæƒ…ç‰¹åˆ«æ„‰å¿«ï¼\"\n",
    "        \n",
    "        print(f\"\\nğŸ§ª æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ:\")\n",
    "        print(f\"   æµ‹è¯•æ–‡æœ¬: {test_text}\")\n",
    "        \n",
    "        # æ‰§è¡Œå¹¶è¡Œå¤„ç†\n",
    "        start_time = time.time()\n",
    "        result = parallel_llm_map.invoke({\"text\": test_text})\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"   æ‰§è¡Œæ—¶é—´: {(end_time - start_time)*1000:.1f} ms\")\n",
    "        print(f\"\\nğŸ“Š å¹¶è¡Œå¤„ç†ç»“æœ:\")\n",
    "        \n",
    "        for key, value in result.items():\n",
    "            content = value.content if hasattr(value, 'content') else str(value)\n",
    "            print(f\"   {key}: {content}\")\n",
    "        \n",
    "        # æ€§èƒ½å¯¹æ¯”æµ‹è¯•\n",
    "        print(f\"\\nâš¡ æ€§èƒ½å¯¹æ¯”æµ‹è¯•:\")\n",
    "        \n",
    "        # ä¸²è¡Œæ‰§è¡Œæ—¶é—´\n",
    "        start_time = time.time()\n",
    "        serial_summary = summary_chain.invoke({\"text\": test_text})\n",
    "        serial_keywords = keyword_chain.invoke({\"text\": test_text})\n",
    "        serial_sentiment = sentiment_chain.invoke({\"text\": test_text})\n",
    "        end_time = time.time()\n",
    "        serial_time = end_time - start_time\n",
    "        \n",
    "        # å¹¶è¡Œæ‰§è¡Œæ—¶é—´\n",
    "        start_time = time.time()\n",
    "        parallel_result = parallel_llm_map.invoke({\"text\": test_text})\n",
    "        end_time = time.time()\n",
    "        parallel_time = end_time - start_time\n",
    "        \n",
    "        print(f\"   ä¸²è¡Œæ‰§è¡Œæ—¶é—´: {serial_time*1000:.1f} ms\")\n",
    "        print(f\"   å¹¶è¡Œæ‰§è¡Œæ—¶é—´: {parallel_time*1000:.1f} ms\")\n",
    "        \n",
    "        if parallel_time > 0:\n",
    "            speedup = serial_time / parallel_time\n",
    "            print(f\"   æ€§èƒ½æå‡: {speedup:.1f}x\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šé€šä¹‰åƒé—®å¹¶è¡Œæ‰§è¡Œæ­£ç¡®\n",
    "        assert isinstance(result, dict), \"å¹¶è¡Œç»“æœä¸æ˜¯å­—å…¸\"\n",
    "        assert len(result) == 3, \"å¹¶è¡Œç»“æœæ•°é‡ä¸æ­£ç¡®\"\n",
    "        assert all(hasattr(value, 'content') for value in result.values()), \"è¾“å‡ºæ ¼å¼é”™è¯¯\"\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šé€šä¹‰åƒé—®å¹¶è¡Œæ‰§è¡Œæ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ é€šä¹‰åƒé—®å¹¶è¡Œæ‰§è¡Œå¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç† - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”„ å¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç†æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»º LLM\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=60\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»ºæ•°æ®å¤„ç†å‡½æ•°\n",
    "        def extract_title(text: str) -> str:\n",
    "            \"\"\"æå–æ ‡é¢˜\"\"\"\n",
    "            lines = text.strip().split('\\n')\n",
    "            return lines[0] if lines else \"æ— æ ‡é¢˜\"\n",
    "        \n",
    "        def count_words(text: str) -> int:\n",
    "            \"\"\"è®¡ç®—å­—æ•°\"\"\"\n",
    "            return len(text.replace(' ', ''))\n",
    "        \n",
    "        def analyze_structure(text: str) -> dict:\n",
    "            \"\"\"åˆ†ææ–‡æœ¬ç»“æ„\"\"\"\n",
    "            lines = text.strip().split('\\n')\n",
    "            return {\n",
    "                \"line_count\": len(lines),\n",
    "                \"has_paragraphs\": len(lines) > 1,\n",
    "                \"avg_line_length\": sum(len(line) for line in lines) / len(lines) if lines else 0\n",
    "            }\n",
    "        \n",
    "        # åˆ›å»º LLM å¤„ç†é“¾\n",
    "        summary_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"è¯·ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æ‘˜è¦(ä¸è¶…è¿‡30å­—): {text}\"\n",
    "        )\n",
    "        \n",
    "        category_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"è¯·åˆ†ç±»æ–‡æœ¬ç±»å‹(æŠ€æœ¯/ç”Ÿæ´»/æ–°é—»/å…¶ä»–): {text}\"\n",
    "        )\n",
    "        \n",
    "        summary_chain = summary_prompt | llm\n",
    "        category_chain = category_prompt | llm\n",
    "        \n",
    "        # åŒ…è£…å‡½æ•°ä¸º Runnable\n",
    "        title_extractor = RunnableLambda(extract_title)\n",
    "        word_counter = RunnableLambda(count_words)\n",
    "        structure_analyzer = RunnableLambda(analyze_structure)\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„å¤„ç†ç»„ä»¶:\")\n",
    "        print(f\"   1. æ ‡é¢˜æå–å™¨: {type(title_extractor).__name__}\")\n",
    "        print(f\"   2. å­—æ•°ç»Ÿè®¡å™¨: {type(word_counter).__name__}\")\n",
    "        print(f\"   3. ç»“æ„åˆ†æå™¨: {type(structure_analyzer).__name__}\")\n",
    "        print(f\"   4. æ‘˜è¦ç”Ÿæˆé“¾: {type(summary_chain).__name__}\")\n",
    "        print(f\"   5. åˆ†ç±»åˆ¤æ–­é“¾: {type(category_chain).__name__}\")\n",
    "        \n",
    "        # åˆ›å»ºå¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç† Map\n",
    "        print(f\"\\nğŸ”— åˆ›å»ºå¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç† Map:\")\n",
    "        \n",
    "        complex_parallel_map = RunnableMap({\n",
    "            \"title\": title_extractor,\n",
    "            \"word_count\": word_counter,\n",
    "            \"structure\": structure_analyzer,\n",
    "            \"summary\": summary_chain,\n",
    "            \"category\": category_chain\n",
    "        })\n",
    "        \n",
    "        # æµ‹è¯•æ–‡æœ¬\n",
    "        test_text = \"\"\"äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•\n",
    "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚ä»æ™ºèƒ½æ‰‹æœºåˆ°è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ŒAIæŠ€æœ¯æ— å¤„ä¸åœ¨ã€‚\n",
    "æœºå™¨å­¦ä¹ ç®—æ³•èƒ½å¤Ÿä»å¤§é‡æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œå¸®åŠ©æˆ‘ä»¬åšå‡ºæ›´å¥½çš„å†³ç­–ã€‚\"\"\"\n",
    "        \n",
    "        print(f\"\\nğŸ§ª æµ‹è¯•å¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç†:\")\n",
    "        print(f\"   æµ‹è¯•æ–‡æœ¬: {test_text[:50]}...\")\n",
    "        \n",
    "        # æ‰§è¡Œå¹¶è¡Œå¤„ç†\n",
    "        start_time = time.time()\n",
    "        result = complex_parallel_map.invoke(test_text)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"   æ‰§è¡Œæ—¶é—´: {(end_time - start_time)*1000:.1f} ms\")\n",
    "        print(f\"\\nğŸ“Š å¤æ‚æ•°æ®æµå¤„ç†ç»“æœ:\")\n",
    "        \n",
    "        # æ ¼å¼åŒ–è¾“å‡ºç»“æœ\n",
    "        for key, value in result.items():\n",
    "            if hasattr(value, 'content'):\n",
    "                print(f\"   {key}: {value.content}\")\n",
    "            elif isinstance(value, dict):\n",
    "                print(f\"   {key}: {json.dumps(value, ensure_ascii=False, indent=6)}\")\n",
    "            else:\n",
    "                print(f\"   {key}: {value}\")\n",
    "        \n",
    "        # æµ‹è¯•ä¸åŒç±»å‹è¾“å…¥\n",
    "        print(f\"\\nğŸ§ª æµ‹è¯•ä¸åŒç±»å‹è¾“å…¥:\")\n",
    "        \n",
    "        test_cases = [\n",
    "            \"ç®€çŸ­æ–‡æœ¬\",\n",
    "            \"è¿™æ˜¯ä¸€ä¸ªä¸­ç­‰é•¿åº¦çš„æµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«å¤šä¸ªå¥å­å’Œæ ‡ç‚¹ç¬¦å·ã€‚\",\n",
    "            \"\"\"é•¿æ–‡æœ¬æµ‹è¯•\n",
    "ç¬¬ä¸€æ®µå†…å®¹\n",
    "ç¬¬äºŒæ®µå†…å®¹ï¼ŒåŒ…å«æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚\n",
    "ç¬¬ä¸‰æ®µæ€»ç»“å†…å®¹ã€‚\"\"\"\n",
    "        ]\n",
    "        \n",
    "        for i, test_case in enumerate(test_cases, 1):\n",
    "            print(f\"\\n   æµ‹è¯•æ¡ˆä¾‹ {i} (é•¿åº¦: {len(test_case)}):\")\n",
    "            case_result = complex_parallel_map.invoke(test_case)\n",
    "            print(f\"     æ ‡é¢˜: {case_result['title']}\")\n",
    "            print(f\"     å­—æ•°: {case_result['word_count']}\")\n",
    "            print(f\"     è¡Œæ•°: {case_result['structure']['line_count']}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šå¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç†æ­£ç¡®\n",
    "        assert isinstance(result, dict), \"å¤æ‚å¹¶è¡Œç»“æœä¸æ˜¯å­—å…¸\"\n",
    "        assert len(result) == 5, \"å¤æ‚å¹¶è¡Œç»“æœæ•°é‡ä¸æ­£ç¡®\"\n",
    "        assert result[\"word_count\"] == len(test_text.replace(' ', '')), \"å­—æ•°ç»Ÿè®¡é”™è¯¯\"\n",
    "        assert isinstance(result[\"structure\"], dict), \"ç»“æ„åˆ†æç»“æœæ ¼å¼é”™è¯¯\"\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šå¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç†æ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ å¤æ‚æ•°æ®æµå¹¶è¡Œå¤„ç†å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç† - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âš¡ æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»ºä¸åŒæ€§èƒ½çš„ç»„ä»¶\n",
    "        def fast_process(text: str) -> str:\n",
    "            \"\"\"å¿«é€Ÿå¤„ç†\"\"\"\n",
    "            time.sleep(0.01)  # æ¨¡æ‹Ÿå¿«é€Ÿå¤„ç†\n",
    "            return f\"å¿«é€Ÿ: {text[:10]}\"\n",
    "        \n",
    "        def slow_process(text: str) -> str:\n",
    "            \"\"\"æ…¢é€Ÿå¤„ç†\"\"\"\n",
    "            time.sleep(0.05)  # æ¨¡æ‹Ÿæ…¢é€Ÿå¤„ç†\n",
    "            return f\"æ…¢é€Ÿ: {text[-10:]}\"\n",
    "        \n",
    "        def error_process(text: str) -> str:\n",
    "            \"\"\"å¯èƒ½å‡ºé”™çš„å¤„ç†\"\"\"\n",
    "            if \"error\" in text.lower():\n",
    "                raise ValueError(\"æ¨¡æ‹Ÿå¤„ç†é”™è¯¯\")\n",
    "            return f\"æ­£å¸¸: {text}\"\n",
    "        \n",
    "        # åŒ…è£…ä¸º Runnable\n",
    "        fast_runnable = RunnableLambda(fast_process)\n",
    "        slow_runnable = RunnableLambda(slow_process)\n",
    "        error_runnable = RunnableLambda(error_process)\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„æ€§èƒ½æµ‹è¯•ç»„ä»¶:\")\n",
    "        print(f\"   1. å¿«é€Ÿå¤„ç†å™¨: æ¨¡æ‹Ÿ 10ms å»¶è¿Ÿ\")\n",
    "        print(f\"   2. æ…¢é€Ÿå¤„ç†å™¨: æ¨¡æ‹Ÿ 50ms å»¶è¿Ÿ\")\n",
    "        print(f\"   3. é”™è¯¯å¤„ç†å™¨: åŒ…å«é”™è¯¯å¤„ç†é€»è¾‘\")\n",
    "        \n",
    "        # åˆ›å»ºæ€§èƒ½æµ‹è¯• Map\n",
    "        performance_map = RunnableMap({\n",
    "            \"fast_result\": fast_runnable,\n",
    "            \"slow_result\": slow_runnable,\n",
    "            \"error_result\": error_runnable\n",
    "        })\n",
    "        \n",
    "        # 1. æ­£å¸¸æƒ…å†µæ€§èƒ½æµ‹è¯•\n",
    "        print(f\"\\nğŸ§ª 1. æ­£å¸¸æƒ…å†µæ€§èƒ½æµ‹è¯•:\")\n",
    "        \n",
    "        normal_text = \"è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„æµ‹è¯•æ–‡æœ¬\"\n",
    "        \n",
    "        # å¹¶è¡Œæ‰§è¡Œ\n",
    "        start_time = time.time()\n",
    "        parallel_result = performance_map.invoke(normal_text)\n",
    "        parallel_time = time.time() - start_time\n",
    "        \n",
    "        # ä¸²è¡Œæ‰§è¡Œ\n",
    "        start_time = time.time()\n",
    "        fast_result = fast_runnable.invoke(normal_text)\n",
    "        slow_result = slow_runnable.invoke(normal_text)\n",
    "        error_result = error_runnable.invoke(normal_text)\n",
    "        serial_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   å¹¶è¡Œæ‰§è¡Œæ—¶é—´: {parallel_time*1000:.1f} ms\")\n",
    "        print(f\"   ä¸²è¡Œæ‰§è¡Œæ—¶é—´: {serial_time*1000:.1f} ms\")\n",
    "        print(f\"   æ€§èƒ½æå‡: {serial_time/parallel_time:.1f}x\")\n",
    "        \n",
    "        # 2. é”™è¯¯å¤„ç†æµ‹è¯•\n",
    "        print(f\"\\nğŸ§ª 2. é”™è¯¯å¤„ç†æµ‹è¯•:\")\n",
    "        \n",
    "        error_text = \"è¿™æ˜¯ä¸€ä¸ªåŒ…å« error çš„æµ‹è¯•æ–‡æœ¬\"\n",
    "        \n",
    "        try:\n",
    "            error_result = performance_map.invoke(error_text)\n",
    "            print(f\"   âš ï¸  é”™è¯¯è¾“å…¥å±…ç„¶æˆåŠŸäº†: {error_result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âœ… æ­£ç¡®æ•è·é”™è¯¯: {type(e).__name__}: {e}\")\n",
    "        \n",
    "        # 3. éƒ¨åˆ†é”™è¯¯å¤„ç†\n",
    "        print(f\"\\nğŸ§ª 3. éƒ¨åˆ†é”™è¯¯å¤„ç†ç­–ç•¥:\")\n",
    "        \n",
    "        def safe_error_process(text: str) -> str:\n",
    "            \"\"\"å®‰å…¨çš„é”™è¯¯å¤„ç†\"\"\"\n",
    "            try:\n",
    "                if \"error\" in text.lower():\n",
    "                    raise ValueError(\"æ¨¡æ‹Ÿå¤„ç†é”™è¯¯\")\n",
    "                return f\"æ­£å¸¸: {text}\"\n",
    "            except Exception as e:\n",
    "                return f\"é”™è¯¯å¤„ç†: {str(e)}\"\n",
    "        \n",
    "        safe_error_runnable = RunnableLambda(safe_error_process)\n",
    "        \n",
    "        safe_map = RunnableMap({\n",
    "            \"fast_result\": fast_runnable,\n",
    "            \"slow_result\": slow_runnable,\n",
    "            \"safe_error_result\": safe_error_runnable\n",
    "        })\n",
    "        \n",
    "        safe_result = safe_map.invoke(error_text)\n",
    "        print(f\"   å®‰å…¨å¤„ç†ç»“æœ: {safe_result}\")\n",
    "        \n",
    "        # 4. æ‰¹é‡å¤„ç†æ€§èƒ½\n",
    "        print(f\"\\nğŸ§ª 4. æ‰¹é‡å¤„ç†æ€§èƒ½:\")\n",
    "        \n",
    "        batch_texts = [\"æ–‡æœ¬1\", \"æ–‡æœ¬2\", \"æ–‡æœ¬3\"]\n",
    "        \n",
    "        # å•ä¸ªå¤„ç†æ—¶é—´\n",
    "        single_times = []\n",
    "        for text in batch_texts:\n",
    "            start_time = time.time()\n",
    "            result = performance_map.invoke(text)\n",
    "            single_times.append(time.time() - start_time)\n",
    "        \n",
    "        avg_single_time = sum(single_times) / len(single_times)\n",
    "        print(f\"   å•ä¸ªå¹³å‡å¤„ç†æ—¶é—´: {avg_single_time*1000:.1f} ms\")\n",
    "        \n",
    "        # 5. å†…å­˜å’Œèµ„æºä½¿ç”¨å»ºè®®\n",
    "        print(f\"\\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:\")\n",
    "        print(f\"   1. å¹¶è¡Œæ‰§è¡Œé€‚åˆ I/O å¯†é›†å‹ä»»åŠ¡\")\n",
    "        print(f\"   2. é¿å…åœ¨å¹¶è¡Œä»»åŠ¡ä¸­å…±äº«çŠ¶æ€\")\n",
    "        print(f\"   3. åˆç†è®¾ç½®è¶…æ—¶å’Œé‡è¯•æœºåˆ¶\")\n",
    "        print(f\"   4. ä½¿ç”¨é”™è¯¯å¤„ç†é¿å…å•ç‚¹å¤±è´¥\")\n",
    "        print(f\"   5. ç›‘æ§å¹¶è¡Œä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šæ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†æ­£ç¡®\n",
    "        assert parallel_time < serial_time, \"å¹¶è¡Œæ‰§è¡Œæ²¡æœ‰æ€§èƒ½ä¼˜åŠ¿\"\n",
    "        assert \"é”™è¯¯å¤„ç†\" in safe_result[\"safe_error_result\"], \"é”™è¯¯å¤„ç†å¤±è´¥\"\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šæ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†æ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¦ä¹ æ€»ç»“ä¸æœ€ä½³å®è·µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ä¹ æ€»ç»“ä¸æœ€ä½³å®è·µ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ“‹ RunnableMap å¹¶è¡Œæ‰§è¡Œå­¦ä¹ æ€»ç»“:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# éªŒè¯ç‚¹æ£€æŸ¥\n",
    "verification_points = [\n",
    "    \"âœ… å¹¶è¡Œæ‰§è¡Œæœºåˆ¶ï¼šå¤šä»»åŠ¡åŒæ—¶å¤„ç†\",\n",
    "    \"âœ… ç»“æœç»„åˆï¼šè‡ªåŠ¨å­—å…¸æ ¼å¼è¾“å‡º\",\n",
    "    \"âœ… æ€§èƒ½ä¼˜åŒ–ï¼šå¹¶è¡Œ vs ä¸²è¡Œå¯¹æ¯”\",\n",
    "    \"âœ… é”™è¯¯å¤„ç†ï¼šå¼‚å¸¸æ•è·å’Œå®‰å…¨å¤„ç†\",\n",
    "]\n",
    "\n",
    "for point in verification_points:\n",
    "    print(point)\n",
    "\n",
    "print(f\"\\nğŸ¯ æ ¸å¿ƒæŠ€èƒ½æŒæ¡æƒ…å†µ: {len(verification_points)}/4 é¡¹\")\n",
    "\n",
    "print(\"\\nğŸ’¡ RunnableMap æœ€ä½³å®è·µ:\")\n",
    "print(\"1. å¹¶è¡Œè®¾è®¡ï¼šå°†ç‹¬ç«‹ä»»åŠ¡æ”¾å…¥å¹¶è¡Œæ‰§è¡Œ\")\n",
    "print(\"2. æ€§èƒ½ç›‘æ§ï¼šå¯¹æ¯”ä¸²è¡Œå’Œå¹¶è¡Œæ‰§è¡Œæ—¶é—´\")\n",
    "print(\"3. é”™è¯¯éš”ç¦»ï¼šå•ä¸ªä»»åŠ¡å¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡\")\n",
    "print(\"4. ç»“æœæ ¼å¼ï¼šç»Ÿä¸€å­—å…¸æ ¼å¼ä¾¿äºåç»­å¤„ç†\")\n",
    "print(\"5. èµ„æºç®¡ç†ï¼šé¿å…è¿‡åº¦å¹¶è¡Œå¯¼è‡´èµ„æºç«äº‰\")\n",
    "\n",
    "print(\"\\nğŸ”§ é€‚ç”¨åœºæ™¯:\")\n",
    "print(\"1. å¤šç»´åº¦æ–‡æœ¬åˆ†æï¼šæ‘˜è¦ã€å…³é”®è¯ã€æƒ…æ„Ÿ\")\n",
    "print(\"2. æ•°æ®é¢„å¤„ç†ï¼šæ¸…æ´—ã€è½¬æ¢ã€éªŒè¯\")\n",
    "print(\"3. å¤šæ¨¡å‹è°ƒç”¨ï¼šä¸åŒ LLM æˆ–å‚æ•°ç»„åˆ\")\n",
    "print(\"4. æ‰¹é‡ä»»åŠ¡å¤„ç†ï¼šå¤šä¸ªç‹¬ç«‹ä»»åŠ¡å¹¶è¡Œ\")\n",
    "print(\"5. å®æ—¶æ•°æ®å¤„ç†ï¼šå¤šä¸ªæ•°æ®æºåŒæ—¶å¤„ç†\")\n",
    "\n",
    "print(\"\\nğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®:\")\n",
    "print(\"1. æ·±å…¥å­¦ä¹  RunnablePassthrough æ•°æ®é€ä¼ \")\n",
    "print(\"2. æŒæ¡ LCEL ç®¡é“è¯­æ³• (prompt|llm|parser)\")\n",
    "print(\"3. å­¦ä¹ æµå¼è¾“å‡º Streaming æŠ€æœ¯\")\n",
    "print(\"4. æ¢ç´¢æ›´å¤æ‚çš„å¹¶è¡Œç¼–æ’æ¨¡å¼\")\n",
    "print(\"5. å®è·µç”Ÿäº§çº§å¹¶è¡Œå¤„ç†åº”ç”¨\")\n",
    "\n",
    "# æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿ RunnableMap åŸºç¡€åŠŸèƒ½å¯ç”¨\n",
    "try:\n",
    "    # åˆ›å»ºç®€å•æµ‹è¯•\n",
    "    def task1(x): return f\"ä»»åŠ¡1: {x}\"\n",
    "    def task2(x): return f\"ä»»åŠ¡2: {x.upper()}\"\n",
    "    def task3(x): return len(x)\n",
    "    \n",
    "    test_map = RunnableMap({\n",
    "        \"result1\": RunnableLambda(task1),\n",
    "        \"result2\": RunnableLambda(task2),\n",
    "        \"result3\": RunnableLambda(task3)\n",
    "    })\n",
    "    \n",
    "    result = test_map.invoke(\"test\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ æœ€ç»ˆéªŒè¯æˆåŠŸ:\")\n",
    "    print(f\"   è¾“å…¥: 'test'\")\n",
    "    print(f\"   è¾“å‡º: {result}\")\n",
    "    print(f\"   è¾“å‡ºç±»å‹: {type(result)}\")\n",
    "    print(f\"   å­—æ®µæ•°é‡: {len(result)}\")\n",
    "    print(\"\\nâœ… RunnableMap å¹¶è¡Œæ‰§è¡Œå­¦ä¹ å®Œæˆï¼\")\n",
    "    \n",
    "    print(f\"\\nğŸŠ å¹¶è¡Œç¼–æ’æŠ€æœ¯æŒæ¡ï¼\")\n",
    "    print(f\"   å·²æŒæ¡: Runnable åŸºç¡€ + RunnableMap å¹¶è¡Œæ‰§è¡Œ\")\n",
    "    print(f\"   ä¸‹ä¸€æ­¥: å­¦ä¹ æ•°æ®é€ä¼ å’Œç®¡é“è¯­æ³•æŠ€æœ¯\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
