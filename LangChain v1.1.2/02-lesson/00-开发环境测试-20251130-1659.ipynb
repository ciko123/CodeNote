{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - å¼€å‘ç¯å¢ƒæµ‹è¯•\n",
    "\n",
    "## ç”¨é€”\n",
    "æµ‹è¯• LangChain + GPT å¼€å‘ç¯å¢ƒæ˜¯å¦é…ç½®æ­£ç¡®\n",
    "\n",
    "## æµ‹è¯•é¡¹ç›®\n",
    "- Python ç¯å¢ƒæ£€æŸ¥\n",
    "- ä¾èµ–åŒ…å®‰è£…éªŒè¯\n",
    "- GPT API è¿æ¥æµ‹è¯•\n",
    "- åŸºç¡€åŠŸèƒ½éªŒè¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python ç¯å¢ƒæ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ Python ç¯å¢ƒä¿¡æ¯:\n",
      "Python ç‰ˆæœ¬: 3.14.1 | packaged by Anaconda, Inc. | (main, Dec  3 2025, 21:21:48) [MSC v.1929 64 bit (AMD64)]\n",
      "Python è·¯å¾„: c:\\ProgramData\\miniconda3\\envs\\langchain-last\\python.exe\n",
      "æ“ä½œç³»ç»Ÿ: Windows 11\n",
      "æ¶æ„: AMD64\n",
      "âœ… Python ç‰ˆæœ¬æ»¡è¶³è¦æ±‚ (>= 3.8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"ğŸ Python ç¯å¢ƒä¿¡æ¯:\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"Python è·¯å¾„: {sys.executable}\")\n",
    "print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\")\n",
    "print(f\"æ¶æ„: {platform.machine()}\")\n",
    "\n",
    "# æ£€æŸ¥ Python ç‰ˆæœ¬è¦æ±‚\n",
    "if sys.version_info >= (3, 8):\n",
    "    print(\"âœ… Python ç‰ˆæœ¬æ»¡è¶³è¦æ±‚ (>= 3.8)\")\n",
    "else:\n",
    "    print(\"âš ï¸  å»ºè®®å‡çº§ Python åˆ° 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ ¸å¿ƒä¾èµ–åŒ…æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ä¾èµ–åŒ…æ£€æŸ¥:\n",
      "âœ… langchain (LangChain æ ¸å¿ƒæ¡†æ¶): 1.1.2\n",
      "âœ… langchain-community (LangChain ç¤¾åŒºç»„ä»¶): 0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\langchain-last\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… langchain-openai (LangChain OpenAI å…¼å®¹å±‚): æœªçŸ¥\n",
      "âœ… openai (OpenAI API å®¢æˆ·ç«¯): 2.9.0\n",
      "âœ… python-dotenv (ç¯å¢ƒå˜é‡ç®¡ç†): æœªçŸ¥\n",
      "âœ… pydantic (æ•°æ®éªŒè¯): 2.12.5\n",
      "âœ… faiss-cpu (å‘é‡æ•°æ®åº“): 1.13.1\n",
      "âœ… tiktoken (Token è®¡ç®—): 0.12.0\n",
      "\n",
      "ğŸ‰ æ‰€æœ‰æ ¸å¿ƒä¾èµ–åŒ…å·²å®‰è£…!\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥æ ¸å¿ƒä¾èµ–åŒ…\n",
    "package_import_map = {\n",
    "    'langchain': 'langchain',\n",
    "    'langchain-community': 'langchain_community',\n",
    "    'langchain-openai': 'langchain_openai',\n",
    "    'openai': 'openai',\n",
    "    'python-dotenv': 'dotenv',  # ä¿®å¤ï¼špython-dotenv å¯¼å…¥ä¸º dotenv\n",
    "    'pydantic': 'pydantic',\n",
    "    'faiss-cpu': 'faiss',      # ä¿®å¤ï¼šfaiss-cpu å¯¼å…¥ä¸º faiss\n",
    "    'tiktoken': 'tiktoken'\n",
    "}\n",
    "\n",
    "required_packages = {\n",
    "    'langchain': 'LangChain æ ¸å¿ƒæ¡†æ¶',\n",
    "    'langchain-community': 'LangChain ç¤¾åŒºç»„ä»¶',\n",
    "    'langchain-openai': 'LangChain OpenAI å…¼å®¹å±‚',\n",
    "    'openai': 'OpenAI API å®¢æˆ·ç«¯',\n",
    "    'python-dotenv': 'ç¯å¢ƒå˜é‡ç®¡ç†',\n",
    "    'pydantic': 'æ•°æ®éªŒè¯',\n",
    "    'faiss-cpu': 'å‘é‡æ•°æ®åº“',\n",
    "    'tiktoken': 'Token è®¡ç®—'\n",
    "}\n",
    "\n",
    "print(\"ğŸ“¦ ä¾èµ–åŒ…æ£€æŸ¥:\")\n",
    "all_installed = True\n",
    "\n",
    "for package, description in required_packages.items():\n",
    "    try:\n",
    "        import_name = package_import_map[package]\n",
    "        module = __import__(import_name)\n",
    "        version = getattr(module, '__version__', 'æœªçŸ¥')\n",
    "        print(f\"âœ… {package} ({description}): {version}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ {package} ({description}): æœªå®‰è£… - {e}\")\n",
    "        all_installed = False\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒä¾èµ–åŒ…å·²å®‰è£…!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  è¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…\")\n",
    "    print(\"å®‰è£…å‘½ä»¤: pip install langchain langchain-community langchain-openai openai python-dotenv pydantic faiss-cpu tiktoken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ç¯å¢ƒå˜é‡é…ç½®æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ ç¯å¢ƒå˜é‡æ£€æŸ¥:\n",
      "âœ… OPENAI_API_KEY: sk_1L1UP...kLhQ\n",
      "âœ… OPENAI_BASE_URL: https://api.jiekou.ai/openai\n",
      "\n",
      "âœ… GPT ç¯å¢ƒé…ç½®å®Œæ•´!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”‘ ç¯å¢ƒå˜é‡æ£€æŸ¥:\")\n",
    "\n",
    "# æ£€æŸ¥ GPT é…ç½®\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai_base_url = os.getenv('OPENAI_BASE_URL')\n",
    "\n",
    "if openai_api_key:\n",
    "    # éšè—éƒ¨åˆ† API Key æ˜¾ç¤º\n",
    "    masked_key = openai_api_key[:8] + \"...\" + openai_api_key[-4:] if len(openai_api_key) > 12 else \"***\"\n",
    "    print(f\"âœ… OPENAI_API_KEY: {masked_key}\")\n",
    "else:\n",
    "    print(\"âŒ OPENAI_API_KEY: æœªé…ç½®\")\n",
    "\n",
    "if openai_base_url:\n",
    "    print(f\"âœ… OPENAI_BASE_URL: {openai_base_url}\")\n",
    "else:\n",
    "    print(\"âŒ OPENAI_BASE_URL: æœªé…ç½®\")\n",
    "\n",
    "# ç¯å¢ƒå˜é‡é…ç½®æ€»ç»“\n",
    "if openai_api_key and openai_base_url:\n",
    "    print(\"\\nâœ… GPT ç¯å¢ƒé…ç½®å®Œæ•´!\")\n",
    "else:\n",
    "    print(\"\\nâŒ GPT ç¯å¢ƒé…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GPT API è¿æ¥æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— GPT API è¿æ¥æµ‹è¯•:\n",
      "âœ… ChatOpenAI (GPT-4o) åˆå§‹åŒ–æˆåŠŸ\n",
      "âœ… API è¿æ¥æˆåŠŸ\n",
      "ğŸ“ æµ‹è¯•å›å¤: è¿æ¥æˆåŠŸ\n",
      "â±ï¸  å“åº”æ—¶é—´: 7.22 ç§’\n",
      "âœ… å“åº”å†…å®¹æ­£å¸¸\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "\n",
    "print(\"ğŸ”— GPT API è¿æ¥æµ‹è¯•:\")\n",
    "\n",
    "try:\n",
    "    # åˆå§‹åŒ– ChatOpenAI\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",  # ä½¿ç”¨ GPT-4o æ¨¡å‹è¿›è¡Œæµ‹è¯•\n",
    "        temperature=0.1,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… ChatOpenAI (GPT-4o) åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    # æµ‹è¯•ç®€å•è¿æ¥\n",
    "    start_time = time.time()\n",
    "    test_message = \"æµ‹è¯•è¿æ¥ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'\"\n",
    "    response = llm.invoke(test_message)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"âœ… API è¿æ¥æˆåŠŸ\")\n",
    "    print(f\"ğŸ“ æµ‹è¯•å›å¤: {response.content}\")\n",
    "    print(f\"â±ï¸  å“åº”æ—¶é—´: {end_time - start_time:.2f} ç§’\")\n",
    "    \n",
    "    # æ£€æŸ¥å“åº”è´¨é‡\n",
    "    if \"æˆåŠŸ\" in response.content or \"ok\" in response.content.lower():\n",
    "        print(\"âœ… å“åº”å†…å®¹æ­£å¸¸\")\n",
    "    else:\n",
    "        print(\"âš ï¸  å“åº”å†…å®¹å¯èƒ½å¼‚å¸¸\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ API è¿æ¥å¤±è´¥: {e}\")\n",
    "    print(\"å¯èƒ½çš„åŸå› :\")\n",
    "    print(\"1. API Key æ— æ•ˆæˆ–è¿‡æœŸ\")\n",
    "    print(\"2. ç½‘ç»œè¿æ¥é—®é¢˜\")\n",
    "    print(\"3. æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding åŠŸèƒ½æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¤ Embedding åŠŸèƒ½æµ‹è¯•:\n",
      "âœ… OpenAIEmbeddings åˆå§‹åŒ–æˆåŠŸ\n",
      "âŒ Embedding æµ‹è¯•å¤±è´¥: Error code: 404 - {'code': 404, 'reason': 'MODEL_NOT_FOUND', 'message': 'model not found', 'metadata': {'reason': 'model: text-embedding-ada-002 not found'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ”¤ Embedding åŠŸèƒ½æµ‹è¯•:\")\n",
    "\n",
    "try:\n",
    "    # åˆå§‹åŒ– Embedding\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… OpenAIEmbeddings åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    # æµ‹è¯•æ–‡æœ¬å‘é‡åŒ–\n",
    "    test_text = \"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬\"\n",
    "    start_time = time.time()\n",
    "    embedding_vector = embeddings.embed_query(test_text)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"âœ… æ–‡æœ¬å‘é‡åŒ–æˆåŠŸ\")\n",
    "    print(f\"ğŸ“Š å‘é‡ç»´åº¦: {len(embedding_vector)}\")\n",
    "    print(f\"ğŸ“Š å‘é‡ç±»å‹: {type(embedding_vector)}\")\n",
    "    print(f\"ğŸ“Š å‰5ä¸ªå€¼: {embedding_vector[:5]}\")\n",
    "    print(f\"â±ï¸  å¤„ç†æ—¶é—´: {end_time - start_time:.2f} ç§’\")\n",
    "    \n",
    "    # éªŒè¯å‘é‡è´¨é‡\n",
    "    if len(embedding_vector) > 0 and all(isinstance(x, (int, float)) for x in embedding_vector):\n",
    "        print(\"âœ… å‘é‡æ ¼å¼æ­£ç¡®\")\n",
    "    else:\n",
    "        print(\"âŒ å‘é‡æ ¼å¼å¼‚å¸¸\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Embedding æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. åŸºç¡€ LangChain åŠŸèƒ½æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  åŸºç¡€ LangChain åŠŸèƒ½æµ‹è¯•:\n",
      "âœ… PromptTemplate åˆ›å»ºæˆåŠŸ\n",
      "âœ… LCEL é“¾åˆ›å»ºæˆåŠŸ\n",
      "âœ… é“¾å¼è°ƒç”¨æˆåŠŸ\n",
      "ğŸ“ æµ‹è¯•ç»“æœ: äººå·¥æ™ºèƒ½æ˜¯ä¸€é—¨é€šè¿‡æ¨¡æ‹Ÿå’Œæ‰©å±•äººç±»æ™ºèƒ½ï¼Œä½¿æœºå™¨èƒ½å¤Ÿæ‰§è¡Œæ„ŸçŸ¥ã€å­¦ä¹ ã€æ¨ç†å’Œå†³ç­–ç­‰ä»»åŠ¡çš„æŠ€æœ¯ä¸ç§‘å­¦ã€‚\n",
      "âœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"âš™ï¸  åŸºç¡€ LangChain åŠŸèƒ½æµ‹è¯•:\")\n",
    "\n",
    "try:\n",
    "    # æµ‹è¯• PromptTemplate\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"topic\"],\n",
    "        template=\"è¯·ç”¨ä¸€å¥è¯ä»‹ç» {topic}\"\n",
    "    )\n",
    "    print(\"âœ… PromptTemplate åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # æµ‹è¯• LCEL é“¾\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1, max_tokens=50)\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    print(\"âœ… LCEL é“¾åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # æµ‹è¯•é“¾å¼è°ƒç”¨\n",
    "    result = chain.invoke({\"topic\": \"äººå·¥æ™ºèƒ½\"})\n",
    "    print(f\"âœ… é“¾å¼è°ƒç”¨æˆåŠŸ\")\n",
    "    print(f\"ğŸ“ æµ‹è¯•ç»“æœ: {result}\")\n",
    "    \n",
    "    if len(result) > 0:\n",
    "        print(\"âœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡\")\n",
    "    else:\n",
    "        print(\"âš ï¸  é“¾å¼è°ƒç”¨ç»“æœä¸ºç©º\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
