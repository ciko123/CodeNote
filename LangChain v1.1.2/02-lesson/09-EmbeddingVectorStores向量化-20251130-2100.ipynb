{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Embedding + Vector Stores å‘é‡åŒ–\n",
    "\n",
    "## ç”¨é€”\n",
    "å­¦ä¹ ä½¿ç”¨ DashScope Embedding å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œå¹¶ç”¨ FAISS è¿›è¡Œå‘é‡å­˜å‚¨å’Œç›¸ä¼¼åº¦æ£€ç´¢\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- æŒæ¡ DashScope Embeddings ä½¿ç”¨æ–¹æ³•\n",
    "- ç†è§£æ–‡æœ¬å‘é‡åŒ–åŸç†å’Œè¿‡ç¨‹\n",
    "- èƒ½è¿›è¡Œä¸­æ–‡æ–‡æœ¬å‘é‡åŒ–\n",
    "- æŒæ¡å‘é‡åº“åˆ›å»ºå’Œç›¸ä¼¼åº¦æ£€ç´¢\n",
    "\n",
    "## ğŸ”‘ API é…ç½®è¦æ±‚\n",
    "**æ³¨æ„**ï¼šéœ€è¦é…ç½® DashScope API å¯†é’¥ï¼Œä¸ OpenAI åˆ†å¼€è®¡è´¹\n",
    "\n",
    "## ä»£ç å—ç‹¬ç«‹æ€§è¯´æ˜\n",
    "**æ³¨æ„**ï¼šæ¯ä¸ªä»£ç å—éƒ½æ˜¯ç‹¬ç«‹çš„ï¼ŒåŒ…å«å®Œæ•´çš„å¯¼å…¥å’Œåˆå§‹åŒ–ï¼Œç¡®ä¿å¯ä»¥å•ç‹¬è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DashScope Embeddings åŸºç¡€ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DashScope Embeddings åŸºç¡€ä½¿ç”¨ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”¤ DashScope Embeddings åŸºç¡€æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ£€æŸ¥ DashScope API é…ç½®\n",
    "dashscope_api_key = os.getenv('DASHSCOPE_API_KEY')\n",
    "if not dashscope_api_key:\n",
    "    print(\"âŒ æœªæ‰¾åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡\")\n",
    "    print(\"   è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : DASHSCOPE_API_KEY=your_key_here\")\n",
    "    print(\"   æˆ–è®¾ç½®ç¯å¢ƒå˜é‡: export DASHSCOPE_API_KEY=your_key_here\")\n",
    "else:\n",
    "    print(f\"âœ… DashScope API Key å·²é…ç½® (é•¿åº¦: {len(dashscope_api_key)})\")\n",
    "    \n",
    "    try:\n",
    "        # åˆå§‹åŒ– DashScope Embeddings\n",
    "        embeddings = DashScopeEmbeddings(\n",
    "            model=\"text-embedding-v1\",  # ä½¿ç”¨åŸºç¡€æ¨¡å‹æ§åˆ¶æˆæœ¬\n",
    "            dashscope_api_key=dashscope_api_key\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ“ Embeddings é…ç½®:\")\n",
    "        print(f\"   æ¨¡å‹: text-embedding-v1\")\n",
    "        print(f\"   ç»´åº¦: 1536 (é¢„æœŸ)\")\n",
    "        \n",
    "        # æµ‹è¯•å•å¥ä¸­æ–‡å‘é‡åŒ–\n",
    "        test_text = \"LangChain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ LLM åº”ç”¨å¼€å‘æ¡†æ¶\"\n",
    "        print(f\"\\nğŸ§ª æµ‹è¯•æ–‡æœ¬: {test_text}\")\n",
    "        \n",
    "        # ç”Ÿæˆå‘é‡\n",
    "        embedding_vector = embeddings.embed_query(test_text)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š å‘é‡åŒ–ç»“æœ:\")\n",
    "        print(f\"   å‘é‡ç±»å‹: {type(embedding_vector)}\")\n",
    "        print(f\"   å‘é‡ç»´åº¦: {len(embedding_vector)}\")\n",
    "        print(f\"   æ•°æ®ç±»å‹: {type(embedding_vector[0])}\")\n",
    "        print(f\"   æ•°å€¼èŒƒå›´: [{min(embedding_vector):.4f}, {max(embedding_vector):.4f}]\")\n",
    "        print(f\"   å‘é‡èŒƒæ•°: {sum(x**2 for x in embedding_vector)**0.5:.4f}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå‘é‡å‰10ä¸ªå€¼\n",
    "        print(f\"\\nğŸ”¢ å‘é‡å‰10ä¸ªå€¼:\")\n",
    "        print(f\"   {embedding_vector[:10]}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šèƒ½æˆåŠŸç”Ÿæˆæ•°å€¼å‘é‡\n",
    "        assert isinstance(embedding_vector, list), \"å‘é‡ä¸æ˜¯åˆ—è¡¨ç±»å‹\"\n",
    "        assert len(embedding_vector) > 0, \"å‘é‡ä¸ºç©º\"\n",
    "        assert all(isinstance(x, (int, float)) for x in embedding_vector), \"å‘é‡åŒ…å«éæ•°å€¼\"\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šDashScope å‘é‡åŒ–æ­£å¸¸å·¥ä½œ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ DashScope API è°ƒç”¨å¤±è´¥: {e}\")\n",
    "        print(\"   å¯èƒ½åŸå› :\")\n",
    "        print(\"   1. API Key æ— æ•ˆæˆ–è¿‡æœŸ\")\n",
    "        print(\"   2. ç½‘ç»œè¿æ¥é—®é¢˜\")\n",
    "        print(\"   3. API é…é¢ä¸è¶³\")\n",
    "        print(\"   4. æ¨¡å‹åç§°é”™è¯¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–æµ‹è¯• - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ“¦ æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dashscope_api_key = os.getenv('DASHSCOPE_API_KEY')\n",
    "if not dashscope_api_key:\n",
    "    print(\"âŒ DashScope API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆå§‹åŒ– Embeddings\n",
    "        embeddings = DashScopeEmbeddings(\n",
    "            model=\"text-embedding-v1\",\n",
    "            dashscope_api_key=dashscope_api_key\n",
    "        )\n",
    "        \n",
    "        # å‡†å¤‡æµ‹è¯•æ–‡æœ¬ï¼ˆæ§åˆ¶æ•°é‡ä»¥èŠ‚çœæˆæœ¬ï¼‰\n",
    "        test_texts = [\n",
    "            \"LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»º LLM åº”ç”¨çš„æ¡†æ¶\",\n",
    "            \"Python æ˜¯ä¸€ç§æµè¡Œçš„ç¼–ç¨‹è¯­è¨€\",\n",
    "            \"æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯\",\n",
    "            \"å‘é‡åŒ–æ˜¯æ–‡æœ¬å¤„ç†çš„å…³é”®æŠ€æœ¯\",\n",
    "            \"FAISS æ˜¯é«˜æ•ˆçš„å‘é‡æ£€ç´¢åº“\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"ğŸ“ æµ‹è¯•æ–‡æœ¬æ•°é‡: {len(test_texts)}\")\n",
    "        print(f\"ğŸ’° æˆæœ¬æ§åˆ¶: ä½¿ç”¨æœ€å°æµ‹è¯•é›†\")\n",
    "        \n",
    "        # å•ä¸ªå‘é‡åŒ–æµ‹è¯•\n",
    "        print(f\"\\nğŸ” å•ä¸ªå‘é‡åŒ–æµ‹è¯•:\")\n",
    "        start_time = time.time()\n",
    "        single_vector = embeddings.embed_query(test_texts[0])\n",
    "        single_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   å¤„ç†æ—¶é—´: {single_time:.2f} ç§’\")\n",
    "        print(f\"   å‘é‡ç»´åº¦: {len(single_vector)}\")\n",
    "        \n",
    "        # æ‰¹é‡å‘é‡åŒ–æµ‹è¯•\n",
    "        print(f\"\\nğŸ“¦ æ‰¹é‡å‘é‡åŒ–æµ‹è¯•:\")\n",
    "        start_time = time.time()\n",
    "        batch_vectors = embeddings.embed_documents(test_texts)\n",
    "        batch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   å¤„ç†æ—¶é—´: {batch_time:.2f} ç§’\")\n",
    "        print(f\"   å¹³å‡æ¯æ¡: {batch_time/len(test_texts):.2f} ç§’\")\n",
    "        print(f\"   å‘é‡æ•°é‡: {len(batch_vectors)}\")\n",
    "        \n",
    "        # åˆ†ææ‰¹é‡ç»“æœ\n",
    "        print(f\"\\nğŸ“Š æ‰¹é‡ç»“æœåˆ†æ:\")\n",
    "        for i, (text, vector) in enumerate(zip(test_texts, batch_vectors), 1):\n",
    "            print(f\"   æ–‡æœ¬ {i}: {len(vector)} ç»´\")\n",
    "            print(f\"   å†…å®¹: {text[:30]}...\")\n",
    "        \n",
    "        # æ£€æŸ¥å‘é‡ä¸€è‡´æ€§\n",
    "        dimensions = [len(vector) for vector in batch_vectors]\n",
    "        if len(set(dimensions)) == 1:\n",
    "            print(f\"\\nâœ… å‘é‡ç»´åº¦ä¸€è‡´: {dimensions[0]} ç»´\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  å‘é‡ç»´åº¦ä¸ä¸€è‡´: {dimensions}\")\n",
    "        \n",
    "        # æ€§èƒ½å¯¹æ¯”\n",
    "        print(f\"\\nâš¡ æ€§èƒ½å¯¹æ¯”:\")\n",
    "        print(f\"   å•æ¡å¤„ç†: {single_time:.2f} ç§’\")\n",
    "        print(f\"   æ‰¹é‡å¤„ç†: {batch_time:.2f} ç§’\")\n",
    "        print(f\"   æ•ˆç‡æå‡: {(single_time * len(test_texts) / batch_time):.1f}x\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šæ‰¹é‡å‘é‡åŒ–æ­£ç¡®\n",
    "        assert len(batch_vectors) == len(test_texts), \"å‘é‡æ•°é‡ä¸åŒ¹é…\"\n",
    "        assert all(len(vector) > 0 for vector in batch_vectors), \"å­˜åœ¨ç©ºå‘é‡\"\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šæ‰¹é‡å‘é‡åŒ–æ­£å¸¸å·¥ä½œ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ æ‰¹é‡å‘é‡åŒ–å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FAISS å‘é‡åº“åˆ›å»ºå’Œå­˜å‚¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS å‘é‡åº“åˆ›å»ºå’Œå­˜å‚¨ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ—„ï¸  FAISS å‘é‡åº“åˆ›å»ºå’Œå­˜å‚¨æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dashscope_api_key = os.getenv('DASHSCOPE_API_KEY')\n",
    "if not dashscope_api_key:\n",
    "    print(\"âŒ DashScope API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆå§‹åŒ– Embeddings\n",
    "        embeddings = DashScopeEmbeddings(\n",
    "            model=\"text-embedding-v1\",\n",
    "            dashscope_api_key=dashscope_api_key\n",
    "        )\n",
    "        \n",
    "        # å‡†å¤‡æ–‡æ¡£æ•°æ®ï¼ˆæ§åˆ¶æ•°é‡ä»¥èŠ‚çœæˆæœ¬ï¼‰\n",
    "        documents = [\n",
    "            \"LangChain æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºç®€åŒ– LLM åº”ç”¨å¼€å‘\",\n",
    "            \"Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´æ˜“å­¦\",\n",
    "            \"æœºå™¨å­¦ä¹ é€šè¿‡æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œå®ç°æ™ºèƒ½å†³ç­–\",\n",
    "            \"å‘é‡åŒ–å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼Œä¾¿äºæ•°å­¦è®¡ç®—\",\n",
    "            \"FAISS æ˜¯ Facebook å¼€å‘çš„é«˜æ•ˆå‘é‡æ£€ç´¢åº“\"\n",
    "        ]\n",
    "        \n",
    "        metadatas = [\n",
    "            {\"source\": \"langchain_doc\", \"category\": \"framework\"},\n",
    "            {\"source\": \"python_doc\", \"category\": \"language\"},\n",
    "            {\"source\": \"ml_doc\", \"category\": \"ai\"},\n",
    "            {\"source\": \"embedding_doc\", \"category\": \"technique\"},\n",
    "            {\"source\": \"faiss_doc\", \"category\": \"library\"}\n",
    "        ]\n",
    "        \n",
    "        print(f\"ğŸ“ å‡†å¤‡æ–‡æ¡£æ•°é‡: {len(documents)}\")\n",
    "        print(f\"ğŸ’° æˆæœ¬æ§åˆ¶: æœ€å°æµ‹è¯•é›†\")\n",
    "        \n",
    "        # åˆ›å»º FAISS å‘é‡åº“\n",
    "        print(f\"\\nğŸ—ï¸  åˆ›å»º FAISS å‘é‡åº“:\")\n",
    "        vector_store = FAISS.from_texts(\n",
    "            texts=documents,\n",
    "            embedding=embeddings,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        \n",
    "        print(f\"   å‘é‡åº“ç±»å‹: {type(vector_store)}\")\n",
    "        print(f\"   æ–‡æ¡£æ•°é‡: {vector_store.index.ntotal}\")\n",
    "        print(f\"   å‘é‡ç»´åº¦: {vector_store.index.d}\")\n",
    "        \n",
    "        # æµ‹è¯•å‘é‡åº“åŸºæœ¬ä¿¡æ¯\n",
    "        print(f\"\\nğŸ“Š å‘é‡åº“ä¿¡æ¯:\")\n",
    "        print(f\"   ç´¢å¼•ç±»å‹: {type(vector_store.index).__name__}\")\n",
    "        print(f\"   æ˜¯å¦å¯è®­ç»ƒ: {vector_store.index.is_trained}\")\n",
    "        \n",
    "        # æµ‹è¯•æ·»åŠ å•ä¸ªæ–‡æ¡£\n",
    "        print(f\"\\nâ• æ·»åŠ å•ä¸ªæ–‡æ¡£:\")\n",
    "        new_doc = \"å‘é‡ç›¸ä¼¼åº¦è®¡ç®—ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æˆ–æ¬§æ°è·ç¦»\"\n",
    "        new_meta = {\"source\": \"similarity_doc\", \"category\": \"technique\"}\n",
    "        \n",
    "        vector_store.add_texts([new_doc], [new_meta])\n",
    "        print(f\"   æ·»åŠ åæ–‡æ¡£æ•°: {vector_store.index.ntotal}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šå‘é‡åº“åˆ›å»ºæˆåŠŸ\n",
    "        assert vector_store.index.ntotal > 0, \"å‘é‡åº“ä¸ºç©º\"\n",
    "        assert vector_store.index.d > 0, \"å‘é‡ç»´åº¦ä¸º0\"\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šFAISS å‘é‡åº“åˆ›å»ºæˆåŠŸ\")\n",
    "        \n",
    "        # ä¿å­˜å‘é‡åº“åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼‰\n",
    "        print(f\"\\nğŸ’¾ ä¿å­˜å‘é‡åº“åˆ°æœ¬åœ°:\")\n",
    "        save_path = \"./faiss_index\"\n",
    "        vector_store.save_local(save_path)\n",
    "        print(f\"   ä¿å­˜è·¯å¾„: {save_path}\")\n",
    "        print(f\"   æ–‡ä»¶æ•°é‡: {len(os.listdir(save_path))}\")\n",
    "        \n",
    "        # æ¸…ç†ä¿å­˜çš„æ–‡ä»¶\n",
    "        import shutil\n",
    "        if os.path.exists(save_path):\n",
    "            shutil.rmtree(save_path)\n",
    "            print(f\"   ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ FAISS å‘é‡åº“åˆ›å»ºå¤±è´¥: {e}\")\n",
    "        print(\"   å¯èƒ½åŸå› :\")\n",
    "        print(\"   1. FAISS åº“æœªå®‰è£…\")\n",
    "        print(\"   2. å‘é‡åŒ–å¤±è´¥\")\n",
    "        print(\"   3. å†…å­˜ä¸è¶³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ç›¸ä¼¼åº¦æ£€ç´¢æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›¸ä¼¼åº¦æ£€ç´¢æµ‹è¯• - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ” ç›¸ä¼¼åº¦æ£€ç´¢æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dashscope_api_key = os.getenv('DASHSCOPE_API_KEY')\n",
    "if not dashscope_api_key:\n",
    "    print(\"âŒ DashScope API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆå§‹åŒ– Embeddings\n",
    "        embeddings = DashScopeEmbeddings(\n",
    "            model=\"text-embedding-v1\",\n",
    "            dashscope_api_key=dashscope_api_key\n",
    "        )\n",
    "        \n",
    "        # å‡†å¤‡æµ‹è¯•æ•°æ®\n",
    "        documents = [\n",
    "            \"LangChain æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºç®€åŒ– LLM åº”ç”¨å¼€å‘\",\n",
    "            \"Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´æ˜“å­¦\",\n",
    "            \"æœºå™¨å­¦ä¹ é€šè¿‡æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œå®ç°æ™ºèƒ½å†³ç­–\",\n",
    "            \"å‘é‡åŒ–å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼Œä¾¿äºæ•°å­¦è®¡ç®—\",\n",
    "            \"FAISS æ˜¯ Facebook å¼€å‘çš„é«˜æ•ˆå‘é‡æ£€ç´¢åº“\"\n",
    "        ]\n",
    "        \n",
    "        metadatas = [\n",
    "            {\"source\": \"langchain_doc\", \"category\": \"framework\"},\n",
    "            {\"source\": \"python_doc\", \"category\": \"language\"},\n",
    "            {\"source\": \"ml_doc\", \"category\": \"ai\"},\n",
    "            {\"source\": \"embedding_doc\", \"category\": \"technique\"},\n",
    "            {\"source\": \"faiss_doc\", \"category\": \"library\"}\n",
    "        ]\n",
    "        \n",
    "        # åˆ›å»ºå‘é‡åº“\n",
    "        vector_store = FAISS.from_texts(documents, embeddings, metadatas)\n",
    "        \n",
    "        print(f\"ğŸ“š å‘é‡åº“åˆ›å»ºå®Œæˆ: {vector_store.index.ntotal} ä¸ªæ–‡æ¡£\")\n",
    "        \n",
    "        # æµ‹è¯•ç›¸ä¼¼åº¦æ£€ç´¢\n",
    "        test_queries = [\n",
    "            \"å¦‚ä½•å¼€å‘äººå·¥æ™ºèƒ½åº”ç”¨\",\n",
    "            \"ç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹\",\n",
    "            \"æ•°æ®æ£€ç´¢æŠ€æœ¯\"\n",
    "        ]\n",
    "        \n",
    "        for i, query in enumerate(test_queries, 1):\n",
    "            print(f\"\\nğŸ” æŸ¥è¯¢ {i}: {query}\")\n",
    "            \n",
    "            # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢\n",
    "            results = vector_store.similarity_search_with_score(query, k=3)\n",
    "            \n",
    "            print(f\"   æ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "            \n",
    "            for j, (doc, score) in enumerate(results, 1):\n",
    "                print(f\"   ç»“æœ {j} (ç›¸ä¼¼åº¦: {score:.4f}):\")\n",
    "                print(f\"     å†…å®¹: {doc.page_content}\")\n",
    "                print(f\"     æ¥æº: {doc.metadata}\")\n",
    "        \n",
    "        # æµ‹è¯•æŒ‰é˜ˆå€¼æ£€ç´¢\n",
    "        print(f\"\\nğŸ¯ æŒ‰é˜ˆå€¼æ£€ç´¢æµ‹è¯•:\")\n",
    "        threshold_query = \"æœºå™¨å­¦ä¹ ç®—æ³•\"\n",
    "        threshold_results = vector_store.similarity_search_with_score(\n",
    "            threshold_query, \n",
    "            k=5,\n",
    "            score_threshold=0.3  # ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "        )\n",
    "        \n",
    "        print(f\"   æŸ¥è¯¢: {threshold_query}\")\n",
    "        print(f\"   é˜ˆå€¼: 0.3\")\n",
    "        print(f\"   ç»“æœæ•°é‡: {len(threshold_results)}\")\n",
    "        \n",
    "        for doc, score in threshold_results:\n",
    "            print(f\"   - {doc.page_content} (ç›¸ä¼¼åº¦: {score:.4f})\")\n",
    "        \n",
    "        # æµ‹è¯•æœ€å¤§è¾¹é™…ç›¸å…³æ€§æ£€ç´¢ï¼ˆMMRï¼‰\n",
    "        print(f\"\\nğŸ”„ MMR æ£€ç´¢æµ‹è¯•:\")\n",
    "        mmr_results = vector_store.max_marginal_relevance_search(\n",
    "            \"ç¼–ç¨‹å’Œäººå·¥æ™ºèƒ½\", \n",
    "            k=3,\n",
    "            fetch_k=5\n",
    "        )\n",
    "        \n",
    "        print(f\"   æŸ¥è¯¢: ç¼–ç¨‹å’Œäººå·¥æ™ºèƒ½\")\n",
    "        print(f\"   MMR ç»“æœæ•°é‡: {len(mmr_results)}\")\n",
    "        \n",
    "        for i, doc in enumerate(mmr_results, 1):\n",
    "            print(f\"   ç»“æœ {i}: {doc.page_content}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šèƒ½è¿”å›æœ€ç›¸ä¼¼çš„ä¸­æ–‡æ–‡æœ¬ç‰‡æ®µ\n",
    "        assert len(results) > 0, \"æ£€ç´¢ç»“æœä¸ºç©º\"\n",
    "        assert all(hasattr(doc, 'page_content') for doc, _ in results), \"ç»“æœç¼ºå°‘å†…å®¹\"\n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šç›¸ä¼¼åº¦æ£€ç´¢æ­£å¸¸å·¥ä½œ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ç›¸ä¼¼åº¦æ£€ç´¢å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¦ä¹ æ€»ç»“ä¸æˆæœ¬æ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ä¹ æ€»ç»“ä¸æˆæœ¬æ§åˆ¶ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ“‹ Embedding + Vector Stores å­¦ä¹ æ€»ç»“:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# éªŒè¯ç‚¹æ£€æŸ¥\n",
    "verification_points = [\n",
    "    \"âœ… DashScope Embeddingsï¼šæ–‡æœ¬å‘é‡åŒ–åŸºç¡€\",\n",
    "    \"âœ… æ‰¹é‡å‘é‡åŒ–ï¼šå¤šæ–‡æœ¬å¤„ç†ä¼˜åŒ–\",\n",
    "    \"âœ… FAISS å‘é‡åº“ï¼šå­˜å‚¨å’Œç®¡ç†\",\n",
    "    \"âœ… ç›¸ä¼¼åº¦æ£€ç´¢ï¼šå¤šç§æ£€ç´¢ç­–ç•¥\",\n",
    "]\n",
    "\n",
    "for point in verification_points:\n",
    "    print(point)\n",
    "\n",
    "print(f\"\\nğŸ¯ æ ¸å¿ƒæŠ€èƒ½æŒæ¡æƒ…å†µ: {len(verification_points)}/4 é¡¹\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Embedding + Vector Stores æœ€ä½³å®è·µ:\")\n",
    "print(\"1. API ç®¡ç†ï¼šåˆ†åˆ«é…ç½® OpenAI å’Œ DashScope å¯†é’¥\")\n",
    "print(\"2. æˆæœ¬æ§åˆ¶ï¼šä½¿ç”¨æœ€å°æµ‹è¯•é›†ï¼Œé¿å…æ‰¹é‡å¤„ç†\")\n",
    "print(\"3. æ¨¡å‹é€‰æ‹©ï¼štext-embedding-v1 å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬\")\n",
    "print(\"4. å‘é‡åº“ï¼šFAISS é€‚åˆæœ¬åœ°å¿«é€Ÿæ£€ç´¢\")\n",
    "print(\"5. æ£€ç´¢ç­–ç•¥ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©ç›¸ä¼¼åº¦æˆ– MMR\")\n",
    "\n",
    "print(\"\\nğŸ’° æˆæœ¬æ§åˆ¶ç­–ç•¥:\")\n",
    "print(\"1. æµ‹è¯•é˜¶æ®µï¼šä½¿ç”¨ 3-5 æ¡çŸ­æ–‡æœ¬\")\n",
    "print(\"2. ç¼“å­˜å‘é‡ï¼šé¿å…é‡å¤å‘é‡åŒ–ç›¸åŒå†…å®¹\")\n",
    "print(\"3. æ‰¹é‡å¤„ç†ï¼šä¸€æ¬¡å¤„ç†å¤šæ¡æ¯”å•æ¡æ›´é«˜æ•ˆ\")\n",
    "print(\"4. æœ¬åœ°å­˜å‚¨ï¼šä¿å­˜å‘é‡åº“é¿å…é‡å¤è®¡ç®—\")\n",
    "print(\"5. ç›‘æ§ä½¿ç”¨ï¼šå®šæœŸæ£€æŸ¥ API è°ƒç”¨ç»Ÿè®¡\")\n",
    "\n",
    "print(\"\\nğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®:\")\n",
    "print(\"1. æ·±å…¥å­¦ä¹  Retrievers æ£€ç´¢å™¨é…ç½®\")\n",
    "print(\"2. æŒæ¡ RAG ç³»ç»Ÿå®Œæ•´æµç¨‹\")\n",
    "print(\"3. å­¦ä¹ å…¶ä»–å‘é‡åº“ï¼ˆChromaã€Pineconeï¼‰\")\n",
    "print(\"4. æ¢ç´¢å‘é‡æ£€ç´¢ä¼˜åŒ–ç®—æ³•\")\n",
    "print(\"5. å®è·µç”Ÿäº§çº§ RAG åº”ç”¨å¼€å‘\")\n",
    "\n",
    "# æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿åŸºç¡€åŠŸèƒ½å¯ç”¨\n",
    "try:\n",
    "    dashscope_api_key = os.getenv('DASHSCOPE_API_KEY')\n",
    "    \n",
    "    if dashscope_api_key:\n",
    "        # ç®€å•æµ‹è¯•\n",
    "        embeddings = DashScopeEmbeddings(\n",
    "            model=\"text-embedding-v1\",\n",
    "            dashscope_api_key=dashscope_api_key\n",
    "        )\n",
    "        \n",
    "        test_vector = embeddings.embed_query(\"æµ‹è¯•æ–‡æœ¬\")\n",
    "        \n",
    "        print(f\"\\nğŸ‰ æœ€ç»ˆéªŒè¯æˆåŠŸ:\")\n",
    "        print(f\"   API çŠ¶æ€: å¯ç”¨\")\n",
    "        print(f\"   å‘é‡ç»´åº¦: {len(test_vector)}\")\n",
    "        print(f\"   å‘é‡ç±»å‹: {type(test_vector)}\")\n",
    "        print(\"\\nâœ… Embedding + Vector Stores å­¦ä¹ å®Œæˆï¼\")\n",
    "        \n",
    "        print(f\"\\nâš ï¸  é‡è¦æé†’:\")\n",
    "        print(\"   - DashScope API ä¸ OpenAI åˆ†å¼€è®¡è´¹\")\n",
    "        print(\"   - ç”Ÿäº§ç¯å¢ƒè¯·è®¾ç½®åˆç†çš„è°ƒç”¨é™åˆ¶\")\n",
    "        print(\"   - å»ºè®®ä½¿ç”¨å‘é‡ç¼“å­˜å‡å°‘ API è°ƒç”¨\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  æœ€ç»ˆéªŒè¯è·³è¿‡: DashScope API Key æœªé…ç½®\")\n",
    "        print(\"   è¯·é…ç½® DASHSCOPE_API_KEY åé‡è¯•\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
