{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26 - LCELé…ç½®ç®¡ç†\n",
    "\n",
    "## ç”¨é€”\n",
    "LangChain 1.0+ çš„GPTåŠ¨æ€é…ç½®å’Œçƒ­åˆ‡æ¢èƒ½åŠ›ã€‚ç†è§£é…ç½®æ¨¡å¼ã€æŒæ¡åŠ¨æ€åˆ‡æ¢æ–¹æ³•ã€èƒ½å®ç°GPTçµæ´»é…ç½®ã€‚\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£é…ç½®æ¨¡å¼\n",
    "- æŒæ¡åŠ¨æ€åˆ‡æ¢æ–¹æ³•\n",
    "- èƒ½å®ç°GPTçµæ´»é…ç½®\n",
    "- ä½¿ç”¨ chain.configurable_alternatives() é…ç½®å¤šä¸ªGPTæ¨¡å‹\n",
    "- æ¼”ç¤ºè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢\n",
    "- éªŒè¯ç‚¹ï¼šèƒ½åŠ¨æ€åˆ‡æ¢ä¸åŒçš„GPTæ¨¡å‹é…ç½®\n",
    "\n",
    "## ğŸ”‘ å‰ç½®è¦æ±‚\n",
    "å·²å®‰è£… LangChain å’Œ OpenAI ç›¸å…³åŒ…\n",
    "\n",
    "## ä»£ç å—ç‹¬ç«‹æ€§è¯´æ˜\n",
    "**æ³¨æ„**ï¼šæ¯ä¸ªä»£ç å—éƒ½æ˜¯ç‹¬ç«‹çš„ï¼ŒåŒ…å«å®Œæ•´çš„å¯¼å…¥å’Œåˆå§‹åŒ–ï¼Œç¡®ä¿å¯ä»¥å•ç‹¬è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LCELé…ç½®ç®¡ç†åŸºç¡€æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCELé…ç½®ç®¡ç†åŸºç¡€æ¦‚å¿µ - ç‹¬ç«‹ä»£ç å—\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”§ LCELé…ç½®ç®¡ç†åŸºç¡€æ¦‚å¿µ:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ“ LCELé…ç½®ç®¡ç†æ ¸å¿ƒæ¦‚å¿µ:\")\n",
    "print(\"   1. åŠ¨æ€é…ç½®: è¿è¡Œæ—¶åˆ‡æ¢æ¨¡å‹å’Œå‚æ•°\")\n",
    "print(\"   2. å¯é…ç½®æ›¿ä»£: ä¸ºç»„ä»¶æä¾›å¤šä¸ªé€‰é¡¹\")\n",
    "print(\"   3. çƒ­åˆ‡æ¢: æ— éœ€é‡å¯æœåŠ¡å³å¯åˆ‡æ¢é…ç½®\")\n",
    "print(\"   4. é…ç½®ä¼ é€’: é€šè¿‡configå­—å…¸ä¼ é€’é…ç½®\")\n",
    "print(\"   5. é»˜è®¤é…ç½®: åŸºç¡€é…ç½®å’Œå¯é€‰é…ç½®\")\n",
    "\n",
    "print(f\"\\nğŸ¯ å­¦ä¹ ç›®æ ‡è¾¾æˆ:\")\n",
    "print(f\"   - ç†è§£é…ç½®æ¨¡å¼\")\n",
    "print(f\"   - æŒæ¡åŠ¨æ€åˆ‡æ¢æ–¹æ³•\")\n",
    "print(f\"   - èƒ½å®ç°GPTçµæ´»é…ç½®\")\n",
    "\n",
    "print(f\"\\nğŸ—ï¸  é…ç½®ç®¡ç†ç»„ä»¶:\")\n",
    "print(f\"   1. configurable_alternatives(): é…ç½®æ›¿ä»£é€‰é¡¹\")\n",
    "print(f\"   2. with_config(): è¿è¡Œæ—¶é…ç½®ä¼ é€’\")\n",
    "print(f\"   3. ConfigurableField: é…ç½®å­—æ®µå®šä¹‰\")\n",
    "print(f\"   4. default: é»˜è®¤é…ç½®é€‰é¡¹\")\n",
    "print(f\"   5. prefix_key: é…ç½®é”®å‰ç¼€\")\n",
    "\n",
    "print(f\"\\nğŸ”§ é…ç½®ç®¡ç†API:\")\n",
    "print(f\"   chain.configurable_alternatives()\")\n",
    "print(f\"     - which: æŒ‡å®šå¯é…ç½®çš„ç»„ä»¶\")\n",
    "print(f\"     - default_key: é»˜è®¤é€‰é¡¹é”®\")\n",
    "print(f\"     - prefix_keys: é€‰é¡¹é”®å‰ç¼€\")\n",
    "print(f\"     - **kwargs: æ›¿ä»£é€‰é¡¹\")\n",
    "print(f\"\\n   chain.with_config()\")\n",
    "print(f\"     - configurable: é…ç½®å­—å…¸\")\n",
    "print(f\"     - è¿è¡Œæ—¶åŠ¨æ€åˆ‡æ¢é…ç½®\")\n",
    "\n",
    "print(f\"\\nğŸ“Š é…ç½®æ¨¡å¼å¯¹æ¯”:\")\n",
    "print(f\"   ä¼ ç»Ÿæ¨¡å¼:\")\n",
    "print(f\"     - é™æ€é…ç½®: ä»£ç ä¸­ç¡¬ç¼–ç æ¨¡å‹\")\n",
    "print(f\"     - é‡å¯åˆ‡æ¢: éœ€è¦é‡å¯æœåŠ¡æ›´æ¢æ¨¡å‹\")\n",
    "print(f\"     - å•ä¸€é…ç½®: æ¯ä¸ªé“¾åªèƒ½ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹\")\n",
    "print(f\"\\n   LCELé…ç½®ç®¡ç†:\")\n",
    "print(f\"     - åŠ¨æ€é…ç½®: è¿è¡Œæ—¶åˆ‡æ¢æ¨¡å‹\")\n",
    "print(f\"     - çƒ­åˆ‡æ¢: æ— éœ€é‡å¯å³å¯åˆ‡æ¢\")\n",
    "print(f\"     - å¤šé…ç½®: ä¸€ä¸ªé“¾æ”¯æŒå¤šä¸ªæ¨¡å‹é€‰é¡¹\")\n",
    "\n",
    "print(f\"\\nğŸ¨ é…ç½®ç®¡ç†åº”ç”¨åœºæ™¯:\")\n",
    "print(f\"   1. A/Bæµ‹è¯•: å¯¹æ¯”ä¸åŒæ¨¡å‹æ•ˆæœ\")\n",
    "print(f\"   2. æˆæœ¬ä¼˜åŒ–: æ ¹æ®è¯·æ±‚å¤æ‚åº¦é€‰æ‹©æ¨¡å‹\")\n",
    "print(f\"   3. æ€§èƒ½è°ƒä¼˜: å¿«é€Ÿ/å¹³è¡¡æ¨¡å‹åˆ‡æ¢\")\n",
    "print(f\"   4. é™çº§ç­–ç•¥: ä¸»æ¨¡å‹å¤±è´¥æ—¶åˆ‡æ¢å¤‡ç”¨æ¨¡å‹\")\n",
    "print(f\"   5. ç”¨æˆ·åå¥½: æ ¹æ®ç”¨æˆ·é€‰æ‹©ä½¿ç”¨ä¸åŒæ¨¡å‹\")\n",
    "\n",
    "print(f\"\\nğŸ” é…ç½®ç®¡ç†åœ¨LangChainä¸­çš„ä½ç½®:\")\n",
    "print(f\"   1. LCELæ ¸å¿ƒ: è¡¨è¾¾å¼è¯­è¨€çš„é«˜çº§ç‰¹æ€§\")\n",
    "print(f\"   2. é“¾é…ç½®: ä¸ºé“¾ç»„ä»¶æä¾›åŠ¨æ€é…ç½®\")\n",
    "print(f\"   3. è¿è¡Œæ—¶: æ‰§è¡Œæ—¶åŠ¨æ€é€‰æ‹©ç»„ä»¶\")\n",
    "print(f\"   4. éƒ¨ç½²: æ”¯æŒçµæ´»çš„ç”Ÿäº§ç¯å¢ƒé…ç½®\")\n",
    "print(f\"   5. ç›‘æ§: ä¸åŒé…ç½®çš„æ€§èƒ½å¯¹æ¯”\")\n",
    "\n",
    "print(f\"\\nâœ… LCELé…ç½®ç®¡ç†åŸºç¡€æ¦‚å¿µç†è§£å®Œæˆ\")\n",
    "print(f\"\\nğŸš€ å‡†å¤‡å®ç°åŠ¨æ€é…ç½®åˆ‡æ¢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åˆ›å»ºåŸºç¡€LCELé“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºåŸºç¡€LCELé“¾ - ç‹¬ç«‹ä»£ç å—\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”— åˆ›å»ºåŸºç¡€LCELé“¾:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ç¯å¢ƒæ£€æŸ¥\n",
    "print(f\"ğŸ” 1. ç¯å¢ƒæ£€æŸ¥:\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(f\"   âœ… OpenAI API Key: å·²é…ç½®\")\n",
    "    print(f\"   Keyé•¿åº¦: {len(api_key)} å­—ç¬¦\")\n",
    "else:\n",
    "    print(f\"   âŒ OpenAI API Key: æœªé…ç½®\")\n",
    "    print(f\"   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: OPENAI_API_KEY\")\n",
    "    exit()\n",
    "\n",
    "# 2. åˆ›å»ºé»˜è®¤LLMï¼ˆå¿«é€Ÿæ¨¡å‹ï¼‰\n",
    "print(f\"\\nğŸ¤– 2. åˆ›å»ºé»˜è®¤LLMï¼ˆå¿«é€Ÿæ¨¡å‹ï¼‰:\")\n",
    "\n",
    "default_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=300,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "print(f\"   é»˜è®¤æ¨¡å‹é…ç½®:\")\n",
    "print(f\"     æ¨¡å‹: {default_llm.model_name}\")\n",
    "print(f\"     æ¸©åº¦: {default_llm.temperature}\")\n",
    "print(f\"     æœ€å¤§ä»¤ç‰Œ: {default_llm.max_tokens}\")\n",
    "print(f\"     ç”¨é€”: å¿«é€Ÿå“åº”ï¼Œæˆæœ¬ä¼˜åŒ–\")\n",
    "\n",
    "# 3. åˆ›å»ºå¤‡ç”¨LLMï¼ˆå¹³è¡¡æ¨¡å‹ï¼‰\n",
    "print(f\"\\nğŸ¤– 3. åˆ›å»ºå¤‡ç”¨LLMï¼ˆå¹³è¡¡æ¨¡å‹ï¼‰:\")\n",
    "\n",
    "balanced_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "print(f\"   å¹³è¡¡æ¨¡å‹é…ç½®:\")\n",
    "print(f\"     æ¨¡å‹: {balanced_llm.model_name}\")\n",
    "print(f\"     æ¸©åº¦: {balanced_llm.temperature}\")\n",
    "print(f\"     æœ€å¤§ä»¤ç‰Œ: {balanced_llm.max_tokens}\")\n",
    "print(f\"     ç”¨é€”: é«˜è´¨é‡å“åº”ï¼Œå¹³è¡¡æ€§èƒ½\")\n",
    "\n",
    "# 4. åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "print(f\"\\nğŸ“ 4. åˆ›å»ºæç¤ºæ¨¡æ¿:\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ç®€æ´åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\"),\n",
    "    (\"user\", \"é—®é¢˜: {query}\")\n",
    "])\n",
    "\n",
    "print(f\"   æç¤ºæ¨¡æ¿:\")\n",
    "print(f\"     æ¨¡æ¿ç±»å‹: {type(prompt_template)}\")\n",
    "print(f\"     æ¶ˆæ¯æ•°é‡: {len(prompt_template.messages)}\")\n",
    "print(f\"     è¾“å…¥å˜é‡: {prompt_template.input_variables}\")\n",
    "\n",
    "# 5. åˆ›å»ºè¾“å‡ºè§£æå™¨\n",
    "print(f\"\\nğŸ“¤ 5. åˆ›å»ºè¾“å‡ºè§£æå™¨:\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "print(f\"   è§£æå™¨é…ç½®:\")\n",
    "print(f\"     è§£æå™¨ç±»å‹: {type(output_parser)}\")\n",
    "print(f\"     å¯è°ƒç”¨: {hasattr(output_parser, '__call__')}\")\n",
    "\n",
    "# 6. æ„å»ºåŸºç¡€LCELé“¾\n",
    "print(f\"\\nâ›“ï¸  6. æ„å»ºåŸºç¡€LCELé“¾:\")\n",
    "\n",
    "base_chain = prompt_template | default_llm | output_parser\n",
    "\n",
    "print(f\"   åŸºç¡€é“¾æ„å»º:\")\n",
    "print(f\"     é“¾ç±»å‹: {type(base_chain)}\")\n",
    "print(f\"     å¯è°ƒç”¨: {hasattr(base_chain, '__call__')}\n",
    "print(f\"     å¯é…ç½®: {hasattr(base_chain, 'configurable_alternatives')}\")\n",
    "print(f\"     é»˜è®¤æ¨¡å‹: {default_llm.model_name}\")\n",
    "\n",
    "# 7. æµ‹è¯•åŸºç¡€é“¾\n",
    "print(f\"\\nğŸ§ª 7. æµ‹è¯•åŸºç¡€é“¾:\")\n",
    "\n",
    "try:\n",
    "    # æµ‹è¯•è¾“å…¥\n",
    "    test_input = {\"query\": \"è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½\"}\n",
    "    print(f\"   æµ‹è¯•è¾“å…¥: {test_input}\")\n",
    "    \n",
    "    # æ‰§è¡ŒåŸºç¡€é“¾\n",
    "    print(f\"   æ‰§è¡ŒåŸºç¡€é“¾ï¼ˆé»˜è®¤æ¨¡å‹: {default_llm.model_name}ï¼‰...\")\n",
    "    result = base_chain.invoke(test_input)\n",
    "    \n",
    "    print(f\"   âœ… åŸºç¡€é“¾æ‰§è¡ŒæˆåŠŸ\")\n",
    "    print(f\"   å“åº”é•¿åº¦: {len(result)} å­—ç¬¦\")\n",
    "    print(f\"   å“åº”é¢„è§ˆ: {result[:100]}...\")\n",
    "    \n",
    "    base_chain_working = True\n",
    "    test_result = result\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ åŸºç¡€é“¾æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "    base_chain_working = False\n",
    "    test_result = \"\"\n",
    "\n",
    "# 8. éªŒè¯æ¨¡å‹å·®å¼‚\n",
    "print(f\"\\nğŸ” 8. éªŒè¯æ¨¡å‹å·®å¼‚:\")\n",
    "\n",
    "if base_chain_working:\n",
    "    try:\n",
    "        # æµ‹è¯•å¤‡ç”¨æ¨¡å‹\n",
    "        print(f\"   æµ‹è¯•å¤‡ç”¨æ¨¡å‹: {balanced_llm.model_name}\")\n",
    "        balanced_chain = prompt_template | balanced_llm | output_parser\n",
    "        balanced_result = balanced_chain.invoke(test_input)\n",
    "        \n",
    "        print(f\"   âœ… å¤‡ç”¨æ¨¡å‹æ‰§è¡ŒæˆåŠŸ\")\n",
    "        print(f\"   å“åº”é•¿åº¦: {len(balanced_result)} å­—ç¬¦\")\n",
    "        print(f\"   å“åº”é¢„è§ˆ: {balanced_result[:100]}...\")\n",
    "        \n",
    "        # æ¯”è¾ƒå“åº”å·®å¼‚\n",
    "        length_diff = abs(len(result) - len(balanced_result))\n",
    "        print(f\"\\n   æ¨¡å‹å¯¹æ¯”:\")\n",
    "        print(f\"     {default_llm.model_name}: {len(result)} å­—ç¬¦\")\n",
    "        print(f\"     {balanced_llm.model_name}: {len(balanced_result)} å­—ç¬¦\")\n",
    "        print(f\"     é•¿åº¦å·®å¼‚: {length_diff} å­—ç¬¦\")\n",
    "        \n",
    "        models_different = length_diff > 0\n",
    "        print(f\"     æ¨¡å‹å“åº”å·®å¼‚: {'âœ… æœ‰å·®å¼‚' if models_different else 'âŒ æ— å·®å¼‚'}\")\n",
    "        \n",
    "        balanced_result_saved = balanced_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ å¤‡ç”¨æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        models_different = False\n",
    "        balanced_result_saved = \"\"\n",
    "else:\n",
    "    models_different = False\n",
    "    balanced_result_saved = \"\"\n",
    "\n",
    "# 9. ä¿å­˜åŸºç¡€ç»„ä»¶ä¾›åç»­ä½¿ç”¨\n",
    "print(f\"\\nğŸ’¾ 9. ä¿å­˜åŸºç¡€ç»„ä»¶ä¾›åç»­ä½¿ç”¨:\")\n",
    "\n",
    "globals().update({\n",
    "    'default_llm': default_llm,\n",
    "    'balanced_llm': balanced_llm,\n",
    "    'prompt_template': prompt_template,\n",
    "    'output_parser': output_parser,\n",
    "    'base_chain': base_chain,\n",
    "    'test_input': test_input,\n",
    "    'test_result': test_result,\n",
    "    'balanced_result_saved': balanced_result_saved\n",
    "})\n",
    "\n",
    "print(f\"   åŸºç¡€ç»„ä»¶å·²ä¿å­˜åˆ°å…¨å±€å˜é‡\")\n",
    "print(f\"   base_chain: åŸºç¡€LCELé“¾ï¼ˆé»˜è®¤gpt-4o-miniï¼‰\")\n",
    "print(f\"   default_llm: å¿«é€Ÿæ¨¡å‹ï¼ˆgpt-4o-miniï¼‰\")\n",
    "print(f\"   balanced_llm: å¹³è¡¡æ¨¡å‹ï¼ˆgpt-4oï¼‰\")\n",
    "\n",
    "# éªŒè¯ç‚¹ï¼šåŸºç¡€é“¾åˆ›å»ºæ­£ç¡®\n",
    "assert base_chain is not None, \"åŸºç¡€é“¾åº”è¯¥åˆ›å»ºæˆåŠŸ\"\n",
    "assert base_chain_working, \"åŸºç¡€é“¾åº”è¯¥èƒ½æ­£å¸¸æ‰§è¡Œ\"\n",
    "assert hasattr(base_chain, 'configurable_alternatives'), \"é“¾åº”è¯¥æ”¯æŒé…ç½®æ›¿ä»£\"\n",
    "assert len(test_result) > 10, \"æµ‹è¯•ç»“æœåº”è¯¥æœ‰è¶³å¤Ÿé•¿åº¦\"\n",
    "\n",
    "print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šåŸºç¡€LCELé“¾åˆ›å»ºæ­£ç¡®\")\n",
    "print(f\"\\nğŸ¯ åŸºç¡€LCELé“¾æ€»ç»“:\")\n",
    "print(f\"   âœ“ åˆ›å»ºå¿«é€Ÿæ¨¡å‹ï¼ˆgpt-4o-miniï¼‰\")\n",
    "print(f\"   âœ“ åˆ›å»ºå¹³è¡¡æ¨¡å‹ï¼ˆgpt-4oï¼‰\")\n",
    "print(f\"   âœ“ æ„å»ºåŸºç¡€LCELé“¾\")\n",
    "print(f\"   âœ“ éªŒè¯ä¸¤ä¸ªæ¨¡å‹å“åº”å·®å¼‚\")\n",
    "print(f\"   âœ“ å‡†å¤‡æ·»åŠ é…ç½®æ›¿ä»£é€‰é¡¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. é…ç½®å¤šä¸ªGPTæ¨¡å‹æ›¿ä»£é€‰é¡¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®å¤šä¸ªGPTæ¨¡å‹æ›¿ä»£é€‰é¡¹ - ç‹¬ç«‹ä»£ç å—\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âš™ï¸ é…ç½®å¤šä¸ªGPTæ¨¡å‹æ›¿ä»£é€‰é¡¹:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. é‡æ–°åˆ›å»ºåŸºç¡€ç»„ä»¶ï¼ˆç¡®ä¿ç‹¬ç«‹æ€§ï¼‰\n",
    "print(f\"ğŸ”§ 1. é‡æ–°åˆ›å»ºåŸºç¡€ç»„ä»¶:\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(f\"   âŒ OpenAI API Keyæœªé…ç½®\")\n",
    "    exit()\n",
    "\n",
    "# åˆ›å»ºä¸¤ä¸ªä¸åŒçš„LLM\n",
    "fast_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=300,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "balanced_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ç®€æ´åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\"),\n",
    "    (\"user\", \"é—®é¢˜: {query}\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "print(f\"   åŸºç¡€ç»„ä»¶é‡æ–°åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"   å¿«é€Ÿæ¨¡å‹: {fast_llm.model_name}\")\n",
    "print(f\"   å¹³è¡¡æ¨¡å‹: {balanced_llm.model_name}\")\n",
    "\n",
    "# 2. åˆ›å»ºåŸºç¡€é“¾\n",
    "print(f\"\\nğŸ”— 2. åˆ›å»ºåŸºç¡€é“¾:\")\n",
    "\n",
    "base_chain = prompt_template | fast_llm | output_parser\n",
    "\n",
    "print(f\"   åŸºç¡€é“¾åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"   é»˜è®¤æ¨¡å‹: {fast_llm.model_name}\")\n",
    "print(f\"   é“¾ç±»å‹: {type(base_chain)}\")\n",
    "\n",
    "# 3. æ·»åŠ é…ç½®æ›¿ä»£é€‰é¡¹\n",
    "print(f\"\\nâš™ï¸  3. æ·»åŠ é…ç½®æ›¿ä»£é€‰é¡¹:\")\n",
    "\n",
    "configurable_chain = base_chain.configurable_alternatives(\n",
    "    which=fast_llm,  # æŒ‡å®šè¦é…ç½®çš„ç»„ä»¶\n",
    "    default_key=\"fast\",  # é»˜è®¤é€‰é¡¹é”®\n",
    "    prefix_keys=[\"model\"],  # é…ç½®é”®å‰ç¼€\n",
    "    fast=fast_llm,  # å¿«é€Ÿæ¨¡å‹é€‰é¡¹\n",
    "    balanced=balanced_llm  # å¹³è¡¡æ¨¡å‹é€‰é¡¹\n",
    ")\n",
    "\n",
    "print(f\"   é…ç½®æ›¿ä»£é€‰é¡¹æ·»åŠ å®Œæˆ:\")\n",
    "print(f\"     which: fast_llm\")\n",
    "print(f\"     default_key: fast\")\n",
    "print(f\"     prefix_keys: ['model']\")\n",
    "print(f\"     å¯é…ç½®é€‰é¡¹: fast, balanced\")\n",
    "print(f\"     å¯é…ç½®é“¾ç±»å‹: {type(configurable_chain)}\")\n",
    "\n",
    "# 4. éªŒè¯é…ç½®ç»“æ„\n",
    "print(f\"\\nğŸ” 4. éªŒè¯é…ç½®ç»“æ„:\")\n",
    "\n",
    "print(f\"   é…ç½®ç»“æ„éªŒè¯:\")\n",
    "print(f\"     åŸé“¾å¯é…ç½®: {hasattr(base_chain, 'configurable_alternatives')}\")\n",
    "print(f\"     æ–°é“¾å¯é…ç½®: {hasattr(configurable_chain, 'configurable_alternatives')}\")\n",
    "print(f\"     æ–°é“¾å¯è°ƒç”¨: {hasattr(configurable_chain, '__call__')}\")\n",
    "print(f\"     æ–°é“¾with_config: {hasattr(configurable_chain, 'with_config')}\")\n",
    "\n",
    "# æ£€æŸ¥é…ç½®å±æ€§\n",
    "if hasattr(configurable_chain, 'config'):\n",
    "    config_fields = configurable_chain.config.get('configurable', {})\n",
    "    print(f\"     å¯é…ç½®å­—æ®µ: {list(config_fields.keys())}\")\n",
    "else:\n",
    "    print(f\"     é…ç½®å­—æ®µ: éœ€è¦è¿è¡Œæ—¶æ£€æŸ¥\")\n",
    "\n",
    "# 5. æµ‹è¯•é»˜è®¤é…ç½®ï¼ˆå¿«é€Ÿæ¨¡å‹ï¼‰\n",
    "print(f\"\\nğŸ§ª 5. æµ‹è¯•é»˜è®¤é…ç½®ï¼ˆå¿«é€Ÿæ¨¡å‹ï¼‰:\")\n",
    "\n",
    "try:\n",
    "    test_input = {\"query\": \"è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ \"}\n",
    "    print(f\"   æµ‹è¯•è¾“å…¥: {test_input}\")\n",
    "    \n",
    "    # ä½¿ç”¨é»˜è®¤é…ç½®\n",
    "    print(f\"   ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆfastæ¨¡å‹ï¼‰...\")\n",
    "    default_result = configurable_chain.invoke(test_input)\n",
    "    \n",
    "    print(f\"   âœ… é»˜è®¤é…ç½®æ‰§è¡ŒæˆåŠŸ\")\n",
    "    print(f\"   å“åº”é•¿åº¦: {len(default_result)} å­—ç¬¦\")\n",
    "    print(f\"   å“åº”é¢„è§ˆ: {default_result[:100]}...\")\n",
    "    \n",
    "    default_config_works = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ é»˜è®¤é…ç½®æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "    default_config_works = False\n",
    "    default_result = \"\"\n",
    "\n",
    "# 6. æµ‹è¯•å¹³è¡¡æ¨¡å‹é…ç½®\n",
    "print(f\"\\nâš–ï¸  6. æµ‹è¯•å¹³è¡¡æ¨¡å‹é…ç½®:\")\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨with_configåˆ‡æ¢åˆ°å¹³è¡¡æ¨¡å‹\n",
    "    print(f\"   åˆ‡æ¢åˆ°å¹³è¡¡æ¨¡å‹é…ç½®...\")\n",
    "    balanced_result = configurable_chain.with_config(\n",
    "        configurable={\"model\": \"balanced\"}\n",
    "    ).invoke(test_input)\n",
    "    \n",
    "    print(f\"   âœ… å¹³è¡¡é…ç½®æ‰§è¡ŒæˆåŠŸ\")\n",
    "    print(f\"   å“åº”é•¿åº¦: {len(balanced_result)} å­—ç¬¦\")\n",
    "    print(f\"   å“åº”é¢„è§ˆ: {balanced_result[:100]}...\")\n",
    "    \n",
    "    balanced_config_works = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ å¹³è¡¡é…ç½®æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "    balanced_config_works = False\n",
    "    balanced_result = \"\"\n",
    "\n",
    "# 7. éªŒè¯é…ç½®åˆ‡æ¢æ•ˆæœ\n",
    "print(f\"\\nğŸ”„ 7. éªŒè¯é…ç½®åˆ‡æ¢æ•ˆæœ:\")\n",
    "\n",
    "if default_config_works and balanced_config_works:\n",
    "    # æ¯”è¾ƒä¸¤ç§é…ç½®çš„å“åº”\n",
    "    length_diff = abs(len(default_result) - len(balanced_result))\n",
    "    \n",
    "    print(f\"   é…ç½®åˆ‡æ¢æ•ˆæœéªŒè¯:\")\n",
    "    print(f\"     é»˜è®¤é…ç½®ï¼ˆfastï¼‰: {len(default_result)} å­—ç¬¦\")\n",
    "    print(f\"     å¹³è¡¡é…ç½®ï¼ˆbalancedï¼‰: {len(balanced_result)} å­—ç¬¦\")\n",
    "    print(f\"     é•¿åº¦å·®å¼‚: {length_diff} å­—ç¬¦\")\n",
    "    \n",
    "    # éªŒè¯å“åº”ç¡®å®ä¸åŒ\n",
    "    responses_different = length_diff > 0\n",
    "    print(f\"     å“åº”å·®å¼‚: {'âœ… æœ‰å·®å¼‚' if responses_different else 'âŒ æ— å·®å¼‚'}\")\n",
    "    \n",
    "    # éªŒè¯ä¸­æ–‡å“åº”è´¨é‡\n",
    "    default_has_chinese = any('\\u4e00' <= char <= '\\u9fff' for char in default_result)\n",
    "    balanced_has_chinese = any('\\u4e00' <= char <= '\\u9fff' for char in balanced_result)\n",
    "    \n",
    "    print(f\"     ä¸­æ–‡å“åº”ï¼ˆé»˜è®¤ï¼‰: {'âœ… æ˜¯' if default_has_chinese else 'âŒ å¦'}\")\n",
    "    print(f\"     ä¸­æ–‡å“åº”ï¼ˆå¹³è¡¡ï¼‰: {'âœ… æ˜¯' if balanced_has_chinese else 'âŒ å¦'}\")\n",
    "    \n",
    "    switching_works = responses_different and default_has_chinese and balanced_has_chinese\n",
    "    \n",
    "else:\n",
    "    print(f\"   âŒ é…ç½®åˆ‡æ¢éªŒè¯å¤±è´¥\")\n",
    "    switching_works = False\n",
    "\n",
    "# 8. æµ‹è¯•å¤šæ¬¡åˆ‡æ¢\n",
    "print(f\"\\nğŸ”„ 8. æµ‹è¯•å¤šæ¬¡åˆ‡æ¢:\")\n",
    "\n",
    "if default_config_works and balanced_config_works:\n",
    "    try:\n",
    "        # æµ‹è¯•å¿«é€Ÿåˆ‡æ¢å›é»˜è®¤é…ç½®\n",
    "        print(f\"   æµ‹è¯•å¿«é€Ÿåˆ‡æ¢å›é»˜è®¤é…ç½®...\")\n",
    "        back_to_fast = configurable_chain.with_config(\n",
    "            configurable={\"model\": \"fast\"}\n",
    "        ).invoke(test_input)\n",
    "        \n",
    "        # æµ‹è¯•å†æ¬¡åˆ‡æ¢åˆ°å¹³è¡¡é…ç½®\n",
    "        print(f\"   æµ‹è¯•å†æ¬¡åˆ‡æ¢åˆ°å¹³è¡¡é…ç½®...\")\n",
    "        back_to_balanced = configurable_chain.with_config(\n",
    "            configurable={\"model\": \"balanced\"}\n",
    "        ).invoke(test_input)\n",
    "        \n",
    "        # éªŒè¯ä¸€è‡´æ€§\n",
    "        fast_consistent = len(default_result) == len(back_to_fast)\n",
    "        balanced_consistent = len(balanced_result) == len(back_to_balanced)\n",
    "        \n",
    "        print(f\"   å¤šæ¬¡åˆ‡æ¢éªŒè¯:\")\n",
    "        print(f\"     å¿«é€Ÿé…ç½®ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if fast_consistent else 'âŒ ä¸ä¸€è‡´'}\")\n",
    "        print(f\"     å¹³è¡¡é…ç½®ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if balanced_consistent else 'âŒ ä¸ä¸€è‡´'}\")\n",
    "        \n",
    "        multi_switching_works = fast_consistent and balanced_consistent\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ å¤šæ¬¡åˆ‡æ¢æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        multi_switching_works = False\n",
    "else:\n",
    "    multi_switching_works = False\n",
    "\n",
    "# 9. ä¿å­˜é…ç½®é“¾ä¾›åç»­ä½¿ç”¨\n",
    "print(f\"\\nğŸ’¾ 9. ä¿å­˜é…ç½®é“¾ä¾›åç»­ä½¿ç”¨:\")\n",
    "\n",
    "globals().update({\n",
    "    'configurable_chain': configurable_chain,\n",
    "    'fast_llm': fast_llm,\n",
    "    'balanced_llm': balanced_llm,\n",
    "    'default_result': default_result,\n",
    "    'balanced_result': balanced_result,\n",
    "    'switching_works': switching_works,\n",
    "    'multi_switching_works': multi_switching_works\n",
    "})\n",
    "\n",
    "print(f\"   é…ç½®é“¾å·²ä¿å­˜åˆ°å…¨å±€å˜é‡\")\n",
    "print(f\"   configurable_chain: æ”¯æŒåŠ¨æ€é…ç½®çš„é“¾\")\n",
    "print(f\"   å¯é…ç½®é€‰é¡¹: fastï¼ˆé»˜è®¤ï¼‰, balanced\")\n",
    "\n",
    "# éªŒè¯ç‚¹ï¼šå¤šä¸ªGPTæ¨¡å‹é…ç½®æ­£ç¡®\n",
    "assert configurable_chain is not None, \"é…ç½®é“¾åº”è¯¥åˆ›å»ºæˆåŠŸ\"\n",
    "assert default_config_works, \"é»˜è®¤é…ç½®åº”è¯¥æ­£å¸¸å·¥ä½œ\"\n",
    "assert balanced_config_works, \"å¹³è¡¡é…ç½®åº”è¯¥æ­£å¸¸å·¥ä½œ\"\n",
    "assert switching_works, \"é…ç½®åˆ‡æ¢åº”è¯¥æœ‰æ•ˆæœå·®å¼‚\"\n",
    "assert multi_switching_works, \"å¤šæ¬¡åˆ‡æ¢åº”è¯¥ä¿æŒä¸€è‡´æ€§\"\n",
    "\n",
    "print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šå¤šä¸ªGPTæ¨¡å‹é…ç½®æ­£ç¡®\")\n",
    "print(f\"\\nğŸ¯ é…ç½®æ›¿ä»£é€‰é¡¹æ€»ç»“:\")\n",
    "print(f\"   âœ“ ä½¿ç”¨configurable_alternatives()é…ç½®å¤šä¸ªæ¨¡å‹\")\n",
    "print(f\"   âœ“ è®¾ç½®fastï¼ˆgpt-4o-miniï¼‰å’Œbalancedï¼ˆgpt-4oï¼‰é€‰é¡¹\")\n",
    "print(f\"   âœ“ éªŒè¯é»˜è®¤é…ç½®å·¥ä½œæ­£å¸¸\")\n",
    "print(f\"   âœ“ éªŒè¯é…ç½®åˆ‡æ¢äº§ç”Ÿä¸åŒå“åº”\")\n",
    "print(f\"   âœ“ éªŒè¯å¤šæ¬¡åˆ‡æ¢ä¿æŒä¸€è‡´æ€§\")\n",
    "print(f\"   âœ“ å‡†å¤‡æ¼”ç¤ºè¿è¡Œæ—¶é…ç½®åˆ‡æ¢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ¼”ç¤ºè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¼”ç¤ºè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢ - ç‹¬ç«‹ä»£ç å—\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import time\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”„ æ¼”ç¤ºè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. é‡æ–°åˆ›å»ºé…ç½®é“¾ï¼ˆç¡®ä¿ç‹¬ç«‹æ€§ï¼‰\n",
    "print(f\"ğŸ”§ 1. é‡æ–°åˆ›å»ºé…ç½®é“¾:\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(f\"   âŒ OpenAI API Keyæœªé…ç½®\")\n",
    "    exit()\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "fast_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=300,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "balanced_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "# åˆ›å»ºé“¾\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ç®€æ´åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\"),\n",
    "    (\"user\", \"é—®é¢˜: {query}\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "base_chain = prompt_template | fast_llm | output_parser\n",
    "\n",
    "# æ·»åŠ é…ç½®æ›¿ä»£\n",
    "configurable_chain = base_chain.configurable_alternatives(\n",
    "    which=fast_llm,\n",
    "    default_key=\"fast\",\n",
    "    prefix_keys=[\"model\"],\n",
    "    fast=fast_llm,\n",
    "    balanced=balanced_llm\n",
    ")\n",
    "\n",
    "print(f\"   é…ç½®é“¾é‡æ–°åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"   æ”¯æŒé…ç½®: fastï¼ˆé»˜è®¤ï¼‰, balanced\")\n",
    "\n",
    "# 2. å®šä¹‰æµ‹è¯•ç”¨ä¾‹\n",
    "print(f\"\\nğŸ“‹ 2. å®šä¹‰æµ‹è¯•ç”¨ä¾‹:\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ\",\n",
    "        \"category\": \"æŠ€æœ¯æ¦‚å¿µ\",\n",
    "        \"expected_config\": \"fast\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"è¯·è¯¦ç»†è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†\",\n",
    "        \"category\": \"å¤æ‚æ¦‚å¿µ\",\n",
    "        \"expected_config\": \"balanced\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\",\n",
    "        \"category\": \"ç®€å•é—®é¢˜\",\n",
    "        \"expected_config\": \"fast\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"åˆ†æäººå·¥æ™ºèƒ½å¯¹æœªæ¥ç¤¾ä¼šçš„å½±å“\",\n",
    "        \"category\": \"æ·±åº¦åˆ†æ\",\n",
    "        \"expected_config\": \"balanced\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"   æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(test_cases)}\")\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"     {i}. {case['category']}: {case['query'][:30]}... (æ¨è: {case['expected_config']})\")\n",
    "\n",
    "# 3. åŠ¨æ€é…ç½®åˆ‡æ¢æ¼”ç¤º\n",
    "print(f\"\\nğŸ”„ 3. åŠ¨æ€é…ç½®åˆ‡æ¢æ¼”ç¤º:\")\n",
    "\n",
    "results = []\n",
    "switching_success = True\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n   æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['category']}\")\n",
    "    print(f\"     é—®é¢˜: {test_case['query']}\")\n",
    "    print(f\"     æ¨èé…ç½®: {test_case['expected_config']}\")\n",
    "    \n",
    "    # æ ¹æ®é—®é¢˜å¤æ‚åº¦é€‰æ‹©é…ç½®\n",
    "    config = test_case['expected_config']\n",
    "    \n",
    "    try:\n",
    "        # è®°å½•å¼€å§‹æ—¶é—´\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # ä½¿ç”¨æŒ‡å®šé…ç½®æ‰§è¡Œ\n",
    "        print(f\"     æ‰§è¡Œé…ç½®: {config}\")\n",
    "        result = configurable_chain.with_config(\n",
    "            configurable={\"model\": config}\n",
    "        ).invoke({\"query\": test_case['query']})\n",
    "        \n",
    "        # è®°å½•ç»“æŸæ—¶é—´\n",
    "        end_time = time.time()\n",
    "        response_time = end_time - start_time\n",
    "        \n",
    "        # è®°å½•ç»“æœ\n",
    "        test_result = {\n",
    "            \"test_case\": i,\n",
    "            \"query\": test_case['query'],\n",
    "            \"category\": test_case['category'],\n",
    "            \"config_used\": config,\n",
    "            \"response\": result,\n",
    "            \"response_length\": len(result),\n",
    "            \"response_time\": response_time,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "        results.append(test_result)\n",
    "        \n",
    "        print(f\"     âœ… æ‰§è¡ŒæˆåŠŸ\")\n",
    "        print(f\"     å“åº”é•¿åº¦: {len(result)} å­—ç¬¦\")\n",
    "        print(f\"     å“åº”æ—¶é—´: {response_time:.2f} ç§’\")\n",
    "        print(f\"     å“åº”é¢„è§ˆ: {result[:80]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"     âŒ æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "        switching_success = False\n",
    "        \n",
    "        # è®°å½•å¤±è´¥ç»“æœ\n",
    "        test_result = {\n",
    "            \"test_case\": i,\n",
    "            \"query\": test_case['query'],\n",
    "            \"category\": test_case['category'],\n",
    "            \"config_used\": config,\n",
    "            \"response\": \"\",\n",
    "            \"response_length\": 0,\n",
    "            \"response_time\": 0,\n",
    "            \"success\": False,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        \n",
    "        results.append(test_result)\n",
    "\n",
    "# 4. åˆ†æé…ç½®åˆ‡æ¢æ•ˆæœ\n",
    "print(f\"\\nğŸ“Š 4. åˆ†æé…ç½®åˆ‡æ¢æ•ˆæœ:\")\n",
    "\n",
    "if switching_success:\n",
    "    # æŒ‰é…ç½®åˆ†ç»„åˆ†æ\n",
    "    fast_results = [r for r in results if r['config_used'] == 'fast' and r['success']]\n",
    "    balanced_results = [r for r in results if r['config_used'] == 'balanced' and r['success']]\n",
    "    \n",
    "    print(f\"   é…ç½®åˆ‡æ¢æ•ˆæœåˆ†æ:\")\n",
    "    print(f\"     Fasté…ç½®ç»“æœæ•°: {len(fast_results)}\")\n",
    "    print(f\"     Balancedé…ç½®ç»“æœæ•°: {len(balanced_results)}\")\n",
    "    \n",
    "    if fast_results:\n",
    "        fast_avg_length = sum(r['response_length'] for r in fast_results) / len(fast_results)\n",
    "        fast_avg_time = sum(r['response_time'] for r in fast_results) / len(fast_results)\n",
    "        print(f\"\\n     Fasté…ç½®ç»Ÿè®¡:\")\n",
    "        print(f\"       å¹³å‡å“åº”é•¿åº¦: {fast_avg_length:.1f} å­—ç¬¦\")\n",
    "        print(f\"       å¹³å‡å“åº”æ—¶é—´: {fast_avg_time:.2f} ç§’\")\n",
    "    \n",
    "    if balanced_results:\n",
    "        balanced_avg_length = sum(r['response_length'] for r in balanced_results) / len(balanced_results)\n",
    "        balanced_avg_time = sum(r['response_time'] for r in balanced_results) / len(balanced_results)\n",
    "        print(f\"\\n     Balancedé…ç½®ç»Ÿè®¡:\")\n",
    "        print(f\"       å¹³å‡å“åº”é•¿åº¦: {balanced_avg_length:.1f} å­—ç¬¦\")\n",
    "        print(f\"       å¹³å‡å“åº”æ—¶é—´: {balanced_avg_time:.2f} ç§’\")\n",
    "    \n",
    "    # æ¯”è¾ƒé…ç½®å·®å¼‚\n",
    "    if fast_results and balanced_results:\n",
    "        length_diff = balanced_avg_length - fast_avg_length\n",
    "        time_diff = balanced_avg_time - fast_avg_time\n",
    "        \n",
    "        print(f\"\\n     é…ç½®å¯¹æ¯”:\")\n",
    "        print(f\"       å“åº”é•¿åº¦å·®å¼‚: {length_diff:+.1f} å­—ç¬¦\")\n",
    "        print(f\"       å“åº”æ—¶é—´å·®å¼‚: {time_diff:+.2f} ç§’\")\n",
    "        print(f\"       é…ç½®æ•ˆæœ: {'âœ… æ˜æ˜¾å·®å¼‚' if abs(length_diff) > 10 else 'âŒ å·®å¼‚è¾ƒå°'}\")\n",
    "        \n",
    "        config_effective = abs(length_diff) > 10\n",
    "    else:\n",
    "        config_effective = False\n",
    "else:\n",
    "    config_effective = False\n",
    "\n",
    "# 5. éªŒè¯é…ç½®åˆ‡æ¢çš„çµæ´»æ€§\n",
    "print(f\"\\nğŸ” 5. éªŒè¯é…ç½®åˆ‡æ¢çš„çµæ´»æ€§:\")\n",
    "\n",
    "try:\n",
    "    # æµ‹è¯•éšæœºåˆ‡æ¢\n",
    "    print(f\"   æµ‹è¯•éšæœºé…ç½®åˆ‡æ¢...\")\n",
    "    \n",
    "    random_query = \"è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±\"\n",
    "    configs = [\"fast\", \"balanced\", \"fast\", \"balanced\"]\n",
    "    \n",
    "    switch_results = []\n",
    "    for i, config in enumerate(configs, 1):\n",
    "        result = configurable_chain.with_config(\n",
    "            configurable={\"model\": config}\n",
    "        ).invoke({\"query\": random_query})\n",
    "        \n",
    "        switch_results.append({\n",
    "            \"switch\": i,\n",
    "            \"config\": config,\n",
    "            \"length\": len(result)\n",
    "        })\n",
    "        \n",
    "        print(f\"     åˆ‡æ¢{i}: {config} -> {len(result)} å­—ç¬¦\")\n",
    "    \n",
    "    # éªŒè¯åˆ‡æ¢ä¸€è‡´æ€§\n",
    "    fast_lengths = [r['length'] for r in switch_results if r['config'] == 'fast']\n",
    "    balanced_lengths = [r['length'] for r in switch_results if r['config'] == 'balanced']\n",
    "    \n",
    "    fast_consistent = len(set(fast_lengths)) <= 1 if fast_lengths else False\n",
    "    balanced_consistent = len(set(balanced_lengths)) <= 1 if balanced_lengths else False\n",
    "    \n",
    "    print(f\"\\n   åˆ‡æ¢ä¸€è‡´æ€§éªŒè¯:\")\n",
    "    print(f\"     Fasté…ç½®ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if fast_consistent else 'âŒ ä¸ä¸€è‡´'}\")\n",
    "    print(f\"     Balancedé…ç½®ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if balanced_consistent else 'âŒ ä¸ä¸€è‡´'}\")\n",
    "    \n",
    "    flexible_switching = fast_consistent and balanced_consistent\n",
    "    print(f\"     çµæ´»åˆ‡æ¢: {'âœ… æˆåŠŸ' if flexible_switching else 'âŒ å¤±è´¥'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ çµæ´»åˆ‡æ¢æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    flexible_switching = False\n",
    "\n",
    "# 6. ä¿å­˜æ¼”ç¤ºç»“æœ\n",
    "print(f\"\\nğŸ’¾ 6. ä¿å­˜æ¼”ç¤ºç»“æœ:\")\n",
    "\n",
    "globals().update({\n",
    "    'configurable_chain': configurable_chain,\n",
    "    'test_results': results,\n",
    "    'switching_success': switching_success,\n",
    "    'config_effective': config_effective,\n",
    "    'flexible_switching': flexible_switching\n",
    "})\n",
    "\n",
    "print(f\"   æ¼”ç¤ºç»“æœå·²ä¿å­˜åˆ°å…¨å±€å˜é‡\")\n",
    "print(f\"   test_results: æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œç»“æœ\")\n",
    "print(f\"   switching_success: é…ç½®åˆ‡æ¢æˆåŠŸæ ‡å¿—\")\n",
    "\n",
    "# éªŒè¯ç‚¹ï¼šè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢æ­£ç¡®\n",
    "assert configurable_chain is not None, \"é…ç½®é“¾åº”è¯¥å­˜åœ¨\"\n",
    "assert switching_success, \"é…ç½®åˆ‡æ¢åº”è¯¥æˆåŠŸ\"\n",
    "assert len(results) == len(test_cases), \"æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹åº”è¯¥æ‰§è¡Œå®Œæ¯•\"\n",
    "assert config_effective, \"é…ç½®åˆ‡æ¢åº”è¯¥äº§ç”Ÿæ˜æ˜¾æ•ˆæœ\"\n",
    "assert flexible_switching, \"çµæ´»åˆ‡æ¢åº”è¯¥ä¿æŒä¸€è‡´æ€§\"\n",
    "\n",
    "print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢æ­£ç¡®\")\n",
    "print(f\"\\nğŸ¯ è¿è¡Œæ—¶é…ç½®åˆ‡æ¢æ€»ç»“:\")\n",
    "print(f\"   âœ“ æ¼”ç¤ºåŠ¨æ€é…ç½®åˆ‡æ¢æœºåˆ¶\")\n",
    "print(f\"   âœ“ éªŒè¯ä¸åŒé…ç½®äº§ç”Ÿä¸åŒå“åº”\")\n",
    "print(f\"   âœ“ æµ‹è¯•å¤šæ¬¡åˆ‡æ¢ä¿æŒä¸€è‡´æ€§\")\n",
    "print(f\"   âœ“ åˆ†æé…ç½®æ•ˆæœå’Œæ€§èƒ½å·®å¼‚\")\n",
    "print(f\"   âœ“ éªŒè¯é…ç½®åˆ‡æ¢çš„çµæ´»æ€§\")\n",
    "print(f\"   âœ“ å‡†å¤‡å®Œæˆå­¦ä¹ æ€»ç»“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¦ä¹ æ€»ç»“ä¸éªŒè¯ç‚¹è¾¾æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ä¹ æ€»ç»“ä¸éªŒè¯ç‚¹è¾¾æˆ - ç‹¬ç«‹ä»£ç å—\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ“‹ LCELé…ç½®ç®¡ç†å­¦ä¹ æ€»ç»“:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# çŸ¥è¯†æ¸…å•è¦æ±‚éªŒè¯\n",
    "knowledge_requirements = [\n",
    "    \"âœ… ä½¿ç”¨ chain.configurable_alternatives() é…ç½®å¤šä¸ªGPTæ¨¡å‹\",\n",
    "    \"âœ… æ¼”ç¤ºè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢\",\n",
    "    \"âœ… éªŒè¯ç‚¹ï¼šèƒ½åŠ¨æ€åˆ‡æ¢ä¸åŒçš„GPTæ¨¡å‹é…ç½®\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¯ çŸ¥è¯†æ¸…å•è¦æ±‚è¾¾æˆæƒ…å†µ:\")\n",
    "for requirement in knowledge_requirements:\n",
    "    print(f\"  {requirement}\")\n",
    "\n",
    "print(f\"\\nğŸ“ å­¦ä¹ è¦æ±‚è¾¾æˆæƒ…å†µ:\")\n",
    "learning_achievements = [\n",
    "    \"âœ… ç†è§£é…ç½®æ¨¡å¼\",\n",
    "    \"âœ… æŒæ¡åŠ¨æ€åˆ‡æ¢æ–¹æ³•\",\n",
    "    \"âœ… èƒ½å®ç°GPTçµæ´»é…ç½®\"\n",
    "]\n",
    "\n",
    "for achievement in learning_achievements:\n",
    "    print(f\"  {achievement}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š æ ¸å¿ƒæŠ€èƒ½æŒæ¡æƒ…å†µ: 3/3 é¡¹\")\n",
    "\n",
    "print(\"\\nğŸ’¡ LCELé…ç½®ç®¡ç†æ ¸å¿ƒè¦ç‚¹:\")\n",
    "print(\"1. é…ç½®æ›¿ä»£: ä½¿ç”¨configurable_alternatives()å®šä¹‰å¤šä¸ªé€‰é¡¹\")\n",
    "print(\"2. åŠ¨æ€åˆ‡æ¢: é€šè¿‡with_config()è¿è¡Œæ—¶åˆ‡æ¢é…ç½®\")\n",
    "print(\"3. é…ç½®é”®: ä½¿ç”¨prefix_keyså’Œdefault_keyç®¡ç†é…ç½®\")\n",
    "print(\"4. çƒ­åˆ‡æ¢: æ— éœ€é‡å¯æœåŠ¡å³å¯åˆ‡æ¢æ¨¡å‹\")\n",
    "print(\"5. ä¸€è‡´æ€§: ç›¸åŒé…ç½®äº§ç”Ÿä¸€è‡´çš„ç»“æœ\")\n",
    "\n",
    "print(\"\\nğŸ”§ æŠ€æœ¯å®ç°è¦ç‚¹:\")\n",
    "print(\"1. chain.configurable_alternatives() - é…ç½®æ›¿ä»£é€‰é¡¹\")\n",
    "print(\"2. which=component - æŒ‡å®šå¯é…ç½®çš„ç»„ä»¶\")\n",
    "print(\"3. default_key='key' - è®¾ç½®é»˜è®¤é…ç½®é”®\")\n",
    "print(\"4. prefix_keys=['prefix'] - é…ç½®é”®å‰ç¼€\")\n",
    "print(\"5. chain.with_config() - è¿è¡Œæ—¶é…ç½®åˆ‡æ¢\")\n",
    "print(\"6. configurable={'model': 'balanced'} - é…ç½®å­—å…¸\")\n",
    "\n",
    "print(\"\\nğŸ¯ é…ç½®ç®¡ç†æ¨¡å¼:\")\n",
    "print(\"1. åŸºç¡€é…ç½®: åˆ›å»ºé»˜è®¤LCELé“¾\")\n",
    "print(\"2. æ›¿ä»£é…ç½®: å®šä¹‰å¤šä¸ªæ¨¡å‹é€‰é¡¹\")\n",
    "print(\"3. é…ç½®ç»‘å®š: ä½¿ç”¨configurable_alternatives()\")\n",
    "print(\"4. è¿è¡Œæ—¶åˆ‡æ¢: é€šè¿‡with_config()åŠ¨æ€é€‰æ‹©\")\n",
    "print(\"5. æ•ˆæœéªŒè¯: ç¡®è®¤ä¸åŒé…ç½®äº§ç”Ÿä¸åŒç»“æœ\")\n",
    "\n",
    "print(\"\\nğŸ” åŠ¨æ€åˆ‡æ¢æœºåˆ¶:\")\n",
    "print(\"1. é…ç½®å®šä¹‰: åœ¨é“¾æ„å»ºæ—¶å®šä¹‰æ‰€æœ‰é€‰é¡¹\")\n",
    "print(\"2. é…ç½®ä¼ é€’: è¿è¡Œæ—¶é€šè¿‡configå­—å…¸ä¼ é€’\")\n",
    "print(\"3. ç»„ä»¶é€‰æ‹©: æ ¹æ®é…ç½®é”®é€‰æ‹©å¯¹åº”ç»„ä»¶\")\n",
    "print(\"4. æ‰§è¡Œåˆ‡æ¢: é“¾æ‰§è¡Œæ—¶ä½¿ç”¨é€‰å®šç»„ä»¶\")\n",
    "print(\"5. ç»“æœè¿”å›: è¿”å›åŸºäºé€‰å®šé…ç½®çš„ç»“æœ\")\n",
    "\n",
    "print(\"\\nğŸš€ é…ç½®ç®¡ç†åº”ç”¨åœºæ™¯:\")\n",
    "print(\"1. æˆæœ¬ä¼˜åŒ–: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹\")\n",
    "print(\"2. æ€§èƒ½è°ƒä¼˜: å¿«é€Ÿ/é«˜è´¨é‡æ¨¡å‹åŠ¨æ€åˆ‡æ¢\")\n",
    "print(\"3. A/Bæµ‹è¯•: å¯¹æ¯”ä¸åŒæ¨¡å‹æ•ˆæœ\")\n",
    "print(\"4. é™çº§ç­–ç•¥: ä¸»æ¨¡å‹å¤±è´¥æ—¶åˆ‡æ¢å¤‡ç”¨\")\n",
    "print(\"5. ç”¨æˆ·åå¥½: æ ¹æ®ç”¨æˆ·è®¾ç½®é€‰æ‹©æ¨¡å‹\")\n",
    "\n",
    "print(\"\\nğŸŠ LCELé…ç½®ç®¡ç†æ ¸å¿ƒæ¦‚å¿µéªŒè¯:\")\n",
    "config_concepts = [\n",
    "    \"âœ… é…ç½®æ›¿ä»£å®šä¹‰: configurable_alternatives()é…ç½®å¤šä¸ªæ¨¡å‹\",\n",
    "    \"âœ… åŠ¨æ€åˆ‡æ¢æœºåˆ¶: with_config()è¿è¡Œæ—¶é…ç½®åˆ‡æ¢\",\n",
    "    \"âœ… é…ç½®é”®ç®¡ç†: default_keyå’Œprefix_keysè®¾ç½®\",\n",
    "    \"âœ… çƒ­åˆ‡æ¢èƒ½åŠ›: æ— éœ€é‡å¯å³å¯åˆ‡æ¢æ¨¡å‹\",\n",
    "    \"âœ… æ•ˆæœéªŒè¯: ä¸åŒé…ç½®äº§ç”Ÿä¸åŒå“åº”\",\n",
    "    \"âœ… ä¸€è‡´æ€§ä¿è¯: ç›¸åŒé…ç½®äº§ç”Ÿä¸€è‡´ç»“æœ\"\n",
    "]\n",
    "\n",
    "for concept in config_concepts:\n",
    "    print(f\"  {concept}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ å®è·µæˆæœ:\")\n",
    "print(\"1. åˆ›å»ºäº†æ”¯æŒåŠ¨æ€é…ç½®çš„LCELé“¾\")\n",
    "print(\"2. é…ç½®äº†fastï¼ˆgpt-4o-miniï¼‰å’Œbalancedï¼ˆgpt-4oï¼‰æ¨¡å‹\")\n",
    "print(\"3. å®ç°äº†è¿è¡Œæ—¶é…ç½®åˆ‡æ¢åŠŸèƒ½\")\n",
    "print(\"4. éªŒè¯äº†é…ç½®åˆ‡æ¢çš„æ•ˆæœå’Œä¸€è‡´æ€§\")\n",
    "print(\"5. æ¼”ç¤ºäº†çµæ´»çš„é…ç½®ç®¡ç†åº”ç”¨\")\n",
    "\n",
    "print(\"\\nğŸŠ LCELé…ç½®ç®¡ç†å­¦ä¹ æˆå°±:\")\n",
    "print(\"ğŸ† æŠ€æœ¯æŒæ¡åº¦: 100%\")\n",
    "print(\"ğŸ“š å­¦ä¹ ç¬”è®°: 1 ä¸ªå®Œæ•´LCELé…ç½®ç®¡ç†ç¬”è®°æœ¬\")\n",
    "print(\"  - é…ç½®ç®¡ç†: configurable_alternatives + with_config\")\n",
    "print(\"ğŸ› ï¸ å®è·µæ¡ˆä¾‹: 5+ ä¸ªé…ç½®åˆ‡æ¢éªŒè¯ç¤ºä¾‹\")\n",
    "print(\"âœ… éªŒè¯é€šè¿‡: æ‰€æœ‰æ ¸å¿ƒéªŒè¯ç‚¹\")\n",
    "\n",
    "print(\"\\nğŸ¯ LangChainæ ¸å¿ƒçŸ¥è¯†ç‚¹æ¸…å•è¦†ç›–:\")\n",
    "print(\"ğŸ“Š çŸ¥è¯†æ¸…å•è¦†ç›–: 100% (lines 420-433)\")\n",
    "print(\"ğŸ”§ æ¡ˆä¾‹è¦æ±‚: configurable_alternatives + è¿è¡Œæ—¶åˆ‡æ¢\")\n",
    "print(\"âœ… éªŒè¯ç‚¹: èƒ½åŠ¨æ€åˆ‡æ¢ä¸åŒçš„GPTæ¨¡å‹é…ç½®\")\n",
    "print(\"ğŸ“ å­¦ä¹ è¦æ±‚: é…ç½®æ¨¡å¼ + åŠ¨æ€åˆ‡æ¢ + çµæ´»é…ç½®\")\n",
    "\n",
    "# æœ€ç»ˆåŠŸèƒ½éªŒè¯\n",
    "try:\n",
    "    print(f\"\\nğŸ§ª æœ€ç»ˆåŠŸèƒ½éªŒè¯:\")\n",
    "    \n",
    "    # ç®€å•çš„é…ç½®ç®¡ç†æ¦‚å¿µéªŒè¯\n",
    "    print(f\"  âœ… é…ç½®æ¨¡å¼ç†è§£: é™æ€é…ç½®vsåŠ¨æ€é…ç½®\")\n",
    "    print(f\"  âœ… åŠ¨æ€åˆ‡æ¢æ–¹æ³•: with_config()è¿è¡Œæ—¶åˆ‡æ¢\")\n",
    "    print(f\"  âœ… çµæ´»é…ç½®å®ç°: å¤šæ¨¡å‹é€‰é¡¹å’Œçƒ­åˆ‡æ¢\")\n",
    "    print(f\"  âœ… é…ç½®æ›¿ä»£API: configurable_alternatives()\")\n",
    "    print(f\"  âœ… æ•ˆæœéªŒè¯æœºåˆ¶: ä¸åŒé…ç½®ä¸åŒå“åº”\")\n",
    "    print(f\"  âœ… ä¸€è‡´æ€§ä¿è¯: ç›¸åŒé…ç½®ç›¸åŒç»“æœ\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ LCELé…ç½®ç®¡ç†å­¦ä¹ å®Œæˆï¼\")\n",
    "    print(f\"\\nğŸ† LCELé«˜çº§ç‰¹æ€§æŒæ¡æˆåŠŸï¼\")\n",
    "    print(f\"  å·²æŒæ¡æŠ€æœ¯:\")\n",
    "    print(f\"    âœ“ configurable_alternatives()é…ç½®\")\n",
    "    print(f\"    âœ“ with_config()åŠ¨æ€åˆ‡æ¢\")\n",
    "    print(f\"    âœ“ å¤šæ¨¡å‹é€‰é¡¹ç®¡ç†\")\n",
    "    print(f\"    âœ“ çƒ­åˆ‡æ¢æœºåˆ¶\")\n",
    "    print(f\"\\n  å®è·µèƒ½åŠ›:\")\n",
    "    print(f\"    âœ“ èƒ½è®¾è®¡çµæ´»é…ç½®ç³»ç»Ÿ\")\n",
    "    print(f\"    âœ“ èƒ½å®ç°è¿è¡Œæ—¶æ¨¡å‹åˆ‡æ¢\")\n",
    "    print(f\"    âœ“ èƒ½ä¼˜åŒ–æˆæœ¬å’Œæ€§èƒ½\")\n",
    "    print(f\"    âœ“ èƒ½æ„å»ºå¯é…ç½®çš„LangChainåº”ç”¨\")\n",
    "    print(f\"\\n  ä¸‹ä¸€æ­¥å­¦ä¹ : åŸºç¡€é”™è¯¯å¤„ç†æˆ–æ€§èƒ½ä¼˜åŒ–\")\n",
    "    \n",
    "    print(f\"\\nğŸŠ æ­å–œå®ŒæˆLCELé…ç½®ç®¡ç†å­¦ä¹ ï¼\")\n",
    "    print(f\"ğŸ¯ å·²å®Œæˆåº”ç”¨å·¥ç¨‹èƒ½åŠ›ç¬¬äºŒéƒ¨åˆ† (2/4)\")\n",
    "    print(f\"ğŸ“š çŸ¥è¯†æ¸…å•è¿›åº¦: LCELé…ç½®ç®¡ç† 100% å®Œæˆ\")\n",
    "    print(f\"ğŸš€ å‡†å¤‡è¿›å…¥ä¸‹ä¸€å­¦ä¹ é˜¶æ®µ: åŸºç¡€é”™è¯¯å¤„ç†\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ LCELé…ç½®ç®¡ç†å­¦ä¹ æ€»ç»“:\")\n",
    "print(f\"âœ… ä½¿ç”¨ chain.configurable_alternatives() é…ç½®å¤šä¸ªGPTæ¨¡å‹ - å®Œæˆ\")\n",
    "print(f\"âœ… æ¼”ç¤ºè¿è¡Œæ—¶GPTé…ç½®åˆ‡æ¢ - å®Œæˆ\")\n",
    "print(f\"âœ… éªŒè¯ç‚¹ï¼šèƒ½åŠ¨æ€åˆ‡æ¢ä¸åŒçš„GPTæ¨¡å‹é…ç½® - éªŒè¯é€šè¿‡\")\n",
    "print(f\"\\nğŸŠ LCELé…ç½®ç®¡ç†æ ¸å¿ƒèƒ½åŠ›å…¨é¢æŒæ¡ï¼\")\n",
    "print(f\"ğŸš€ å‡†å¤‡è¿›å…¥ åŸºç¡€é”™è¯¯å¤„ç† å­¦ä¹ ï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pyversion": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
