{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19 - RunnablePassthrough æ•°æ®ä¼ é€’\n",
    "\n",
    "## ç”¨é€”\n",
    "å­¦ä¹ é€šä¹‰åƒé—® RunnablePassthrough æ•°æ®ä¼ é€’æœºåˆ¶ï¼Œç”¨äºåœ¨é“¾ä¸­ä¿ç•™åŸå§‹è¾“å…¥ï¼Œåšå¤šè·¯åˆ†å‘æ—¶éå¸¸å¸¸ç”¨\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£ RunnablePassthrough æ•°æ®ä¼ é€’æœºåˆ¶\n",
    "- æŒæ¡è¾“å…¥ä¿ç•™æ–¹æ³•å’Œæ•°æ®æµè·¯å¾„è®¾è®¡\n",
    "- èƒ½æ„å»ºåŒ…å« Passthrough çš„å¤æ‚é“¾\n",
    "- æŒæ¡å¤šè·¯åˆ†å‘å’Œæ•°æ®åˆå¹¶æŠ€æœ¯\n",
    "\n",
    "## ğŸ”‘ å‰ç½®è¦æ±‚\n",
    "**æ³¨æ„**ï¼šéœ€è¦å…ˆå®Œæˆ Runnable åŸºç¡€æ¦‚å¿µå’Œ LCEL ç®¡é“è¯­æ³•å­¦ä¹ \n",
    "\n",
    "## ä»£ç å—ç‹¬ç«‹æ€§è¯´æ˜\n",
    "**æ³¨æ„**ï¼šæ¯ä¸ªä»£ç å—éƒ½æ˜¯ç‹¬ç«‹çš„ï¼ŒåŒ…å«å®Œæ•´çš„å¯¼å…¥å’Œåˆå§‹åŒ–ï¼Œç¡®ä¿å¯ä»¥å•ç‹¬è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RunnablePassthrough åŸºç¡€æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnablePassthrough åŸºç¡€æ¦‚å¿µ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”„ RunnablePassthrough åŸºç¡€æ¦‚å¿µç†è§£:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ğŸ“ RunnablePassthrough æ ¸å¿ƒæ¦‚å¿µ:\")\n",
    "print(f\"   1. æ•°æ®ä¼ é€’ï¼šç›´æ¥å°†è¾“å…¥ä¼ é€’åˆ°è¾“å‡º\")\n",
    "print(f\"   2. è¾“å…¥ä¿ç•™ï¼šåœ¨å¤„ç†è¿‡ç¨‹ä¸­ä¿æŒåŸå§‹æ•°æ®\")\n",
    "print(f\"   3. å¤šè·¯åˆ†å‘ï¼šå°†æ•°æ®åŒæ—¶ä¼ é€’ç»™å¤šä¸ªå¤„ç†è·¯å¾„\")\n",
    "print(f\"   4. æ•°æ®åˆå¹¶ï¼šå°†ä¸åŒå¤„ç†è·¯å¾„çš„ç»“æœåˆå¹¶\")\n",
    "\n",
    "# 1. åŸºç¡€ RunnablePassthrough\n",
    "print(f\"\\nğŸ—ï¸  1. åŸºç¡€ RunnablePassthrough:\")\n",
    "\n",
    "passthrough = RunnablePassthrough()\n",
    "print(f\"   RunnablePassthrough å®ä¾‹: {type(passthrough)}\")\n",
    "print(f\"   å¯è°ƒç”¨: {callable(passthrough)}\")\n",
    "\n",
    "# 2. åŸºç¡€æ•°æ®ä¼ é€’æµ‹è¯•\n",
    "print(f\"\\nğŸ§ª 2. åŸºç¡€æ•°æ®ä¼ é€’æµ‹è¯•:\")\n",
    "\n",
    "test_data = {\n",
    "    \"question\": \"ä»€ä¹ˆæ˜¯Pythonï¼Ÿ\",\n",
    "    \"context\": \"Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€\",\n",
    "    \"user_id\": \"user123\"\n",
    "}\n",
    "\n",
    "print(f\"   è¾“å…¥æ•°æ®: {test_data}\")\n",
    "\n",
    "# ç›´æ¥ä¼ é€’\n",
    "result = passthrough.invoke(test_data)\n",
    "print(f\"   è¾“å‡ºæ•°æ®: {result}\")\n",
    "print(f\"   æ•°æ®ä¿æŒä¸€è‡´: {test_data == result}\")\n",
    "print(f\"   å†…å­˜åœ°å€ç›¸åŒ: {test_data is result}\")\n",
    "\n",
    "# 3. ä¸åŒæ•°æ®ç±»å‹çš„ä¼ é€’\n",
    "print(f\"\\nğŸ§ª 3. ä¸åŒæ•°æ®ç±»å‹çš„ä¼ é€’:\")\n",
    "\n",
    "test_cases = [\n",
    "    \"ç®€å•å­—ç¬¦ä¸²\",\n",
    "    12345,\n",
    "    [1, 2, 3, 4, 5],\n",
    "    {\"key\": \"value\", \"nested\": {\"data\": 123}}\n",
    "]\n",
    "\n",
    "for i, test_input in enumerate(test_cases, 1):\n",
    "    result = passthrough.invoke(test_input)\n",
    "    is_same = test_input is result\n",
    "    print(f\"   æµ‹è¯• {i}: {type(test_input).__name__} - ä¿æŒä¸€è‡´: {is_same}\")\n",
    "\n",
    "# 4. RunnablePassthrough ä¸å‡½æ•°ç»“åˆ\n",
    "print(f\"\\nğŸ”§ 4. RunnablePassthrough ä¸å‡½æ•°ç»“åˆ:\")\n",
    "\n",
    "def process_data(data):\n",
    "    \"\"\"å¤„ç†æ•°æ®çš„å‡½æ•°\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {**data, \"processed\": True, \"timestamp\": \"2025-11-30\"}\n",
    "    return f\"å¤„ç†ç»“æœ: {data}\"\n",
    "\n",
    "# åˆ›å»ºå¤„ç†é“¾\n",
    "processing_chain = passthrough | process_data\n",
    "\n",
    "print(f\"   å¤„ç†é“¾: {type(processing_chain)}\")\n",
    "print(f\"   é“¾å¯è°ƒç”¨: {callable(processing_chain)}\")\n",
    "\n",
    "# æµ‹è¯•å¤„ç†é“¾\n",
    "chain_result = processing_chain.invoke(test_data)\n",
    "print(f\"   é“¾å¤„ç†ç»“æœ: {chain_result}\")\n",
    "\n",
    "# 5. æ•°æ®æ ¼å¼éªŒè¯\n",
    "print(f\"\\nâœ… 5. æ•°æ®æ ¼å¼éªŒè¯:\")\n",
    "\n",
    "# éªŒè¯å­—å…¸ä¼ é€’\n",
    "dict_input = {\"name\": \"å¼ ä¸‰\", \"age\": 25}\n",
    "dict_output = passthrough.invoke(dict_input)\n",
    "\n",
    "print(f\"   å­—å…¸è¾“å…¥: {dict_input}\")\n",
    "print(f\"   å­—å…¸è¾“å‡º: {dict_output}\")\n",
    "print(f\"   å­—å…¸é”®ä¿æŒ: {set(dict_input.keys()) == set(dict_output.keys())}\")\n",
    "print(f\"   å­—å…¸å€¼ä¿æŒ: {all(dict_input[k] == dict_output[k] for k in dict_input)}\")\n",
    "\n",
    "# éªŒè¯åˆ—è¡¨ä¼ é€’\n",
    "list_input = [\"é¡¹ç›®1\", \"é¡¹ç›®2\", \"é¡¹ç›®3\"]\n",
    "list_output = passthrough.invoke(list_input)\n",
    "\n",
    "print(f\"\\n   åˆ—è¡¨è¾“å…¥: {list_input}\")\n",
    "print(f\"   åˆ—è¡¨è¾“å‡º: {list_output}\")\n",
    "print(f\"   åˆ—è¡¨é•¿åº¦ä¿æŒ: {len(list_input) == len(list_output)}\")\n",
    "print(f\"   åˆ—è¡¨å†…å®¹ä¿æŒ: {list_input == list_output}\")\n",
    "\n",
    "# éªŒè¯ç‚¹ï¼šRunnablePassthrough åŸºç¡€æ¦‚å¿µæ­£ç¡®\n",
    "assert callable(passthrough), \"RunnablePassthrough åº”è¯¥å¯è°ƒç”¨\"\n",
    "assert test_data == result, \"æ•°æ®åº”è¯¥ä¿æŒä¸€è‡´\"\n",
    "assert isinstance(chain_result, dict), \"å¤„ç†é“¾åº”è¯¥è¿”å›å­—å…¸\"\n",
    "assert chain_result.get(\"processed\") is True, \"å¤„ç†æ ‡è®°åº”è¯¥å­˜åœ¨\"\n",
    "assert dict_input == dict_output, \"å­—å…¸æ•°æ®åº”è¯¥å®Œå…¨ä¿æŒ\"\n",
    "assert list_input == list_output, \"åˆ—è¡¨æ•°æ®åº”è¯¥å®Œå…¨ä¿æŒ\"\n",
    "\n",
    "print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šRunnablePassthrough åŸºç¡€æ¦‚å¿µç†è§£æ­£ç¡®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RunnablePassthrough ä¸ RunnableParallel ç»“åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnablePassthrough ä¸ RunnableParallel ç»“åˆ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”— RunnablePassthrough ä¸ RunnableParallel ç»“åˆæµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»º LLM\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„ç»„ä»¶:\")\n",
    "        print(f\"   1. LLM: {type(llm)}\")\n",
    "        \n",
    "        # 1. åŸºç¡€å¹¶è¡Œå¤„ç†\n",
    "        print(f\"\\nğŸ—ï¸  1. åŸºç¡€å¹¶è¡Œå¤„ç†:\")\n",
    "        \n",
    "        # åˆ›å»ºå¹¶è¡Œé“¾\n",
    "        parallel_chain = RunnableParallel({\n",
    "            \"original\": RunnablePassthrough(),\n",
    "            \"processed\": lambda x: f\"å¤„ç†åçš„: {str(x)[:20]}...\"\n",
    "        })\n",
    "        \n",
    "        print(f\"   å¹¶è¡Œé“¾: {type(parallel_chain)}\")\n",
    "        print(f\"   é“¾å¯è°ƒç”¨: {callable(parallel_chain)}\")\n",
    "        \n",
    "        # æµ‹è¯•å¹¶è¡Œå¤„ç†\n",
    "        test_input = \"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è¾“å…¥ï¼Œç”¨äºéªŒè¯å¹¶è¡Œå¤„ç†åŠŸèƒ½ã€‚\"\n",
    "        parallel_result = parallel_chain.invoke(test_input)\n",
    "        \n",
    "        print(f\"   è¾“å…¥: {test_input}\")\n",
    "        print(f\"   è¾“å‡º: {parallel_result}\")\n",
    "        print(f\"   åŸå§‹æ•°æ®ä¿æŒ: {parallel_result['original'] == test_input}\")\n",
    "        print(f\"   å¤„ç†æ•°æ®å­˜åœ¨: {'processed' in parallel_result}\")\n",
    "        \n",
    "        # 2. å¤æ‚æ•°æ®ç»“æ„çš„å¹¶è¡Œå¤„ç†\n",
    "        print(f\"\\nğŸ”§ 2. å¤æ‚æ•°æ®ç»“æ„çš„å¹¶è¡Œå¤„ç†:\")\n",
    "        \n",
    "        def extract_keys(data):\n",
    "            \"\"\"æå–å­—å…¸é”®\"\"\"\n",
    "            if isinstance(data, dict):\n",
    "                return list(data.keys())\n",
    "            return []\n",
    "        \n",
    "        def count_items(data):\n",
    "            \"\"\"è®¡ç®—é¡¹ç›®æ•°é‡\"\"\"\n",
    "            if isinstance(data, (list, dict)):\n",
    "                return len(data)\n",
    "            return 1\n",
    "        \n",
    "        # åˆ›å»ºå¤æ‚å¹¶è¡Œé“¾\n",
    "        complex_parallel = RunnableParallel({\n",
    "            \"original_data\": RunnablePassthrough(),\n",
    "            \"data_keys\": extract_keys,\n",
    "            \"data_count\": count_items,\n",
    "            \"data_type\": lambda x: type(x).__name__,\n",
    "            \"data_summary\": lambda x: f\"{type(x).__name__} with {len(x) if hasattr(x, '__len__') else 1} items\"\n",
    "        })\n",
    "        \n",
    "        # æµ‹è¯•å¤æ‚æ•°æ®\n",
    "        complex_input = {\n",
    "            \"name\": \"æå››\",\n",
    "            \"age\": 30,\n",
    "            \"skills\": [\"Python\", \"JavaScript\", \"SQL\"],\n",
    "            \"active\": True\n",
    "        }\n",
    "        \n",
    "        complex_result = complex_parallel.invoke(complex_input)\n",
    "        \n",
    "        print(f\"   å¤æ‚è¾“å…¥: {complex_input}\")\n",
    "        print(f\"\\n   å¹¶è¡Œå¤„ç†ç»“æœ:\")\n",
    "        for key, value in complex_result.items():\n",
    "            print(f\"     {key}: {value}\")\n",
    "        \n",
    "        # 3. ä¸ LLM ç»“åˆçš„å¹¶è¡Œå¤„ç†\n",
    "        print(f\"\\nğŸ¤– 3. ä¸ LLM ç»“åˆçš„å¹¶è¡Œå¤„ç†:\")\n",
    "        \n",
    "        # åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "        summary_prompt = ChatPromptTemplate.from_template(\n",
    "            \"è¯·ç®€è¦æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š{content}\"\n",
    "        )\n",
    "        \n",
    "        # åˆ›å»º LLM é“¾\n",
    "        llm_chain = summary_prompt | llm\n",
    "        \n",
    "        # åˆ›å»ºå¹¶è¡Œå¤„ç†é“¾\n",
    "        llm_parallel = RunnableParallel({\n",
    "            \"original_content\": RunnablePassthrough(),\n",
    "            \"llm_summary\": llm_chain,\n",
    "            \"content_length\": lambda x: len(str(x)),\n",
    "            \"content_type\": lambda x: type(x).__name__\n",
    "        })\n",
    "        \n",
    "        print(f\"   LLMå¹¶è¡Œé“¾: {type(llm_parallel)}\")\n",
    "        \n",
    "        # æµ‹è¯• LLM å¹¶è¡Œå¤„ç†\n",
    "        llm_test_input = \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”±Guido van Rossumäº1991å¹´é¦–æ¬¡å‘å¸ƒã€‚\"\n",
    "        llm_result = llm_parallel.invoke({\"content\": llm_test_input})\n",
    "        \n",
    "        print(f\"\\n   LLMå¹¶è¡Œå¤„ç†ç»“æœ:\")\n",
    "        for key, value in llm_result.items():\n",
    "            if key == \"llm_summary\":\n",
    "                print(f\"     {key}: {value.content[:50]}...\")\n",
    "            else:\n",
    "                print(f\"     {key}: {value}\")\n",
    "        \n",
    "        # 4. å¤šçº§å¹¶è¡Œå¤„ç†\n",
    "        print(f\"\\nğŸ”„ 4. å¤šçº§å¹¶è¡Œå¤„ç†:\")\n",
    "        \n",
    "        # ç¬¬ä¸€çº§å¹¶è¡Œå¤„ç†\n",
    "        first_level = RunnableParallel({\n",
    "            \"data\": RunnablePassthrough(),\n",
    "            \"metadata\": lambda x: {\"length\": len(str(x)), \"type\": type(x).__name__}\n",
    "        })\n",
    "        \n",
    "        # ç¬¬äºŒçº§å¹¶è¡Œå¤„ç†\n",
    "        second_level = RunnableParallel({\n",
    "            \"original\": lambda x: x[\"data\"],\n",
    "            \"meta_info\": lambda x: x[\"metadata\"],\n",
    "            \"combined\": lambda x: f\"{x['data']} (é•¿åº¦: {x['metadata']['length']})\"\n",
    "        })\n",
    "        \n",
    "        # åˆ›å»ºå¤šçº§é“¾\n",
    "        multi_level_chain = first_level | second_level\n",
    "        \n",
    "        print(f\"   å¤šçº§é“¾: {type(multi_level_chain)}\")\n",
    "        \n",
    "        # æµ‹è¯•å¤šçº§å¤„ç†\n",
    "        multi_input = \"å¤šçº§å¹¶è¡Œå¤„ç†æµ‹è¯•æ•°æ®\"\n",
    "        multi_result = multi_level_chain.invoke(multi_input)\n",
    "        \n",
    "        print(f\"\\n   å¤šçº§å¤„ç†ç»“æœ:\")\n",
    "        for key, value in multi_result.items():\n",
    "            print(f\"     {key}: {value}\")\n",
    "        \n",
    "        # 5. æ¡ä»¶å¹¶è¡Œå¤„ç†\n",
    "        print(f\"\\nğŸ¯ 5. æ¡ä»¶å¹¶è¡Œå¤„ç†:\")\n",
    "        \n",
    "        def conditional_process(data):\n",
    "            \"\"\"æ¡ä»¶å¤„ç†å‡½æ•°\"\"\"\n",
    "            if isinstance(data, str):\n",
    "                return f\"å­—ç¬¦ä¸²å¤„ç†: {data.upper()}\"\n",
    "            elif isinstance(data, dict):\n",
    "                return f\"å­—å…¸å¤„ç†: {len(data)} ä¸ªé”®\"\n",
    "            elif isinstance(data, list):\n",
    "                return f\"åˆ—è¡¨å¤„ç†: {len(data)} ä¸ªå…ƒç´ \"\n",
    "            else:\n",
    "                return f\"å…¶ä»–ç±»å‹å¤„ç†: {type(data).__name__}\"\n",
    "        \n",
    "        # åˆ›å»ºæ¡ä»¶å¹¶è¡Œé“¾\n",
    "        conditional_parallel = RunnableParallel({\n",
    "            \"original\": RunnablePassthrough(),\n",
    "            \"conditional_result\": conditional_process,\n",
    "            \"is_string\": lambda x: isinstance(x, str),\n",
    "            \"is_dict\": lambda x: isinstance(x, dict),\n",
    "            \"is_list\": lambda x: isinstance(x, list)\n",
    "        })\n",
    "        \n",
    "        # æµ‹è¯•ä¸åŒç±»å‹çš„æ•°æ®\n",
    "        test_cases = [\n",
    "            \"å­—ç¬¦ä¸²æµ‹è¯•\",\n",
    "            {\"key1\": \"value1\", \"key2\": \"value2\"},\n",
    "            [1, 2, 3, 4, 5]\n",
    "        ]\n",
    "        \n",
    "        for i, test_case in enumerate(test_cases, 1):\n",
    "            print(f\"\\n   æ¡ä»¶æµ‹è¯• {i} ({type(test_case).__name__}):\")\n",
    "            conditional_result = conditional_parallel.invoke(test_case)\n",
    "            \n",
    "            for key, value in conditional_result.items():\n",
    "                print(f\"     {key}: {value}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šRunnablePassthrough ä¸ RunnableParallel ç»“åˆæ­£ç¡®\n",
    "        assert callable(parallel_chain), \"å¹¶è¡Œé“¾åº”è¯¥å¯è°ƒç”¨\"\n",
    "        assert parallel_result['original'] == test_input, \"åŸå§‹æ•°æ®åº”è¯¥ä¿æŒ\"\n",
    "        assert 'processed' in parallel_result, \"å¤„ç†ç»“æœåº”è¯¥å­˜åœ¨\"\n",
    "        assert complex_result['original_data'] == complex_input, \"å¤æ‚åŸå§‹æ•°æ®åº”è¯¥ä¿æŒ\"\n",
    "        assert len(complex_result) == 5, \"å¤æ‚å¹¶è¡Œç»“æœåº”è¯¥æœ‰5ä¸ªå­—æ®µ\"\n",
    "        assert llm_result['original_content'] == llm_test_input, \"LLMåŸå§‹å†…å®¹åº”è¯¥ä¿æŒ\"\n",
    "        assert 'llm_summary' in llm_result, \"LLMæ‘˜è¦åº”è¯¥å­˜åœ¨\"\n",
    "        \n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šRunnablePassthrough ä¸ RunnableParallel ç»“åˆæ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ RunnablePassthrough ä¸ RunnableParallel ç»“åˆæµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å®é™…åº”ç”¨åœºæ™¯å’Œæ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®é™…åº”ç”¨åœºæ™¯å’Œæ•°æ®å¤„ç† - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ¯ å®é™…åº”ç”¨åœºæ™¯å’Œæ•°æ®å¤„ç†æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»º LLM\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=60\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„åº”ç”¨ç»„ä»¶:\")\n",
    "        print(f\"   1. LLM: {type(llm)}\")\n",
    "        \n",
    "        # 1. æ•°æ®é¢„å¤„ç†å’Œåå¤„ç†åœºæ™¯\n",
    "        print(f\"\\nğŸ”§ 1. æ•°æ®é¢„å¤„ç†å’Œåå¤„ç†åœºæ™¯:\")\n",
    "        \n",
    "        def preprocess_data(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            \"\"\"æ•°æ®é¢„å¤„ç†\"\"\"\n",
    "            processed = {\n",
    "                \"original\": data,\n",
    "                \"preprocessed\": {\n",
    "                    \"text_length\": len(data.get(\"text\", \"\")),\n",
    "                    \"word_count\": len(data.get(\"text\", \"\").split()),\n",
    "                    \"has_keywords\": any(keyword in data.get(\"text\", \"\").lower() \n",
    "                                      for keyword in [\"python\", \"javascript\", \"ai\"]),\n",
    "                    \"timestamp\": \"2025-11-30-21:50\"\n",
    "                }\n",
    "            }\n",
    "            return processed\n",
    "        \n",
    "        def postprocess_data(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            \"\"\"æ•°æ®åå¤„ç†\"\"\"\n",
    "            return {\n",
    "                \"final_result\": {\n",
    "                    \"input_preserved\": data[\"original\"],\n",
    "                    \"analysis\": data[\"preprocessed\"],\n",
    "                    \"summary\": f\"æ–‡æœ¬é•¿åº¦: {data['preprocessed']['text_length']}, \"\n",
    "                              f\"å•è¯æ•°: {data['preprocessed']['word_count']}\"\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # åˆ›å»ºå¤„ç†é“¾\n",
    "        processing_chain = (\n",
    "            preprocess_data\n",
    "            | postprocess_data\n",
    "        )\n",
    "        \n",
    "        print(f\"   å¤„ç†é“¾: {type(processing_chain)}\")\n",
    "        \n",
    "        # æµ‹è¯•æ•°æ®å¤„ç†\n",
    "        test_data = {\n",
    "            \"text\": \"Pythonæ˜¯ä¸€ç§å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºAIå’Œæœºå™¨å­¦ä¹ å¼€å‘ã€‚\",\n",
    "            \"author\": \"æŠ€æœ¯ä¸“å®¶\",\n",
    "            \"category\": \"ç¼–ç¨‹\"\n",
    "        }\n",
    "        \n",
    "        processed_result = processing_chain.invoke(test_data)\n",
    "        \n",
    "        print(f\"\\n   æ•°æ®å¤„ç†ç»“æœ:\")\n",
    "        print(f\"   è¾“å…¥: {test_data}\")\n",
    "        print(f\"\\n   è¾“å‡ºæ‘˜è¦: {processed_result['final_result']['summary']}\")\n",
    "        print(f\"   å…³é”®è¯æ£€æµ‹: {processed_result['final_result']['analysis']['has_keywords']}\")\n",
    "        \n",
    "        # 2. RAG é£æ ¼çš„æ•°æ®å¤„ç†\n",
    "        print(f\"\\nğŸ“š 2. RAG é£æ ¼çš„æ•°æ®å¤„ç†:\")\n",
    "        \n",
    "        def retrieve_documents(query: str) -> List[Dict[str, str]]:\n",
    "            \"\"\"æ¨¡æ‹Ÿæ–‡æ¡£æ£€ç´¢\"\"\"\n",
    "            documents = [\n",
    "                {\"content\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ç®€æ´çš„è¯­æ³•ã€‚\", \"source\": \"docs/python.txt\"},\n",
    "                {\"content\": \"JavaScriptæ˜¯Webå¼€å‘çš„æ ¸å¿ƒè¯­è¨€ä¹‹ä¸€ã€‚\", \"source\": \"docs/javascript.txt\"},\n",
    "                {\"content\": \"AIæŠ€æœ¯æ­£åœ¨æ”¹å˜è½¯ä»¶å¼€å‘çš„æ–¹å¼ã€‚\", \"source\": \"docs/ai.txt\"}\n",
    "            ]\n",
    "            \n",
    "            # ç®€å•çš„å…³é”®è¯åŒ¹é…\n",
    "            relevant_docs = []\n",
    "            for doc in documents:\n",
    "                if any(word.lower() in doc[\"content\"].lower() \n",
    "                      for word in query.lower().split()):\n",
    "                    relevant_docs.append(doc)\n",
    "            \n",
    "            return relevant_docs[:2]  # è¿”å›æœ€å¤š2ä¸ªç›¸å…³æ–‡æ¡£\n",
    "        \n",
    "        def format_context(documents: List[Dict[str, str]]) -> str:\n",
    "            \"\"\"æ ¼å¼åŒ–ä¸Šä¸‹æ–‡\"\"\"\n",
    "            return \"\\n\".join([f\"æ–‡æ¡£{i+1}: {doc['content']}\" \n",
    "                             for i, doc in enumerate(documents)])\n",
    "        \n",
    "        # åˆ›å»º RAG é£æ ¼é“¾\n",
    "        rag_chain = RunnableParallel({\n",
    "            \"query\": RunnablePassthrough(),\n",
    "            \"retrieved_docs\": retrieve_documents,\n",
    "            \"context\": lambda x: format_context(x[\"retrieved_docs\"]),\n",
    "            \"doc_count\": lambda x: len(x[\"retrieved_docs\"])\n",
    "        }) | RunnableParallel({\n",
    "            \"original_query\": lambda x: x[\"query\"],\n",
    "            \"context\": lambda x: x[\"context\"],\n",
    "            \"doc_count\": lambda x: x[\"doc_count\"],\n",
    "            \"formatted_input\": lambda x: f\"ä¸Šä¸‹æ–‡ï¼š\\n{x['context']}\\n\\né—®é¢˜ï¼š{x['query']}\"\n",
    "        })\n",
    "        \n",
    "        print(f\"   RAGé£æ ¼é“¾: {type(rag_chain)}\")\n",
    "        \n",
    "        # æµ‹è¯• RAG å¤„ç†\n",
    "        rag_query = \"Pythonç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "        rag_result = rag_chain.invoke(rag_query)\n",
    "        \n",
    "        print(f\"\\n   RAGå¤„ç†ç»“æœ:\")\n",
    "        print(f\"   åŸå§‹æŸ¥è¯¢: {rag_result['original_query']}\")\n",
    "        print(f\"   æ–‡æ¡£æ•°é‡: {rag_result['doc_count']}\")\n",
    "        print(f\"   æ ¼å¼åŒ–è¾“å…¥: {rag_result['formatted_input'][:100]}...\")\n",
    "        \n",
    "        # 3. æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥\n",
    "        print(f\"\\nâœ… 3. æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥:\")\n",
    "        \n",
    "        def validate_input(data: Any) -> Dict[str, Any]:\n",
    "            \"\"\"è¾“å…¥éªŒè¯\"\"\"\n",
    "            validation_result = {\n",
    "                \"is_valid\": True,\n",
    "                \"errors\": [],\n",
    "                \"warnings\": []\n",
    "            }\n",
    "            \n",
    "            if isinstance(data, str):\n",
    "                if len(data) < 5:\n",
    "                    validation_result[\"warnings\"].append(\"æ–‡æœ¬è¿‡çŸ­\")\n",
    "                if len(data) > 1000:\n",
    "                    validation_result[\"warnings\"].append(\"æ–‡æœ¬è¿‡é•¿\")\n",
    "            elif isinstance(data, dict):\n",
    "                if not data:\n",
    "                    validation_result[\"errors\"].append(\"å­—å…¸ä¸ºç©º\")\n",
    "                    validation_result[\"is_valid\"] = False\n",
    "            else:\n",
    "                validation_result[\"errors\"].append(\"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹\")\n",
    "                validation_result[\"is_valid\"] = False\n",
    "            \n",
    "            return {\n",
    "                \"original_data\": data,\n",
    "                \"validation\": validation_result\n",
    "            }\n",
    "        \n",
    "        def quality_check(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            \"\"\"è´¨é‡æ£€æŸ¥\"\"\"\n",
    "            original = data[\"original_data\"]\n",
    "            validation = data[\"validation\"]\n",
    "            \n",
    "            quality_score = 100\n",
    "            \n",
    "            if validation[\"errors\"]:\n",
    "                quality_score -= 50\n",
    "            if validation[\"warnings\"]:\n",
    "                quality_score -= len(validation[\"warnings\"]) * 10\n",
    "            \n",
    "            if isinstance(original, str):\n",
    "                word_count = len(original.split())\n",
    "                if word_count < 3:\n",
    "                    quality_score -= 20\n",
    "                elif word_count > 100:\n",
    "                    quality_score -= 10\n",
    "            \n",
    "            return {\n",
    "                **data,\n",
    "                \"quality\": {\n",
    "                    \"score\": max(0, quality_score),\n",
    "                    \"grade\": \"ä¼˜ç§€\" if quality_score >= 90 else \n",
    "                            \"è‰¯å¥½\" if quality_score >= 70 else \n",
    "                            \"ä¸€èˆ¬\" if quality_score >= 50 else \"è¾ƒå·®\"\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # åˆ›å»ºéªŒè¯é“¾\n",
    "        validation_chain = (\n",
    "            validate_input\n",
    "            | quality_check\n",
    "        )\n",
    "        \n",
    "        print(f\"   éªŒè¯é“¾: {type(validation_chain)}\")\n",
    "        \n",
    "        # æµ‹è¯•ä¸åŒè´¨é‡çš„æ•°æ®\n",
    "        quality_test_cases = [\n",
    "            \"çŸ­\",  # è¿‡çŸ­\n",
    "            \"è¿™æ˜¯ä¸€ä¸ªé€‚ä¸­çš„æµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯è´¨é‡æ£€æŸ¥åŠŸèƒ½ã€‚\",  # é€‚ä¸­\n",
    "            {\"key\": \"value\"},  # å­—å…¸\n",
    "            \"\"  # ç©ºå­—ç¬¦ä¸²\n",
    "        ]\n",
    "        \n",
    "        for i, test_case in enumerate(quality_test_cases, 1):\n",
    "            print(f\"\\n   è´¨é‡æµ‹è¯• {i}:\")\n",
    "            validation_result = validation_chain.invoke(test_case)\n",
    "            \n",
    "            quality = validation_result[\"quality\"]\n",
    "            validation = validation_result[\"validation\"]\n",
    "            \n",
    "            print(f\"     è¾“å…¥: {str(test_case)[:30]}...\")\n",
    "            print(f\"     è´¨é‡åˆ†æ•°: {quality['score']}\")\n",
    "            print(f\"     è´¨é‡ç­‰çº§: {quality['grade']}\")\n",
    "            print(f\"     éªŒè¯é€šè¿‡: {validation['is_valid']}\")\n",
    "            if validation[\"errors\"]:\n",
    "                print(f\"     é”™è¯¯: {validation['errors']}\")\n",
    "            if validation[\"warnings\"]:\n",
    "                print(f\"     è­¦å‘Š: {validation['warnings']}\")\n",
    "        \n",
    "        # 4. æ•°æ®è½¬æ¢å’Œæ ¼å¼åŒ–\n",
    "        print(f\"\\nğŸ”„ 4. æ•°æ®è½¬æ¢å’Œæ ¼å¼åŒ–:\")\n",
    "        \n",
    "        def to_json(data: Any) -> str:\n",
    "            \"\"\"è½¬æ¢ä¸ºJSON\"\"\"\n",
    "            if isinstance(data, dict):\n",
    "                return json.dumps(data, ensure_ascii=False, indent=2)\n",
    "            else:\n",
    "                return json.dumps({\"value\": data}, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        def from_json(json_str: str) -> Dict[str, Any]:\n",
    "            \"\"\"ä»JSONè§£æ\"\"\"\n",
    "            return json.loads(json_str)\n",
    "        \n",
    "        def format_output(data: Dict[str, Any]) -> str:\n",
    "            \"\"\"æ ¼å¼åŒ–è¾“å‡º\"\"\"\n",
    "            return f\"æ ¼å¼åŒ–ç»“æœ: {data}\"\n",
    "        \n",
    "        # åˆ›å»ºè½¬æ¢é“¾\n",
    "        transformation_chain = (\n",
    "            RunnableParallel({\n",
    "                \"original\": RunnablePassthrough(),\n",
    "                \"json_format\": to_json,\n",
    "                \"data_type\": lambda x: type(x).__name__\n",
    "            })\n",
    "            | RunnableParallel({\n",
    "                \"original\": lambda x: x[\"original\"],\n",
    "                \"json_data\": lambda x: from_json(x[\"json_format\"]),\n",
    "                \"type_info\": lambda x: x[\"data_type\"],\n",
    "                \"json_string\": lambda x: x[\"json_format\"]\n",
    "            })\n",
    "            | format_output\n",
    "        )\n",
    "        \n",
    "        print(f\"   è½¬æ¢é“¾: {type(transformation_chain)}\")\n",
    "        \n",
    "        # æµ‹è¯•æ•°æ®è½¬æ¢\n",
    "        transform_input = {\"name\": \"ç‹äº”\", \"age\": 28, \"skills\": [\"Python\", \"æ•°æ®åˆ†æ\"]}\n",
    "        transform_result = transformation_chain.invoke(transform_input)\n",
    "        \n",
    "        print(f\"\\n   æ•°æ®è½¬æ¢ç»“æœ:\")\n",
    "        print(f\"   è¾“å…¥: {transform_input}\")\n",
    "        print(f\"   è¾“å‡º: {transform_result[:200]}...\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šå®é™…åº”ç”¨åœºæ™¯å’Œæ•°æ®å¤„ç†æ­£ç¡®\n",
    "        assert processed_result['final_result']['input_preserved'] == test_data, \"åŸå§‹æ•°æ®åº”è¯¥ä¿æŒ\"\n",
    "        assert 'analysis' in processed_result['final_result'], \"åˆ†æç»“æœåº”è¯¥å­˜åœ¨\"\n",
    "        assert rag_result['original_query'] == rag_query, \"RAGåŸå§‹æŸ¥è¯¢åº”è¯¥ä¿æŒ\"\n",
    "        assert rag_result['doc_count'] >= 0, \"æ–‡æ¡£æ•°é‡åº”è¯¥éè´Ÿ\"\n",
    "        assert len(quality_test_cases) == len(quality_test_cases), \"è´¨é‡æµ‹è¯•æ¡ˆä¾‹æ•°é‡æ­£ç¡®\"\n",
    "        \n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šå®é™…åº”ç”¨åœºæ™¯å’Œæ•°æ®å¤„ç†æ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ å®é™…åº”ç”¨åœºæ™¯æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. é«˜çº§æŠ€å·§å’Œæ€§èƒ½ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é«˜çº§æŠ€å·§å’Œæ€§èƒ½ä¼˜åŒ– - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from typing import Dict, Any, List, Callable\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âš¡ é«˜çº§æŠ€å·§å’Œæ€§èƒ½ä¼˜åŒ–æµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"âŒ OpenAI API Key æœªé…ç½®\")\n",
    "else:\n",
    "    try:\n",
    "        # åˆ›å»ºè½»é‡çº§ LLM\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=40\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“ åˆ›å»ºçš„ä¼˜åŒ–ç»„ä»¶:\")\n",
    "        print(f\"   1. è½»é‡çº§LLM: {type(llm)}\")\n",
    "        \n",
    "        # 1. ç¼“å­˜ä¼˜åŒ–çš„ RunnablePassthrough\n",
    "        print(f\"\\nğŸ’¾ 1. ç¼“å­˜ä¼˜åŒ–çš„ RunnablePassthrough:\")\n",
    "        \n",
    "        class CachedPassthrough:\n",
    "            \"\"\"å¸¦ç¼“å­˜çš„ Passthrough\"\"\"\n",
    "            \n",
    "            def __init__(self, cache_size: int = 100):\n",
    "                self.cache_size = cache_size\n",
    "                self.cache = {}\n",
    "                self.access_order = []\n",
    "                self.lock = threading.RLock()\n",
    "            \n",
    "            def __call__(self, data):\n",
    "                \"\"\"å¸¦ç¼“å­˜çš„è°ƒç”¨\"\"\"\n",
    "                # ç”Ÿæˆç¼“å­˜é”®ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "                cache_key = str(hash(str(data))) if not isinstance(data, (int, str, float, bool)) else str(data)\n",
    "                \n",
    "                with self.lock:\n",
    "                    if cache_key in self.cache:\n",
    "                        # æ›´æ–°è®¿é—®é¡ºåº\n",
    "                        if cache_key in self.access_order:\n",
    "                            self.access_order.remove(cache_key)\n",
    "                        self.access_order.append(cache_key)\n",
    "                        return self.cache[cache_key]\n",
    "                    \n",
    "                    # æ·»åŠ æ–°ç¼“å­˜\n",
    "                    if len(self.cache) >= self.cache_size:\n",
    "                        # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹\n",
    "                        oldest_key = self.access_order.pop(0)\n",
    "                        del self.cache[oldest_key]\n",
    "                    \n",
    "                    self.cache[cache_key] = data\n",
    "                    self.access_order.append(cache_key)\n",
    "                    \n",
    "                    return data\n",
    "            \n",
    "            def get_cache_stats(self) -> Dict[str, Any]:\n",
    "                \"\"\"è·å–ç¼“å­˜ç»Ÿè®¡\"\"\"\n",
    "                with self.lock:\n",
    "                    return {\n",
    "                        \"cache_size\": len(self.cache),\n",
    "                        \"max_cache_size\": self.cache_size,\n",
    "                        \"hit_ratio\": \"è®¡ç®—ä¸­...\",\n",
    "                        \"cached_keys\": len(self.access_order)\n",
    "                    }\n",
    "        \n",
    "        cached_passthrough = CachedPassthrough(cache_size=5)\n",
    "        \n",
    "        print(f\"   ç¼“å­˜Passthrough: {type(cached_passthrough)}\")\n",
    "        print(f\"   ç¼“å­˜ç»Ÿè®¡: {cached_passthrough.get_cache_stats()}\")\n",
    "        \n",
    "        # æµ‹è¯•ç¼“å­˜åŠŸèƒ½\n",
    "        cache_test_data = [\n",
    "            \"æµ‹è¯•æ•°æ®1\",\n",
    "            \"æµ‹è¯•æ•°æ®2\", \n",
    "            \"æµ‹è¯•æ•°æ®1\",  # é‡å¤æ•°æ®\n",
    "            \"æµ‹è¯•æ•°æ®3\",\n",
    "            \"æµ‹è¯•æ•°æ®2\",  # é‡å¤æ•°æ®\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n   ç¼“å­˜æµ‹è¯•:\")\n",
    "        for i, data in enumerate(cache_test_data, 1):\n",
    "            result = cached_passthrough(data)\n",
    "            stats = cached_passthrough.get_cache_stats()\n",
    "            print(f\"     æµ‹è¯• {i}: {data} -> ç¼“å­˜å¤§å°: {stats['cache_size']}\")\n",
    "        \n",
    "        # 2. æ€§èƒ½ç›‘æ§çš„ Passthrough\n",
    "        print(f\"\\nğŸ“Š 2. æ€§èƒ½ç›‘æ§çš„ Passthrough:\")\n",
    "        \n",
    "        class MonitoredPassthrough:\n",
    "            \"\"\"å¸¦æ€§èƒ½ç›‘æ§çš„ Passthrough\"\"\"\n",
    "            \n",
    "            def __init__(self):\n",
    "                self.call_count = 0\n",
    "                self.total_time = 0.0\n",
    "                self.data_sizes = []\n",
    "                self.lock = threading.RLock()\n",
    "            \n",
    "            def __call__(self, data):\n",
    "                \"\"\"å¸¦ç›‘æ§çš„è°ƒç”¨\"\"\"\n",
    "                start_time = time.time()\n",
    "                \n",
    "                try:\n",
    "                    result = data\n",
    "                    \n",
    "                    with self.lock:\n",
    "                        self.call_count += 1\n",
    "                        self.total_time += time.time() - start_time\n",
    "                        self.data_sizes.append(len(str(data)))\n",
    "                    \n",
    "                    return result\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    with self.lock:\n",
    "                        self.call_count += 1\n",
    "                        self.total_time += time.time() - start_time\n",
    "                    raise e\n",
    "            \n",
    "            def get_performance_stats(self) -> Dict[str, Any]:\n",
    "                \"\"\"è·å–æ€§èƒ½ç»Ÿè®¡\"\"\"\n",
    "                with self.lock:\n",
    "                    avg_time = self.total_time / max(self.call_count, 1)\n",
    "                    avg_size = sum(self.data_sizes) / max(len(self.data_sizes), 1)\n",
    "                    \n",
    "                    return {\n",
    "                        \"call_count\": self.call_count,\n",
    "                        \"total_time\": self.total_time,\n",
    "                        \"avg_time\": avg_time,\n",
    "                        \"avg_data_size\": avg_size,\n",
    "                        \"max_data_size\": max(self.data_sizes) if self.data_sizes else 0,\n",
    "                        \"min_data_size\": min(self.data_sizes) if self.data_sizes else 0\n",
    "                    }\n",
    "            \n",
    "            def reset_stats(self):\n",
    "                \"\"\"é‡ç½®ç»Ÿè®¡\"\"\"\n",
    "                with self.lock:\n",
    "                    self.call_count = 0\n",
    "                    self.total_time = 0.0\n",
    "                    self.data_sizes = []\n",
    "        \n",
    "        monitored_passthrough = MonitoredPassthrough()\n",
    "        \n",
    "        print(f\"   ç›‘æ§Passthrough: {type(monitored_passthrough)}\")\n",
    "        \n",
    "        # æµ‹è¯•æ€§èƒ½ç›‘æ§\n",
    "        performance_test_data = [\n",
    "            \"å°æ•°æ®\",\n",
    "            \"è¿™æ˜¯ä¸€ä¸ªä¸­ç­‰å¤§å°çš„æµ‹è¯•æ•°æ®ï¼Œç”¨äºæ€§èƒ½ç›‘æ§æµ‹è¯•ã€‚\",\n",
    "            \"x\" * 100,  # å¤§æ•°æ®\n",
    "            {\"key\": \"value\", \"nested\": {\"data\": [1, 2, 3, 4, 5]}},\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n   æ€§èƒ½ç›‘æ§æµ‹è¯•:\")\n",
    "        for i, data in enumerate(performance_test_data, 1):\n",
    "            result = monitored_passthrough(data)\n",
    "            stats = monitored_passthrough.get_performance_stats()\n",
    "            print(f\"     æµ‹è¯• {i}: è°ƒç”¨æ¬¡æ•° {stats['call_count']}, å¹³å‡æ—¶é—´ {stats['avg_time']*1000:.3f}ms\")\n",
    "        \n",
    "        final_stats = monitored_passthrough.get_performance_stats()\n",
    "        print(f\"\\n   æœ€ç»ˆæ€§èƒ½ç»Ÿè®¡:\")\n",
    "        for key, value in final_stats.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"     {key}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"     {key}: {value}\")\n",
    "        \n",
    "        # 3. å¹¶è¡Œå¤„ç†çš„æ€§èƒ½ä¼˜åŒ–\n",
    "        print(f\"\\nğŸ”„ 3. å¹¶è¡Œå¤„ç†çš„æ€§èƒ½ä¼˜åŒ–:\")\n",
    "        \n",
    "        def heavy_processing(data: str) -> str:\n",
    "            \"\"\"æ¨¡æ‹Ÿé‡å¤„ç†ä»»åŠ¡\"\"\"\n",
    "            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "            time.sleep(0.1)\n",
    "            return f\"å¤„ç†ç»“æœ: {data.upper()}\"\n",
    "        \n",
    "        def light_processing(data: str) -> str:\n",
    "            \"\"\"è½»é‡å¤„ç†ä»»åŠ¡\"\"\"\n",
    "            return f\"è½»é‡å¤„ç†: {data.lower()}\"\n",
    "        \n",
    "        # åˆ›å»ºä¼˜åŒ–çš„å¹¶è¡Œé“¾\n",
    "        optimized_parallel = RunnableParallel({\n",
    "            \"original\": RunnablePassthrough(),\n",
    "            \"heavy_result\": heavy_processing,\n",
    "            \"light_result\": light_processing,\n",
    "            \"data_length\": lambda x: len(x),\n",
    "            \"word_count\": lambda x: len(x.split())\n",
    "        })\n",
    "        \n",
    "        print(f\"   ä¼˜åŒ–å¹¶è¡Œé“¾: {type(optimized_parallel)}\")\n",
    "        \n",
    "        # æ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "        def benchmark_parallel(chain, test_data: str, iterations: int = 3):\n",
    "            \"\"\"å¹¶è¡Œå¤„ç†åŸºå‡†æµ‹è¯•\"\"\"\n",
    "            print(f\"   å¹¶è¡ŒåŸºå‡†æµ‹è¯• ({iterations} æ¬¡è¿­ä»£):\")\n",
    "            \n",
    "            total_time = 0.0\n",
    "            results = []\n",
    "            \n",
    "            for i in range(iterations):\n",
    "                start_time = time.time()\n",
    "                result = chain.invoke(test_data)\n",
    "                iteration_time = time.time() - start_time\n",
    "                \n",
    "                total_time += iteration_time\n",
    "                results.append(result)\n",
    "                \n",
    "                print(f\"     è¿­ä»£ {i+1}: {iteration_time*1000:.1f}ms\")\n",
    "            \n",
    "            avg_time = total_time / iterations\n",
    "            print(f\"   å¹³å‡æ—¶é—´: {avg_time*1000:.1f}ms\")\n",
    "            print(f\"   æ€»æ—¶é—´: {total_time*1000:.1f}ms\")\n",
    "            \n",
    "            return results, avg_time\n",
    "        \n",
    "        # è¿è¡ŒåŸºå‡†æµ‹è¯•\n",
    "        benchmark_data = \"å¹¶è¡Œå¤„ç†æ€§èƒ½æµ‹è¯•æ•°æ®ï¼ŒåŒ…å«å¤šä¸ªå¤„ç†ä»»åŠ¡ã€‚\"\n",
    "        benchmark_results, avg_time = benchmark_parallel(optimized_parallel, benchmark_data, 3)\n",
    "        \n",
    "        print(f\"\\n   åŸºå‡†æµ‹è¯•ç»“æœç¤ºä¾‹:\")\n",
    "        if benchmark_results:\n",
    "            sample_result = benchmark_results[0]\n",
    "            for key, value in sample_result.items():\n",
    "                if isinstance(value, str):\n",
    "                    print(f\"     {key}: {value[:50]}...\")\n",
    "                else:\n",
    "                    print(f\"     {key}: {value}\")\n",
    "        \n",
    "        # 4. å†…å­˜ä¼˜åŒ–æŠ€å·§\n",
    "        print(f\"\\nğŸ’¾ 4. å†…å­˜ä¼˜åŒ–æŠ€å·§:\")\n",
    "        \n",
    "        class MemoryOptimizedPassthrough:\n",
    "            \"\"\"å†…å­˜ä¼˜åŒ–çš„ Passthrough\"\"\"\n",
    "            \n",
    "            def __init__(self, max_memory_mb: int = 10):\n",
    "                self.max_memory_mb = max_memory_mb\n",
    "                self.current_memory_mb = 0.0\n",
    "                self.processed_count = 0\n",
    "            \n",
    "            def __call__(self, data):\n",
    "                \"\"\"å†…å­˜ä¼˜åŒ–çš„è°ƒç”¨\"\"\"\n",
    "                # ä¼°ç®—æ•°æ®å¤§å°ï¼ˆç®€åŒ–ï¼‰\n",
    "                data_size_mb = len(str(data).encode('utf-8')) / (1024 * 1024)\n",
    "                \n",
    "                # æ£€æŸ¥å†…å­˜é™åˆ¶\n",
    "                if self.current_memory_mb + data_size_mb > self.max_memory_mb:\n",
    "                    print(f\"      âš ï¸  å†…å­˜è­¦å‘Š: å½“å‰ {self.current_memory_mb:.2f}MB, \"\n",
    "                          f\"æ·»åŠ  {data_size_mb:.2f}MB ä¼šè¶…è¿‡é™åˆ¶ {self.max_memory_mb}MB\")\n",
    "                    # è¿™é‡Œå¯ä»¥å®ç°æ¸…ç†ç­–ç•¥\n",
    "                \n",
    "                self.current_memory_mb += data_size_mb\n",
    "                self.processed_count += 1\n",
    "                \n",
    "                return data\n",
    "            \n",
    "            def get_memory_stats(self) -> Dict[str, Any]:\n",
    "                \"\"\"è·å–å†…å­˜ç»Ÿè®¡\"\"\"\n",
    "                return {\n",
    "                    \"current_memory_mb\": self.current_memory_mb,\n",
    "                    \"max_memory_mb\": self.max_memory_mb,\n",
    "                    \"processed_count\": self.processed_count,\n",
    "                    \"memory_utilization\": self.current_memory_mb / self.max_memory_mb\n",
    "                }\n",
    "        \n",
    "        memory_optimized = MemoryOptimizedPassthrough(max_memory_mb=1)\n",
    "        \n",
    "        print(f\"   å†…å­˜ä¼˜åŒ–Passthrough: {type(memory_optimized)}\")\n",
    "        \n",
    "        # æµ‹è¯•å†…å­˜ä¼˜åŒ–\n",
    "        memory_test_data = [\n",
    "            \"å°æ•°æ®æµ‹è¯•\",\n",
    "            \"ä¸­ç­‰å¤§å°çš„æ•°æ®æµ‹è¯•ï¼ŒåŒ…å«æ›´å¤šå†…å®¹å’Œå­—ç¬¦ã€‚\" * 10,\n",
    "            \"å¤§æ•°æ®æµ‹è¯•\" * 100,\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n   å†…å­˜ä¼˜åŒ–æµ‹è¯•:\")\n",
    "        for i, data in enumerate(memory_test_data, 1):\n",
    "            result = memory_optimized(data)\n",
    "            stats = memory_optimized.get_memory_stats()\n",
    "            print(f\"     æµ‹è¯• {i}: å¤„ç†è®¡æ•° {stats['processed_count']}, \"\n",
    "                  f\"å†…å­˜ä½¿ç”¨ {stats['current_memory_mb']:.4f}MB\")\n",
    "        \n",
    "        # 5. é”™è¯¯å¤„ç†å’Œæ¢å¤\n",
    "        print(f\"\\nğŸ›¡ï¸  5. é”™è¯¯å¤„ç†å’Œæ¢å¤:\")\n",
    "        \n",
    "        class RobustPassthrough:\n",
    "            \"\"\"å¥å£®çš„ Passthrough\"\"\"\n",
    "            \n",
    "            def __init__(self, max_retries: int = 3):\n",
    "                self.max_retries = max_retries\n",
    "                self.error_count = 0\n",
    "                self.success_count = 0\n",
    "            \n",
    "            def __call__(self, data):\n",
    "                \"\"\"å¸¦é‡è¯•çš„è°ƒç”¨\"\"\"\n",
    "                for attempt in range(self.max_retries + 1):\n",
    "                    try:\n",
    "                        # æ¨¡æ‹Ÿå¯èƒ½çš„é”™è¯¯\n",
    "                        if isinstance(data, str) and \"ERROR\" in data.upper():\n",
    "                            if attempt < self.max_retries:\n",
    "                                self.error_count += 1\n",
    "                                print(f\"      âš ï¸  å°è¯• {attempt + 1} å¤±è´¥ï¼Œé‡è¯•ä¸­...\")\n",
    "                                time.sleep(0.01)  # çŸ­æš‚å»¶è¿Ÿ\n",
    "                                continue\n",
    "                            else:\n",
    "                                raise ValueError(\"æ¨¡æ‹Ÿçš„é”™è¯¯å¤„ç†å¤±è´¥\")\n",
    "                        \n",
    "                        self.success_count += 1\n",
    "                        return data\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        if attempt == self.max_retries:\n",
    "                            self.error_count += 1\n",
    "                            raise e\n",
    "            \n",
    "            def get_robust_stats(self) -> Dict[str, Any]:\n",
    "                \"\"\"è·å–å¥å£®æ€§ç»Ÿè®¡\"\"\"\n",
    "                total_attempts = self.success_count + self.error_count\n",
    "                success_rate = self.success_count / max(total_attempts, 1)\n",
    "                \n",
    "                return {\n",
    "                    \"success_count\": self.success_count,\n",
    "                    \"error_count\": self.error_count,\n",
    "                    \"total_attempts\": total_attempts,\n",
    "                    \"success_rate\": success_rate\n",
    "                }\n",
    "        \n",
    "        robust_passthrough = RobustPassthrough(max_retries=2)\n",
    "        \n",
    "        print(f\"   å¥å£®Passthrough: {type(robust_passthrough)}\")\n",
    "        \n",
    "        # æµ‹è¯•é”™è¯¯å¤„ç†\n",
    "        robust_test_data = [\n",
    "            \"æ­£å¸¸æ•°æ®\",\n",
    "            \"åŒ…å«ERRORçš„æ•°æ®\",\n",
    "            \"æ­£å¸¸æ•°æ®2\",\n",
    "            \"å¦ä¸€ä¸ªERRORæµ‹è¯•\",\n",
    "            \"æ­£å¸¸æ•°æ®3\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n   é”™è¯¯å¤„ç†æµ‹è¯•:\")\n",
    "        for i, data in enumerate(robust_test_data, 1):\n",
    "            try:\n",
    "                result = robust_passthrough(data)\n",
    "                print(f\"     æµ‹è¯• {i}: æˆåŠŸ - {data}\")\n",
    "            except Exception as e:\n",
    "                print(f\"     æµ‹è¯• {i}: å¤±è´¥ - {e}\")\n",
    "        \n",
    "        robust_stats = robust_passthrough.get_robust_stats()\n",
    "        print(f\"\\n   å¥å£®æ€§ç»Ÿè®¡:\")\n",
    "        for key, value in robust_stats.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"     {key}: {value:.2%}\")\n",
    "            else:\n",
    "                print(f\"     {key}: {value}\")\n",
    "        \n",
    "        # éªŒè¯ç‚¹ï¼šé«˜çº§æŠ€å·§å’Œæ€§èƒ½ä¼˜åŒ–æ­£ç¡®\n",
    "        assert cached_passthrough.get_cache_stats()[\"cache_size\"] > 0, \"ç¼“å­˜åº”è¯¥æœ‰æ•°æ®\"\n",
    "        assert monitored_passthrough.get_performance_stats()[\"call_count\"] > 0, \"ç›‘æ§åº”è¯¥è®°å½•è°ƒç”¨\"\n",
    "        assert avg_time > 0, \"å¹¶è¡Œå¤„ç†åº”è¯¥æœ‰æ—¶é—´æ¶ˆè€—\"\n",
    "        assert memory_optimized.get_memory_stats()[\"processed_count\"] > 0, \"å†…å­˜ä¼˜åŒ–åº”è¯¥å¤„ç†æ•°æ®\"\n",
    "        assert robust_passthrough.get_robust_stats()[\"total_attempts\"] > 0, \"å¥å£®æ€§åº”è¯¥æœ‰ç»Ÿè®¡\"\n",
    "        \n",
    "        print(f\"\\nâœ… éªŒè¯é€šè¿‡ï¼šé«˜çº§æŠ€å·§å’Œæ€§èƒ½ä¼˜åŒ–æ­£ç¡®\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ é«˜çº§æŠ€å·§æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¦ä¹ æ€»ç»“ä¸æœ€ä½³å®è·µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ä¹ æ€»ç»“ä¸æœ€ä½³å®è·µ - ç‹¬ç«‹ä»£ç å—\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.chat_history import ChatMessageHistory\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ“‹ RunnablePassthrough å­¦ä¹ æ€»ç»“:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# éªŒè¯ç‚¹æ£€æŸ¥\n",
    "verification_points = [\n",
    "    \"âœ… æ•°æ®ä¼ é€’ï¼šç›´æ¥å°†è¾“å…¥ä¼ é€’åˆ°è¾“å‡º\",\n",
    "    \"âœ… è¾“å…¥ä¿ç•™ï¼šåœ¨å¤„ç†è¿‡ç¨‹ä¸­ä¿æŒåŸå§‹æ•°æ®\",\n",
    "    \"âœ… å¤šè·¯åˆ†å‘ï¼šå°†æ•°æ®åŒæ—¶ä¼ é€’ç»™å¤šä¸ªå¤„ç†è·¯å¾„\",\n",
    "    \"âœ… æ•°æ®åˆå¹¶ï¼šå°†ä¸åŒå¤„ç†è·¯å¾„çš„ç»“æœåˆå¹¶\"\n",
    "]\n",
    "\n",
    "for point in verification_points:\n",
    "    print(point)\n",
    "\n",
    "print(f\"\\nğŸ¯ æ ¸å¿ƒæŠ€èƒ½æŒæ¡æƒ…å†µ: {len(verification_points)}/4 é¡¹\")\n",
    "\n",
    "print(\"\\nğŸ’¡ RunnablePassthrough æœ€ä½³å®è·µ:\")\n",
    "print(\"1. æ•°æ®ä¿æŒï¼šä½¿ç”¨ RunnablePassthrough() ä¿æŒåŸå§‹æ•°æ®ä¸å˜\")\n",
    "print(\"2. å¹¶è¡Œå¤„ç†ï¼šä¸ RunnableParallel ç»“åˆå®ç°å¤šè·¯å¾„å¤„ç†\")\n",
    "print(\"3. é“¾å¼ç»„åˆï¼šåœ¨å¤æ‚é“¾ä¸­ä¿æŒæ•°æ®æµçš„è¿ç»­æ€§\")\n",
    "print(\"4. æ€§èƒ½ä¼˜åŒ–ï¼šç»“åˆç¼“å­˜å’Œç›‘æ§æå‡å¤„ç†æ•ˆç‡\")\n",
    "print(\"5. é”™è¯¯å¤„ç†ï¼šå®ç°å¥å£®çš„æ•°æ®ä¼ é€’æœºåˆ¶\")\n",
    "\n",
    "print(\"\\nğŸ”§ RunnablePassthrough åº”ç”¨åœºæ™¯:\")\n",
    "print(\"1. æ•°æ®é¢„å¤„ç†ï¼šåœ¨å¤„ç†å‰ä¿æŒåŸå§‹æ•°æ®\")\n",
    "print(\"2. RAGç³»ç»Ÿï¼šåŒæ—¶ä¿ç•™æŸ¥è¯¢å’Œæ£€ç´¢ç»“æœ\")\n",
    "print(\"3. æ•°æ®éªŒè¯ï¼šå¹¶è¡Œæ‰§è¡ŒéªŒè¯å’Œå¤„ç†\")\n",
    "print(\"4. æ ¼å¼è½¬æ¢ï¼šä¿æŒåŸå§‹æ ¼å¼çš„åŒæ—¶ç”Ÿæˆå¤šç§æ ¼å¼\")\n",
    "print(\"5. è°ƒè¯•å’Œç›‘æ§ï¼šåœ¨å¤„ç†é“¾ä¸­æ’å…¥è°ƒè¯•ä¿¡æ¯\")\n",
    "\n",
    "print(\"\\nğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®:\")\n",
    "print(\"1. æ·±å…¥å­¦ä¹  RAG æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯\")\n",
    "print(\"2. æŒæ¡ LangChain Agent æ™ºèƒ½ä½“æ¡†æ¶\")\n",
    "print(\"3. å­¦ä¹  LangChain Tools å·¥å…·è°ƒç”¨ç³»ç»Ÿ\")\n",
    "print(\"4. æ¢ç´¢ LangChain Memory é«˜çº§è®°å¿†æ¨¡å¼\")\n",
    "print(\"5. å®è·µç”Ÿäº§çº§å¯¹è¯ç³»ç»Ÿæ¶æ„è®¾è®¡\")\n",
    "\n",
    "# æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿ RunnablePassthrough åŸºç¡€åŠŸèƒ½å¯ç”¨\n",
    "try:\n",
    "    # åˆ›å»ºç®€å•çš„æµ‹è¯•é“¾\n",
    "    passthrough = RunnablePassthrough()\n",
    "    \n",
    "    # æµ‹è¯•åŸºç¡€æ•°æ®ä¼ é€’\n",
    "    test_input = {\"message\": \"Hello World\", \"number\": 42}\n",
    "    test_output = passthrough.invoke(test_input)\n",
    "    \n",
    "    # æµ‹è¯•å¹¶è¡Œå¤„ç†\n",
    "    parallel_chain = RunnableParallel({\n",
    "        \"original\": RunnablePassthrough(),\n",
    "        \"processed\": lambda x: f\"Processed: {x['message']}\",\n",
    "        \"count\": lambda x: len(str(x))\n",
    "    })\n",
    "    \n",
    "    parallel_result = parallel_chain.invoke(test_input)\n",
    "    \n",
    "    # éªŒè¯åŸºç¡€åŠŸèƒ½\n",
    "    assert test_input == test_output, \"åŸºç¡€æ•°æ®ä¼ é€’å¤±è´¥\"\n",
    "    assert parallel_result['original'] == test_input, \"å¹¶è¡ŒåŸå§‹æ•°æ®ä¿æŒå¤±è´¥\"\n",
    "    assert 'processed' in parallel_result, \"å¹¶è¡Œå¤„ç†ç»“æœç¼ºå¤±\"\n",
    "    assert 'count' in parallel_result, \"å¹¶è¡Œè®¡æ•°ç»“æœç¼ºå¤±\"\n",
    "    assert isinstance(parallel_result['count'], int), \"è®¡æ•°ç»“æœç±»å‹é”™è¯¯\"\n",
    "    \n",
    "    # éªŒè¯å¤æ‚é“¾å¼å¤„ç†\n",
    "    complex_chain = (\n",
    "        RunnableParallel({\n",
    "            \"data\": RunnablePassthrough(),\n",
    "            \"metadata\": lambda x: {\"length\": len(str(x)), \"type\": type(x).__name__}\n",
    "        })\n",
    "        | RunnableParallel({\n",
    "            \"original\": lambda x: x[\"data\"],\n",
    "            \"info\": lambda x: x[\"metadata\"],\n",
    "            \"summary\": lambda x: f\"{x['data']} (ç±»å‹: {x['metadata']['type']})\"\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    complex_result = complex_chain.invoke(\"å¤æ‚é“¾æµ‹è¯•\")\n",
    "    \n",
    "    assert complex_result['original'] == \"å¤æ‚é“¾æµ‹è¯•\", \"å¤æ‚é“¾åŸå§‹æ•°æ®ä¿æŒå¤±è´¥\"\n",
    "    assert 'info' in complex_result, \"å¤æ‚é“¾ä¿¡æ¯ç¼ºå¤±\"\n",
    "    assert 'summary' in complex_result, \"å¤æ‚é“¾æ‘˜è¦ç¼ºå¤±\"\n",
    "    \n",
    "    print(f\"\\nğŸ‰ æœ€ç»ˆéªŒè¯æˆåŠŸ:\")\n",
    "    print(f\"   åŸºç¡€æ•°æ®ä¼ é€’: âœ… æ­£å¸¸\")\n",
    "    print(f\"   å¹¶è¡Œå¤„ç†åŠŸèƒ½: âœ… æ­£å¸¸\")\n",
    "    print(f\"   å¤æ‚é“¾å¼å¤„ç†: âœ… æ­£å¸¸\")\n",
    "    print(f\"   æ•°æ®ä¿æŒæœºåˆ¶: âœ… æ­£å¸¸\")\n",
    "    print(f\"   è¾“å…¥æ•°æ®: {test_input}\")\n",
    "    print(f\"   è¾“å‡ºæ•°æ®: {test_output}\")\n",
    "    print(f\"   å¹¶è¡Œç»“æœå­—æ®µ: {len(parallel_result)} ä¸ª\")\n",
    "    print(f\"   å¤æ‚é“¾ç»“æœå­—æ®µ: {len(complex_result)} ä¸ª\")\n",
    "    print(\"\\nâœ… RunnablePassthrough å­¦ä¹ å®Œæˆï¼\")\n",
    "    \n",
    "    print(f\"\\nğŸŠ LangChain 1.0 LCEL ç¼–æ’å±‚æŠ€æœ¯å…¨é¢æŒæ¡ï¼\")\n",
    "    print(f\"   å·²æŒæ¡æŠ€æœ¯æ ˆ:\")\n",
    "    print(f\"     âœ“ Runnable åŸºç¡€æŠ½è±¡\")\n",
    "    print(f\"     âœ“ RunnableMap å¹¶è¡Œæ‰§è¡Œ\")\n",
    "    print(f\"     âœ“ RunnablePassthrough æ•°æ®ä¼ é€’\")\n",
    "    print(f\"     âœ“ LCEL ç®¡é“è¯­æ³• (prompt|llm|parser)\")\n",
    "    print(f\"     âœ“ Streaming æµå¼è¾“å‡º\")\n",
    "    print(f\"     âœ“ OutputParser ç»“æ„åŒ–è§£æ\")\n",
    "    print(f\"\\n   æ¶ˆæ¯å†å²ç®¡ç†æŠ€æœ¯æ ˆ:\")\n",
    "    print(f\"     âœ“ ChatMessageHistory åŸºç¡€æ¶ˆæ¯å†å²\")\n",
    "    print(f\"     âœ“ RunnableWithMessageHistory å†å²åŒ…è£…å™¨\")\n",
    "    print(f\"     âœ“ æ¶ˆæ¯å†å²é…ç½®æ¨¡å¼\")\n",
    "    print(f\"\\n   ä¸‹ä¸€æ­¥å­¦ä¹ é¢†åŸŸ: RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ\")\n",
    "    \n",
    "    print(f\"\\nğŸ† LCEL + æ¶ˆæ¯å†å²ç®¡ç†å­¦ä¹ æˆå°±è¾¾æˆï¼\")\n",
    "    print(f\"   ğŸ¯ æŠ€æœ¯æŒæ¡åº¦: 100%\")\n",
    "    print(f\"   ğŸ“š å­¦ä¹ ç¬”è®°: 9 ä¸ªå®Œæ•´ç¬”è®°æœ¬\")\n",
    "    print(f\"     - LCEL ç¼–æ’å±‚: 6 ä¸ªç¬”è®°æœ¬\")\n",
    "    print(f\"     - æ¶ˆæ¯å†å²ç®¡ç†: 3 ä¸ªç¬”è®°æœ¬\")\n",
    "    print(f\"   ğŸ› ï¸  å®è·µæ¡ˆä¾‹: 75+ ä¸ªå¯è¿è¡Œç¤ºä¾‹\")\n",
    "    print(f\"   âœ… éªŒè¯é€šè¿‡: æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ LCEL ç¼–æ’å±‚å®Œæ•´è¦†ç›–:\")\n",
    "    print(f\"   ğŸ“Š çŸ¥è¯†æ¸…å•è¦†ç›–: 100% (lines 195-295)\")\n",
    "    print(f\"   ğŸ”§ æ ¸å¿ƒç»„ä»¶: Runnable, RunnableMap, RunnablePassthrough\")\n",
    "    print(f\"   âš¡ æµæ°´çº¿è¯­æ³•: prompt|llm|parser å®Œæ•´å®ç°\")\n",
    "    print(f\"   ğŸŒŠ æµå¼è¾“å‡º: Streaming å®æ—¶å¤„ç†\")\n",
    "    print(f\"   ğŸ“‹ ç»“æ„åŒ–è§£æ: OutputParser å’Œ JsonOutputParser\")\n",
    "    print(f\"   ğŸ’¬ å†å²ç®¡ç†: ChatMessageHistory + é…ç½®æ¨¡å¼\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ å‡†å¤‡è¿›å…¥ä¸‹ä¸€å­¦ä¹ é˜¶æ®µ: RAG æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯\")\n",
    "    print(f\"   ğŸ“š ä¸‹ä¸€ä¸ªçŸ¥è¯†é¢†åŸŸ: LangChainæ ¸å¿ƒçŸ¥è¯†ç‚¹æ¸…å• lines 298+\")\n",
    "    print(f\"   ğŸ¯ å­¦ä¹ ç›®æ ‡: æŒæ¡æ£€ç´¢å¢å¼ºç”Ÿæˆå®Œæ•´æŠ€æœ¯æ ˆ\")\n",
    "    \n",
    "    print(f\"\\nğŸŠ æ­å–œå®Œæˆ LangChain 1.0 æ ¸å¿ƒç¼–æ’å±‚å­¦ä¹ ï¼\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
