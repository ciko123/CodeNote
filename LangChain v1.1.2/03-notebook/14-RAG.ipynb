{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214388e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# ================== é…ç½® ==================\n",
    "load_dotenv()\n",
    "api_base = os.getenv(\"OPENAI_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LangChain æœ€æ–°RAGç³»ç»Ÿ - å®Œæ•´ç‰ˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ================== æ­¥éª¤1ï¼šåŠ è½½æ–‡æœ¬æ–‡ä»¶ ==================\n",
    "print(\"\\n[1/5] åŠ è½½æ–‡æœ¬æ–‡ä»¶...\")\n",
    "loader = TextLoader(\"./test/file/sample.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "print(f\"     âœ“ åŠ è½½ {len(docs)} ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "# ================== æ­¥éª¤2ï¼šåˆ†å‰²æ–‡æœ¬ ==================\n",
    "print(\"[2/5] åˆ†å‰²æ–‡æœ¬...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"     âœ“ åˆ†å‰²æˆ {len(chunks)} ä¸ªå—\")\n",
    "\n",
    "# ================== æ­¥éª¤3ï¼šåˆ›å»ºå‘é‡å­˜å‚¨ ==================\n",
    "print(\"[3/5] åˆ›å»ºå‘é‡å­˜å‚¨...\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"baai/bge-m3\",\n",
    "    api_key=api_key,\n",
    "    base_url=api_base,\n",
    ")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"     âœ“ å‘é‡å­˜å‚¨å·²åˆ›å»º\")\n",
    "\n",
    "# ================== æ­¥éª¤4ï¼šåˆ›å»ºLLM ==================\n",
    "print(\"[4/5] åˆå§‹åŒ–è¯­è¨€æ¨¡å‹...\")\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=api_key,\n",
    "    base_url=api_base,\n",
    "    temperature=0.7,\n",
    ")\n",
    "print(\"     âœ“ LLMå·²åˆå§‹åŒ–\")\n",
    "\n",
    "# ================== æ­¥éª¤5ï¼šæ„å»ºRAGé“¾ï¼ˆä½¿ç”¨æœ€æ–°çš„Runnable APIï¼‰==================\n",
    "print(\"[5/5] æ„å»ºRAGé“¾...\")\n",
    "\n",
    "# å®šä¹‰æç¤ºè¯æ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "æ ¹æ®ä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "è¯·æä¾›è¯¦ç»†ä¸”å‡†ç¡®çš„å›ç­”ï¼š\"\"\")\n",
    "\n",
    "# âœ… è¿™æ˜¯æœ€æ–°çš„æ„å»ºRAGé“¾çš„æ–¹å¼ï¼ˆæ›¿ä»£äº†è¿‡æ—¶çš„RetrievalQA.from_chain_typeï¼‰\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "print(\"     âœ“ RAGé“¾å·²æ„å»ºå®Œæˆ\")\n",
    "\n",
    "# ================== æµ‹è¯•ç³»ç»Ÿ ==================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ç³»ç»Ÿæµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å•ä¸ªé—®é¢˜æµ‹è¯•\n",
    "question = \"LangChainæœ‰å“ªäº›ä¸»è¦ç‰¹æ€§ï¼Ÿ\"\n",
    "print(f\"\\nğŸ” é—®é¢˜: {question}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "result = rag_chain.invoke(question)\n",
    "print(f\"ğŸ“ å›ç­”: {result.content}\")\n",
    "\n",
    "# ================== æµå¼è¾“å‡ºï¼ˆå¯é€‰ï¼‰==================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"æµå¼è¾“å‡ºæµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "question2 = \"ä»€ä¹ˆæ˜¯æ–‡æœ¬åˆ†å‰²ï¼Ÿ\"\n",
    "print(f\"\\nğŸ” é—®é¢˜: {question2}\")\n",
    "print(\"-\" * 60)\n",
    "print(\"ğŸ“ å›ç­”: \", end=\"\", flush=True)\n",
    "\n",
    "# ä½¿ç”¨streamæ–¹æ³•è·å–æµå¼è¾“å‡º\n",
    "for chunk in rag_chain.stream(question2):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "print()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ ç³»ç»Ÿè¿è¡Œå®Œæ¯•ï¼\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
