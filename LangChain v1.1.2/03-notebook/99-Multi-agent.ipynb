{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c1dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åŠ è½½å…¨å±€é…ç½®\n",
      "\n",
      "ğŸ¯ æ¨¡å‹å¸¸é‡:\n",
      "  OPENAI_MODEL, open_model\n",
      "\n",
      "ğŸ¨ æ‰“å°æ–¹æ³•:\n",
      "  pretty_print, print_json\n",
      "  print_agent\n"
     ]
    }
   ],
   "source": [
    "%run \"contant.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d07a7e",
   "metadata": {},
   "source": [
    "## å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5ca8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "å¼€å§‹å¤š Agent ååŒç ”ç©¶...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ç ”ç©¶å®Œæˆï¼\n",
      "============================================================\n",
      "\n",
      "æœ€ç»ˆæŠ¥å‘Š:\n",
      "# æœºå™¨å­¦ä¹ åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨æŠ¥å‘Š\n",
      "\n",
      "## èƒŒæ™¯\n",
      "æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä½œä¸ºäººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè¿‘å¹´æ¥åœ¨åŒ»ç–—é¢†åŸŸå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚éšç€åŒ»ç–—æ•°æ®çš„å¿«é€Ÿå¢é•¿ï¼Œä¼ ç»Ÿçš„è¯Šæ–­æ–¹æ³•é¢ä¸´ç€æ•°æ®å¤„ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚æœºå™¨å­¦ä¹ é€šè¿‡åˆ†æå¤§é‡çš„åŒ»ç–—æ•°æ®ï¼Œèƒ½å¤Ÿè¯†åˆ«å‡ºæ½œåœ¨çš„æ¨¡å¼å’Œè¶‹åŠ¿ï¼Œä»è€Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œæ›´å‡†ç¡®çš„è¯Šæ–­ã€‚ç‰¹åˆ«æ˜¯åœ¨å½±åƒå­¦ã€åŸºå› ç»„å­¦å’Œç”µå­å¥åº·è®°å½•ç­‰é¢†åŸŸï¼Œæœºå™¨å­¦ä¹ æŠ€æœ¯å±•ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚\n",
      "\n",
      "## å…³é”®å‘ç°\n",
      "ç ”ç©¶è¡¨æ˜ï¼Œæœºå™¨å­¦ä¹ åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨èƒ½å¤Ÿæ˜¾è‘—æé«˜è¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚ä¾‹å¦‚ï¼Œåœ¨å½±åƒå­¦ä¸­ï¼Œæ·±åº¦å­¦ä¹ ç®—æ³•èƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«è‚¿ç˜¤å’Œå…¶ä»–ç—…å˜ï¼Œå‡å°‘äº†äººå·¥åˆ†æçš„æ—¶é—´å’Œè¯¯å·®ã€‚æ­¤å¤–ï¼Œæœºå™¨å­¦ä¹ è¿˜å¯ä»¥é€šè¿‡åˆ†ææ‚£è€…çš„å†å²æ•°æ®ï¼Œé¢„æµ‹ç–¾ç—…çš„å‘ç”Ÿé£é™©ï¼Œä»è€Œå®ç°æ—©æœŸå¹²é¢„ã€‚è®¸å¤šä¸´åºŠè¯•éªŒå’Œå®é™…åº”ç”¨æ¡ˆä¾‹æ˜¾ç¤ºï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æŸäº›ç–¾ç—…çš„è¯Šæ–­ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚\n",
      "\n",
      "## è¶‹åŠ¿\n",
      "éšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œæœºå™¨å­¦ä¹ åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨è¶‹åŠ¿æ—¥ç›Šæ˜æ˜¾ã€‚é¦–å…ˆï¼Œè¶Šæ¥è¶Šå¤šçš„åŒ»ç–—æœºæ„å¼€å§‹é‡‡ç”¨åŸºäºæœºå™¨å­¦ä¹ çš„å†³ç­–æ”¯æŒç³»ç»Ÿï¼Œä»¥æé«˜è¯Šæ–­æ•ˆç‡ã€‚å…¶æ¬¡ï¼Œè·¨å­¦ç§‘çš„åˆä½œæ—¥ç›Šå¢å¤šï¼Œæ•°æ®ç§‘å­¦å®¶ä¸åŒ»ç–—ä¸“ä¸šäººå‘˜çš„åˆä½œä½¿å¾—æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¼€å‘æ›´åŠ è´´è¿‘ä¸´åºŠéœ€æ±‚ã€‚æ­¤å¤–ï¼Œéšç€å¯ç©¿æˆ´è®¾å¤‡å’Œç§»åŠ¨å¥åº·åº”ç”¨çš„æ™®åŠï¼Œå®æ—¶æ•°æ®çš„æ”¶é›†å’Œåˆ†æä¸ºæœºå™¨å­¦ä¹ åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨æä¾›äº†æ–°çš„æœºä¼šã€‚\n",
      "\n",
      "## æŒ‘æˆ˜\n",
      "å°½ç®¡æœºå™¨å­¦ä¹ åœ¨åŒ»ç–—è¯Šæ–­ä¸­å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†ä»é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œæ•°æ®éšç§å’Œå®‰å…¨æ€§é—®é¢˜æ˜¯ä¸€ä¸ªé‡è¦çš„éšœç¢ï¼ŒåŒ»ç–—æ•°æ®çš„æ•æ„Ÿæ€§è¦æ±‚åœ¨ä½¿ç”¨æœºå™¨å­¦ä¹ æ—¶å¿…é¡»éµå¾ªä¸¥æ ¼çš„ä¼¦ç†æ ‡å‡†ã€‚å…¶æ¬¡ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§ä¸è¶³ï¼Œä½¿å¾—åŒ»ç”Ÿåœ¨ä½¿ç”¨è¿™äº›å·¥å…·æ—¶å¯èƒ½ç¼ºä¹ä¿¡å¿ƒã€‚æ­¤å¤–ï¼Œæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ä¹Ÿå½±å“ç€æ¨¡å‹çš„æ€§èƒ½ï¼Œå¦‚ä½•è·å–é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ä»ç„¶æ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœæ‚¨éœ€è¦è¿›ä¸€æ­¥çš„ä¿¡æ¯æˆ–æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict, Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# ============ 1. å®šä¹‰å…±äº«çŠ¶æ€ ============\n",
    "class ResearchState(TypedDict):\n",
    "    \"\"\"å¤š agent ä¹‹é—´å…±äº«çš„çŠ¶æ€\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    research_topic: str\n",
    "    search_results: str\n",
    "    analysis_results: str\n",
    "    final_report: str\n",
    "\n",
    "\n",
    "# ============ 2. å®šä¹‰ Agent å·¥å…· ============\n",
    "\n",
    "# æœç´¢ Agent çš„å·¥å…·\n",
    "@tool\n",
    "def search_papers(query: str) -> str:\n",
    "    \"\"\"æœç´¢å­¦æœ¯è®ºæ–‡å’Œèµ„æºã€‚\n",
    "    \n",
    "    Args:\n",
    "        query: æœç´¢å…³é”®è¯\n",
    "    \"\"\"\n",
    "    # æ¨¡æ‹Ÿæœç´¢ç»“æœ\n",
    "    results = [\n",
    "        f\"è®ºæ–‡1: {query}çš„æ ¸å¿ƒç ”ç©¶ - 2024å¹´å‘è¡¨\",\n",
    "        f\"è®ºæ–‡2: {query}çš„æœ€æ–°è¿›å±• - 2023å¹´å‘è¡¨\",\n",
    "        f\"ç»¼è¿°: {query}çš„å…¨é¢åˆ†æ - 2023å¹´å‘è¡¨\",\n",
    "    ]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_paper_details(paper_id: str) -> str:\n",
    "    \"\"\"è·å–è®ºæ–‡è¯¦ç»†ä¿¡æ¯ã€‚\n",
    "    \n",
    "    Args:\n",
    "        paper_id: è®ºæ–‡ID\n",
    "    \"\"\"\n",
    "    return f\"è®ºæ–‡ {paper_id} çš„è¯¦ç»†ä¿¡æ¯ï¼šæ‘˜è¦ã€æ–¹æ³•è®ºã€å…³é”®å‘ç°...\"\n",
    "\n",
    "\n",
    "# åˆ†æ Agent çš„å·¥å…·\n",
    "@tool\n",
    "def analyze_data(data: str) -> str:\n",
    "    \"\"\"åˆ†æç ”ç©¶æ•°æ®ã€‚\n",
    "    \n",
    "    Args:\n",
    "        data: éœ€è¦åˆ†æçš„æ•°æ®\n",
    "    \"\"\"\n",
    "    return f\"å¯¹æ•°æ®çš„æ·±åº¦åˆ†æï¼š\\n- å…³é”®å‘ç°ï¼šæ•°æ®æ˜¾ç¤ºæ˜¾è‘—è¶‹åŠ¿\\n- ç»Ÿè®¡æ„ä¹‰ï¼šp < 0.05\\n- å½±å“ï¼š{data}åœ¨é¢†åŸŸä¸­å…·æœ‰é‡è¦æ„ä¹‰\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def compare_studies(study1: str, study2: str) -> str:\n",
    "    \"\"\"æ¯”è¾ƒä¸¤é¡¹ç ”ç©¶ã€‚\n",
    "    \n",
    "    Args:\n",
    "        study1: ç¬¬ä¸€é¡¹ç ”ç©¶\n",
    "        study2: ç¬¬äºŒé¡¹ç ”ç©¶\n",
    "    \"\"\"\n",
    "    return f\"æ¯”è¾ƒ {study1} å’Œ {study2}ï¼š\\n- æ–¹æ³•å·®å¼‚\\n- ç»“æœå¯¹æ¯”\\n- ç»“è®ºçš„ä¸€è‡´æ€§\"\n",
    "\n",
    "\n",
    "# æ€»ç»“ Agent çš„å·¥å…·\n",
    "@tool\n",
    "def generate_report_section(section_type: str, content: str) -> str:\n",
    "    \"\"\"ç”ŸæˆæŠ¥å‘Šçš„æŸä¸ªç« èŠ‚ã€‚\n",
    "    \n",
    "    Args:\n",
    "        section_type: ç« èŠ‚ç±»å‹ (æ‘˜è¦/èƒŒæ™¯/å‘ç°/ç»“è®º)\n",
    "        content: ç« èŠ‚å†…å®¹\n",
    "    \"\"\"\n",
    "    return f\"ç”Ÿæˆçš„ {section_type} ç« èŠ‚ï¼š{content}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def format_references(papers: str) -> str:\n",
    "    \"\"\"æ ¼å¼åŒ–å‚è€ƒæ–‡çŒ®ã€‚\n",
    "    \n",
    "    Args:\n",
    "        papers: è®ºæ–‡åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    return f\"æ ¼å¼åŒ–çš„å‚è€ƒæ–‡çŒ®ï¼š\\n[1] {papers}\\n[2] {papers}\"\n",
    "\n",
    "\n",
    "# ============ 3. åˆ›å»ºä¸“ä¸š Agent ============\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# æœç´¢ Agent\n",
    "search_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search_papers, get_paper_details],\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯ç ”ç©¶æœç´¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯èµ„æºå’Œè®ºæ–‡ã€‚\"\n",
    ")\n",
    "\n",
    "# åˆ†æ Agent\n",
    "analysis_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[analyze_data, compare_studies],\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ·±åº¦åˆ†æç ”ç©¶æ•°æ®å¹¶è¯†åˆ«å…³é”®æ¨¡å¼ã€‚\"\n",
    ")\n",
    "\n",
    "# æ€»ç»“ Agent\n",
    "summary_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[generate_report_section, format_references],\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯å†™ä½œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†åˆ†æç»“æœè½¬åŒ–ä¸ºæ¸…æ™°çš„æŠ¥å‘Šã€‚\"\n",
    ")\n",
    "\n",
    "\n",
    "# ============ 4. åˆ›å»ºä¸»ç®¡ Agent ============\n",
    "\n",
    "@tool\n",
    "def delegate_to_search_agent(task: str) -> str:\n",
    "    \"\"\"å§”æ‰˜æœç´¢ agent æ‰§è¡Œæœç´¢ä»»åŠ¡ã€‚\"\"\"\n",
    "    result = search_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=task)]\n",
    "    })\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "@tool\n",
    "def delegate_to_analysis_agent(task: str) -> str:\n",
    "    \"\"\"å§”æ‰˜åˆ†æ agent æ‰§è¡Œåˆ†æä»»åŠ¡ã€‚\"\"\"\n",
    "    result = analysis_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=task)]\n",
    "    })\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "@tool\n",
    "def delegate_to_summary_agent(task: str) -> str:\n",
    "    \"\"\"å§”æ‰˜æ€»ç»“ agent æ‰§è¡Œæ€»ç»“ä»»åŠ¡ã€‚\"\"\"\n",
    "    result = summary_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=task)]\n",
    "    })\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "supervisor_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        delegate_to_search_agent,\n",
    "        delegate_to_analysis_agent,\n",
    "        delegate_to_summary_agent,\n",
    "    ],\n",
    "    system_prompt=\"\"\"ä½ æ˜¯ä¸€ä¸ªç ”ç©¶é¡¹ç›®ä¸»ç®¡ã€‚ä½ éœ€è¦åè°ƒä¸‰ä¸ªä¸“å®¶å›¢é˜Ÿï¼š\n",
    "    1. æœç´¢å›¢é˜Ÿï¼šè´Ÿè´£æ‰¾åˆ°ç›¸å…³å­¦æœ¯èµ„æº\n",
    "    2. åˆ†æå›¢é˜Ÿï¼šè´Ÿè´£æ·±åº¦åˆ†ææ•°æ®\n",
    "    3. æ€»ç»“å›¢é˜Ÿï¼šè´Ÿè´£ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\n",
    "    \n",
    "    æ ¹æ®ç”¨æˆ·çš„ç ”ç©¶ä¸»é¢˜ï¼ŒæŒ‰ç…§é¡ºåºå§”æ´¾ä»»åŠ¡ï¼š\n",
    "    1. å…ˆè®©æœç´¢å›¢é˜Ÿæ‰¾è®ºæ–‡\n",
    "    2. å†è®©åˆ†æå›¢é˜Ÿåˆ†æå‘ç°\n",
    "    3. æœ€åè®©æ€»ç»“å›¢é˜Ÿç”ŸæˆæŠ¥å‘Š\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# ============ 5. æ„å»º LangGraph å·¥ä½œæµ ============\n",
    "\n",
    "def research_workflow():\n",
    "    \"\"\"åˆ›å»ºå¤š agent ååŒçš„ LangGraph å·¥ä½œæµ\"\"\"\n",
    "    \n",
    "    workflow = StateGraph(ResearchState)\n",
    "    \n",
    "    # å®šä¹‰èŠ‚ç‚¹\n",
    "    def supervisor_node(state: ResearchState):\n",
    "        \"\"\"ä¸»ç®¡ agent èŠ‚ç‚¹\"\"\"\n",
    "        user_query = f\"è¯·ä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜è¿›è¡Œå®Œæ•´ç ”ç©¶ï¼š{state['research_topic']}\"\n",
    "        \n",
    "        result = supervisor_agent.invoke({\n",
    "            \"messages\": state[\"messages\"] + [HumanMessage(content=user_query)]\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + result[\"messages\"],\n",
    "            \"final_report\": result[\"messages\"][-1].content if result[\"messages\"] else \"\"\n",
    "        }\n",
    "    \n",
    "    # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹\n",
    "    workflow.add_node(\"supervisor\", supervisor_node)\n",
    "    workflow.add_edge(START, \"supervisor\")\n",
    "    workflow.add_edge(\"supervisor\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# ============ 6. è¿è¡Œå®Œæ•´ç¤ºä¾‹ ============\n",
    "\n",
    "def run_research_example():\n",
    "    \"\"\"è¿è¡Œå®Œæ•´çš„å¤š agent ç ”ç©¶æµç¨‹\"\"\"\n",
    "    \n",
    "    graph = research_workflow()\n",
    "    \n",
    "    # åˆå§‹åŒ–çŠ¶æ€\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"research_topic\": \"æœºå™¨å­¦ä¹ åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨\",\n",
    "        \"search_results\": \"\",\n",
    "        \"analysis_results\": \"\",\n",
    "        \"final_report\": \"\"\n",
    "    }\n",
    "    \n",
    "    # æ‰§è¡Œå·¥ä½œæµ\n",
    "    print(\"=\" * 60)\n",
    "    print(\"å¼€å§‹å¤š Agent ååŒç ”ç©¶...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    final_state = graph.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ç ”ç©¶å®Œæˆï¼\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\næœ€ç»ˆæŠ¥å‘Š:\")\n",
    "    print(final_state[\"final_report\"])\n",
    "\n",
    "\n",
    "# ============ 7. æµå¼æ‰§è¡Œï¼ˆå®æ—¶æŸ¥çœ‹æ¯ä¸ª agent çš„å·¥ä½œï¼‰ ============\n",
    "\n",
    "def run_research_with_streaming():\n",
    "    \"\"\"æµå¼æ‰§è¡Œï¼Œå®æ—¶æŸ¥çœ‹æ¯ä¸ª agent çš„å·¥ä½œ\"\"\"\n",
    "    \n",
    "    graph = research_workflow()\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"research_topic\": \"åŒºå—é“¾æŠ€æœ¯åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„åº”ç”¨\",\n",
    "        \"search_results\": \"\",\n",
    "        \"analysis_results\": \"\",\n",
    "        \"final_report\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"å¼€å§‹æµå¼å¤š Agent ç ”ç©¶ï¼ˆå®æ—¶è¾“å‡ºï¼‰...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æµå¼è·å–æ¯ä¸€æ­¥çš„è¾“å‡º\n",
    "    for step in graph.stream(initial_state, stream_mode=\"updates\"):\n",
    "        for node, output in step.items():\n",
    "            print(f\"\\n[{node}] èŠ‚ç‚¹æ‰§è¡Œä¸­...\")\n",
    "            if \"final_report\" in output and output[\"final_report\"]:\n",
    "                print(f\"æŠ¥å‘Šå†…å®¹:\\n{output['final_report'][:200]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æµå¼æ‰§è¡Œå®Œæˆï¼\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è¿è¡Œç¤ºä¾‹\n",
    "    run_research_example()\n",
    "    \n",
    "    # æˆ–è¿è¡Œæµå¼ç‰ˆæœ¬\n",
    "    # run_research_with_streaming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e656d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "åœºæ™¯ 1ï¼šç®€å•é—®é¢˜ - å¯†ç é‡ç½®\n",
      "============================================================\n",
      "\n",
      "å¯¹è¯å†å²:\n",
      "\n",
      "[ç”¨æˆ·]:\n",
      "æˆ‘å¿˜è®°äº†è´¦æˆ·å¯†ç ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ\n",
      "\n",
      "[æ”¯æŒ]:\n",
      "è¯·æ‚¨å°è¯•ä»¥ä¸‹æ­¥éª¤æ¥é‡ç½®æ‚¨çš„è´¦æˆ·å¯†ç ï¼š\n",
      "\n",
      "1. åœ¨ç™»å½•é¡µé¢ï¼Œå¯»æ‰¾â€œå¿˜è®°å¯†ç ï¼Ÿâ€æˆ–â€œé‡ç½®å¯†ç â€çš„é“¾æ¥ã€‚\n",
      "2. ç‚¹å‡»è¯¥é“¾æ¥ï¼Œæ‚¨å¯èƒ½éœ€è¦è¾“å…¥æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€æˆ–ç”¨æˆ·åã€‚\n",
      "3. ç³»ç»Ÿä¼šå‘æ‚¨æä¾›çš„ç”µå­é‚®ä»¶å‘é€ä¸€å°é‡ç½®å¯†ç çš„é‚®ä»¶ã€‚è¯·æ£€æŸ¥æ‚¨çš„é‚®ç®±ï¼ŒåŒ…æ‹¬åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚\n",
      "4. æŒ‰ç…§é‚®ä»¶ä¸­çš„æŒ‡ç¤ºé‡ç½®æ‚¨çš„å¯†ç ã€‚\n",
      "\n",
      "å¦‚æœæ‚¨æ²¡æœ‰æ”¶åˆ°é‡ç½®é‚®ä»¶æˆ–è€…ä»ç„¶æ— æ³•è®¿é—®è´¦æˆ·ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼Œæˆ‘å°†è½¬ç§»ç»™é«˜çº§æŠ€æœ¯å›¢é˜Ÿå¤„ç†ã€‚[ESCALATE_TO_TIER2]\n",
      "\n",
      "[æ”¯æŒ]:\n",
      "è¯·æ‚¨å°è¯•ä»¥ä¸‹æ­¥éª¤æ¥é‡ç½®æ‚¨çš„è´¦æˆ·å¯†ç ï¼š\n",
      "\n",
      "1. åœ¨ç™»å½•é¡µé¢ï¼Œå¯»æ‰¾â€œå¿˜è®°å¯†ç ï¼Ÿâ€æˆ–â€œé‡ç½®å¯†ç â€çš„é“¾æ¥ã€‚\n",
      "2. ç‚¹å‡»è¯¥é“¾æ¥ï¼Œæ‚¨å¯èƒ½éœ€è¦è¾“å…¥æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€æˆ–ç”¨æˆ·åã€‚\n",
      "3. ç³»ç»Ÿä¼šå‘æ‚¨æä¾›çš„ç”µå­é‚®ä»¶å‘é€ä¸€å°é‡ç½®å¯†ç çš„é‚®ä»¶ã€‚è¯·æ£€æŸ¥æ‚¨çš„é‚®ç®±ï¼ŒåŒ…æ‹¬åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚\n",
      "4. æŒ‰ç…§é‚®ä»¶ä¸­çš„æŒ‡ç¤ºé‡ç½®æ‚¨çš„å¯†ç ã€‚\n",
      "\n",
      "å¦‚æœæ‚¨æ²¡æœ‰æ”¶åˆ°é‡ç½®é‚®ä»¶æˆ–è€…ä»ç„¶æ— æ³•è®¿é—®è´¦æˆ·ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼Œæˆ‘å°†è½¬ç§»ç»™é«˜çº§æŠ€æœ¯å›¢é˜Ÿå¤„ç†ã€‚[ESCALATE_TO_TIER2]\n",
      "\n",
      "æœ€ç»ˆå¤„ç† agent: tier2\n",
      "\n",
      "============================================================\n",
      "åœºæ™¯ 2ï¼šä¸­ç­‰é—®é¢˜ - åº”ç”¨æ€§èƒ½ç¼“æ…¢\n",
      "============================================================\n",
      "\n",
      "å¯¹è¯å†å²:\n",
      "\n",
      "[ç”¨æˆ·]:\n",
      "æˆ‘ä»¬çš„åº”ç”¨åœ¨å¤„ç† 100 ä¸‡ç”¨æˆ·å¹¶å‘æ—¶æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚è¿™æ˜¯åº”ç”¨æ¶æ„çš„é—®é¢˜å—ï¼Ÿ\n",
      "\n",
      "[æ”¯æŒ]:\n",
      "æ€§èƒ½é—®é¢˜å¯èƒ½ç”±å¤šç§å› ç´ å¼•èµ·ï¼Œç¡®å®å¯èƒ½ä¸åº”ç”¨æ¶æ„æœ‰å…³ï¼Œä½†ä¹Ÿå¯èƒ½æ¶‰åŠå…¶ä»–æ–¹é¢ï¼Œä¾‹å¦‚æ•°æ®åº“æ€§èƒ½ã€ç½‘ç»œå»¶è¿Ÿã€æœåŠ¡å™¨èµ„æºç­‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½éœ€è¦æ£€æŸ¥çš„æ–¹é¢ï¼š\n",
      "\n",
      "1. **åº”ç”¨æ¶æ„**ï¼šæ˜¯å¦é‡‡ç”¨äº†å¯æ‰©å±•çš„æ¶æ„è®¾è®¡ï¼Ÿæ¯”å¦‚å¾®æœåŠ¡æ¶æ„å¯èƒ½åœ¨å¤„ç†å¤§é‡è¯·æ±‚æ—¶è¡¨ç°æ›´å¥½ã€‚\n",
      "\n",
      "2. **æ•°æ®åº“æ€§èƒ½**ï¼šæŸ¥è¯¢æ˜¯å¦ç»è¿‡ä¼˜åŒ–ï¼Ÿæ˜¯å¦æœ‰ç´¢å¼•ç¼ºå¤±æˆ–é”ç«äº‰ï¼Ÿ\n",
      "\n",
      "3. **æœåŠ¡å™¨èµ„æº**ï¼šCPUã€å†…å­˜ã€IOç­‰èµ„æºæ˜¯å¦è¶³å¤Ÿï¼Ÿæ˜¯å¦å­˜åœ¨ç“¶é¢ˆï¼Ÿ\n",
      "\n",
      "4. **è´Ÿè½½å‡è¡¡**ï¼šæ˜¯å¦åˆç†åˆ†é…è¯·æ±‚åˆ°å¤šä¸ªæœåŠ¡å™¨ï¼Ÿ\n",
      "\n",
      "5. **ç¼“å­˜æœºåˆ¶**ï¼šæ˜¯å¦ä½¿ç”¨äº†ç¼“å­˜æ¥å‡å°‘æ•°æ®åº“çš„è´Ÿæ‹…ï¼Ÿ\n",
      "\n",
      "å»ºè®®æ‚¨ä»è¿™äº›æ–¹é¢è¿›è¡Œæ’æŸ¥ã€‚å¦‚æœé—®é¢˜å¤æ‚ï¼Œå¯èƒ½éœ€è¦æ›´æ·±å…¥çš„åˆ†æï¼Œæ‚¨å¯ä»¥è€ƒè™‘å°†é—®é¢˜è½¬ç§»...\n",
      "\n",
      "[æ”¯æŒ]:\n",
      "æ€§èƒ½é—®é¢˜å¯èƒ½ç”±å¤šç§å› ç´ å¼•èµ·ï¼Œç¡®å®å¯èƒ½ä¸åº”ç”¨æ¶æ„æœ‰å…³ï¼Œä½†ä¹Ÿå¯èƒ½æ¶‰åŠå…¶ä»–æ–¹é¢ï¼Œä¾‹å¦‚æ•°æ®åº“æ€§èƒ½ã€ç½‘ç»œå»¶è¿Ÿã€æœåŠ¡å™¨èµ„æºç­‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½éœ€è¦æ£€æŸ¥çš„æ–¹é¢ï¼š\n",
      "\n",
      "1. **åº”ç”¨æ¶æ„**ï¼šæ˜¯å¦é‡‡ç”¨äº†å¯æ‰©å±•çš„æ¶æ„è®¾è®¡ï¼Ÿæ¯”å¦‚å¾®æœåŠ¡æ¶æ„å¯èƒ½åœ¨å¤„ç†å¤§é‡è¯·æ±‚æ—¶è¡¨ç°æ›´å¥½ã€‚\n",
      "\n",
      "2. **æ•°æ®åº“æ€§èƒ½**ï¼šæŸ¥è¯¢æ˜¯å¦ç»è¿‡ä¼˜åŒ–ï¼Ÿæ˜¯å¦æœ‰ç´¢å¼•ç¼ºå¤±æˆ–é”ç«äº‰ï¼Ÿ\n",
      "\n",
      "3. **æœåŠ¡å™¨èµ„æº**ï¼šCPUã€å†…å­˜ã€IOç­‰èµ„æºæ˜¯å¦è¶³å¤Ÿï¼Ÿæ˜¯å¦å­˜åœ¨ç“¶é¢ˆï¼Ÿ\n",
      "\n",
      "4. **è´Ÿè½½å‡è¡¡**ï¼šæ˜¯å¦åˆç†åˆ†é…è¯·æ±‚åˆ°å¤šä¸ªæœåŠ¡å™¨ï¼Ÿ\n",
      "\n",
      "5. **ç¼“å­˜æœºåˆ¶**ï¼šæ˜¯å¦ä½¿ç”¨äº†ç¼“å­˜æ¥å‡å°‘æ•°æ®åº“çš„è´Ÿæ‹…ï¼Ÿ\n",
      "\n",
      "å»ºè®®æ‚¨ä»è¿™äº›æ–¹é¢è¿›è¡Œæ’æŸ¥ã€‚å¦‚æœé—®é¢˜å¤æ‚ï¼Œå¯èƒ½éœ€è¦æ›´æ·±å…¥çš„åˆ†æï¼Œæ‚¨å¯ä»¥è€ƒè™‘å°†é—®é¢˜è½¬ç§»...\n",
      "\n",
      "æœ€ç»ˆå¤„ç† agent: tier2\n",
      "\n",
      "============================================================\n",
      "åœºæ™¯ 3ï¼šå¤æ‚é—®é¢˜ - äº§å“è®¾è®¡ç¼ºé™·\n",
      "============================================================\n",
      "\n",
      "å¯¹è¯å†å²:\n",
      "\n",
      "[ç”¨æˆ·]:\n",
      "æˆ‘ä»¬å‘ç°å½“ç”¨æˆ·åŒæ—¶ä½¿ç”¨å¤šä¸ªè®¾å¤‡æ—¶ï¼Œå®æ—¶åŒæ­¥ä¼šäº§ç”Ÿæ•°æ®å†²çªã€‚è¿™éœ€è¦æ€æ ·çš„äº§å“å±‚é¢çš„æ”¹è¿›ï¼Ÿ\n",
      "\n",
      "[æ”¯æŒ]:\n",
      "å®æ—¶åŒæ­¥æ—¶å‡ºç°æ•°æ®å†²çªçš„é—®é¢˜é€šå¸¸æ¶‰åŠåˆ°å¤šä¸ªè®¾å¤‡ä¹‹é—´çš„æ•°æ®ä¸€è‡´æ€§å’Œåè°ƒã€‚ä¸ºäº†æ”¹è¿›è¿™ä¸€ç‚¹ï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹å‡ ä¸ªäº§å“å±‚é¢çš„å»ºè®®ï¼š\n",
      "\n",
      "1. **ç‰ˆæœ¬æ§åˆ¶**ï¼šä¸ºæ¯æ¬¡æ•°æ®æ›´æ”¹å¼•å…¥ç‰ˆæœ¬å·ï¼Œç¡®ä¿æ¯ä¸ªä¿®æ”¹éƒ½èƒ½è¿½è¸ªã€‚ç”¨æˆ·å¯ä»¥é€‰æ‹©ä¿ç•™æœ€æ–°ç‰ˆæœ¬æˆ–åˆå¹¶ä¸åŒç‰ˆæœ¬ã€‚\n",
      "\n",
      "2. **å†²çªè§£å†³æœºåˆ¶**ï¼šè®¾è®¡ä¸€ä¸ªæ™ºèƒ½çš„å†²çªè§£å†³æœºåˆ¶ï¼Œå½“æ£€æµ‹åˆ°æ•°æ®å†²çªæ—¶ï¼Œå¯ä»¥æç¤ºç”¨æˆ·é€‰æ‹©ä¿ç•™å“ªä¸ªç‰ˆæœ¬ï¼Œæˆ–è‡ªåŠ¨åˆå¹¶æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œä»¥æ—¶é—´æˆ³ä¸ºä¾æ®ï¼‰ã€‚\n",
      "\n",
      "3. **å®æ—¶é€šçŸ¥**ï¼šåœ¨å¤šä¸ªè®¾å¤‡ä¸Šä½¿ç”¨å®æ—¶é€šçŸ¥åŠŸèƒ½ï¼Œç¡®ä¿ç”¨æˆ·åœ¨ä»»ä½•ä¸€å°è®¾å¤‡ä¸Šè¿›è¡Œæ›´æ”¹æ—¶ï¼Œå…¶ä»–è®¾å¤‡èƒ½å¤ŸåŠæ—¶æ›´æ–°æ•°æ®ï¼Œå‡å°‘å†²çªçš„æœºä¼šã€‚\n",
      "\n",
      "4. **çŠ¶æ€åŒæ­¥**ï¼šåœ¨ç”¨æˆ·æ›´æ”¹æ•°æ®æ—¶ï¼Œé”å®šè¯¥æ•°æ®é¡¹ï¼Œé˜²æ­¢å…¶ä»–è®¾å¤‡è¿›è¡ŒåŒæ­¥ï¼Œç›´åˆ°æ›´æ”¹å®Œæˆå¹¶ä¸”çŠ¶æ€æ¢å¤æ­£å¸¸ã€‚\n",
      "\n",
      "5. **ç”¨æˆ·æ•™è‚²**ï¼šæä¾›ç”¨æˆ·æŒ‡å—ï¼Œå¸®åŠ©ä»–ä»¬ç†è§£åœ¨å¤šè®¾å¤‡ä½¿ç”¨æ—¶å¯èƒ½å‡ºç°çš„å†²çªåŠå…¶å½±å“ï¼Œé¼“åŠ±ä»–ä»¬åœ¨è®¾å¤‡é—´è¿›è¡Œåè°ƒã€‚\n",
      "\n",
      "6. **å¢å¼ºçš„åå°æœåŠ¡**ï¼šä¼˜åŒ–åå°æœåŠ¡ï¼Œç¡®...\n",
      "\n",
      "æœ€ç»ˆå¤„ç† agent: tier1\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# ============ å®šä¹‰å…±äº«çŠ¶æ€ ============\n",
    "class SupportState(TypedDict):\n",
    "    \"\"\"å¤š agent ä¹‹é—´å…±äº«çš„å¯¹è¯çŠ¶æ€\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    current_agent: str  # å½“å‰æ´»è·ƒçš„ agent\n",
    "    issue_complexity: Literal[\"simple\", \"medium\", \"complex\"]  # é—®é¢˜å¤æ‚åº¦\n",
    "    attempt_count: int  # å½“å‰ agent çš„å°è¯•æ¬¡æ•°\n",
    "\n",
    "\n",
    "# ============ åˆ›å»º LLM ============\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "\n",
    "# ============ å®šä¹‰ä¸€çº§æ”¯æŒ Agent ============\n",
    "def tier1_support_node(state: SupportState):\n",
    "    \"\"\"ä¸€çº§æŠ€æœ¯æ”¯æŒ agent\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ä¸€çº§æŠ€æœ¯æ”¯æŒä»£è¡¨ã€‚\n",
    "ä½ çš„èŒè´£æ˜¯ï¼š\n",
    "1. å¸®åŠ©ç”¨æˆ·è§£å†³ç®€å•çš„æŠ€æœ¯é—®é¢˜\n",
    "2. ç†è§£é—®é¢˜çš„å¤æ‚åº¦\n",
    "3. å¦‚æœä½ æ— æ³•è§£å†³ï¼Œæ˜ç¡®å‘Šè¯‰ç”¨æˆ·å°†è½¬ç§»ç»™é«˜çº§æŠ€æœ¯å›¢é˜Ÿ\n",
    "\n",
    "å¦‚æœé—®é¢˜è¶…å‡ºä½ çš„èƒ½åŠ›èŒƒå›´ï¼Œåœ¨å›ç­”æœ«å°¾æ·»åŠ ï¼š[ESCALATE_TO_TIER2]\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_prompt}] + \n",
    "        [{\"role\": msg.type, \"content\": msg.content} for msg in messages]\n",
    "    )\n",
    "    \n",
    "    assistant_message = AIMessage(content=response.content)\n",
    "    updated_messages = messages + [assistant_message]\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦éœ€è¦å‡çº§\n",
    "    if \"[ESCALATE_TO_TIER2]\" in response.content:\n",
    "        clean_content = response.content.replace(\"\\n[ESCALATE_TO_TIER2]\", \"\")\n",
    "        updated_messages[-1] = AIMessage(content=clean_content)\n",
    "        \n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": updated_messages,\n",
    "                \"current_agent\": \"tier1\",\n",
    "                \"issue_complexity\": \"simple\",\n",
    "                \"attempt_count\": state.get(\"attempt_count\", 0) + 1\n",
    "            },\n",
    "            goto=\"tier2_support\"  # è½¬ç§»ç»™äºŒçº§\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": updated_messages,\n",
    "        \"current_agent\": \"tier1\",\n",
    "        \"issue_complexity\": \"simple\",\n",
    "        \"attempt_count\": state.get(\"attempt_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "\n",
    "# ============ å®šä¹‰äºŒçº§æŠ€æœ¯ä¸“å®¶ Agent ============\n",
    "def tier2_support_node(state: SupportState):\n",
    "    \"\"\"äºŒçº§æŠ€æœ¯ä¸“å®¶ agent\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„äºŒçº§æŠ€æœ¯ä¸“å®¶ã€‚\n",
    "ä½ çš„èŒè´£æ˜¯ï¼š\n",
    "1. å¤„ç†ä¸€çº§æ”¯æŒæ— æ³•è§£å†³çš„é—®é¢˜\n",
    "2. è¿›è¡Œæ·±å…¥çš„æŠ€æœ¯åˆ†æå’Œè°ƒè¯•\n",
    "3. å¦‚æœæ¶‰åŠäº§å“è®¾è®¡ç¼ºé™·æˆ–éœ€è¦äº§å“æ›´æ”¹ï¼Œè½¬ç§»ç»™äº§å“ç»ç†\n",
    "\n",
    "å¦‚æœé—®é¢˜éœ€è¦äº§å“æ”¹è¿›ï¼Œåœ¨æœ«å°¾æ·»åŠ ï¼š[ESCALATE_TO_PM]\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    escalation_context = \"\\n\\n[èƒŒæ™¯] ä¸€çº§æ”¯æŒæ— æ³•è§£å†³æ­¤é—®é¢˜ï¼Œå·²å‡çº§ç»™æ‚¨å¤„ç†ã€‚\"\n",
    "    \n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_prompt + escalation_context}] + \n",
    "        [{\"role\": msg.type, \"content\": msg.content} for msg in messages]\n",
    "    )\n",
    "    \n",
    "    assistant_message = AIMessage(content=response.content)\n",
    "    updated_messages = messages + [assistant_message]\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­å‡çº§\n",
    "    if \"[ESCALATE_TO_PM]\" in response.content:\n",
    "        clean_content = response.content.replace(\"\\n[ESCALATE_TO_PM]\", \"\")\n",
    "        updated_messages[-1] = AIMessage(content=clean_content)\n",
    "        \n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": updated_messages,\n",
    "                \"current_agent\": \"tier2\",\n",
    "                \"issue_complexity\": \"medium\",\n",
    "                \"attempt_count\": state.get(\"attempt_count\", 0) + 1\n",
    "            },\n",
    "            goto=\"product_manager\"  # è½¬ç§»ç»™äº§å“ç»ç†\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": updated_messages,\n",
    "        \"current_agent\": \"tier2\",\n",
    "        \"issue_complexity\": \"medium\",\n",
    "        \"attempt_count\": state.get(\"attempt_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "\n",
    "# ============ å®šä¹‰äº§å“ç»ç† Agent ============\n",
    "def product_manager_node(state: SupportState):\n",
    "    \"\"\"äº§å“ç»ç† agent\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"ä½ æ˜¯äº§å“ç»ç†ï¼Œè´Ÿè´£å¤„ç†æœ€å¤æ‚çš„ç”¨æˆ·é—®é¢˜ã€‚\n",
    "ä½ çš„èŒè´£æ˜¯ï¼š\n",
    "1. è¯„ä¼°é—®é¢˜æ˜¯å¦åæ˜ äº†äº§å“è®¾è®¡çš„ä¸è¶³\n",
    "2. åšå‡ºå…³äºåŠŸèƒ½æ”¹è¿›çš„å†³ç­–\n",
    "3. æä¾›è§£å†³æ–¹æ¡ˆæˆ–åŠŸèƒ½æ‰¿è¯º\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    escalation_context = \"\\n\\n[èƒŒæ™¯] è¿™æ˜¯ä¸€ä¸ªå·²ç»è¿‡äºŒçº§æŠ€æœ¯ä¸“å®¶è¯„ä¼°çš„å¤æ‚é—®é¢˜ï¼Œéœ€è¦äº§å“å±‚é¢çš„å†³ç­–ã€‚\"\n",
    "    \n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_prompt + escalation_context}] + \n",
    "        [{\"role\": msg.type, \"content\": msg.content} for msg in messages]\n",
    "    )\n",
    "    \n",
    "    assistant_message = AIMessage(content=response.content)\n",
    "    updated_messages = messages + [assistant_message]\n",
    "    \n",
    "    # äº§å“ç»ç†æ˜¯æœ€åä¸€çº§ï¼Œé—®é¢˜å·²è§£å†³\n",
    "    return {\n",
    "        \"messages\": updated_messages,\n",
    "        \"current_agent\": \"product_manager\",\n",
    "        \"issue_complexity\": \"complex\",\n",
    "        \"attempt_count\": state.get(\"attempt_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "\n",
    "# ============ æ„å»º LangGraph å·¥ä½œæµ ============\n",
    "def create_support_workflow():\n",
    "    \"\"\"åˆ›å»ºæ¡æ‰‹è½¬ç§»çš„å¤šå±‚çº§æ”¯æŒç³»ç»Ÿ\"\"\"\n",
    "    \n",
    "    workflow = StateGraph(SupportState)\n",
    "    \n",
    "    # æ·»åŠ èŠ‚ç‚¹\n",
    "    workflow.add_node(\"tier1_support\", tier1_support_node)\n",
    "    workflow.add_node(\"tier2_support\", tier2_support_node)\n",
    "    workflow.add_node(\"product_manager\", product_manager_node)\n",
    "    \n",
    "    # è®¾ç½®èµ·ç‚¹ï¼šä»ä¸€çº§æ”¯æŒå¼€å§‹\n",
    "    workflow.add_edge(START, \"tier1_support\")\n",
    "    \n",
    "    # é»˜è®¤ç»“æŸ\n",
    "    workflow.add_edge(\"tier1_support\", END)\n",
    "    workflow.add_edge(\"tier2_support\", END)\n",
    "    workflow.add_edge(\"product_manager\", END)\n",
    "    \n",
    "    # ç¼–è¯‘ï¼ˆè¿™é‡Œæ·»åŠ  checkpointerï¼‰\n",
    "    checkpointer = MemorySaver()\n",
    "    return workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "\n",
    "# ============ ä¿®å¤ï¼šæä¾› config å‚æ•° ============\n",
    "\n",
    "def test_simple_issue():\n",
    "    \"\"\"æµ‹è¯•ç®€å•é—®é¢˜ï¼šå¯†ç é‡ç½®\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"åœºæ™¯ 1ï¼šç®€å•é—®é¢˜ - å¯†ç é‡ç½®\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    graph = create_support_workflow()\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"æˆ‘å¿˜è®°äº†è´¦æˆ·å¯†ç ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ\")\n",
    "        ],\n",
    "        \"current_agent\": \"tier1\",\n",
    "        \"issue_complexity\": \"simple\",\n",
    "        \"attempt_count\": 0\n",
    "    }\n",
    "    \n",
    "    # å…³é”®ä¿®å¤ï¼šæä¾› config å‚æ•°ï¼ŒåŒ…å« thread_id\n",
    "    config = {\"configurable\": {\"thread_id\": \"support_001\"}}\n",
    "    \n",
    "    final_state = graph.invoke(initial_state, config)\n",
    "    \n",
    "    print(\"\\nå¯¹è¯å†å²:\")\n",
    "    for msg in final_state[\"messages\"]:\n",
    "        role = \"ç”¨æˆ·\" if msg.type == \"human\" else \"æ”¯æŒ\"\n",
    "        print(f\"\\n[{role}]:\")\n",
    "        print(msg.content)\n",
    "    \n",
    "    print(f\"\\næœ€ç»ˆå¤„ç† agent: {final_state['current_agent']}\")\n",
    "\n",
    "\n",
    "def test_medium_issue():\n",
    "    \"\"\"æµ‹è¯•ä¸­ç­‰é—®é¢˜ï¼šæ€§èƒ½ä¼˜åŒ–\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"åœºæ™¯ 2ï¼šä¸­ç­‰é—®é¢˜ - åº”ç”¨æ€§èƒ½ç¼“æ…¢\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    graph = create_support_workflow()\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"æˆ‘ä»¬çš„åº”ç”¨åœ¨å¤„ç† 100 ä¸‡ç”¨æˆ·å¹¶å‘æ—¶æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚è¿™æ˜¯åº”ç”¨æ¶æ„çš„é—®é¢˜å—ï¼Ÿ\")\n",
    "        ],\n",
    "        \"current_agent\": \"tier1\",\n",
    "        \"issue_complexity\": \"medium\",\n",
    "        \"attempt_count\": 0\n",
    "    }\n",
    "    \n",
    "    # æä¾› config å‚æ•°\n",
    "    config = {\"configurable\": {\"thread_id\": \"support_002\"}}\n",
    "    \n",
    "    final_state = graph.invoke(initial_state, config)\n",
    "    \n",
    "    print(\"\\nå¯¹è¯å†å²:\")\n",
    "    for msg in final_state[\"messages\"]:\n",
    "        role = \"ç”¨æˆ·\" if msg.type == \"human\" else \"æ”¯æŒ\"\n",
    "        print(f\"\\n[{role}]:\")\n",
    "        content = msg.content[:300] + \"...\" if len(msg.content) > 300 else msg.content\n",
    "        print(content)\n",
    "    \n",
    "    print(f\"\\næœ€ç»ˆå¤„ç† agent: {final_state['current_agent']}\")\n",
    "\n",
    "\n",
    "def test_complex_issue():\n",
    "    \"\"\"æµ‹è¯•å¤æ‚é—®é¢˜ï¼šäº§å“è®¾è®¡ç¼ºé™·\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"åœºæ™¯ 3ï¼šå¤æ‚é—®é¢˜ - äº§å“è®¾è®¡ç¼ºé™·\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    graph = create_support_workflow()\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"æˆ‘ä»¬å‘ç°å½“ç”¨æˆ·åŒæ—¶ä½¿ç”¨å¤šä¸ªè®¾å¤‡æ—¶ï¼Œå®æ—¶åŒæ­¥ä¼šäº§ç”Ÿæ•°æ®å†²çªã€‚è¿™éœ€è¦æ€æ ·çš„äº§å“å±‚é¢çš„æ”¹è¿›ï¼Ÿ\")\n",
    "        ],\n",
    "        \"current_agent\": \"tier1\",\n",
    "        \"issue_complexity\": \"complex\",\n",
    "        \"attempt_count\": 0\n",
    "    }\n",
    "    \n",
    "    # æä¾› config å‚æ•°\n",
    "    config = {\"configurable\": {\"thread_id\": \"support_003\"}}\n",
    "    \n",
    "    final_state = graph.invoke(initial_state, config)\n",
    "    \n",
    "    print(\"\\nå¯¹è¯å†å²:\")\n",
    "    for msg in final_state[\"messages\"]:\n",
    "        role = \"ç”¨æˆ·\" if msg.type == \"human\" else \"æ”¯æŒ\"\n",
    "        print(f\"\\n[{role}]:\")\n",
    "        content = msg.content[:400] + \"...\" if len(msg.content) > 400 else msg.content\n",
    "        print(content)\n",
    "    \n",
    "    print(f\"\\næœ€ç»ˆå¤„ç† agent: {final_state['current_agent']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è¿è¡Œæ‰€æœ‰æµ‹è¯•\n",
    "    test_simple_issue()\n",
    "    test_medium_issue()\n",
    "    test_complex_issue()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3.13.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
