{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b1e7c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åŠ è½½å…¨å±€é…ç½®\n",
      "\n",
      "ğŸ¯ æ¨¡å‹å¸¸é‡:\n",
      "  OPENAI_MODEL, open_model\n",
      "\n",
      "ğŸ¨ æ‰“å°æ–¹æ³•:\n",
      "  pretty_print, print_json\n",
      "  print_agent\n"
     ]
    }
   ],
   "source": [
    "%run \"contant.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b3bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ã€‚\"\"\"\n",
    "    return f\"{city} çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼\"\n",
    "\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    tools=[get_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659f1e3",
   "metadata": {},
   "source": [
    "### stream_mode=\"messages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b16878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': 'call_OBiT6pM5T3FptIi6zrJC0L1l', 'name': 'get_weather', 'args': None, 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '{\"', 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'city', 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\":\"', 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'æ—§', 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'é‡‘', 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'å±±', 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\"}', 'index': 0}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n",
      "èŠ‚ç‚¹: tools\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æ—§'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'é‡‘'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'å±±'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'çš„'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'å¤©æ°”'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æ€»'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æ˜¯'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æ™´'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æœ—'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'çš„'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'ï¼'}]\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n",
      "èŠ‚ç‚¹: model\n",
      "å†…å®¹: []\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨æ¶ˆæ¯æµå¼è¾“å‡º\n",
    "for token, metadata in agent.stream(   \n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"èŠ‚ç‚¹: {metadata['langgraph_node']}\")\n",
    "    print(f\"å†…å®¹: {token.content_blocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb882eeb",
   "metadata": {},
   "source": [
    "### stream_mode=\"updates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db4200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­¥éª¤: model\n",
      "å†…å®¹: [{'type': 'tool_call', 'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_mb91PLqbXj6Fgh1Z3sGtLKIJ'}]\n",
      "æ­¥éª¤: tools\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼'}]\n",
      "æ­¥éª¤: model\n",
      "å†…å®¹: [{'type': 'text', 'text': 'æ—§é‡‘å±±çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼'}]\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨æµå¼è¾“å‡º\n",
    "for chunk in agent.stream(   \n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        print(f\"æ­¥éª¤: {step}\")\n",
    "        print(f\"å†…å®¹: {data['messages'][-1].content_blocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb41b7",
   "metadata": {},
   "source": [
    "### stream_mode=\"values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1624fa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='372f6cde-ab29-46b8-84e1-1340df046b51')]}\n",
      "{'messages': [HumanMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='372f6cde-ab29-46b8-84e1-1340df046b51'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 50, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': '1c3076dadbf889d0dc6118ea2cfbde9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019af8d1-c22c-7560-9b58-1094e9e27925-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_o0vE5a3UKUAaaXpeKfpyoGzR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 50, 'output_tokens': 17, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='372f6cde-ab29-46b8-84e1-1340df046b51'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 50, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': '1c3076dadbf889d0dc6118ea2cfbde9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019af8d1-c22c-7560-9b58-1094e9e27925-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_o0vE5a3UKUAaaXpeKfpyoGzR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 50, 'output_tokens': 17, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼', name='get_weather', id='2a2a4444-ff9d-459d-8557-2ba6dfbc8752', tool_call_id='call_o0vE5a3UKUAaaXpeKfpyoGzR')]}\n",
      "{'messages': [HumanMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='372f6cde-ab29-46b8-84e1-1340df046b51'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 50, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': '1c3076dadbf889d0dc6118ea2cfbde9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019af8d1-c22c-7560-9b58-1094e9e27925-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_o0vE5a3UKUAaaXpeKfpyoGzR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 50, 'output_tokens': 17, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼', name='get_weather', id='2a2a4444-ff9d-459d-8557-2ba6dfbc8752', tool_call_id='call_o0vE5a3UKUAaaXpeKfpyoGzR'), AIMessage(content='æ—§é‡‘å±±çš„å¤©æ°”ä¸€ç›´éƒ½å¾ˆæ™´æœ—ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 85, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': '963bd5f57aea29a91a55c55ddff3ed44', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019af8d1-de68-7cd0-921e-90af0028dd73-0', usage_metadata={'input_tokens': 85, 'output_tokens': 13, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨æ¶ˆæ¯æµå¼è¾“å‡º\n",
    "for state in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8083bf6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 1, 'timestamp': '2025-12-07T12:39:00.553001+00:00', 'type': 'task', 'payload': {'id': '7c139c85-e7e2-d39f-2213-a12190858b89', 'name': 'model', 'input': {'messages': [HumanMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='f35fe343-9617-42c9-bf6d-c556d44acf58')]}, 'triggers': ('branch:to:model',)}}\n",
      "{'step': 1, 'timestamp': '2025-12-07T12:39:07.244222+00:00', 'type': 'task_result', 'payload': {'id': '7c139c85-e7e2-d39f-2213-a12190858b89', 'name': 'model', 'error': None, 'result': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 50, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': 'e0e526ec53fccfb468d3446e3279d54a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019af8d2-90ca-78a0-8ac1-d33aa7a20869-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_uQnF6KllR0AgzlhhgKVymKMH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 50, 'output_tokens': 17, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, 'interrupts': []}}\n",
      "{'step': 2, 'timestamp': '2025-12-07T12:39:07.244384+00:00', 'type': 'task', 'payload': {'id': 'ee2ead4c-ba78-c10f-85b5-0f2ad552ecb9', 'name': 'tools', 'input': {'__type': 'tool_call_with_context', 'tool_call': {'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_uQnF6KllR0AgzlhhgKVymKMH', 'type': 'tool_call'}, 'state': {'messages': [HumanMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='f35fe343-9617-42c9-bf6d-c556d44acf58'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 50, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': 'e0e526ec53fccfb468d3446e3279d54a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019af8d2-90ca-78a0-8ac1-d33aa7a20869-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_uQnF6KllR0AgzlhhgKVymKMH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 50, 'output_tokens': 17, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'triggers': ('__pregel_push',)}}\n",
      "{'step': 2, 'timestamp': '2025-12-07T12:39:07.246849+00:00', 'type': 'task_result', 'payload': {'id': 'ee2ead4c-ba78-c10f-85b5-0f2ad552ecb9', 'name': 'tools', 'error': None, 'result': {'messages': [ToolMessage(content='æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼', name='get_weather', id='40949096-fd0b-45fd-bca5-fd2796c4e0ef', tool_call_id='call_uQnF6KllR0AgzlhhgKVymKMH')]}, 'interrupts': []}}\n",
      "{'step': 3, 'timestamp': '2025-12-07T12:39:07.246991+00:00', 'type': 'task', 'payload': {'id': '35156ba7-74bf-57c3-69ad-2ad006e002d7', 'name': 'model', 'input': {'messages': [HumanMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='f35fe343-9617-42c9-bf6d-c556d44acf58'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 50, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': 'e0e526ec53fccfb468d3446e3279d54a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019af8d2-90ca-78a0-8ac1-d33aa7a20869-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_uQnF6KllR0AgzlhhgKVymKMH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 50, 'output_tokens': 17, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼', name='get_weather', id='40949096-fd0b-45fd-bca5-fd2796c4e0ef', tool_call_id='call_uQnF6KllR0AgzlhhgKVymKMH')]}, 'triggers': ('branch:to:model',)}}\n",
      "{'step': 3, 'timestamp': '2025-12-07T12:39:08.788662+00:00', 'type': 'task_result', 'payload': {'id': '35156ba7-74bf-57c3-69ad-2ad006e002d7', 'name': 'model', 'error': None, 'result': {'messages': [AIMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 85, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': '5fbc8fe7e6ee42978bdeeb5e9102354b', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019af8d2-aaf0-7550-8cc7-dd83349c55cc-0', usage_metadata={'input_tokens': 85, 'output_tokens': 13, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, 'interrupts': []}}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨æ¶ˆæ¯æµå¼è¾“å‡º\n",
    "for state in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    stream_mode=\"debug\",\n",
    "):\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccb2d0",
   "metadata": {},
   "source": [
    "### stream_mode=\"custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0c04d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è·å– æ—§é‡‘å±± çš„æ•°æ®ã€‚\n",
      "å·²è·å– æ—§é‡‘å±± çš„æ•°æ®ã€‚\n",
      "æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer  \n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"è·å–ç»™å®šåŸå¸‚çš„å¤©æ°”ã€‚\"\"\"\n",
    "    writer = get_stream_writer()  \n",
    "    # æµå¼ä¼ è¾“ä»»æ„æ•°æ®\n",
    "    writer(f\"æ­£åœ¨è·å– {city} çš„æ•°æ®ã€‚\")\n",
    "    writer(f\"å·²è·å– {city} çš„æ•°æ®ã€‚\")\n",
    "    result = f\"{city} çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼\"\n",
    "    writer(result)\n",
    "    return result\n",
    "\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    stream_mode=\"custom\"\n",
    "):\n",
    "    print(chunk)\n",
    "    \n",
    "# æ­£åœ¨è·å– San Francisco çš„æ•°æ®ã€‚\n",
    "# å·²è·å– San Francisco çš„æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e266821",
   "metadata": {},
   "source": [
    "### stream_mode=[\"updates\", \"custom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40410f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream_mode: updates\n",
      "content: {'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 51, 'total_tokens': 84, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': '804028fb097c9a243cbc482b229778e5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019af8cb-2965-7e52-a7ea-9ead8bbf6468-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'æ—§é‡‘å±±'}, 'id': 'call_RukpVZW7C37fHnRBc4wawv9T', 'type': 'tool_call'}], usage_metadata={'input_tokens': 51, 'output_tokens': 33, 'total_tokens': 84, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "stream_mode: custom\n",
      "content: æ­£åœ¨è·å– æ—§é‡‘å±± çš„æ•°æ®ã€‚\n",
      "stream_mode: custom\n",
      "content: å·²è·å– æ—§é‡‘å±± çš„æ•°æ®ã€‚\n",
      "stream_mode: updates\n",
      "content: {'tools': {'messages': [ToolMessage(content='æ—§é‡‘å±± çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼', name='get_weather', id='9663430f-1b32-4f65-aee7-ab292c4731e4', tool_call_id='call_RukpVZW7C37fHnRBc4wawv9T')]}}\n",
      "stream_mode: updates\n",
      "content: {'model': {'messages': [AIMessage(content='æ—§é‡‘å±±çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 86, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano', 'system_fingerprint': 'fp_03e44fcc34', 'id': 'fc9b656c163d3e2c1096f6393d71c4fb', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019af8cb-46e9-77b3-8f70-8707e2a8eab9-0', usage_metadata={'input_tokens': 86, 'output_tokens': 13, 'total_tokens': 99, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"è·å–ç»™å®šåŸå¸‚çš„å¤©æ°”ã€‚\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    writer(f\"æ­£åœ¨è·å– {city} çš„æ•°æ®ã€‚\")\n",
    "    writer(f\"å·²è·å– {city} çš„æ•°æ®ã€‚\")\n",
    "    return f\"{city} çš„å¤©æ°”æ€»æ˜¯æ™´æœ—çš„ï¼\"\n",
    "\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for stream_mode, chunk in agent.stream(  \n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    stream_mode=[\"updates\", \"custom\"]\n",
    "):\n",
    "    print(f\"stream_mode: {stream_mode}\")\n",
    "    print(f\"content: {chunk}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3.13.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
