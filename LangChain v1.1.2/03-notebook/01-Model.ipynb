{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63fb13e9",
   "metadata": {},
   "source": [
    "## ChatOpenAI ç¯å¢ƒå˜é‡è¯»å–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec9d3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åŠ è½½å…¨å±€é…ç½®\n"
     ]
    }
   ],
   "source": [
    "%run \"contant.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167cb27",
   "metadata": {},
   "source": [
    "\n",
    "âœ… ä¼šè‡ªåŠ¨è¯»å–è¿™äº›\n",
    "\n",
    "OPENAI_API_KEY          # APIå¯†é’¥ï¼ˆå¿…éœ€ï¼‰\n",
    "\n",
    "OPENAI_ORGANIZATION     # ç»„ç»‡ID\n",
    "\n",
    "OPENAI_BASE_URL         # è‡ªå®šä¹‰base URL\n",
    "\n",
    "OPENAI_API_VERSION      # APIç‰ˆæœ¬ï¼ˆAzureç”¨ï¼‰\n",
    "\n",
    "âŒ ä¸ä¼šè¯»å–è¿™äº›\n",
    "\n",
    "OPENAI_MODEL           # âŒ ä¸æ”¯æŒ\n",
    "\n",
    "MODEL_NAME             # âŒ ä¸æ”¯æŒ\n",
    "\n",
    "LLM_MODEL              # âŒ ä¸æ”¯æŒ\n",
    "\n",
    "model = ChatOpenAI() # gpt-3.5-turboï¼ˆé»˜è®¤ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0f64b",
   "metadata": {},
   "source": [
    "## ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552438d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"refusal\": null\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 10,\n",
      "      \"prompt_tokens\": 8,\n",
      "      \"total_tokens\": 18,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0,\n",
      "        \"cache_creation_input_tokens\": 0,\n",
      "        \"cache_read_input_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4.1-nano\",\n",
      "    \"system_fingerprint\": \"fp_03e44fcc34\",\n",
      "    \"id\": \"3a5bb63cf607735cc6d3af2d684c8496\",\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"logprobs\": null\n",
      "  },\n",
      "  \"type\": \"ai\",\n",
      "  \"name\": null,\n",
      "  \"id\": \"lc_run--019af87b-2c87-79b0-838a-14b02f393461-0\",\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 8,\n",
      "    \"output_tokens\": 10,\n",
      "    \"total_tokens\": 18,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from turtle import mode\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# å®Œæ•´å‚æ•°\n",
    "model = ChatOpenAI(model=OPENAI_MODEL)\n",
    "\n",
    "reslut = model.invoke(\"ä½ å¥½\")\n",
    "\n",
    "jprint(reslut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5375d",
   "metadata": {},
   "source": [
    "## ä»é¢„è®¾é…ç½®åˆ›å»º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b048f",
   "metadata": {},
   "source": [
    "### å±€éƒ¨é…ç½®åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff971137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_efad92c60b', 'id': '1fa2bed0f843aa6e6392dcd846bc4398', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019af74c-af9a-7a50-99be-2230875d6e50-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# é¢„è®¾é…ç½®\n",
    "preset_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_tokens\": 500\n",
    "}\n",
    "\n",
    "model = ChatOpenAI(**preset_config)\n",
    "\n",
    "reslut = model.invoke(\"ä½ å¥½\")\n",
    "print(reslut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6182f",
   "metadata": {},
   "source": [
    "### æ ¹æ®ä¸åŒå¼€å‘ç¯å¢ƒåˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7946a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å‘¢ï¼ŸğŸ˜Š' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'id': '55f70290196f8b0cb7eeae3268fee7e4', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019af75a-68d8-75f1-adf9-2db3745058ba-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# config.py\n",
    "MODELS = {\n",
    "    \"default\": {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 50,\n",
    "        \"timeout\": 30,\n",
    "        \"max_retries\": 3\n",
    "    },\n",
    "    \"creative\": {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.8,\n",
    "        \"max_tokens\": 50\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_model(model_name: str = \"default\"):\n",
    "    \"\"\"å·¥å‚å‡½æ•°åˆ›å»ºæ¨¡å‹\"\"\"\n",
    "    config = MODELS.get(model_name, MODELS[\"default\"])\n",
    "    return ChatOpenAI(**config)\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "result = model.invoke(\"ä½ å¥½\")\n",
    "\n",
    "print(reslut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feeaa7c",
   "metadata": {},
   "source": [
    "## å…‹éš†ç°æœ‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59111b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å‘¢ï¼ŸğŸ˜Š' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'id': '55f70290196f8b0cb7eeae3268fee7e4', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019af75a-68d8-75f1-adf9-2db3745058ba-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åˆ›å»ºåŸºç¡€æ¨¡å‹\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "# å…‹éš†ä¿®æ”¹å‚æ•°\n",
    "model_copy = model.with_config(temperature=0.1)\n",
    "\n",
    "reslut = model_copy.invoke(\"ä½ å¥½\")\n",
    "print(reslut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96252c7f",
   "metadata": {},
   "source": [
    "## init_chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573e80a",
   "metadata": {},
   "source": [
    "### æœ€ç®€å•çš„å†™æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea89516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_efad92c60b', 'id': 'fb472ce7ed06a89470f496d8eeeca01f', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019af790-e1ae-7833-8559-804d7719d984-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "reslut = model.invoke(\"ä½ å¥½\")\n",
    "print(reslut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab4cf60",
   "metadata": {},
   "source": [
    "### é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85988a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_efad92c60b', 'id': 'c3add5c0db1b3a0880b492980f1ae897', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019af7c0-7251-76b1-ad0b-442e0bcf014b-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# è‡ªåŠ¨é€‰æ‹©æä¾›å•†\n",
    "model = init_chat_model(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        temperature=0.7,\n",
    "        max_tokens=50,\n",
    "    )\n",
    "\n",
    "reslut = model.invoke(\"ä½ å¥½\")\n",
    "print(reslut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d94a5",
   "metadata": {},
   "source": [
    "### åˆ¶å®šä¾›åº”å•†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ca467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26548\\993233523.py:4: UserWarning: Parameters {'frequency_penalty'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  model = init_chat_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_efad92c60b', 'id': '2ba4a98b68eac7bf6acbef7acb0494d5', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019af74c-0c5b-79c0-b4ae-c17de71bfe65-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# æŒ‡å®šæä¾›å•†\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-4o-mini\", \n",
    "    temperature=0.7,\n",
    "    max_tokens=50,\n",
    "    model_kwargs={\"frequency_penalty\": 0.1}\n",
    ")\n",
    "\n",
    "reslut = model.invoke(\"ä½ å¥½\")\n",
    "print(reslut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3.13.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
