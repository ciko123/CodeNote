{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a74b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åŠ è½½å…¨å±€é…ç½®\n",
      "ğŸ¤– å¯ç”¨Agentæ‰“å°æ–¹æ³•: print_last_message(), print_agent(), agent_reply()\n"
     ]
    }
   ],
   "source": [
    "%run \"contant.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b3ac637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"content\": \"ä½ å¥½ï¼æˆ‘çš„åå­—æ˜¯é²å‹ƒã€‚\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"23c34942-3ddb-495f-9249-eaab435e6195\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"content\": \"ä½ å¥½ï¼æˆ‘çš„åå­—æ˜¯é²å‹ƒã€‚\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"23c34942-3ddb-495f-9249-eaab435e6195\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "ä½ å¥½ï¼Œé²å‹ƒï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€éº¼æˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"content\": \"ä½ å¥½ï¼æˆ‘çš„åå­—æ˜¯é²å‹ƒã€‚\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"23c34942-3ddb-495f-9249-eaab435e6195\"\n",
      "    },\n",
      "    {\n",
      "      \"content\": \"ä½ å¥½ï¼Œé²å‹ƒï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€éº¼æˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "          \"completion_tokens\": 22,\n",
      "          \"prompt_tokens\": 17,\n",
      "          \"total_tokens\": 39,\n",
      "          \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          },\n",
      "          \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0,\n",
      "            \"cache_creation_input_tokens\": 0,\n",
      "            \"cache_read_input_tokens\": 0\n",
      "          }\n",
      "        },\n",
      "        \"model_provider\": \"openai\",\n",
      "        \"model_name\": \"gpt-4.1-nano\",\n",
      "        \"system_fingerprint\": \"fp_03e44fcc34\",\n",
      "        \"id\": \"f45ac24119ac0b289e1c8a527c50c2a1\",\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "      },\n",
      "      \"type\": \"ai\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"lc_run--019af89c-5032-7f22-a3e8-125c5ee158d9-0\",\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 17,\n",
      "        \"output_tokens\": 22,\n",
      "        \"total_tokens\": 39,\n",
      "        \"input_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"reasoning\": 0\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"content\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"f6aa8a3d-57cb-4c60-b541-ad81daa38ddc\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"content\": \"ä½ å¥½ï¼æˆ‘çš„åå­—æ˜¯é²å‹ƒã€‚\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"23c34942-3ddb-495f-9249-eaab435e6195\"\n",
      "    },\n",
      "    {\n",
      "      \"content\": \"ä½ å¥½ï¼Œé²å‹ƒï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€éº¼æˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "          \"completion_tokens\": 22,\n",
      "          \"prompt_tokens\": 17,\n",
      "          \"total_tokens\": 39,\n",
      "          \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          },\n",
      "          \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0,\n",
      "            \"cache_creation_input_tokens\": 0,\n",
      "            \"cache_read_input_tokens\": 0\n",
      "          }\n",
      "        },\n",
      "        \"model_provider\": \"openai\",\n",
      "        \"model_name\": \"gpt-4.1-nano\",\n",
      "        \"system_fingerprint\": \"fp_03e44fcc34\",\n",
      "        \"id\": \"f45ac24119ac0b289e1c8a527c50c2a1\",\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "      },\n",
      "      \"type\": \"ai\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"lc_run--019af89c-5032-7f22-a3e8-125c5ee158d9-0\",\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 17,\n",
      "        \"output_tokens\": 22,\n",
      "        \"total_tokens\": 39,\n",
      "        \"input_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"reasoning\": 0\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"content\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"f6aa8a3d-57cb-4c60-b541-ad81daa38ddc\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "ä½ çš„åå­—æ˜¯é²å‹ƒã€‚\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"content\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"38de59e7-b389-48ac-91df-a43803f1b504\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"content\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"38de59e7-b389-48ac-91df-a43803f1b504\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "æŠ±æ­‰ï¼Œæˆ‘ä¸çŸ¥é“ä½ çš„åå­—ã€‚å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ä½ çš„åå­—ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "@before_model\n",
    "def custom_message_filter(state, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print_json(state)\n",
    "    print_json(state)\n",
    "\n",
    "# åˆ›å»ºæ£€æŸ¥ç‚¹ä¿å­˜å™¨\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# åˆ›å»ºå¸¦è®°å¿†çš„ Agent\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    middleware=[custom_message_filter],\n",
    "    checkpointer=checkpointer,  \n",
    ")\n",
    "\n",
    "# ä½¿ç”¨ thread_id åŒºåˆ†ä¸åŒå¯¹è¯\n",
    "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# ç¬¬ä¸€æ¬¡è°ƒç”¨ - Agent ä¼šè®°ä½ç”¨æˆ·å\n",
    "result1 = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"ä½ å¥½ï¼æˆ‘çš„åå­—æ˜¯é²å‹ƒã€‚\")]},\n",
    "    config1\n",
    ")\n",
    "\n",
    "print(result1[\"messages\"][-1].content) \n",
    "\n",
    "# ç¬¬äºŒæ¬¡è°ƒç”¨ - Agent è¿˜è®°å¾—ç”¨æˆ·å\n",
    "result2 = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\")]},\n",
    "    config1\n",
    ")\n",
    "print(result2[\"messages\"][-1].content) \n",
    "\n",
    "\n",
    "# ç¬¬ä¸‰æ¬¡è°ƒç”¨ - æ¢äº†config2\n",
    "result3 = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\")]},\n",
    "    config2\n",
    ")\n",
    "print(result3[\"messages\"][-1].content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08964e7",
   "metadata": {},
   "source": [
    "### ä¿®å‰ªæ¶ˆæ¯ (Trim Messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä¿®å‰ªæ¶ˆæ¯æ¼”ç¤º ===\n",
      "\n",
      "ç¬¬1è½®å¯¹è¯: ä½ å¥½ï¼Œæˆ‘æ˜¯å¼ ä¸‰\n",
      "Agentå›å¤: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è§åˆ°ä½  ğŸ˜Š æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ...\n",
      "\n",
      "ç¬¬2è½®å¯¹è¯: æˆ‘å–œæ¬¢ç¼–ç¨‹\n",
      "Agentå›å¤: å¤ªæ£’äº†ï¼ç¼–ç¨‹æ˜¯ä¸€é¡¹éå¸¸æœ‰è¶£åˆå®ç”¨çš„æŠ€èƒ½ï¼Œå¯ä»¥è®©ä½ åˆ›é€ ä¸åŒçš„äº‹ç‰©å¹¶è§£å†³å„ç§é—®é¢˜ã€‚ä½ æœ‰ç‰¹åˆ«å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€...\n",
      "\n",
      "ç¬¬3è½®å¯¹è¯: ä»Šå¤©å¤©æ°”ä¸é”™\n",
      "ğŸ”„ ä¿®å‰ªæ¶ˆæ¯ï¼šä» 5 æ¡å‡å°‘åˆ° 4 æ¡\n",
      "Agentå›å¤: æ˜¯å•Šï¼Œå¤©æ°”å¥½æ€»èƒ½è®©äººå¿ƒæƒ…æ›´æ„‰æ‚¦ï¼è¿™æ ·çš„æ—¥å­ç‰¹åˆ«é€‚åˆå‡ºå»èµ°èµ°ï¼Œæ•£æ•£å¿ƒï¼Œæˆ–è€…é™ä¸‹æ¥åšäº›è‡ªå·±å–œæ¬¢çš„äº‹æƒ…ã€‚ä½ ...\n",
      "\n",
      "ç¬¬4è½®å¯¹è¯: æˆ‘æƒ³å­¦ä¹ Python\n",
      "ğŸ”„ ä¿®å‰ªæ¶ˆæ¯ï¼šä» 6 æ¡å‡å°‘åˆ° 4 æ¡\n",
      "Agentå›å¤: å¤ªæ£’äº†ï¼Pythonæ˜¯ä¸€é—¨éå¸¸å—æ¬¢è¿ã€æ˜“äºå…¥é—¨ä¸”åŠŸèƒ½å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œæ— è®ºæ˜¯æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½è¿˜æ˜¯We...\n",
      "\n",
      "ç¬¬5è½®å¯¹è¯: è¯·æ¨èä¸€äº›å­¦ä¹ èµ„æº\n",
      "ğŸ”„ ä¿®å‰ªæ¶ˆæ¯ï¼šä» 6 æ¡å‡å°‘åˆ° 4 æ¡\n",
      "Agentå›å¤: å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸€äº›ä¸“é—¨ä¸ºäº†å­¦ä¹ Pythonçš„é«˜è´¨é‡èµ„æºï¼Œä»åœ¨çº¿æ•™ç¨‹ã€å­¦ä¹ å¹³å°åˆ°ä¹¦ç±å’Œè§†é¢‘è¯¾ç¨‹ï¼Œæˆ‘å°†...\n",
      "\n",
      "ç¬¬6è½®å¯¹è¯: è°¢è°¢ä½ çš„å»ºè®®\n",
      "ğŸ”„ ä¿®å‰ªæ¶ˆæ¯ï¼šä» 6 æ¡å‡å°‘åˆ° 4 æ¡\n",
      "Agentå›å¤: ä¸å®¢æ°”ï¼å¾ˆé«˜å…´èƒ½å¤Ÿå¸®åˆ°ä½  ğŸ˜Š  \n",
      "å¦‚æœåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œæ¯”å¦‚ä»£ç é€»è¾‘ã€æŠ€æœ¯æ¦‚å¿µæˆ–è€…é¡¹ç›®å®æˆ˜çš„...\n",
      "\n",
      "âœ… ä¿®å‰ªæ¶ˆæ¯æ¼”ç¤ºå®Œæˆ - Agentå§‹ç»ˆè®°ä½å…³é”®ä¿¡æ¯\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import before_model\n",
    "from langchain_core.messages import HumanMessage, RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "# ä¿®å‰ªæ¶ˆæ¯ä¸­é—´ä»¶ - åªä¿ç•™æœ€å3æ¡æ¶ˆæ¯\n",
    "@before_model\n",
    "def trim_messages(state, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"åªä¿ç•™æœ€å3æ¡æ¶ˆæ¯ä»¥é€‚åº”ä¸Šä¸‹æ–‡çª—å£\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # å¦‚æœæ¶ˆæ¯ä¸è¶…è¿‡3æ¡ï¼Œæ— éœ€ä¿®å‰ª\n",
    "    if len(messages) <= 3:\n",
    "        return None\n",
    "    \n",
    "    # ä¿ç•™ç¬¬ä¸€æ¡å’Œæœ€å3æ¡\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "    \n",
    "    print(f\"ğŸ”„ ä¿®å‰ªæ¶ˆæ¯ï¼šä» {len(messages)} æ¡å‡å°‘åˆ° {len(new_messages)} æ¡\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# åˆ›å»ºå¸¦ä¿®å‰ªåŠŸèƒ½çš„Agent\n",
    "checkpointer = InMemorySaver()\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"trim_demo\"}}\n",
    "\n",
    "print(\"=== ä¿®å‰ªæ¶ˆæ¯æ¼”ç¤º ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿé•¿å¯¹è¯\n",
    "messages = [\n",
    "    \"ä½ å¥½ï¼Œæˆ‘æ˜¯å¼ ä¸‰\",\n",
    "    \"æˆ‘å–œæ¬¢ç¼–ç¨‹\",\n",
    "    \"ä»Šå¤©å¤©æ°”ä¸é”™\",\n",
    "    \"æˆ‘æƒ³å­¦ä¹ Python\",\n",
    "    \"è¯·æ¨èä¸€äº›å­¦ä¹ èµ„æº\",\n",
    "    \"è°¢è°¢ä½ çš„å»ºè®®\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"\\nç¬¬{i}è½®å¯¹è¯: {msg}\")\n",
    "    result = agent.invoke({\"messages\": [HumanMessage(msg)]}, config)\n",
    "    print(f\"Agentå›å¤: {result['messages'][-1].content[:50]}...\")\n",
    "\n",
    "print(\"\\nâœ… ä¿®å‰ªæ¶ˆæ¯æ¼”ç¤ºå®Œæˆ - Agentå§‹ç»ˆè®°ä½å…³é”®ä¿¡æ¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05af9b",
   "metadata": {},
   "source": [
    "### åˆ é™¤æ¶ˆæ¯ (Delete Messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7df1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== åˆ é™¤æ¶ˆæ¯æ¼”ç¤º ===\n",
      "\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘æƒ³å’¨è¯¢ä¸€äº›é—®é¢˜\n",
      "Agent: æ‚¨å¥½ï¼è¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘å¯ä»¥å¸®æ‚¨è§£ç­”çš„ï¼Ÿ\n",
      "\n",
      "ç”¨æˆ·: æˆ‘çš„å¯†ç æ˜¯123456ï¼Œè¯·å¸®æˆ‘ä¿å­˜\n",
      "ğŸ—‘ï¸ åˆ é™¤æ•æ„Ÿæ¶ˆæ¯: æˆ‘çš„å¯†ç æ˜¯123456ï¼Œè¯·å¸®æˆ‘ä¿å­˜...\n",
      "Agent: æ‚¨å¥½ï¼ä¸ºäº†æ‚¨çš„è´¦æˆ·å®‰å…¨ï¼Œå»ºè®®æ‚¨ä¸è¦å°†å¯†ç ç›´æ¥åœ¨å…¬å…±å¹³å°æˆ–ä¸å®‰å…¨çš„åœ°æ–¹ä¿å­˜ã€‚å¦‚æœæ‚¨éœ€è¦å¸®åŠ©è®¾ç½®æˆ–ç®¡ç†å¯†ç ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å¯†ç ç®¡ç†å·¥å…·ï¼Œæˆ–è€…ä½¿ç”¨å¤æ‚ä¸”å”¯ä¸€çš„å¯†ç ä»¥ä¿æŠ¤æ‚¨çš„è´¦æˆ·å®‰å…¨ã€‚å¦‚æœæœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "\n",
      "ç”¨æˆ·: æˆ‘çš„å¯†ç æ˜¯ä»€ä¹ˆ\n",
      "ğŸ—‘ï¸ åˆ é™¤æ•æ„Ÿæ¶ˆæ¯: æ‚¨å¥½ï¼ä¸ºäº†æ‚¨çš„è´¦æˆ·å®‰å…¨ï¼Œå»ºè®®æ‚¨ä¸è¦å°†å¯†ç ç›´æ¥åœ¨å…¬å…±å¹³å°æˆ–ä¸å®‰...\n",
      "Agent: æŠ±æ­‰ï¼Œæˆ‘æ— æ³•çŸ¥é“æ‚¨çš„å¯†ç ã€‚å¦‚æœæ‚¨å¿˜è®°äº†å¯†ç ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨â€œå¿˜è®°å¯†ç â€åŠŸèƒ½è¿›è¡Œé‡ç½®ï¼Œæˆ–è€…è”ç³»ç›¸å…³å¹³å°çš„å®¢æœè·å–å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®æ‚¨æŒ‡å¯¼çš„åœ°æ–¹å—ï¼Ÿ\n",
      "\n",
      "âœ… åˆ é™¤æ¶ˆæ¯æ¼”ç¤ºå®Œæˆ - æ•æ„Ÿä¿¡æ¯è¢«è‡ªåŠ¨æ¸…ç†\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import after_model\n",
    "from langchain_core.messages import HumanMessage, RemoveMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "# åˆ é™¤æ¶ˆæ¯ä¸­é—´ä»¶ - åˆ é™¤åŒ…å«æ•æ„Ÿè¯çš„æ¶ˆæ¯\n",
    "@after_model\n",
    "def delete_sensitive_messages(state, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"åˆ é™¤åŒ…å«æ•æ„Ÿè¯çš„æ¶ˆæ¯\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # æ•æ„Ÿè¯åˆ—è¡¨\n",
    "    SENSITIVE_WORDS = [\"å¯†ç \", \"secret\", \"token\"]\n",
    "    \n",
    "    for message in messages:\n",
    "        if any(word in message.content for word in SENSITIVE_WORDS):\n",
    "            print(f\"ğŸ—‘ï¸ åˆ é™¤æ•æ„Ÿæ¶ˆæ¯: {message.content[:30]}...\")\n",
    "            return {\"messages\": [RemoveMessage(id=message.id)]}\n",
    "    \n",
    "    return None\n",
    "\n",
    "# åˆ›å»ºå¸¦åˆ é™¤åŠŸèƒ½çš„Agent\n",
    "checkpointer = InMemorySaver()\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    middleware=[delete_sensitive_messages],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"delete_demo\"}}\n",
    "\n",
    "print(\"=== åˆ é™¤æ¶ˆæ¯æ¼”ç¤º ===\")\n",
    "\n",
    "# æµ‹è¯•æ¶ˆæ¯\n",
    "test_messages = [\n",
    "    \"ä½ å¥½ï¼Œæˆ‘æƒ³å’¨è¯¢ä¸€äº›é—®é¢˜\",\n",
    "    \"æˆ‘çš„å¯†ç æ˜¯123456ï¼Œè¯·å¸®æˆ‘ä¿å­˜\",  # åŒ…å«æ•æ„Ÿè¯\n",
    "    \"æˆ‘çš„å¯†ç æ˜¯ä»€ä¹ˆ\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"\\nç”¨æˆ·: {msg}\")\n",
    "    result = agent.invoke({\"messages\": [HumanMessage(msg)]}, config)\n",
    "    print_agent(result)\n",
    "\n",
    "print(\"\\nâœ… åˆ é™¤æ¶ˆæ¯æ¼”ç¤ºå®Œæˆ - æ•æ„Ÿä¿¡æ¯è¢«è‡ªåŠ¨æ¸…ç†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39626d52",
   "metadata": {},
   "source": [
    "### æ¡ˆä¾‹3ï¼šæ€»ç»“æ¶ˆæ¯ (Summarize Messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a978dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ€»ç»“æ¶ˆæ¯æ¼”ç¤º ===\n",
      "\n",
      "ç¬¬1æ¡æ¶ˆæ¯: ä½ å¥½ï¼Œæˆ‘æ˜¯æå››ï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ\n",
      "å½“å‰æ¶ˆæ¯æ•°é‡: 2\n",
      "\n",
      "ç¬¬2æ¡æ¶ˆæ¯: æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™\n",
      "å½“å‰æ¶ˆæ¯æ•°é‡: 4\n",
      "\n",
      "ç¬¬3æ¡æ¶ˆæ¯: ç½‘ç«™éœ€è¦ç”¨æˆ·è®¤è¯åŠŸèƒ½\n",
      "å½“å‰æ¶ˆæ¯æ•°é‡: 6\n",
      "\n",
      "ç¬¬4æ¡æ¶ˆæ¯: è¿˜è¦æœ‰å•†å“å±•ç¤ºå’Œè´­ç‰©è½¦\n",
      "å½“å‰æ¶ˆæ¯æ•°é‡: 8\n",
      "\n",
      "ç¬¬5æ¡æ¶ˆæ¯: æ”¯ä»˜æ¥å£ä¹Ÿå¾ˆé‡è¦\n",
      "å½“å‰æ¶ˆæ¯æ•°é‡: 10\n",
      "\n",
      "ç¬¬6æ¡æ¶ˆæ¯: æˆ‘è€ƒè™‘ä½¿ç”¨Reactä½œä¸ºå‰ç«¯æ¡†æ¶\n",
      "å½“å‰æ¶ˆæ¯æ•°é‡: 12\n",
      "\n",
      "ğŸ§ª æµ‹è¯•è®°å¿†æ•ˆæœ:\n",
      "Agentå›å¤: å½“ç„¶å¯ä»¥ï¼Œä»¥ä¸‹æ˜¯å¯¹ä½ é¡¹ç›®éœ€æ±‚çš„æ€»ç»“ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "**é¡¹ç›®åç§°ï¼š** ç”µå•†ç½‘ç«™å¼€å‘\n",
      "\n",
      "**æŠ€æœ¯æ ˆï¼š** å‰ç«¯ä½¿ç”¨React\n",
      "\n",
      "**ä¸»è¦åŠŸèƒ½éœ€æ±‚ï¼š**\n",
      "\n",
      "1. **ç”¨æˆ·è®¤è¯**\n",
      "   - æ³¨å†Œå’Œç™»å½•åŠŸèƒ½\n",
      "   - æ”¯æŒå¯†ç é‡ç½®ã€é‚®ç®±éªŒè¯ï¼ˆå¯é€‰ï¼‰\n",
      "   - ä½¿ç”¨JWTæˆ–ç±»ä¼¼æ–¹æ¡ˆç®¡ç†ç”¨æˆ·ä¼šè¯\n",
      "\n",
      "2. **å•†å“å±•ç¤º**\n",
      "   - å•†å“åˆ—è¡¨é¡µé¢ï¼šæ”¯æŒåˆ†é¡µã€ç­›é€‰ï¼ˆç±»åˆ«ã€ä»·æ ¼ç­‰ï¼‰ã€æ’åº\n",
      "   - å•†å“è¯¦æƒ…é¡µé¢ï¼šå±•ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆå›¾ç‰‡ã€æè¿°ã€ä»·æ ¼ã€åº“å­˜ã€è¯„ä»·ï¼‰\n",
      "\n",
      "3. **è´­ç‰©è½¦**\n",
      "   - æ·»åŠ å•†å“åˆ°è´­ç‰©è½¦\n",
      "   - æ”¯æŒä¿®æ”¹å•†å“æ•°é‡å’Œåˆ é™¤å•†å“\n",
      "   - å±•ç¤ºè´­ç‰©è½¦å†…å®¹åŠæ€»ä»·\n",
      "   - æµç¨‹å¼•å¯¼ç”¨æˆ·ç»“ç®—\n",
      "\n",
      "4. **è®¢å•ç»“ç®—ä¸æ”¯ä»˜**\n",
      "   - è®¢å•ç¡®è®¤é¡µé¢\n",
      "   - æ”¯ä»˜æ¥å£é›†æˆï¼ˆæ”¯æŒå¾®ä¿¡æ”¯ä»˜ã€æ”¯ä»˜å®ç­‰ï¼‰\n",
      "   - æ”¯ä»˜æˆåŠŸåæ›´æ–°è®¢å•çŠ¶æ€ï¼Œå®Œæˆäº¤æ˜“æµç¨‹\n",
      "   - æ”¯ä»˜å¼‚æ­¥é€šçŸ¥å¤„ç†ï¼ˆåç«¯å®ç°ï¼‰\n",
      "\n",
      "5. **åå°ç®¡ç†ï¼ˆå¯æ‰©å±•ï¼‰**\n",
      "   - å•†å“ç®¡ç†\n",
      "   - è®¢å•ç®¡ç†\n",
      "   - ç”¨æˆ·ç®¡ç†ï¼ˆå¯é€‰ï¼‰\n",
      "\n",
      "**é™„åŠ è€ƒè™‘ï¼š**\n",
      "- é¡µé¢UIè®¾è®¡å»ºè®®ä½¿ç”¨UIç»„ä»¶åº“ï¼ˆå¦‚Ant Designï¼‰\n",
      "- å‰ç«¯çŠ¶æ€ç®¡ç†ç”¨Reduxæˆ–Context API\n",
      "- åç«¯APIï¼ˆè™½ç„¶æœªæ˜ç¡®æåŠå…·ä½“åç«¯æŠ€æœ¯ï¼Œä½†éœ€è¦æ”¯æŒä¸Šè¿°å‰ç«¯åŠŸèƒ½ï¼‰\n",
      "- ç¡®ä¿æ•°æ®äº¤äº’å®‰å…¨ï¼ˆä½¿ç”¨HTTPSã€Tokenç®¡ç†ç­‰ï¼‰\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœä½ éœ€è¦æˆ‘å¸®åŠ©å®Œå–„æ–¹æ¡ˆã€è®¾è®¡æ¶æ„æˆ–æä¾›å…·ä½“å®ç°ç¤ºä¾‹ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "\n",
      "âœ… æ€»ç»“æ¶ˆæ¯æ¼”ç¤ºå®Œæˆ - é•¿å¯¹è¯è¢«æ™ºèƒ½å‹ç¼©\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# åˆ›å»ºæ€»ç»“ä¸­é—´ä»¶\n",
    "summarization_middleware = SummarizationMiddleware(\n",
    "    OPENAI_MODEL,\n",
    "    trigger=(\"tokens\", 1000),  # å½“tokenè¶…è¿‡1000æ—¶è§¦å‘æ€»ç»“\n",
    "    keep=(\"messages\", 5)       # ä¿ç•™æœ€è¿‘5æ¡æ¶ˆæ¯\n",
    ")\n",
    "\n",
    "# åˆ›å»ºå¸¦æ€»ç»“åŠŸèƒ½çš„Agent\n",
    "checkpointer = InMemorySaver()\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    middleware=[summarization_middleware],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"summary_demo\"}}\n",
    "\n",
    "print(\"=== æ€»ç»“æ¶ˆæ¯æ¼”ç¤º ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿé•¿å¯¹è¯\n",
    "long_conversation = [\n",
    "    \"ä½ å¥½ï¼Œæˆ‘æ˜¯æå››ï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ\",\n",
    "    \"æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™\",\n",
    "    \"ç½‘ç«™éœ€è¦ç”¨æˆ·è®¤è¯åŠŸèƒ½\",\n",
    "    \"è¿˜è¦æœ‰å•†å“å±•ç¤ºå’Œè´­ç‰©è½¦\",\n",
    "    \"æ”¯ä»˜æ¥å£ä¹Ÿå¾ˆé‡è¦\",\n",
    "    \"æˆ‘è€ƒè™‘ä½¿ç”¨Reactä½œä¸ºå‰ç«¯æ¡†æ¶\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(long_conversation, 1):\n",
    "    print(f\"\\nç¬¬{i}æ¡æ¶ˆæ¯: {msg}\")\n",
    "    result = agent.invoke({\"messages\": [HumanMessage(msg)]}, config)\n",
    "    \n",
    "    # æ˜¾ç¤ºå½“å‰æ¶ˆæ¯æ•°é‡\n",
    "    msg_count = len(result[\"messages\"])\n",
    "    print(f\"å½“å‰æ¶ˆæ¯æ•°é‡: {msg_count}\")\n",
    "\n",
    "# æµ‹è¯•è®°å¿†æ•ˆæœ\n",
    "print(\"\\nğŸ§ª æµ‹è¯•è®°å¿†æ•ˆæœ:\")\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"è¯·æ€»ç»“ä¸€ä¸‹æˆ‘çš„é¡¹ç›®éœ€æ±‚\")]}, \n",
    "    config\n",
    ")\n",
    "print(f\"Agentå›å¤: {result['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nâœ… æ€»ç»“æ¶ˆæ¯æ¼”ç¤ºå®Œæˆ - é•¿å¯¹è¯è¢«æ™ºèƒ½å‹ç¼©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fb5bd",
   "metadata": {},
   "source": [
    "### æ¡ˆä¾‹4ï¼šè‡ªå®šä¹‰ç­–ç•¥ (Custom Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33c2fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== è‡ªå®šä¹‰ç­–ç•¥æ¼”ç¤º ===\n",
      "\n",
      "è¾“å…¥: 'ä½ å¥½'\n",
      "[\n",
      "  {\n",
      "    \"content\": \"ä½ å¥½\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {},\n",
      "    \"type\": \"human\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"e93b4dd5-04a5-4518-aed9-f3e313f09d52\"\n",
      "  }\n",
      "]\n",
      "æœ‰æ•ˆæ¶ˆæ¯æ•°é‡: 2\n",
      "\n",
      "è¾“å…¥: 'æˆ‘å«å°æ˜'\n",
      "[\n",
      "  {\n",
      "    \"content\": \"ä½ å¥½\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {},\n",
      "    \"type\": \"human\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"e93b4dd5-04a5-4518-aed9-f3e313f09d52\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ\",\n",
      "    \"additional_kwargs\": {\n",
      "      \"refusal\": null\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "      \"token_usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 8,\n",
      "        \"total_tokens\": 25,\n",
      "        \"completion_tokens_details\": {\n",
      "          \"accepted_prediction_tokens\": 0,\n",
      "          \"audio_tokens\": 0,\n",
      "          \"reasoning_tokens\": 0,\n",
      "          \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "          \"audio_tokens\": 0,\n",
      "          \"cached_tokens\": 0,\n",
      "          \"cache_creation_input_tokens\": 0,\n",
      "          \"cache_read_input_tokens\": 0\n",
      "        }\n",
      "      },\n",
      "      \"model_provider\": \"openai\",\n",
      "      \"model_name\": \"gpt-4.1-nano\",\n",
      "      \"system_fingerprint\": \"fp_03e44fcc34\",\n",
      "      \"id\": \"5f4a99aba97a62489b866b5b6e1a4e86\",\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"lc_run--019af887-60fc-76d0-b9e1-cf10024d65f2-0\",\n",
      "    \"tool_calls\": [],\n",
      "    \"invalid_tool_calls\": [],\n",
      "    \"usage_metadata\": {\n",
      "      \"input_tokens\": 8,\n",
      "      \"output_tokens\": 17,\n",
      "      \"total_tokens\": 25,\n",
      "      \"input_token_details\": {\n",
      "        \"audio\": 0,\n",
      "        \"cache_read\": 0\n",
      "      },\n",
      "      \"output_token_details\": {\n",
      "        \"audio\": 0,\n",
      "        \"reasoning\": 0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"æˆ‘å«å°æ˜\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {},\n",
      "    \"type\": \"human\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"f6551247-e674-4138-97e1-936d82be2003\"\n",
      "  }\n",
      "]\n",
      "æœ‰æ•ˆæ¶ˆæ¯æ•°é‡: 4\n",
      "\n",
      "âœ… è‡ªå®šä¹‰ç­–ç•¥æ¼”ç¤ºå®Œæˆ - æ¶ˆæ¯è¢«æ™ºèƒ½è¿‡æ»¤\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import before_model\n",
    "from langchain_core.messages import HumanMessage, RemoveMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "import re\n",
    "\n",
    "# è‡ªå®šä¹‰æ¶ˆæ¯è¿‡æ»¤ä¸­é—´ä»¶\n",
    "@before_model\n",
    "def custom_message_filter(state, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"è‡ªå®šä¹‰æ¶ˆæ¯è¿‡æ»¤ç­–ç•¥\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    jprint(messages)\n",
    "\n",
    "    # messages_to_remove = []\n",
    "    \n",
    "    # for message in messages:\n",
    "    #     # ç­–ç•¥1: åˆ é™¤è¿‡çŸ­çš„æ¶ˆæ¯ï¼ˆå°‘äº5ä¸ªå­—ç¬¦ï¼‰\n",
    "    #     if len(message.content.strip()) < 5:\n",
    "    #         messages_to_remove.append(message.id)\n",
    "    #         print(f\"ğŸš« åˆ é™¤è¿‡çŸ­æ¶ˆæ¯: '{message.content}'\")\n",
    "    #         continue\n",
    "        \n",
    "    #     # ç­–ç•¥2: åˆ é™¤é‡å¤çš„é—®å€™è¯­\n",
    "    #     if message.content.lower() in [\"ä½ å¥½\", \"hello\", \"hi\"]:\n",
    "    #         # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç±»ä¼¼é—®å€™\n",
    "    #         for other_msg in messages:\n",
    "    #             if (other_msg.id != message.id and \n",
    "    #                 other_msg.content.lower() in [\"ä½ å¥½\", \"hello\", \"hi\"]):\n",
    "    #                 messages_to_remove.append(message.id)\n",
    "    #                 print(f\"ğŸš« åˆ é™¤é‡å¤é—®å€™: '{message.content}'\")\n",
    "    #                 break\n",
    "        \n",
    "    #     # ç­–ç•¥3: åˆ é™¤çº¯æ•°å­—æ¶ˆæ¯ï¼ˆå¯èƒ½æ˜¯è¯¯è¾“å…¥ï¼‰\n",
    "    #     if message.content.isdigit():\n",
    "    #         messages_to_remove.append(message.id)\n",
    "    #         print(f\"ğŸš« åˆ é™¤çº¯æ•°å­—æ¶ˆæ¯: '{message.content}'\")\n",
    "    \n",
    "    # if messages_to_remove:\n",
    "    #     return {\"messages\": [RemoveMessage(id=msg_id) for msg_id in messages_to_remove]}\n",
    "    \n",
    "    # return None\n",
    "\n",
    "# åˆ›å»ºå¸¦è‡ªå®šä¹‰ç­–ç•¥çš„Agent\n",
    "checkpointer = InMemorySaver()\n",
    "agent = create_agent(\n",
    "    OPENAI_MODEL,\n",
    "    middleware=[custom_message_filter],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"custom_demo\"}}\n",
    "\n",
    "print(\"=== è‡ªå®šä¹‰ç­–ç•¥æ¼”ç¤º ===\")\n",
    "\n",
    "# æµ‹è¯•å„ç§æ¶ˆæ¯ç±»å‹\n",
    "test_messages = [\n",
    "    \"ä½ å¥½\",           # é‡å¤é—®å€™\n",
    "    \"æˆ‘å«å°æ˜\",          # é‡å¤é—®å€™\n",
    "    # \"123\",            # çº¯æ•°å­—\n",
    "    # \"hi\",             # é‡å¤é—®å€™\n",
    "    # \"å¥½çš„\",           # æ­£å¸¸æ¶ˆæ¯\n",
    "    # \"å—¯\",             # è¿‡çŸ­æ¶ˆæ¯\n",
    "    # \"æˆ‘æƒ³å­¦ä¹ ç¼–ç¨‹\",    # æ­£å¸¸æ¶ˆæ¯\n",
    "    # \"456\",            # çº¯æ•°å­—\n",
    "    # \"è¯·æ¨èä¸€äº›èµ„æº\"   # æ­£å¸¸æ¶ˆæ¯\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"\\nè¾“å…¥: '{msg}'\")\n",
    "    result = agent.invoke({\"messages\": [HumanMessage(msg)]}, config)\n",
    "    \n",
    "    # æ˜¾ç¤ºå½“å‰æ¶ˆæ¯æ•°é‡\n",
    "    current_count = len([m for m in result[\"messages\"] if m.type != \"system\"])\n",
    "    print(f\"æœ‰æ•ˆæ¶ˆæ¯æ•°é‡: {current_count}\")\n",
    "\n",
    "print(\"\\nâœ… è‡ªå®šä¹‰ç­–ç•¥æ¼”ç¤ºå®Œæˆ - æ¶ˆæ¯è¢«æ™ºèƒ½è¿‡æ»¤\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3.13.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
