{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.LangGraph实现CRAG.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/18 9:04\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 1.LangGraph实现CRAG.py\n",
    "\"\"\"\n",
    "from typing import TypedDict, Any\n",
    "\n",
    "import dotenv\n",
    "import weaviate\n",
    "from langchain_community.tools import GoogleSerperRun\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langgraph.graph import StateGraph\n",
    "from weaviate.auth import AuthApiKey\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "class GradeDocument(BaseModel):\n",
    "    \"\"\"文档评分Pydantic模型\"\"\"\n",
    "    binary_score: str = Field(description=\"文档与问题是否关联，请回答yes或者no\")\n",
    "\n",
    "\n",
    "class GoogleSerperArgsSchema(BaseModel):\n",
    "    query: str = Field(description=\"执行谷歌搜索的查询语句\")\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"图结构应用程序数据状态\"\"\"\n",
    "    question: str  # 原始问题\n",
    "    generation: str  # 大语言模型生成内容\n",
    "    web_search: str  # 网络搜索内容\n",
    "    documents: list[str]  # 文档列表\n",
    "\n",
    "\n",
    "def format_docs(docs: list[Document]) -> str:\n",
    "    \"\"\"格式化传入的文档列表为字符串\"\"\"\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "\n",
    "# 1.创建大语言模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 2.创建检索器\n",
    "vector_store = WeaviateVectorStore(\n",
    "    client=weaviate.connect_to_wcs(\n",
    "        cluster_url=\"https://uiufdvagtjkaf9i4ey0a.c0.us-west3.gcp.weaviate.cloud\",\n",
    "        auth_credentials=AuthApiKey(\"zGnUn1q5oI3hQUtmqP4NiRty83LNLqDaGoqw\"),\n",
    "    ),\n",
    "    index_name=\"LLMOps\",\n",
    "    text_key=\"text\",\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\")\n",
    "\n",
    "# 3.构建检索评估器\n",
    "system = \"\"\"你是一名评估检索到的文档与用户问题相关性的评估员。\n",
    "如果文档包含与问题相关的关键字或语义，请将其评级为相关。\n",
    "给出一个是否相关得分为yes或者no，以表明文档是否与问题相关。\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"检索文档: \\n\\n{document}\\n\\n用户问题: {question}\"),\n",
    "])\n",
    "retrieval_grader = grade_prompt | llm.with_structured_output(GradeDocument)\n",
    "\n",
    "# 4.RAG检索增强生成\n",
    "template = \"\"\"你是一个问答任务的助理。使用以下检索到的上下文来回答问题。如果不知道就说不知道，不要胡编乱造，并保持答案简洁。\n",
    "\n",
    "问题: {question}\n",
    "上下文: {context}\n",
    "答案: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "rag_chain = prompt | llm.bind(temperature=0) | StrOutputParser()\n",
    "\n",
    "# 5.网络搜索问题重写\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"你是一个将输入问题转换为优化的更好版本的问题重写器并用于网络搜索。请查看输入并尝试推理潜在的语义意图/含义。\"\n",
    "    ),\n",
    "    (\"human\", \"这里是初始化问题:\\n\\n{question}\\n\\n请尝试提出一个改进问题。\")\n",
    "])\n",
    "question_rewriter = rewrite_prompt | llm.bind(temperature=0) | StrOutputParser()\n",
    "\n",
    "# 6.网络搜索工具\n",
    "google_serper = GoogleSerperRun(\n",
    "    name=\"google_serper\",\n",
    "    description=\"一个低成本的谷歌搜索API。当你需要回答有关时事的问题时，可以调用该工具。该工具的输入是搜索查询语句。\",\n",
    "    args_schema=GoogleSerperArgsSchema,\n",
    "    api_wrapper=GoogleSerperAPIWrapper(),\n",
    ")\n",
    "\n",
    "\n",
    "# 7.构建图相关节点函数\n",
    "def retrieve(state: GraphState) -> Any:\n",
    "    \"\"\"检索节点，根据原始问题检索向量数据库\"\"\"\n",
    "    print(\"---检索节点---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state: GraphState) -> Any:\n",
    "    \"\"\"生成节点，根据原始问题+上下文内容调用LLM生成内容\"\"\"\n",
    "    print(\"---LLM生成节点---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": format_docs(documents), \"question\": question})\n",
    "    return {\"question\": question, \"documents\": documents, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state: GraphState) -> Any:\n",
    "    \"\"\"文档与原始问题关联性评分节点\"\"\"\n",
    "    print(\"---检查文档与问题关联性节点---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "    web_search = \"no\"\n",
    "    for doc in documents:\n",
    "        score: GradeDocument = retrieval_grader.invoke({\n",
    "            \"question\": question, \"document\": doc.page_content,\n",
    "        })\n",
    "        grade = score.binary_score\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---文档存在关联---\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"---文档不存在关联---\")\n",
    "            web_search = \"yes\"\n",
    "            continue\n",
    "    return {**state, \"documents\": filtered_docs, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def transform_query(state: GraphState) -> Any:\n",
    "    \"\"\"重写/转换查询节点\"\"\"\n",
    "    print(\"---重写查询节点---\")\n",
    "    question = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {**state, \"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state: GraphState) -> Any:\n",
    "    \"\"\"网络检索节点\"\"\"\n",
    "    print(\"---网络检索节点---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    search_content = google_serper.invoke({\"query\": question})\n",
    "    documents.append(Document(\n",
    "        page_content=search_content,\n",
    "    ))\n",
    "\n",
    "    return {**state, \"documents\": documents}\n",
    "\n",
    "\n",
    "def decide_to_generate(state: GraphState) -> Any:\n",
    "    \"\"\"决定执行生成还是搜索节点\"\"\"\n",
    "    print(\"---路由选择节点---\")\n",
    "    web_search = state[\"web_search\"]\n",
    "    if web_search.lower() == \"yes\":\n",
    "        print(\"---执行Web搜索节点---\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        print(\"---执行LLM生成节点---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "# 8.构件图/工作流\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 9.定义工作流节点\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search_node\", web_search)\n",
    "\n",
    "# 10.定义工作流边\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\"grade_documents\", decide_to_generate)\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.set_finish_point(\"generate\")\n",
    "\n",
    "# 11.编译工作流\n",
    "app = workflow.compile()\n",
    "\n",
    "print(app.invoke({\"question\": \"能介绍下什么是LLMOps么?\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
