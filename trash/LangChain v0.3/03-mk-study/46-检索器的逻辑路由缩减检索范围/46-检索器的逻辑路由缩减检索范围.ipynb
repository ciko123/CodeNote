{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.函数回调规范化输出.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/5 13:08\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 1.函数回调规范化输出.py\n",
    "\"\"\"\n",
    "from typing import Literal\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"将用户查询映射到对应的数据源上\"\"\"\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(\n",
    "        description=\"根据用户的问题，选择哪个数据源最相关以回答用户的问题\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 1.创建绑定结构化输出的大语言模型\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 2.构建一个问题\n",
    "question = \"\"\"为什么下面的代码不工作了，请帮我检查下：\n",
    "\n",
    "var a = \"123\"\n",
    "\"\"\"\n",
    "res: RouteQuery = structured_llm.invoke(question)\n",
    "\n",
    "print(res)\n",
    "print(type(res))\n",
    "print(res.datasource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.基于逻辑和语义的路由分发.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/5 11:45\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 8.基于逻辑和语义的路由分发.py\n",
    "\"\"\"\n",
    "from typing import Literal\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"将用户查询映射到最相关的数据源\"\"\"\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(\n",
    "        description=\"根据给定用户问题，选择哪个数据源最相关以回答他们的问题\"\n",
    "    )\n",
    "\n",
    "\n",
    "def choose_route(result: RouteQuery) -> str:\n",
    "    \"\"\"根据传递的路由结果选择不同的检索器\"\"\"\n",
    "    if \"python_docs\" in result.datasource:\n",
    "        return \"chain in python_docs\"\n",
    "    elif \"js_docs\" in result.datasource:\n",
    "        return \"chain in js_docs\"\n",
    "    else:\n",
    "        return \"golang_docs\"\n",
    "\n",
    "\n",
    "# 1.构建大语言模型并进行结构化输出\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 2.创建路由逻辑链\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个擅长将用户问题路由到适当的数据源的专家。\\n请根据问题涉及的编程语言，将其路由到相关数据源\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "router = {\"question\": RunnablePassthrough()} | prompt | structured_llm | choose_route\n",
    "\n",
    "# 3.执行相应的提问，检查映射的路由\n",
    "question = \"\"\"为什么下面的代码不工作了，请帮我检查下：\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "prompt.invoke(\"中文\")\"\"\"\n",
    "\n",
    "# 4.选择不同的数据库\n",
    "print(router.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
