{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def print_json(data, indent=4, sort_keys=True):\n",
    "    \"\"\"\n",
    "    美化输出 JSON 数据\n",
    "    :param data: 待序列化的 Python 对象（字典/列表）\n",
    "    :param output_file: 输出文件路径（None 则打印到控制台）\n",
    "    :param indent: 缩进空格数\n",
    "    :param sort_keys: 是否按键排序\n",
    "    \"\"\"\n",
    "    # 自定义序列化处理\n",
    "    def serialize(obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()  # ISO 格式时间\n",
    "        elif isinstance(obj, (int, float, bool, str, list, dict, type(None))):\n",
    "            return obj\n",
    "        else:\n",
    "            return str(obj)  # 其他类型转为字符串\n",
    "\n",
    "    # 生成美化的 JSON 字符串\n",
    "    json_str = json.dumps(\n",
    "        data,\n",
    "        indent=indent,\n",
    "        sort_keys=sort_keys,\n",
    "        ensure_ascii=False,\n",
    "        default=serialize\n",
    "    )\n",
    "\n",
    "    print(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_MODEL = os.getenv('OPENAI_MODEL')\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model=\"OPENAI_MODEL\", \n",
    "        temperature=0.1,\n",
    "        max_tokens=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.对话消息历史组件基础.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/5/22 9:22\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 1.对话消息历史组件基础.py\n",
    "\"\"\"\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "chat_history = InMemoryChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"你好，我是慕小课，你是谁？\")\n",
    "chat_history.add_ai_message(\"你好，我是ChatGPT，有什么可以帮到您的？\")\n",
    "\n",
    "print_json(chat_history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.文件对话消息历史组件实现记忆.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import FileChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. 创建文件聊天历史\n",
    "history = FileChatMessageHistory(\"chat-history.json\")\n",
    "\n",
    "# 2. 查看历史消息\n",
    "print(\"历史消息：\", history.messages)\n",
    "\n",
    "# 3. 添加消息\n",
    "history.add_user_message(\"你好，我是张三\")\n",
    "history.add_ai_message(\"你好张三！有什么可以帮助你的？\")\n",
    "\n",
    "# 4. 与LLM结合使用\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个友好的助手。\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 获取历史 + 新输入\n",
    "messages = history.messages + [HumanMessage(content=\"今天天气怎么样？\")]\n",
    "response = llm.invoke(messages)\n",
    "history.add_ai_message(response.content)\n",
    "\n",
    "print(\"最新回复：\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
