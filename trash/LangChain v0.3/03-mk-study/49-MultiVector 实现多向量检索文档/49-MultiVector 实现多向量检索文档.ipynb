{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.多向量索引-摘要检索原文档.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/6 19:35\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 1.多向量索引-摘要检索原文档.py\n",
    "\"\"\"\n",
    "import uuid\n",
    "\n",
    "import dotenv\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.创建加载器、文本分割器并处理文档\n",
    "loader = UnstructuredFileLoader(\"./电商产品数据.txt\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 2.定义摘要生成链\n",
    "summary_chain = (\n",
    "        {\"doc\": lambda x: x.page_content}\n",
    "        | ChatPromptTemplate.from_template(\"请总结以下文档的内容：\\n\\n{doc}\")\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 3.批量生成摘要与唯一标识\n",
    "summaries = summary_chain.batch(docs, {\"max_concurrency\": 5})\n",
    "doc_ids = [str(uuid.uuid4()) for _ in summaries]\n",
    "\n",
    "# 4.构建摘要文档\n",
    "summary_docs = [\n",
    "    Document(page_content=summary, metadata={\"doc_id\": doc_ids[idx]})\n",
    "    for idx, summary in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# 5.构建文档数据库与向量数据库\n",
    "byte_store = LocalFileStore(\"./multy-vector\")\n",
    "db = FAISS.from_documents(\n",
    "    summary_docs,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# 6.构建多向量检索器\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=db,\n",
    "    byte_store=byte_store,\n",
    "    id_key=\"doc_id\",\n",
    ")\n",
    "\n",
    "# 7.将摘要文档和原文档存储到数据库中\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))\n",
    "\n",
    "# 8.执行检索\n",
    "search_docs = retriever.invoke(\"推荐一些潮州特产?\")\n",
    "print(search_docs)\n",
    "print(len(search_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.多向量索引-假设性查询检索原文档.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/6 11:09\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 2.多向量索引-假设性查询检索原文档.py\n",
    "\"\"\"\n",
    "from typing import List\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "class HypotheticalQuestions(BaseModel):\n",
    "    \"\"\"生成假设性问题\"\"\"\n",
    "    questions: List[str] = Field(\n",
    "        description=\"假设性问题列表，类型为字符串列表\",\n",
    "    )\n",
    "\n",
    "\n",
    "# 1.构建一个生成假设性问题的prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"生成一个包含3个假设性问题的列表，这些问题可以用于回答下面的文档:\\n\\n{doc\")\n",
    "\n",
    "# 2.创建大语言模型，并绑定对应的规范化输出结构\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(HypotheticalQuestions)\n",
    "\n",
    "# 3.创建链应用\n",
    "chain = (\n",
    "        {\"doc\": lambda x: x.page_content}\n",
    "        | prompt\n",
    "        | structured_llm\n",
    ")\n",
    "\n",
    "hypothetical_questions: HypotheticalQuestions = chain.invoke(\n",
    "    Document(page_content=\"我叫慕小课，我喜欢打篮球，游泳\")\n",
    ")\n",
    "print(hypothetical_questions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
