{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301e37fe",
   "metadata": {},
   "source": [
    "### 1.æ‰‹å†™Chainå®ç°ç®€æ˜“ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96367bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\llmops\\lib\\site-packages\\langsmith\\client.py:297: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­¥éª¤: input_variables=['query'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]\n",
      "è¾“å‡º: messages=[HumanMessage(content='ä½ å¥½ï¼Œä½ æ˜¯?', additional_kwargs={}, response_metadata={})]\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=019af477-e01b-72e3-806d-0fd48359e693,id=019af477-e01b-72e3-806d-0fd48359e693; trace=019af477-e073-7a00-bc5b-a8d2ee43e932,id=019af477-e073-7a00-bc5b-a8d2ee43e932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­¥éª¤: profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x0000026DF32B4910> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000026DF3C69060> root_client=<openai.OpenAI object at 0x0000026DF32B5570> root_async_client=<openai.AsyncOpenAI object at 0x0000026DF3C691B0> model_name='gpt-4o' temperature=0.1 model_kwargs={} openai_api_key=SecretStr('**********') max_tokens=100\n",
      "è¾“å‡º: content='ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯æˆ–ååŠ©è§£å†³é—®é¢˜ã€‚å¦‚æœæœ‰ä»»ä½•éœ€è¦ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 11, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_b54fe76834', 'id': '1accb6e37250f884dc7bec705091f4db', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019af477-e073-7a00-bc5b-a8d2ee43e932-0' usage_metadata={'input_tokens': 11, 'output_tokens': 30, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "===============\n",
      "æ­¥éª¤: \n",
      "è¾“å‡º: ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯æˆ–ååŠ©è§£å†³é—®é¢˜ã€‚å¦‚æœæœ‰ä»»ä½•éœ€è¦ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "===============\n",
      "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯æˆ–ååŠ©è§£å†³é—®é¢˜ã€‚å¦‚æœæœ‰ä»»ä½•éœ€è¦ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=019af477-e073-7a00-bc5b-a8d2ee43e932,id=019af477-e073-7a00-bc5b-a8d2ee43e932; trace=019af477-fc45-7032-9afd-e9a4ea719a35,id=019af477-fc45-7032-9afd-e9a4ea719a35; trace=019af477-fc45-7032-9afd-e9a4ea719a35,id=019af477-fc45-7032-9afd-e9a4ea719a35\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.æ„å»ºç»„ä»¶\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "parser = StrOutputParser()\n",
    "llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",  # ä½¿ç”¨ GPT-4o æ¨¡å‹è¿›è¡Œæµ‹è¯•\n",
    "        temperature=0.1,\n",
    "        max_tokens=100\n",
    "    )\n",
    "\n",
    "\n",
    "# 2.å®šä¹‰ä¸€ä¸ªé“¾\n",
    "class Chain:\n",
    "    steps: list = []\n",
    "\n",
    "    def __init__(self, steps: list):\n",
    "        self.steps = steps\n",
    "\n",
    "    def invoke(self, input: Any) -> Any:\n",
    "        for step in self.steps:\n",
    "            input = step.invoke(input)\n",
    "            print(\"æ­¥éª¤:\", step)\n",
    "            print(\"è¾“å‡º:\", input)\n",
    "            print(\"===============\")\n",
    "        return input\n",
    "\n",
    "\n",
    "# 3.ç¼–æ’é“¾\n",
    "chain = Chain([prompt, llm, parser])\n",
    "\n",
    "# 4.æ‰§è¡Œé“¾å¹¶è·å–ç»“æœ\n",
    "print(chain.invoke({\"query\": \"ä½ å¥½ï¼Œä½ æ˜¯?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9a85f",
   "metadata": {},
   "source": [
    "### 2.LCELè¡¨è¾¾å¼ç®€åŒ–ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae818cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-033d-72f0-a368-15986fffcc3c; trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-0341-7821-b196-c082f747abe8; trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-0341-7821-b196-c082f747abe8; trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-0342-7ca3-b4a2-dc178993c957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“ç„¶ï¼æ¥ä¸€ä¸ªç¨‹åºå‘˜çš„å†·ç¬‘è¯ï¼š\n",
      "\n",
      "ç¨‹åºå‘˜çš„å¥³æœ‹å‹é—®ä»–ï¼šâ€œä½ çˆ±æˆ‘å—ï¼Ÿâ€  \n",
      "ç¨‹åºå‘˜å›ç­”ï¼šâ€œçˆ±ã€‚â€  \n",
      "å¥³æœ‹å‹åˆé—®ï¼šâ€œæœ‰å¤šçˆ±ï¼Ÿâ€  \n",
      "ç¨‹åºå‘˜è¯´ï¼šâ€œif (ä½  == ä¸–ç•Œ) { return true; } else { return false; }â€  \n",
      "\n",
      "å†·ä¸å†·ï¼ŸğŸ˜„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-0342-7ca3-b4a2-dc178993c957; trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-1fcc-7813-9e6c-0876cd6d0465; trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-1fcc-7813-9e6c-0876cd6d0465; trace=019af47a-033d-72f0-a368-15986fffcc3c,id=019af47a-033d-72f0-a368-15986fffcc3c\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.æ„å»ºç»„ä»¶\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "parser = StrOutputParser()\n",
    "llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",  # ä½¿ç”¨ GPT-4o æ¨¡å‹è¿›è¡Œæµ‹è¯•\n",
    "        temperature=0.1,\n",
    "        max_tokens=100\n",
    "    )\n",
    "\n",
    "# 2.åˆ›å»ºé“¾\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 3.è°ƒç”¨é“¾å¾—åˆ°ç»“æœ\n",
    "print(chain.invoke({\"query\": \"è¯·è®²ä¸€ä¸ªç¨‹åºå‘˜çš„å†·ç¬‘è¯\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
