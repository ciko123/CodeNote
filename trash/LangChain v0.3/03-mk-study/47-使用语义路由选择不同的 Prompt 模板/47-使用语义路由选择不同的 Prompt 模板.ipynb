{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.语义路由选择不同的Prompt模板.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/5 14:41\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 9.语义路由选择不同的Prompt模板.py\n",
    "\"\"\"\n",
    "import dotenv\n",
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.定义两份不同的prompt模板(物理模板、数学模板)\n",
    "physics_template = \"\"\"你是一位非常聪明的物理教程。\n",
    "你擅长以简洁易懂的方式回答物理问题。\n",
    "当你不知道问题的答案时，你会坦率承认自己不知道。\n",
    "\n",
    "这是一个问题：\n",
    "{query}\"\"\"\n",
    "math_template = \"\"\"你是一位非常优秀的数学家。你擅长回答数学问题。\n",
    "你之所以如此优秀，是因为你能将复杂的问题分解成多个小步骤。\n",
    "并且回答这些小步骤，然后将它们整合在一起回来更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{query}\"\"\"\n",
    "\n",
    "# 2.创建文本嵌入模型，并执行嵌入\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "\n",
    "def prompt_router(input) -> ChatPromptTemplate:\n",
    "    \"\"\"根据传递的query计算返回不同的提示模板\"\"\"\n",
    "    # 1.计算传入query的嵌入向量\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "\n",
    "    # 2.计算相似性\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    print(\"使用数学模板\" if most_similar == math_template else \"使用物理模板\")\n",
    "\n",
    "    # 3.构建提示模板\n",
    "    return ChatPromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "        {\"query\": RunnablePassthrough()}\n",
    "        | RunnableLambda(prompt_router)\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"黑洞是什么?\"))\n",
    "print(\"======================\")\n",
    "print(chain.invoke(\"能介绍下余弦计算公式么？\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
