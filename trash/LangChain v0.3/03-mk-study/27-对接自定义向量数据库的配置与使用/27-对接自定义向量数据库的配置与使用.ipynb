{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.对接自定义向量数据库示例.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/6/30 8:12\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 1.对接自定义向量数据库示例.py\n",
    "\"\"\"\n",
    "import uuid\n",
    "from typing import List, Optional, Any, Iterable, Type\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "class MemoryVectorStore(VectorStore):\n",
    "    \"\"\"基于内存+欧几里得距离的向量数据库\"\"\"\n",
    "    store: dict = {}  # 存储向量的临时变量\n",
    "\n",
    "    def __init__(self, embedding: Embeddings):\n",
    "        self._embedding = embedding\n",
    "\n",
    "    def add_texts(self, texts: Iterable[str], metadatas: Optional[List[dict]] = None, **kwargs: Any) -> List[str]:\n",
    "        \"\"\"将数据添加到向量数据库中\"\"\"\n",
    "        # 1.检测metadata的数据格式\n",
    "        if metadatas is not None and len(metadatas) != len(texts):\n",
    "            raise ValueError(\"metadatas格式错误\")\n",
    "\n",
    "        # 2.将数据转换成文本嵌入/向量和ids\n",
    "        embeddings = self._embedding.embed_documents(texts)\n",
    "        ids = [str(uuid.uuid4()) for _ in texts]\n",
    "\n",
    "        # 3.通过for循环组装数据记录\n",
    "        for idx, text in enumerate(texts):\n",
    "            self.store[ids[idx]] = {\n",
    "                \"id\": ids[idx],\n",
    "                \"text\": text,\n",
    "                \"vector\": embeddings[idx],\n",
    "                \"metadata\": metadatas[idx] if metadatas is not None else {},\n",
    "            }\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def similarity_search(self, query: str, k: int = 4, **kwargs: Any) -> List[Document]:\n",
    "        \"\"\"传入对应的query执行相似性搜索\"\"\"\n",
    "        # 1.将query转换成向量\n",
    "        embedding = self._embedding.embed_query(query)\n",
    "\n",
    "        # 2.循环和store中的每一个向量进行比较，计算欧几里得距离\n",
    "        result = []\n",
    "        for key, record in self.store.items():\n",
    "            distance = self._euclidean_distance(embedding, record[\"vector\"])\n",
    "            result.append({\"distance\": distance, **record})\n",
    "\n",
    "        # 3.排序，欧几里得距离越小越靠前\n",
    "        sorted_result = sorted(result, key=lambda x: x[\"distance\"])\n",
    "\n",
    "        # 4.取数据，取k条数据\n",
    "        result_k = sorted_result[:k]\n",
    "\n",
    "        return [\n",
    "            Document(page_content=item[\"text\"], metadata={**item[\"metadata\"], \"score\": item[\"distance\"]})\n",
    "            for item in result_k\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(cls: Type[\"MemoryVectorStore\"], texts: List[str], embedding: Embeddings,\n",
    "                   metadatas: Optional[List[dict]] = None,\n",
    "                   **kwargs: Any) -> \"MemoryVectorStore\":\n",
    "        \"\"\"从文本和元数据中去构建向量数据库\"\"\"\n",
    "        memory_vector_store = cls(embedding=embedding)\n",
    "        memory_vector_store.add_texts(texts, metadatas, **kwargs)\n",
    "        return memory_vector_store\n",
    "\n",
    "    @classmethod\n",
    "    def _euclidean_distance(cls, vec1: list, vec2: list) -> float:\n",
    "        \"\"\"计算两个向量的欧几里得距离\"\"\"\n",
    "        return np.linalg.norm(np.array(vec1) - np.array(vec2))\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.创建初始数据与嵌入模型\n",
    "texts = [\n",
    "    \"笨笨是一只很喜欢睡觉的猫咪\",\n",
    "    \"我喜欢在夜晚听音乐，这让我感到放松。\",\n",
    "    \"猫咪在窗台上打盹，看起来非常可爱。\",\n",
    "    \"学习新技能是每个人都应该追求的目标。\",\n",
    "    \"我最喜欢的食物是意大利面，尤其是番茄酱的那种。\",\n",
    "    \"昨晚我做了一个奇怪的梦，梦见自己在太空飞行。\",\n",
    "    \"我的手机突然关机了，让我有些焦虑。\",\n",
    "    \"阅读是我每天都会做的事情，我觉得很充实。\",\n",
    "    \"他们一起计划了一次周末的野餐，希望天气能好。\",\n",
    "    \"我的狗喜欢追逐球，看起来非常开心。\",\n",
    "]\n",
    "metadatas = [\n",
    "    {\"page\": 1},\n",
    "    {\"page\": 2},\n",
    "    {\"page\": 3},\n",
    "    {\"page\": 4},\n",
    "    {\"page\": 5},\n",
    "    {\"page\": 6, \"account_id\": 1},\n",
    "    {\"page\": 7},\n",
    "    {\"page\": 8},\n",
    "    {\"page\": 9},\n",
    "    {\"page\": 10},\n",
    "]\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 2.构建自定义向量数据库\n",
    "db = MemoryVectorStore(embedding=embedding)\n",
    "\n",
    "ids = db.add_texts(texts, metadatas)\n",
    "print(ids)\n",
    "\n",
    "# 3.执行检索\n",
    "print(db.similarity_search(\"笨笨是谁？\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
