{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.问题分解策略.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/4 9:30\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 3.问题分解策略.py\n",
    "\"\"\"\n",
    "from operator import itemgetter\n",
    "\n",
    "import dotenv\n",
    "import weaviate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from weaviate.auth import AuthApiKey\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "def format_qa_pair(question: str, answer: str) -> str:\n",
    "    \"\"\"格式化传递的问题+答案为单个字符串\"\"\"\n",
    "    return f\"Question: {question}\\nAnswer: {answer}\\n\\n\".strip()\n",
    "\n",
    "\n",
    "# 1.定义分解子问题的prompt\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(\n",
    "    \"你是一个乐于助人的AI助理，可以针对一个输入问题生成多个相关的子问题。\\n\"\n",
    "    \"目标是将输入问题分解成一组可以独立回答的子问题或者子任务。\\n\"\n",
    "    \"生成与一下问题相关的多个搜索查询：{question}\\n\"\n",
    "    \"并使用换行符进行分割，输出（3个子问题/子查询）：\"\n",
    ")\n",
    "\n",
    "# 2.构建分解问题链\n",
    "decomposition_chain = (\n",
    "        {\"question\": RunnablePassthrough()}\n",
    "        | decomposition_prompt\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "        | StrOutputParser()\n",
    "        | (lambda x: x.strip().split(\"\\n\"))\n",
    ")\n",
    "\n",
    "# 3.构建向量数据库与检索器\n",
    "db = WeaviateVectorStore(\n",
    "    client=weaviate.connect_to_wcs(\n",
    "        cluster_url=\"https://mbakeruerziae6psyex7ng.c0.us-west3.gcp.weaviate.cloud\",\n",
    "        auth_credentials=AuthApiKey(\"ZltPVa9ZSOxUcfafelsggGyyH6tnTYQYJvBx\"),\n",
    "    ),\n",
    "    index_name=\"DatasetDemo\",\n",
    "    text_key=\"text\",\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "retriever = db.as_retriever(search_type=\"mmr\")\n",
    "\n",
    "# 4.执行提问获取子问题\n",
    "question = \"关于LLMOps应用配置的文档有哪些\"\n",
    "sub_questions = decomposition_chain.invoke(question)\n",
    "\n",
    "# 5.构建迭代问答链：提示模板+链\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"这是你需要回答的问题：\n",
    "---\n",
    "{question}\n",
    "---\n",
    "\n",
    "这是所有可用的背景问题和答案对：\n",
    "---\n",
    "{qa_pairs}\n",
    "---\n",
    "\n",
    "这是与问题相关的额外背景信息：\n",
    "---\n",
    "{context}\n",
    "---\"\"\")\n",
    "chain = (\n",
    "        {\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"qa_pairs\": itemgetter(\"qa_pairs\"),\n",
    "            \"context\": itemgetter(\"question\") | retriever,\n",
    "        }\n",
    "        | prompt\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 5.循环遍历所有子问题进行检索并获取答案\n",
    "qa_pairs = \"\"\n",
    "for sub_question in sub_questions:\n",
    "    answer = chain.invoke({\"question\": sub_question, \"qa_pairs\": qa_pairs})\n",
    "    qa_pair = format_qa_pair(sub_question, answer)\n",
    "    qa_pairs += \"\\n---\\n\" + qa_pair\n",
    "    print(f\"问题: {sub_question}\")\n",
    "    print(f\"答案: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
