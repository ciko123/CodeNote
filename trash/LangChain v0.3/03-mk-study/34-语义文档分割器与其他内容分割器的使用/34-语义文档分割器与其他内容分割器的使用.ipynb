{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.语义分割器使用示例.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/2 14:33\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 1.语义分割器使用示例.py\n",
    "\"\"\"\n",
    "import dotenv\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.构建加载器和文本分割器\n",
    "loader = UnstructuredFileLoader(\"./科幻短篇.txt\")\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    number_of_chunks=10,\n",
    "    add_start_index=True,\n",
    "    sentence_split_regex=r\"(?<=[。？！.?!])\"\n",
    ")\n",
    "\n",
    "# 2.加载文本与分割\n",
    "documents = loader.load()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3.循环打印\n",
    "for chunk in chunks:\n",
    "    print(f\"块大小: {len(chunk.page_content)}, 元数据: {chunk.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.其他文档分割器使用示例.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/2 14:55\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 2.其他文档分割器使用示例.py\n",
    "\"\"\"\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "# 1.构建文本与分割标题\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>标题1</h1>\n",
    "        <p>关于标题1的一些介绍文本。</p>\n",
    "        <div>\n",
    "            <h2>子标题1</h2>\n",
    "            <p>关于子标题1的一些介绍文本。</p>\n",
    "            <h3>子子标题1</h3>\n",
    "            <p>关于子子标题1的一些文本。</p>\n",
    "            <h3>子子标题2</h3>\n",
    "            <p>关于子子标题2的一些文本。</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h3>子标题2</h2>\n",
    "            <p>关于子标题2的一些文本。</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>关于标题1的一些结束文本。</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"一级标题\"),\n",
    "    (\"h2\", \"二级标题\"),\n",
    "    (\"h3\", \"三级标题\"),\n",
    "]\n",
    "\n",
    "# 2.创建分割器并分割\n",
    "text_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "chunks = text_splitter.split_text(html_string)\n",
    "\n",
    "# 3.输出分割内容\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.递归JSON分割器示例.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/2 21:56\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 3.递归JSON分割器示例.py\n",
    "\"\"\"\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "# 1.获取并加载json\n",
    "url = \"https://api.smith.langchain.com/openapi.json\"\n",
    "json_data = requests.get(url).json()\n",
    "print(len(json.dumps(json_data)))\n",
    "\n",
    "# 2.递归JSON分割器\n",
    "text_splitter = RecursiveJsonSplitter(max_chunk_size=300)\n",
    "\n",
    "# 3.分割json数据并创建文档\n",
    "json_chunks = text_splitter.split_json(json_data)\n",
    "chunks = text_splitter.create_documents(json_chunks)\n",
    "\n",
    "# 4.输出内容\n",
    "count = 0\n",
    "for chunk in chunks:\n",
    "    count += len(chunk.page_content)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.基于标记的分割器.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/2 22:13\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 4.基于标记的分割器.py\n",
    "\"\"\"\n",
    "import tiktoken\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def calculate_token_count(query: str) -> int:\n",
    "    \"\"\"计算传入文本的token数\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
    "    return len(encoding.encode(query))\n",
    "\n",
    "\n",
    "# 1.定义加载器和文本分割器\n",
    "loader = UnstructuredFileLoader(\"./科幻短篇.txt\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \"。|！|？\",\n",
    "        \"\\.\\s|\\!\\s|\\?\\s\",  # 英文标点符号后面通常需要加空格\n",
    "        \"；|;\\s\",\n",
    "        \"，|,\\s\",\n",
    "        \" \",\n",
    "        \"\"\n",
    "    ],\n",
    "    is_separator_regex=True,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=calculate_token_count,\n",
    ")\n",
    "\n",
    "# 2.加载文档并执行分割\n",
    "documents = loader.load()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3.循环打印分块内容\n",
    "for chunk in chunks:\n",
    "    print(f\"块大小: {len(chunk.page_content)}, 元数据: {chunk.metadata}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
