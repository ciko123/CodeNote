{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.带阈值的相似性搜索.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/3 17:06\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 1.带阈值的相似性搜索.py\n",
    "\"\"\"\n",
    "import dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"笨笨是一只很喜欢睡觉的猫咪\", metadata={\"page\": 1}),\n",
    "    Document(page_content=\"我喜欢在夜晚听音乐，这让我感到放松。\", metadata={\"page\": 2}),\n",
    "    Document(page_content=\"猫咪在窗台上打盹，看起来非常可爱。\", metadata={\"page\": 3}),\n",
    "    Document(page_content=\"学习新技能是每个人都应该追求的目标。\", metadata={\"page\": 4}),\n",
    "    Document(page_content=\"我最喜欢的食物是意大利面，尤其是番茄酱的那种。\", metadata={\"page\": 5}),\n",
    "    Document(page_content=\"昨晚我做了一个奇怪的梦，梦见自己在太空飞行。\", metadata={\"page\": 6}),\n",
    "    Document(page_content=\"我的手机突然关机了，让我有些焦虑。\", metadata={\"page\": 7}),\n",
    "    Document(page_content=\"阅读是我每天都会做的事情，我觉得很充实。\", metadata={\"page\": 8}),\n",
    "    Document(page_content=\"他们一起计划了一次周末的野餐，希望天气能好。\", metadata={\"page\": 9}),\n",
    "    Document(page_content=\"我的狗喜欢追逐球，看起来非常开心。\", metadata={\"page\": 10}),\n",
    "]\n",
    "db = FAISS.from_documents(documents, embedding)\n",
    "\n",
    "print(db.similarity_search_with_relevance_scores(\"我养了一只猫，叫笨笨\", score_threshold=0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.as_retriever检索器示例.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/4 8:06\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 3.最大边际相关性示例.py\n",
    "\"\"\"\n",
    "import dotenv\n",
    "import weaviate\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from weaviate.auth import AuthApiKey\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.构建加载器与分割器\n",
    "loader = UnstructuredMarkdownLoader(\"./项目API文档.md\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。|！|？\", \"\\.\\s|\\!\\s|\\?\\s\", \"；|;\\s\", \"，|,\\s\", \" \", \"\", ],\n",
    "    is_separator_regex=True,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "# 2.加载文档并分割\n",
    "documents = loader.load()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3.将数据存储到向量数据库\n",
    "db = WeaviateVectorStore(\n",
    "    client=weaviate.connect_to_wcs(\n",
    "        cluster_url=\"https://eftofnujtxqcsa0sn272jw.c0.us-west3.gcp.weaviate.cloud\",\n",
    "        auth_credentials=AuthApiKey(\"21pzYy0orl2dxH9xCoZG1O2b0euDeKJNEbB0\"),\n",
    "    ),\n",
    "    index_name=\"DatasetDemo\",\n",
    "    text_key=\"text\",\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "db.add_documents(chunks)\n",
    "\n",
    "# 4.转换检索器（带阈值的相似性搜索，数据为10条，得分阈值为0.5）\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 10, \"score_threshold\": 0.5},\n",
    ")\n",
    "\n",
    "# 5.检索结果\n",
    "documents = retriever.invoke(\"关于配置接口的信息有哪些\")\n",
    "\n",
    "print(list(document.page_content[:50] for document in documents))\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.最大边际相关性示例.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 2024/7/4 8:06\n",
    "@Author  : thezehui@gmail.com\n",
    "@File    : 3.最大边际相关性示例.py\n",
    "\"\"\"\n",
    "import dotenv\n",
    "import weaviate\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from weaviate.auth import AuthApiKey\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1.构建加载器与分割器\n",
    "loader = UnstructuredMarkdownLoader(\"./项目API文档.md\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。|！|？\", \"\\.\\s|\\!\\s|\\?\\s\", \"；|;\\s\", \"，|,\\s\", \" \", \"\", ],\n",
    "    is_separator_regex=True,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "# 2.加载文档并分割\n",
    "documents = loader.load()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3.将数据存储到向量数据库\n",
    "db = WeaviateVectorStore(\n",
    "    client=weaviate.connect_to_wcs(\n",
    "        cluster_url=\"https://eftofnujtxqcsa0sn272jw.c0.us-west3.gcp.weaviate.cloud\",\n",
    "        auth_credentials=AuthApiKey(\"21pzYy0orl2dxH9xCoZG1O2b0euDeKJNEbB0\"),\n",
    "    ),\n",
    "    index_name=\"DatasetDemo\",\n",
    "    text_key=\"text\",\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# 4.执行最大边际相关性搜索\n",
    "# search_documents = db.similarity_search(\"关于应用配置的接口有哪些？\")\n",
    "search_documents = db.max_marginal_relevance_search(\"关于应用配置的接口有哪些？\")\n",
    "\n",
    "# 5.打印搜索的结果\n",
    "# print(list(document.page_content[:100] for document in search_documents))\n",
    "for document in search_documents:\n",
    "    print(document.page_content[:100])\n",
    "    print(\"===========\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
